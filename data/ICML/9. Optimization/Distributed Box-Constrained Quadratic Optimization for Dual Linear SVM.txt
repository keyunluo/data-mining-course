Distributed Box-Constrained Quadratic Optimization for Dual Linear SVM

Ching-pei Lee
LEECHINGPEI @ GMAIL . COM
Dan Roth
DANR @ ILLINOIS . EDU
University of Illinois at Urbana-Champaign, 201 N. Goodwin Avenue, Urbana, IL 61801 USA

Abstract

where C > 0 is a specified parameter, and ξ is a loss function. Two common choices of ξ are

Training machine learning models sometimes
needs to be done on large amounts of data that
exceed the capacity of a single machine, motivating recent works on developing algorithms that
train in a distributed fashion. This paper proposes an efficient box-constrained quadratic optimization algorithm for distributedly training linear support vector machines (SVMs) with large
data. Our key technical contribution is an analytical solution to the problem of computing the
optimal step size at each iteration, using an efficient method that requires only O(1) communication cost to ensure fast convergence. With
this optimal step size, our approach is superior to
other methods by possessing global linear convergence, or, equivalently, O(log(1/)) iteration
complexity for an -accurate solution, for distributedly solving the non-strongly-convex linear
SVM dual problem. Experiments also show that
our method is significantly faster than state-ofthe-art distributed linear SVM algorithms including DSVM-AVE, DisDCA and TRON.

max(0, 1 − yi wT xi ), and max(0, 1 − yi wT xi )2 ,
which we refer to as L1-SVM and L2-SVM, respectively.
Linear SVM has been used in many applications, and its
single-machine training has been studied extensively. It is
well-known that instead of directly solving (1), optimizing
its dual problem shown below is sometimes faster (Hsieh
et al., 2008; Yuan et al., 2012), especially when l < n,
because there are fewer variables to optimize.
1 T
α Q̄α − eT α
2
subject to 0 ≤ αi ≤ U, i = 1, . . . , l,
min

α∈Rl

With the rapid growth of data volume, distributed machine
learning gains more importance as a way to address training with massive data sets that could not fit the capacity of
a single machine. Linear support vector machine (SVM)
(Boser et al., 1992; Vapnik, 1995) is a widely adopted
model for large-scale linear classification. Given training instances {(xi , yi ) ∈ Rn × {−1, 1}}li=1 , linear SVM
solves the following problem:
l

w∈R

f P (w) ≡

X
1 T
w w+C
ξ(w, xi ; yi ),
2
i=1

(2)

where e is the vector of ones, Q̄ = Q + sI, Q =
Y X(Y X)T , X = [x1 , . . . , xl ]T , Y is a diagonal matrix
such that Yi,i = yi , I is the identity matrix, and
(
(0, C)
if L1-SVM,
(s, U ) =
(1/2C, ∞) if L2-SVM.

1. Introduction

minn

f (α) ≡

(1)

Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

Because the main computations in batch solvers for (1)
are matrix-vector products that can be naively parallelized,
several works have successfully adapted these solvers to
distributed environments (Agarwal et al., 2014; Zhang
et al., 2012; Zhuang et al., 2015; Lin et al., 2014). However, state-of-the-art single-machine dual algorithms are all
sequential and cannot be easily parallelized. Moreover, in
a distributed setting, because each machine only has a fraction of the training data, and the cost of communication
and synchronization is relatively high, it is important to
consider algorithms with low communication cost. Consequently, algorithms with a faster convergence rate are
desirable because a smaller number of iterations implies
a smaller number of communication rounds. We observe
that without careful consideration of this issue, existing
distributed dual solvers do not achieve satisfactory training speed. However, as mentioned above, given that a dual
solver might be more suitable for high-dimensional data, it

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

is important to develop better distributed dual linear SVM
algorithms for extremely large data sets of high dimensionality.
In this work, we propose an efficient box-constrained
quadratic optimization framework for solving (2) when
the training instances are distributed among K machines,
where the instances in machine k are {(xi , yi )}i∈Jk . In
our setting, Jk are disjoint index sets such that ∪K
k=1 Jk =
{1, . . . , l}. By considering a carefully designed positive
definite block-diagonal approximation of Q̄, at each iteration our algorithm efficiently obtains a descent direction
that ensures fast convergence for (2) with low communication cost. We then conduct a line search method that only
requires negligible computation cost and O(1) communication to establish a global linear convergence rate. In other
words, our algorithm only requires O(log(1/)) iterations
to obtain an -accurate solution for (2). This convergence
rate is better than that of existing distributed dual solvers
for training L1-SVM, whose dual problem is not strongly
convex. We also discuss the main differences between our
algorithm and existing distributed algorithms for (2) and
point out the key differences.

model evaluation at each iteration, we transform the current
αt to a primal solution by the KKT condition of (1).
w t = X T Y αt .
At the t-th iteration, we update the current αt by
αt+1 = αt + ηt ∆αt ,

This paper is organized as follows. Our algorithm and its
convergence analysis are described in Section 2. Section 3
discusses related works. We present experimental results in
Section 4. Section 5 concludes this work.

2. Distributed Box-Constrained Quadratic
Optimization
Before discussing our method, we summarize notations frequently used in this paper. π(i) = k indicates that i ∈ Jk .
We will frequently use the following notation.
P(α) ≡ [−α1 , U − α1 ] × · · · × [−αl , U − αl ].
We denote kuk2A ≡ uT Au for u ∈ Rt , and A ∈ Rt×t ,
where t is a positive integer. For any v ∈ Rl , v Jk denotes the sub-vector of v that contains the coordinates in
Jk . Similarly, P(α)Jk is the constraint subset of P(α) that
only has the coordinates indexed by Jk . For A ∈ Rl×l ,
AJk ,Jm ∈ R|Jk |×|Jm | denotes the sub-matrix of A corresponding to the entries Ai,j with i ∈ Jk , j ∈ Jm . If
Jk = Jm , we simplify it to AJk . We denote by XJk the
sub-matrix of X containing the instances in Jk , and, similarly YJk is the corresponding sub-diagonal matrix of Y .
2.1. Algorithm
Our algorithm starts with a feasible point α0 for (2) and
iteratively generates a sequence of solutions {αt }∞
t=0 . For

(4)

where ηt ∈ R is the step size and ∆αt ∈ Rl is the update direction. We first describe our method for computing
∆αt , and then present two efficient methods for calculating a good ηt for ∆αt .
Computing the Update Direction: In a distributed environment, usually communication and synchronization are
expensive. Therefore, in order to reduce the training time,
we should consider high-order optimization methods that
require fewer iterations to converge. Therefore, we try
to obtain a good ∆αt by solving the following quadratic
problem that approximates (2).
∆αt ≡ arg min
d∈P(αt )

Experiments show that our algorithm is significantly faster
than existing distributed solvers for (2). Our framework can
be easily extended to solve other similar problems.

(3)

1
∇f (αt )T d + dT Hd,
2

(5)

where H is an approximation of Q̄. Because machine k
only has access to those instances in Jk , it is natural to
consider the following H to avoid frequent communication.
(
τ
H = Q̃ + (s + τ̃ )I, where τ̃ =
0

if L1-SVM,
if L2-SVM,

(6)

τ > 0 is a small value to ensure positive definiteness, and
(
Qi,j if π(i) = π(j),
Q̃i,j =
0
otherwise.
After re-indexing the instances, we observe that the choice
of H in (6) is a symmetric, block-diagonal matrix with K
blocks, where the k-th block is
HJk = YJk XJk (YJk XJk )T + (s + τ̃ )I.
Because H is block-diagonal, (5) can be decomposed into
the following independent sub-problems for k = 1, . . . , K.

∆αtJk =

arg min
dJk ∈P(αt )Jk

1
∇f (αt )TJk dJk + kdJk k2HJ . (7)
k
2

If wt is available to all machines, both HJk and
∇f (αt )Jk = YJk XJk wt + sαtJk − e

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

can be obtained using only instances in machine k. Thus
the only communication required in this procedure is making wt available to all machines. We see that obtaining wt
requires gathering information from all machines.
wt =

K
M

XJTk YJk αtJk .

(8)

k=1

L
The symbol
represents the operation of receiving the
information from all machines and broadcasting the results
back to all machines. In practice, this can be achieved by
the allreduce operation in MPI.
With the availability of wt , (7) is in the same form
as (2), with Q̄, e, and P(0) being replaced by Q̄Jk +
τ̃ I, ∇f (αt )Jk , and P(αt )Jk , respectively. Therefore, the
smaller per machine problem can be solved by any existing
single machine dual linear SVM optimization methods. We
will discuss this issue in Section 2.3.

which implies
1
2
(log
log β
k∆αt k2Q̄


T
+ log (σ − 1) ∇f αt ∆αt + σγk∆αt k2H )e. (12)

ηt = min(β 0 , β k̄ ), where k̄ ≡ d

We can obtain k∆αt k2H , k∆αt k2Q̄ , and ∇f (αt )T ∆αt by
k∆αt k2H =

K
M

(kXJTk YJk ∆αtJk k2 ) + (s + τ̃ )

k=1

K
M
(k∆αJk k2 ),
k=1

(13)
k∆αt k2Q̄ = k

K
M

K
M
XJTk YJk ∆αtJk k2 + s
(k∆αJk k2 ), (14)

k=1

k=1

and
∇f (αt )T ∆αt = (wt )T (

K
M

XJTk YJk ∆αtJk )

(15)

k=1

After ∆αt is computed, we need to calculate the step size
ηt to ensure sufficient function decrease. We discuss two
methods to obtain a good ηt . The first approach gives an
approximate solution while the second one computes the
optimal step size. Note that these methods can be applied to
any descent direction, and are not restricted to the direction
obtained by the above method.
Approximate approach for step size: We first consider
backtracking line search with the Armijo rule described in
Tseng & Yun (2009). Given the direction ∆αt , and the parameters σ, β ∈ (0, 1), γ ∈ [0, 1), the Armijo rule assigns
ηt to be the largest element in {β k }∞
k=0 that satisfies
f (αt + β k ∆αt ) − f (αt ) ≤ β k σ∆t ,

+s

K
M

(αtJk )T ∆αtJk −

k=1

eT ∆αtJk .

k=1

To reduce the communication cost, we replace (8) with
wt = wt−1 + ηt ∆wt−1 ,
where
∆wt ≡

K
M

XJTk YJk ∆αtJk .

(16)

(17)

k=1

Thus obtaining wt still has the same communication cost,
but (14) and (15) can respectively be simplified to

(9)
k∆αt k2Q̄ = k∆wt k2 + s

where

K
M

K
M

k(∆αtJk )k2 ,

(18)

k=1

∆t ≡ ∇f (αt )T ∆αt + γk∆αt k2H .

(10)

To obtain the desired β k , a naive approach sequentially
tries k = 0, 1, . . . , and goes through the whole training data
to recompute f (αt + β k ∆αt ) for each k until (9) is satisfied. This approach is expensive because we do not know
ahead of time what value of k satisfies (9). If the direction
is not chosen carefully, it is likely that this approach will be
very time-consuming. To deal with this problem, observe
that, because f is a quadratic function with Hessian Q̄,
f (αt + β k ∆αt )
=f (αt ) + β k ∇f (αt )T ∆αt +

β 2k
k∆αt k2Q̄ .
2

(11)

Hence (9) can be simplified to
βk
k∆αt k2Q̄ ≤ (σ − 1)∇f (αt )T ∆αt + σγk∆αt k2H ,
2

∇f (αt )T ∆αt = (wt )T ∆wt + s

K
M

(αtJk )T ∆αtJk

k=1

−

K
M

eT ∆αtJk .

(19)

k=1

L
Thus, the two size-n allreduce of (8) and
XJk YJk ∆αtJk
required in (15) can be achieved using only one size-n
allreduce. When ∆wt is available, obtaining (18)-(19) and
(13) requires only O(l + n) computation and O(1) additional communication. This additional O(l + n) computation is negligible in comparison with the O(ln) cost of
solving (5), and the new communication can be combined
into the allreduce operation for ∆wt by augmenting the
vector being communicated. With this method, backtracking line search can be done very efficiently.
Exact solution of the best step size: By substituting β k
with ηt in (11), we observe that f (αt + ηt ∆αt ) is a

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

quadratic convex function of ηt . Therefore, we can obtain
ηt∗ that minimizes f (αt + ηt ∆αt ) by
∂f (αt + ηt ∆αt )
−∇f (αt )T ∆αt
= 0 ⇒ ηt∗ =
. (20)
∂ηt
(∆αt )T Q̄∆α
Using (14) and (19), the computation of (20) has identical cost to the approximate approach. However, unlike
the previous method that guarantees ηt ≤ 1 and thus
ηt ∆αt ∈ P(αt ), it is possible that ηt∗ > 1 in (20). In
this case, αt + ηt∗ ∆αt may not be a feasible point for (2).
To avoid the infeasibility, we consider

t
t

if ∆αit < 0,
−αi /∆αi
λi = (U − αit )/(∆αit ) if ∆αit > 0,


∞
if ∆αit = 0.

Algorithm 1 A box-constrained quadratic optimization algorithm for distributedly solving (2)
1. t ← 0, given α0 , computes w0 by (8).
2. While αt is not optimal:
2.1. Obtain ∆αt by distributedly solving (7) on K
machines in parallel.
LK
2.2. Compute ∆wt = k=1 XJTk YJk ∆αtJk .
LK
2.3. Compute (αt )T ∆αt , eT ∆αt , k=1 k∆αtJk k2 ,
LK
T
t
2
k=1 kXJk YJk ∆αJk k by allreduce.
2.4. Obtain ηt by (12) or (21).
2.5. αt+1 ← αt + ηt ∆αt , wt+1 ← wt + ηt ∆wt .
2.6. t ← t + 1.
Proof: 0 ≤ αt ≤ U e indicates ∆αt = 0 is feasible for
(5). Because f (α) is convex, αt is optimal if and only if

and let
ηt = min(ηt∗ , min λi ).
1≤i≤l

∇f (αt )T d ≥ 0, ∀d ∈ P(αt ).

(21)

We can see from convexity that (21) is the optimal feasible
solution for ηt . The minimum λi over {1, . . . , l} is obtained by an O(1) communication.
In L1-SVM, Q̄ is only positive semidefinite. Therefore,
k∆αt k2Q̄ can be zero for a nonzero ∆αt . But this zero
denominator does not cause any problem in (12) or (21).
We will show in Lemma 2.1 in the next section that
∇f (αt )T ∆αt is negative provided ∆αt 6= 0. Consequently, the last log term of k̄ in (12) is finite. If
(∆αt )T Q̄∆αt = 0, k̄ = −∞ because log β < 0. We
thus have ηt = β 0 = 1 when k∆αt k2Q̄ = 0. In (21),
∇f (αt )∆αt < 0 ensures that ηt∗ > 0, hence when
(∆αt )T Q̄∆αt = 0, ηt∗ is ∞. Because of the min operation in (20) and since U is finite in L1-SVM, ηt is still
finite unless ∆αt = 0. We will show in the next section
that this only happens when αt is optimal.
In summary, our algorithm uses (16)-(17) to synchronize
information between machines, solves (7) to obtain the update direction ∆αt , adopts (12) or (21) to decide the step
size ηt , and then updates αt using (4). A detailed description appears in Algorithm 1. In practice, steps 2.2 and 2.3
can be done in one allreduce operation.
2.2. Convergence Analysis
To establish the convergence of Algorithm (1), we first
show that the direction obtained from (5) is always a descent direction and thus the line search computations in
(12) and (20) do not face the problem of 0/0 or ηt = 0.

(22)

Because H is positive definite, by strong convexity of (5),
(22) holds if and only if for all nonzero d ∈ P(αt ),
1
1
∇f (αt )T d + dT Hd > ∇f (αt )T 0 + 0T H0. (23)
2
2
Now if αt is not optimal, there exists d ∈ P(αt ) such that
(23) does not hold. Thus,
1
∇f (αt )T ∆αt < ∇f (αt )T ∆αt + (∆αt )T H∆αt ≤ 0.
2
That H is positive definite implies the strict inequality.
Lemma 2.1 can also be viewed as an application of Lemmas 1-2 in Tseng & Yun (2009).
The following two theorems show that Algorithm 1 possesses global linear convergence for problem (2). Namely,
for any  > 0, Algorithm 1 requires at most O(log(1/))
iterations to obtain a solution of αt such that
(f (αt ) − f (α∗ )) ≤ ,

(24)

where α∗ is the optimal solution of (2).
Theorem 2.2 Algorithm 1 with the Armijo rule backtracking line search (12) has at least global linear convergence
rate for solving problem (2).
Proof Sketch: If we rewrite problem (2) as
min

α∈Rl

F (α) ≡ f (α) + P (α),

(25)

where
Lemma 2.1 If H is positive definite, then αt is optimal if
and only if ∆αt = 0. Moreover, ∆αt obtained from (5) is
a descent direction for f (αt ) such that ∇f (αt )T ∆αt < 0.

P (α) ≡

l
X
i=1

(
Pi (α),

Pi (α) ≡

0
∞

if 0 ≤ αi ≤ U,
otherwise,

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

then (5) can also be written as
∆αt = arg min
d

1
∇f (αt )T d + kdk2H + P (αt + d).
2

Because we optimize over all instances at each iteration,
our algorithm can be seen as a cyclic block coordinate descent method satisfying the Gauss-Seidel rule with only
one block. For L2-SVM, both Q̄ and H are positive definite. For L1-SVM, Q̄ is only positive semidefinite, but
the τ̃ I term in (6) ensures H is positive definite. Thus Algorithm 1 is a special case of the algorithm in Tseng &
Yun (2009) and satisfies their Assumption 1. Theorem 2 in
Tseng & Yun (2009) then provides local linear convergence
for our algorithm such that for some k0 ≥ 0,
f (αt+1 ) − f (α∗ ) ≤ θ(f (αt ) − f (α∗ )), ∀t ≥ k0 , (26)
where θ < 1 is a constant. This k0 indicates the number
of iterations required to make their local error bound assumption hold. This local error bound has been shown to
hold from the first iteration of the algorithm for both L1SVM (Pang, 1987, Theorem 3.1) and L2-SVM (Wang &
Lin, 2014, Theorem 4.6). This implies k0 = 0. We thus
can obtain from (26) with k0 = 0 the desired O(log(1/))
rate for solving both L1-SVM and L2-SVM.
Alternatively, the same result can also be obtained by combining the analysis in Yun (2014) and Tseng & Yun (2009).
A more detailed proof is shown in the supplementary materials.
Corollary 2.3 Algorithm 1 with exact line search (21) converges at least as fast as Algorithm 1 with the Armijo rule
backtracking line search. Thus, it has at least global linear
convergence rate for solving problem (2).
Proof: Note that the global linear convergence in Theorem
2.2 is obtained by (26) with k0 = 0. If we denote by η̄t the
step size obtained from (12) and take η̂t as the step size
obtained from solving (21), we have from the convexity of
(2) that
f (αt + η̂t ∆αt ) ≤ f (αt + η̄t ∆αt ).
Therefore, (26) still holds because
f (αt+1 ) − f (α∗ ) = f (αt + η̂t ∆αt ) − f (α∗ )
≤f (αt + η̄t ∆αt ) − f (α∗ ) ≤ θ(f (αt ) − f (α∗ )).
2.3. Practical Issues
As mentioned earlier, we can use any existing linear SVM
dual solver to solve (7) locally. In our implementation,
we consider dual coordinate descent methods (Hsieh et al.,
2008; Shalev-Shwartz & Zhang, 2013) that are reported to
work well in single-core training. To ensure (5) is minimized, we can adopt the approach of Hsieh et al. (2008),

which cyclically goes through all training instances several
times until a stopping condition related to sub-optimality is
satisfied. Alternatively, we can also use the stochastic approach in Shalev-Shwartz & Zhang (2013) with enough iterations to have a high probability that the solution is close
enough to the optimum. An advantage of the cyclic approach is that it comes with an easily computable stopping
condition for sub-optimality that can prevent redundant inner iterations. On the other hand, even when each machine
contains the same amount of data, the cyclic method could
not guarantee that each machine will finish optimizing the
sub-problems simultaneously, and hence some machines
might be idle for a long time. We thus consider a setting as
follows. For solving each sub-problem, we use the cyclic
approach, but at each inner iteration1 , we follow the approach in Hsieh et al. (2008); Yu et al. (2012); Chang &
Roth (2011) to randomly shuffle the instance order, to have
faster empirical convergence. We also assimilate the idea
of stochastic solvers to set the number of inner iterations for
solving (5) identical for all machines throughout the whole
training procedure of Algorithm 1 to ensure that each machine stops solving (7) at roughly the same time. This hybrid method assimilates advantages of both approaches.
During the procedure of minimizing the dual problem, it
is possible that a descent direction for the dual problem
might not correspond to a descent direction for the primal
problem if we have not reached a solution that is close
enough to the optimum. This may happen in any algorithms optimizing the dual problem. When (2) is properly optimized, strong duality of SVM problems ensure that
the corresponding primal objective value is also minimized.
However, in case where we need to stop our algorithm before reaching an accurate enough solution, a smaller primal
objective value is desirable. We can easily deal with this
problem by adopting the pocket algorithm for perceptrons
(Gallant, 1990). The idea is to compute the primal function value at each iteration and maintain the wt that has the
smallest primal objective value as the current model. Now
that the primal objective value is available, we can use the
relative duality gap as our stopping condition.
(f P (wt ) − (−f (αt ))) ≤ (f P (0) − (−f (0)))

(27)

Computing the primal function value is expensive in the
single-machine setting, but it is relatively cheap in distributed settings because fewer instances are processed by
each machine, and usually the training cost is dominated
by communication and synchronization.

3. Related Works
Our algorithm is closely related to the methods proposed
by Pechyony et al. (2011); Yang (2013). Even though these
1

Here one inner iteration means passing through the data once.

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

approaches were originally discussed in different ways,
they can be described using our framework. The discussion
that follows indicates that our approach provides better theoretical guarantees than these related approaches.
Pechyony et al. (2011) proposed two methods for solving L1-SVM. The first one, DSVM-AVE, iteratively solves
(5) with H = Q̃ to obtain ∆αt , while ηt is fixed to be
1/K. Its iteration complexity is O(1/) for L1-SVM and
O(log(1/) for L2-SVM (Ma et al., 2015).
The second approach in Pechyony et al. (2011), called
DSVM-LS, conducts line search for ∆αt in the primal
problem. However, line search in the primal objective function is more expensive because it requires passing through
the whole training data to evaluate the function value for
each backtracking conducted. Also, DSVM-LS does not
have convergence guarantee. On the other hand, our approach conducts efficient line searches in the dual problem
with a very low cost. The line search approach in our algorithm is the essential step to guaranteeing global linear
convergence for solving L1-SVM. The multi-core parallel primal coordinate descent method in Bian et al. (2014)
is similar to DSVM-LS in conducting primal line search.
They solve L1-regularized logistic regression problems in
the primal by an approach similar to solving (25) with
a diagonal H and conducting Armijo line search. Their
method has guaranteed convergence and can be adopted to
L2-SVM. However, as mentioned above, line search for the
primal problem is expensive. Also, their method requires
differentiable loss term and is not applicable to L1-SVM.
DisDCA (Yang, 2013) can optimize a class of dual problems including (2). This approach iteratively solves (5)
with a stochastic solver and the step size is fixed to ηt = 1.
Yang (2013) proposed a basic and a practical variant, both
of which use positive semi-definite H. In the basic variant,
H is a diagonal matrix such that Hi,i = mKQi,i , where m
is the number of instances used each time (5) is solved. The
author showed that this variant requires O(log(1/)) iteration complexity to satisfy (27) in expected function values for smooth-loss problems like L2-SVM, and O(1/)
for Lipschitz continuous losses such as L1-SVM. Note that
an -accurate solution for (27) is roughly Cl-accurate for
(24), so to compare the constants for convergence in different algorithms, we need to properly scale . In the practical
variant of DisDCA, H = K Q̃ + sI. Yang et al. (2014)
provides convergence for this variant only under the unrealistic assumption Q̄ = Q̃. Recently, Ma et al. (2015) show
that when L2 regularization is used, for both DSVM-AVE
and the practical variant of DisDCA, the number of iterations required to satisfy (27) in expected function values
are also O(log(1/)) and O(1/) for smooth-loss problems and problems with Lipschitz continuous losses, respectively. A key difference between these results and ours

l
n
#nonzeros
Data set
webspam
280, 000 *16, 609, 143
1, 044, 393, 506
url
1, 916, 904
3, 231, 961
221, 663, 296
400, 000
2, 000
800, 000, 000
epsilon
*: Among the feature dimensions, only 680, 715 coordinates have
nonzero entries, but we still use the original data to examine the
situation that communication cost is extremely high.
Table 1. Data statistics. For webspam and url, test sets are not
available so we randomly split the original data into 80%/20% as
training set and test set, respectively.

is that we only require O(log(1/)) iterations for L1-SVM,
and our result is for deterministic function values, which is
stronger than the expected function values.
Ma et al. (2015) proposed a framework CoCoA+, and this
framework in their experimental setting reduces to the practical variant of DisDCA (Yang, 2013). Their experiments
showed that the DisDCA practical variant is faster than
other existing approaches.
Most other distributed linear SVM algorithms optimize (1).
Primal batch solvers that require computing the full gradient or Hessian-vector products are inherently parallelizable and can be easily extended to distributed environments because the main computations are matrix-vector
products like Xw. Vowpal Wabbit (VW) by Agarwal et al.
(2014) uses a distributed L-BFGS method and outperforms
stochastic gradient approaches. Zhuang et al. (2015); Lin
et al. (2014) propose a distributed trust region Newton
method (TRON) that works well and is faster than VW.
These second-order Newton-type algorithms only work on
differentiable primal problems like L2-SVM, but could not
be applied to L1-SVM. Another popular algorithm for distributedly solving (1) without requiring differentiability is
the alternating direction method of multipliers (ADMM)
(Boyd et al., 2011). Zhang et al. (2012) applied ADMM to
solve linear SVM problems. However, ADMM is known
to converge slowly and these works do not provide convergence rates. Using Fenchel dual, Hazan et al. (2008)
derived an algorithm that is similar to ADMM, and showed
that their algorithm possesses global linear convergence in
their reformulated problem for L1-SVM. However, there
are Kl variables in their problem, and thus the training
speed should be slower. Experiment results in Yang (2013);
Zhuang et al. (2015) also verify that ADMM approaches
are empirically slower than other methods.

4. Experiments
The following algorithms are compared in our experiments.
• DisDCA (Yang, 2013): we consider the practical variant
because it is shown to be faster than the basic variant.
• TRON (Zhuang et al., 2015): this method only works on

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines
L1-SVM solvers
L2-SVM solvers
BQO-E BQO-A DisDCA DSVM-AVE BQO-E BQO-A DisDCA DSVM-AVE TRON
url
0.3 2,162.8 3,566.5 6,624.0
8,277.2
68.1
133.0
248.8
299.0 314.2
0.01
3.4
2.6
3.0
2.8
2.3
5.2
2.8
3.7
6.7
epsilon
webspam 0.01
35.1
29.8
27.4
42.3
16.9
29.6
25.9
40.3 123.7
Data set



Table 2. Training time required for a solver to reach (f P (wt ) − f P (w∗ )) ≤ f P (w∗ ). url uses larger  because of longer training time.
L1-SVM solvers
L2-SVM solvers
BQO-E BQO-A DisDCA DSVM-AVE BQO-E BQO-A DisDCA DSVM-AVE
url
0.04 1,092.9 1,801.2 3,524.2
4,343.4 1,328.6 2,201.1 4,251.2
5,126.6
0.01
2.8
3.9
8.0
13.2
6.3
10.9
24.4
28.1
epsilon
webspam 0.01
21.7
30.6
54.7
79.5
19.8
30.3
54.3
84.9
Data set



Table 3. Training time required for a solver to reach (f (α∗ ) − f (αt )) ≤ f (α∗ ). url uses larger  because of longer training time.

L2-SVM. We use the package MPI-LIBLINEAR 1.96.2
• DSVM-AVE (Pechyony et al., 2011).
• BQO-E: our box-constrained quadratic optimization algorithm with exact line search.
• BQO-A: our algorithm with Armijo line search. We follow Tseng & Yun (2009) to use β = 0.5, σ = 0.1, γ = 0.
In order to have a fair comparison between algorithms,
all methods are implemented using the MPI-LIBLINEAR
structure to prevent training time differences resulting from
different implementations. Note that the recent work Ma
et al. (2015) uses the same algorithm as DisDCA so our
comparison already includes it.
In BQO-E and BQO-A, τ = 0.001 is used. All methods are implemented in C++/MPI. ADMM is excluded because DisDCA is reported to outperform it, and its speed
is dependent on additional parameters. The code used in
the experiments is available at http://github.com/
leepei/distcd_exp/.
We compare different dual algorithms in terms of the relative dual objective function value.

|(f (αt ) − f (α∗ ))/f (α∗ )|,

(28)

α∗ is obtained approximately by running our method with
a strict stopping condition. To have a fair comparison with
TRON which solves the primal problem, we also report
the relative primal objective function values and the accuracies relative to the accuracy at the optimum. The pocket
approach discussed in Section 2.3 is adopted in all dual algorithms.

(a) L1-SVM: url

(b) L2-SVM: url

(c) L1-SVM: webspam

(d) L2-SVM: webspam

Figure 1. Time versus relative dual objective value (28).

The statistics of the data sets in our experiments are shown
in Table 1. All of them are publicly available.3 Instances
are split across machines in a uniform random fashion. We
fix C = 1 in all experiments for a fair comparison in optimization. Therefore, some algorithms may have accuracies
exceeding that of the optimal solution because the best C is
not chosen. We note, though, that once parameter selection
is conducted, the method that decreases the function value
faster should also achieve the best accuracy faster.

We use 16 nodes in a cluster. Each node has two Intel HP
X5650 2.66GHZ 6C Processors, and one core per node is
used. The MPI environment is MPICH2 (Gropp, 2002).

Since this work aims at a framework that can accommodate any local solvers, we use the same local solver setting for DisDCA, DSVM-AVE and our algorithm. In particular, at each time of solving (5), we randomly shuffle
the instance order, and then let each machine pass through
all local instances once. The training time could be improved for high-dimensional data if we use more inner iterations, but our setting provides a fair comparison by having
computation-communication ratios similar to TRON.

2
Downloaded from http://www.csie.ntu.edu.tw/
cjlin/libsvmtools/distributed-liblinear/.
˜

http://www.csie.ntu.edu.tw/˜cjlin/
libsvmtools/datasets.

3

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

(a) L1-SVM: url

(b) L2-SVM: url

(a) epsilon

(b) webspam

Figure 4. Training time (I/O time excluded) of L2-SVM using different numbers of machines.

(c) L1-SVM: webspam

(d) L2-SVM: webspam

Figure 2. Time versus relative accuracy.
Training Time

(a) epsilon

(b) webspam

Training Time + IO Time

(c) epsilon

(d) webspam

Figure 3. Speedup of training L2-SVM. Top: training time. Bottom: total running time including training and data loading time.

Tables 2-3 show the results of the primal and dual objective,
respectively. More detailed examination of dual objective
and relative accuracies are in Figures 1-2. Due to space
limit, we only present results on two data sets. More results
are discussed in the supplement. In most cases, BQO-E
reduces the primal objective the fastest. Moreover, BQO-E
always reduces the dual objective significantly faster than
other solvers and almost always reaches stable accuracies
the earliest. Because BQO-A is inferior to BQO-E in most
cases, it is excluded from later comparisons.
We then examine the speedup of solving L2-SVM using
different numbers of machines. In this comparison, we use
the two largest data sets webspam and epsilon that represent the cases l  n and n  l respectively. The results
are in Figure 3. We present both training time speedup and
total running time speedup. In both data sets, the training

time speedup of our algorithm is worse than TRON but
better than other methods. But BQO-E has significantly
better speedup of overall running time when the I/O time
is included. A further investigation of the training time and
data loading time in Figure 4 shows that this running time
speedup of BQO-E results from the fact that BQO-E has
shorter training time in all cases. Thus, the data loading
time is the bottleneck of the running time in BQO-E, and
decreasing the data loading time can significantly improve
the running time, even if its training time does not improve
much with more machines.
From the results above, our method is significantly faster
than the state-of-the-art primal solver TRON and all existing distributed dual linear SVM algorithms.
Note that the comparison between DSVM-AVE and
DisDCA accords the results in the results in Ma et al.
(2015) that when smaller λ (equivalent to larger weight on
the loss term) is used, the difference between the two algorithms is less significant. This can also be verified by the result on the url data set that has larger l and thus a larger loss
term with a fixed C, which is also equivalent to a λ smaller
than that being considered in Ma et al. (2015). Additional
experiments in the supplement show that for smaller C, the
differences are significant and DisDCA is superior. But in
these cases, most algorithms finish training in a very short
time and thus the setting of smaller C does not provide
meaningful comparisons.

5. Conclusions
In this paper, we present an efficient method for distributedly solving linear SVM dual problems. Our algorithm is
shown to have better theoretical convergence rate and faster
empirical training time than state-of-the-art algorithms. We
plan to extend this work to problems like structured SVM
(Tsochantaridis et al., 2005) where optimizing the primal
problem is difficult. Based on this work, we have extended the package MPI-LIBLINEAR (after version 1.96)
at
http://www.csie.ntu.edu.tw/˜cjlin/
libsvmtools/distributed-liblinear/
to
include the proposed implementation.

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

Acknowledgment
This material is based on research sponsored by DARPA
under agreement number FA8750-13-2-0008. The U.S.
Government is authorized to reproduce and distribute
reprints for Governmental purposes notwithstanding any
copyright notation thereon. The views and conclusions
contained herein are those of the authors and should not be
interpreted as necessarily representing the official policies
or endorsements, either expressed or implied, of DARPA
or the U.S. Government.
The authors thank the Illinois Campus Cluster Program for
providing computing resources required to conduct experiments in this work. We also thank the anonymous reviewers for their comments, and thank Eric Horn for proofreading the paper. Ching-Pei Lee thanks Po-Wei Wang
for fruitful discussion and great help, thanks Chih-Jen Lin,
Hsiang-Fu Yu, and Hsuan-Tien Lin for their valuable suggestions, thanks Martin Jaggi for the pointer to the convergence proof of the practical variant of DisDCA, and thanks
Tianbao Yang for discussion on DisDCA.

References
Agarwal, Alekh, Chapelle, Olivier, Dudik, Miroslav, and
Langford, John. A reliable effective terascale linear
learning system. Journal of Machine Learning Research,
15:1111–1133, 2014.
Bian, Yatao, Li, Xiong, and Liu, Yuncai. Parallel coordinate descent Newton for large-scale L1-regularized minimization. Technical report, 2014. arXiv:1306.4080v3.
Boser, Bernhard E., Guyon, Isabelle, and Vapnik, Vladimir.
A training algorithm for optimal margin classifiers. In
Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pp. 144–152. ACM Press, 1992.
Boyd, Stephen, Parikh, Neal, Chu, Eric, Peleato, Borja, and
Eckstein, Jonathan. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning,
3(1):1–122, 2011.

Hazan, Tamir, Man, Amit, and Shashua, Amnon. A parallel decomposition solver for SVM: Distributed dual ascend using Fenchel duality. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 1–8. IEEE, 2008.
Hsieh, Cho-Jui, Chang, Kai-Wei, Lin, Chih-Jen, Keerthi,
S. Sathiya, and Sundararajan, Sellamanickam. A dual
coordinate descent method for large-scale linear SVM.
In Proceedings of the Twenty Fifth International Conference on Machine Learning (ICML), 2008.
Lin, Chieh-Yen, Tsai, Cheng-Hao, pei Lee, Ching, and Lin,
Chih-Jen. Large-scale logistic regression and linear support vector machines using Spark. In Proceedings of the
IEEE International Conference on Big Data, pp. 519–
528, 2014.
Ma, Chenxin, Smith, Virginia, Jaggi, Martin, Jordan,
Michael I, Richtárik, Peter, and Takáč, Martin. Adding
vs. averaging in distributed primal-dual optimization. In
Proceedings of the 32nd International Conference on
Machine Learning (ICML), 2015.
Pang, Jong-Shi. A posteriori error bounds for the linearlyconstrained variational inequality problem. Mathematics
of Operations Research, 12(3):474–484, 1987.
Pechyony, Dmitry, Shen, Libin, and Jones, Rosie. Solving
large scale linear SVM with distributed block minimization. In Neural Information Processing Systems Workshop on Big Learning: Algorithms, Systems, and Tools
for Learning at Scale, 2011.
Shalev-Shwartz, Shai and Zhang, Tong. Stochastic dual coordinate ascent methods for regularized loss minimization. Journal of Machine Learning Research, 14:567–
599, 2013.
Tseng, Paul and Yun, Sangwoon. A coordinate gradient
descent method for nonsmooth separable minimization.
Mathematical Programming, 117:387–423, 2009.

Chang, Kai-Wei and Roth, Dan. Selective block minimization for faster convergence of limited memory largescale linear models. In Proceedings of the Seventeenth
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, 2011.

Tsochantaridis, Ioannis, Joachims, Thorsten, Hofmann,
Thomas, and Altun, Yasemin. Large margin methods for
structured and interdependent output variables. Journal
of Machine Learning Research, 6:1453–1484, 2005.

Gallant, Stephen I. Perceptron-based learning algorithms.
Neural Networks, IEEE Transactions on, 1(2):179–191,
1990.

Vapnik, Vladimir. The Nature of Statistical Learning Theory. Springer-Verlag, New York, NY, 1995.

Gropp, William. MPICH2: A new start for MPI implementations. In Recent Advances in Parallel Virtual Machine
and Message Passing Interface, pp. 7–7. Springer, 2002.

Wang, Po-Wei and Lin, Chih-Jen. Iteration complexity
of feasible descent methods for convex optimization.
Journal of Machine Learning Research, 15:1523–1548,
2014.

Distributed Box-Constrained Quadratic Optimization for Dual Linear Support Vector Machines

Yang, Tianbao. Trading computation for communication:
Distributed stochastic dual coordinate ascent. In Advances in Neural Information Processing Systems 26, pp.
629–637, 2013.
Yang, Tianbao, Zhu, Shenghuo, Jin, Rong, and Lin, Yuanqing. On theoretical analysis of distributed stochastic
dual coordinate ascent. Technical report, 2014. arXiv
preprint arXiv:1312.1031.
Yu, Hsiang-Fu, Hsieh, Cho-Jui, Chang, Kai-Wei, and Lin,
Chih-Jen. Large linear classification when data cannot fit
in memory. ACM Transactions on Knowledge Discovery
from Data, 5(4):23:1–23:23, February 2012.
Yuan, Guo-Xun, Ho, Chia-Hua, and Lin, Chih-Jen. Recent
advances of large-scale linear classification. Proceedings
of the IEEE, 100(9):2584–2603, 2012.
Yun, Sangwoon. On the iteration complexity of cyclic coordinate gradient descent methods. SIAM Journal on Optimization, 24(3):1567–1580, 2014.
Zhang, Caoxie, Lee, Honglak, and Shin, Kang G. Efficient
distributed linear classification algorithms via the alternating direction method of multipliers. In Proceedings
of the 15th International Conference on Artificial Intelligence and Statistics, 2012.
Zhuang, Yong, Chin, Wei-Sheng, Juan, Yu-Chin, and Lin,
Chih-Jen. Distributed Newton method for regularized
logistic regression. In Proceedings of The Pacific-Asia
Conference on Knowledge Discovery and Data Mining
(PAKDD), 2015.

