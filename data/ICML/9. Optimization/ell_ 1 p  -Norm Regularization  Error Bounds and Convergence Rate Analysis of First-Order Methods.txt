`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of
First-Order Methods
Zirui Zhou
Qi Zhang
Anthony Man-Cho So
Department of Systems Engineering and Engineering Management,
The Chinese University of Hong Kong, Shatin, N.T., Hong Kong S.A.R., China

Abstract
In recent years, the `1,p -regularizer has been
widely used to induce structured sparsity in the
solutions to various optimization problems. Currently, such `1,p -regularized problems are typically solved by first-order methods. Motivated
by the desire to analyze the convergence rates of
these methods, we show that for a large class of
`1,p -regularized problems, an error bound condition is satisfied when p âˆˆ [1, 2] or p = âˆ but
fails to hold for any p âˆˆ (2, âˆ). Based on this
result, we show that many first-order methods
enjoy an asymptotic linear rate of convergence
when applied to `1,p -regularized linear or logistic regression with p âˆˆ [1, 2] or p = âˆ. By
contrast, numerical experiments suggest that for
the same class of problems with p âˆˆ (2, âˆ), the
aforementioned methods may not converge linearly.

1. Introduction
Optimization with sparsity-inducing penalties has received
increasing attention in various application domains such
as machine learning, statistics, computational biology, and
signal processing (Bach et al., 2012). As the convex envelope of `0 -norm, the `1 -norm has been widely used as a regularizer in sparse variable selection, such as LASSO (Tibshirani, 1996). Recently, `1 -regularization has been extended to Group-Lasso regularization (Yuan & Lin, 2006;
Bach, 2008; Meier et al., 2008), and more generally, to `1,p regularization with 1 â‰¤ p â‰¤ âˆ (Fornasier & Rauhut, 2008;
Kowalski, 2009; Vogt & Roth, 2012). Such extensions have
been applied to sparse regression (Eldar et al., 2010), multiple kernel learning (Tomioka & Suzuki, 2010; Kloft et al.,
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

ZRZHOU @ SE . CUHK . EDU . HK
QZHANG @ SE . CUHK . EDU . HK
MANCHOSO @ SE . CUHK . EDU . HK

2011), etc., and have witnessed great success in yielding
sparsity on the group level when p > 1. In these applications, one is interested in solving a convex optimization
problem of the form
min F (x) := f (x) + P (x).

xâˆˆRn

(1)

Here, f : Rn â†’ R is a smooth convex function and P :
Rn â†’ R takes the form
X
P (x) =
Ï‰J kxJ kp ,
JâˆˆJ

where J is a non-overlapping partition of the coordinate
index set {1, 2, . . . , n}, Ï‰J > 0 for each J âˆˆ J , and
kÂ·kp is the `p -norm. Note that `1 -regularization and GroupLasso regularization are special cases of (1), as they correspond to p = 1 and p = 2, respectively. Additionally,
`p -regularization is also incorporated when no partition is
made.
To cope with the rapidly growing size of datasets, recent researches on numerical algorithms for solving non-smooth
composite minimization problems such as (1) have chiefly
been focusing on first-order methods, such as the proximal gradient method and its accelerated version (Beck &
Teboulle, 2009), the coordinate descent method (Tseng,
2001), and the coordinate gradient descent method (Tseng
& Yun, 2009). Since then, adaptations of these methods
to the `1,p -regularized problem (1) have been proposed
in (Meier et al., 2008; Liu et al., 2009; Liu & Ye, 2010).
To study the efficiency of these iterative algorithms, one
approach is to analyze the rates at which the iterates generated by the algorithms converge to an optimal solution. Existing results in this line of research reveal that for smooth
convex functions f , the aforementioned first-order methods
for solving the `1,p -regularized problem (1) converge at a
sublinear rate, and a linear rate is achievable when f is additionally assumed to be strongly convex (Nesterov, 2004;
Meier et al., 2008; Liu & Ye, 2010). However, for many
applications, the strong convexity assumption is too stringent. Moreover, various first-order methods for solving (1)

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

have exhibited a linear rate of convergence in numerical
experiments even when f is not strongly convexâ€”a case
in point is the proximal gradient method for solving `1 regularized linear regression problems (Hale et al., 2008;
Xiao & Zhang, 2013). It is thus natural to ask whether such
a phenomenon can be explained theoretically, and more
generally, whether certain structures of the functions f and
P can be exploited to establish faster convergence rates for
the aforementioned first-order methods.
To address these questions, a powerful approach is to utilize a so-called error bound (EB) condition (Definition 1),
which can be viewed as a relaxed notion of strong convexity. Indeed, assuming the EB condition holds, various
first-order algorithms have been demonstrated to achieve a
linear rate of convergence (Luo & Tseng, 1993; Hong &
Luo, 2012; So, 2013; Wang & Lin, 2014). Moreover, it has
been shown that the EB condition is satisfied by a number
of optimization problems for which strong convexity fails
to hold, such as linear regression with `1 -regularizer (Luo
& Tseng, 1992). However, verifying whether a given optimization problem satisfies the EB condition remains an
intriguing issue.
In this paper, we consider the `1,p -regularized problem (1)
with p âˆˆ [1, âˆ] and study when the EB condition holds for
this problem. Previous researches show that under some
mild assumptions on the function f (which are satisfied
by many machine learning applications), the EB condition
holds when p âˆˆ {1, 2, âˆ} (Luo & Tseng, 1992; Tseng,
2010; Zhang et al., 2013). However, to the best of our
knowledge, it is not known whether the same is true for
other values of p. In fact, this question does not seem to
be amenable to the techniques developed in (Luo & Tseng,
1992; Tseng, 2010), as they require either the non-smooth
function P to have a polyhedral epigraph, which merely
corresponds to p = 1 and p = âˆ, or an explicit expression of the residual function, which is only available when
p = 1 and p = 2.
The contribution of this paper is twofold. First, by exploiting the notion of upper Lipschitz continuity of set-valued
mappings, we establish a sufficient condition under which
the EB condition holds for problem (1). In fact, our condition only requires the function P to be convex and thus can
potentially be used to certify the EB condition for a wide
range of regularizations. Second, based on our newly developed sufficient condition, we completely determine the
values of p for which the `1,p -regularized problem (1) satisfies the EB condition. Specifically, we show that under
standard assumptions on the smooth convex function f (see
Assumption 1), the EB condition holds when p âˆˆ [1, 2] and
p = âˆ. On the other hand, we show via a family of examples that without further assumptions, the EB condition
can fail for any p âˆˆ (2, âˆ).

As a direct consequence of our results, we show that many
first-order methods, including the proximal gradient algorithm and coordinate gradient descent method, enjoy an
asymptotic linear rate of convergence when applied to `1,p regularized linear or logistic regression with p âˆˆ [1, 2] or
p = âˆ. By contrast, for the same class of problems with
p âˆˆ (2, âˆ), our numerical results suggest that these methods may not converge linearly. Our results not only expand
the repertoire of optimization problems that are known to
satisfy the EB condition but also explain how the choice of
p could affect the convergence rates of first-order methods.
In the sequel, we shall adopt the following notations. For
any vector x âˆˆ Rn , xJ âˆˆ R|J| denotes the restriction of x
onto the coordinate index set J âŠ† {1, . . . , n}; kxkp , where
p âˆˆ [1, âˆ], denotes the `p -norm of x. For simplicity, we
write kxk for kxk2 . For any matrix B âˆˆ RmÃ—n , kBk is
the matrix norm of B induced by the `2 -norm; i.e., kBk =
maxkvk=1 kBvk. For any scalar a âˆˆ R, sgn(a) is the sign
of a; i.e., sgn(a) = 1 if a > 0, sgn(a) = 0 if a = 0, and
sgn(a) = âˆ’1 if a < 0. For any closed set S, d(x, S) is the
distance of x to S; i.e., d(x, S) = minvâˆˆS kv âˆ’ xk.

2. Preliminaries
2.1. Basic Setup
Throughout the paper, we make the following assumptions
regarding the `1,p -regularized problem (1):
Assumption 1 (a) The convex function f is of the form
f (x) = h(Ax),

(2)

where A âˆˆ RmÃ—n is a matrix and h : Rm â†’ R is
a continuously differentiable function with Lipschitz
continuous gradient âˆ‡h and is strongly convex over
any compact subset of the effective domain dom(h)
of h.
(b) The optimal solution set of (1), denoted by X , is nonempty; i.e., X 6= âˆ….
The above assumption is satisfied by many optimization problems arising in machine learning. For instance, in linear
PNmodels, the empirical risk takes the form
f (x) = N1 i=1 `(yÌ‚ (i) , xT zÌ‚ (i) ), where {(zÌ‚ (i) , yÌ‚ (i) ) âˆˆ
Rn Ã— Rp | i = 1, . . . , N } are sample points and ` :
Rp Ã— Rp â†’ R is a loss function. Such an f can be put
into the form (2) by letting A = [zÌ‚ (1) , . . . , zÌ‚ (N ) ]T and
PN
h(y) = N1 i=1 `(yÌ‚ (i) , y (i) ) with y = (y (1) , . . . , y (N ) ).
Two commonly used loss functions are the square loss
`(yÌ‚ (i) , y (i) ) = 21 kyÌ‚ (i) âˆ’ y (i) k2 and the logistic loss
Pp
(i) (i)
`(yÌ‚ (i) , y (i) ) =
j=1 log(1 + exp(âˆ’yÌ‚j yj )). It can be
verified that linear models with either the square loss or the
logistic loss satisfy Assumption 1.

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

Assumption 1 implies some important properties of the optimal solution set of (1), which we summarize in the following proposition. The proof is given in the supplementary material.
Proposition 1 Under Assumption 1, the optimal solution
set X has the following properties:
(i) There exist a pair of vectors (yÌ„, gÌ„) âˆˆ Rm Ã— Rn with
gÌ„ = AT âˆ‡h(yÌ„) such that for any x âˆˆ X ,
Ax = yÌ„,

âˆ‡f (x) = gÌ„.

2.2. Error Bound Condition
In the convergence analysis of numerical algorithms for (1),
it is essential to measure the distance of any given iterate
xk to the optimal solution set X ; i.e., d(xk , X ). However,
without actually solving (1), such a quantity is not easily
accessible. As an alternative, let us define a function R :
Rn â†’ Rn , which we call the residual function of (1), as
follows:


1
R(x) := argmin hâˆ‡f (x), di + P (x + d) + kdk2 .
2
dâˆˆRn
(3)
It is easy to verify that R(x) = 0 if and only if x âˆˆ X .
Moreover, given any x âˆˆ Rn , R(x) is typically much easier
to compute and analyze than d(x, X ). This suggests that
kR(x)k can serve as a surrogate measure of the proximity
of x to X . However, such a surrogate measure would not
be very useful unless a relationship between kR(x)k and
d(x, X ) can be established. This motivates the exploration
of the following error bound (EB) condition:
Definition 1 (EB Condition) We say that problem (1) satisfies the EB condition if there exist a constant Îº > 0 and a
closed set U âŠ† dom(F ), such that
whenever x âˆˆ U.

Let Y and Z be two Euclidean spaces. A mapping Î“ :
Y â†’ Z is said to be a set-valued mapping, or equivalently,
a multifunction, if for each element of y âˆˆ Y, Î“(y) is a
subset of Z. For example, let B âˆˆ RmÃ—n be given and
consider the solution set of the following linear system:
S(b) = {z âˆˆ Rn | Bz = b}.
Then, S is a set-valued mapping from Rm to Rn , because
for each b âˆˆ Rm , S(b) is an affine subset of Rn . The graph
of a set-valued mapping Î“ : Y â†’ Z, denoted by gph(Î“),
is the subset of Y Ã— Z defined by

(ii) X is a compact convex set.

d(x, X ) â‰¤ ÎºkR(x)k

pings, which features prominently in variational analysis.
Let us begin with some definitions.

(4)

gph(Î“) := {(y, z) âˆˆ Y Ã— Z | z âˆˆ Î“(y)}.
For set-valued mappings, we can define a notion of continuity as follows:
Definition 2 A set-valued mapping Î“ : Y â†’ Z is said to
be upper Lipschitz continuous (ULC) at yÌ„ âˆˆ Y if Î“(yÌ„) is
non-empty and closed, and there exist constants Î¸ > 0 and
Î´ > 0 such that for all y âˆˆ Y with ky âˆ’ yÌ„k â‰¤ Î´,
Î“(y) âŠ† Î“(yÌ„) + Î¸ky âˆ’ yÌ„kB,
where B = {z âˆˆ Z | kzk â‰¤ 1} is the unit `2 -norm ball of
Z and â€œ+â€ is the Minkowski sum of two sets.
The ULC property above can be viewed as an extension
of the calmness property of single-valued functions to setvalued functions (Dontchev & Rockafellar, 2009).
Before leaving this section, we present an important lemma
characterizing the ULC property of polyhedral multifunctions, the proof of which can be found in (Robinson, 1981).
A set-valued mapping is called a polyhedral multifunction
if its graph is a finite union of polyhedral convex sets.

Moreover, we say the EB condition is global if U = dom(F )
and is local if U is the closure of some neighborhood of the
optimal solution set X .

Lemma 1 Let Î“ : Y â†’ Z be a polyhedral multifunction.
Then, Î“ is ULC at any yÌ„ âˆˆ Y such that Î“(yÌ„) is non-empty.

The EB condition can alternatively be viewed as a relaxed
notion of strong convexity, as it is automatically satisfied
if F is strongly convex (Pang, 1987). For illustration, consider the simple case of (1) where P â‰¡ 0. From (3), we
see that R(x) = âˆ’âˆ‡f (x). Hence, the EB condition is asking for a constant Îº > 0 such that d(x, X ) â‰¤ Îºkâˆ‡f (x)k,
which holds globally when f is strongly convex.

3. A Sufficient Condition for the EB
Condition

2.3. Set-Valued Mappings and Upper Lipschitz
Continuity
Our approach to establishing the EB condition is based on
the notion of upper Lipschitz continuity of set-valued map-

In this section, we prove a sufficient condition for the EB
condition to hold, which forms the basis of our subsequent
analysis. Let Î£ : Rm Ã— Rn â†’ Rn be the set-valued mapping defined by
Î£(y, g) := {x âˆˆ Rn | Ax = y, âˆ’g âˆˆ âˆ‚P (x)}.

(5)

The following proposition characterizes the relationship
between the set-valued mapping Î£ and the optimal solution set X :

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

Proposition 2 Under Assumption 1, we have
X = Î£(yÌ„, gÌ„),
where (yÌ„, gÌ„) âˆˆ Rm Ã— Rn are given in Proposition 1.
Furthermore, as shown in the following theorem, the ULC
property of Î£ implies the EB condition for (1).
Theorem 1 Under Assumption 1, the EB condition holds
for (1) if the set-valued mapping Î£ is ULC at (yÌ„, gÌ„) âˆˆ
Rm Ã— Rn .
The proofs of Proposition 2 and Theorem 1 are presented
in the supplementary material. Theorem 1 gives an alternative analysis framework for establishing the EB condition.
Indeed, instead of establishing the inequality (4) directly,
we may turn to study the ULC property of the set-valued
mapping Î£ associated with the optimization problem. This
approach can be advantageous, as it only relies on the properties of the subdifferential of the non-smooth function P ,
which are often simpler than those of the residual function
R. In what follows, we will utilize this approach to study
when the EB condition holds for the `1,p -regularized problem (1).

4. EB Condition for `1,p -Regularization
In this section, we consider the `1,p -regularized problem (1) under Assumption 1 and investigate for which values of p âˆˆ [1, âˆ] will the EB condition hold. In view of
Theorem 1, our strategy is to study when the set-valued
mapping Î£ possesses the ULC property. We divide our
analysis into three cases: (a) p = 1 and p = âˆ; (b)
p âˆˆ (1, 2]; (c) p âˆˆ (2, âˆ).
4.1. EB Condition Holds when p = 1 and p = âˆ

state several technical results that will be used to establish
the ULC property of the set-valued mapping Î£. The proofs
of these results can be found in the supplementary material.
Lemma 3 Let B âˆˆ RmÃ—n , b âˆˆ Rm , d âˆˆ Rn , and J âŠ†
{1, . . . , n} be given. Define the sets
P1 := {x âˆˆ Rn | Bx = b},
P2 := {x âˆˆ Rn | xJ = aJ Â· dJ , aJ â‰¤ 0}.
Suppose that P1 is non-empty. Then, there exists a constant
Î¸ > 0 such that for any x âˆˆ Rn ,
d(x, P1 ) â‰¤ Î¸kBx âˆ’ bk.
Moreover, for any x âˆˆ Rn and p âˆˆ [1, âˆ],


 dJ
xJ 
,

+
d(x, P2 ) â‰¤ kxJ kp Â· 
kdJ kp
kxJ kp 
where we adopt the convention that u/kukp = 0 if u = 0.
The following result is the so-called linear regularity
of a collection of polyhedral sets; see Corollary 5.26
of (Bauschke & Borwein, 1996).
Lemma 4 Let C1 , . . . , CN be polyhedra in Rn . Then, there
exists a constant Ï„ > 0 such that for any x âˆˆ Rn ,
!
N
N
\
X
d x,
Ci â‰¤ Ï„
d (x, Ci ) .
i=1

We next present a result concerning the subdifferential of
the `p -norm when p âˆˆ (1, âˆ). Let q denote the HoÌˆlder
conjugate of p; i.e., 1/p + 1/q = 1.
Proposition 3 Let g âˆˆ Rn , Ï‰ > 0, and p âˆˆ (1, âˆ) be
given. Define the set

We first state a result concerning the set-valued mapping
(5) when P has a polyhedral epigraph.
Lemma 2 Suppose that P has a polyhedral epigraph; i.e.,
the set {(x, t) âˆˆ Rn Ã—R | P (x) â‰¤ t} is a polyhedron. Then,
the set-valued mapping Î£ is a polyhedral multifunction.
The proof is given in the supplementary material. Noting that both the `1 -norm and `âˆ -norm have polyhedral
epigraphs, by Lemma 2, the set-valued mapping Î£ is a
polyhedral multifunction when p = 1 and p = âˆ. Hence,
by Lemma 1, Î£ is ULC at (yÌ„, gÌ„) âˆˆ Rm Ã— Rn if Î£(yÌ„, gÌ„) is
non-empty. The latter is ensured by Assumption 1. Upon
applying Theorem 1, we have the following result:
Corollary 1 Under Assumption 1, the EB condition holds
for (1) when p = 1 and p = âˆ.
4.2. EB Condition Holds when p âˆˆ (1, 2]
Next, we show that under Assumption 1, the EB condition
holds for (1) when p âˆˆ (1, 2]. Towards that end, let us first

i=1

S := {x âˆˆ Rn | âˆ’g âˆˆ Ï‰âˆ‚kxkp }.
Then,
ï£±
ï£² âˆ…
{x | x = a Â· v(g), a â‰¤ 0}
S=
ï£³
{0}

if kgkq > Ï‰;
if kgkq = Ï‰;
if kgkq < Ï‰,

where the function v : Rn â†’ Rn is defined by


q
q
v(g) := sgn(g1 )|g1 | p , . . . , sgn(gn )|gn | p .
In addition, when p âˆˆ (1, 2], for any g âˆˆ Rn , there exist
constants Î´ > 0 and Î½ > 0 such that
kv(g) âˆ’ v(gÌƒ)k â‰¤ Î½kg âˆ’ gÌƒk whenever kg âˆ’ gÌƒk â‰¤ Î´. (6)
P
Recall that P (x) =
JâˆˆJ Ï‰J kxJ kp , where J is a
non-overlapping partition of the coordinate index set
{1, . . . , n}. Hence, for any x, g âˆˆ Rn , âˆ’g âˆˆ âˆ‚P (x) if and

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

only if âˆ’gJ âˆˆ Ï‰J âˆ‚kxJ kp for all J âˆˆ J . This, together
with Proposition 3, implies that if Î£(y, g) is non-empty,
then kgJ k â‰¤ Ï‰J for all J âˆˆ J . In particular, we may write
ï£¼
ï£± 

ï£´
ï£´
ï£½
ï£²  Ax = y,

Î£(y, g) = x  xJ = aJ Â· v(gJ ), aJ â‰¤ 0, âˆ€J âˆˆ J1g , ,
ï£´
ï£´
ï£¾
ï£³ 
xJ = 0, âˆ€J âˆˆ J2g
(7)
where
J1g := {J âˆˆ J | kgJ k = Ï‰J },
J2g := {J âˆˆ J | kgJ k < Ï‰J }.
This shows that Î£(y, g) is closed. The next lemma reveals
that boundedness of Î£ is a property that is stable under
small perturbations.
Lemma 5 Suppose that the set-valued mapping Î£ is nonempty and bounded at (y, g) âˆˆ Rm Ã—Rn . Then, there exists
a constant Î´ > 0 such that Î£(yÌƒ, gÌƒ) is bounded whenever
(yÌƒ, gÌƒ) âˆˆ Rm Ã— Rn satisfies kgÌƒ âˆ’ gk â‰¤ Î´ and Î£(yÌƒ, gÌƒ) is
non-empty.
Now, we are ready to study the ULC property of the setvalued mapping Î£.
Theorem 2 Suppose that p âˆˆ (1, 2]. Then, the set-valued
mapping Î£ is ULC at any (y, g) âˆˆ Rm Ã— Rn such that
Î£(y, g) is non-empty and bounded.
Proof Define the sets
C1 (J) := {x âˆˆ Rn | xJ = aJ Â· v(gJ ), aJ â‰¤ 0} , âˆ€J âˆˆ J1g ,
C2 := {x âˆˆ Rn | xJ = 0, âˆ€J âˆˆ J2g } ,
C3 := {x âˆˆ Rn | Ax = y} .


Then, by (7), we have Î£(y, g) = âˆ©JâˆˆJ1g C1 (J) âˆ©C2 âˆ©C3 .
Moreover, since C1 (J), C2 , C3 , where J âˆˆ J1g , are all polyhedral subsets of Rn , by Lemma 4, there exists a constant
Ï„ > 0 such that for any x âˆˆ Rn ,
ï£«
ï£¶
3
X
X
d(x, Î£(y, g)) â‰¤ Ï„ ï£­
d(x, C1 (J)) +
d(x, Ci )ï£¸ .
JâˆˆJ1g

i=2

(8)
Thus, to prove Theorem 2, it suffices to bound the righthand side of (8) for all x âˆˆ Î£(yÌƒ, gÌƒ), where (yÌƒ, gÌƒ) âˆˆ Rm Ã—
Rn lies in a neighborhood of (y, g) âˆˆ Rm Ã—Rn and Î£(yÌƒ, gÌƒ)
is non-empty. Towards that end, we first note that since
kgJ k < Ï‰J for J âˆˆ J2g , there exists a constant Î´1 > 0
such that
kgÌƒJ k < Ï‰J , âˆ€J âˆˆ J2g
(9)
whenever k(yÌƒ, gÌƒ) âˆ’ (y, g)k â‰¤ Î´1 . Now, for any such pair
(yÌƒ, gÌƒ) âˆˆ Rm Ã— Rn and any index set J âˆˆ J1g , we either
have (a) kgÌƒJ k = Ï‰J or (b) kgÌƒJ k < Ï‰J . (The case kgÌƒJ k >

Ï‰J cannot happen because Î£(yÌƒ, gÌƒ) is assumed to be nonempty.) It follows that J1g = J1g (a) âˆª J1g (b), where
J1g (a) := {J âˆˆ J1g | kgÌƒJ k = Ï‰J } ,

(10)

J1g (b)

(11)

:= {J âˆˆ

J1g

| kgÌƒJ k < Ï‰J } .

Since Î£(y, g) is non-empty and bounded, by Lemma 5,
there exist constants Î´2 > 0 and R > 0 such that for any
x âˆˆ Î£(yÌƒ, gÌƒ), we have
kxkp â‰¤ R

whenever k(yÌƒ, gÌƒ) âˆ’ (y, g)k â‰¤ Î´2 .

(12)

Therefore, in view of (9)â€“(12) and Proposition 3, every x âˆˆ
Î£(yÌƒ, gÌƒ) that satisfies k(yÌƒ, gÌƒ) âˆ’ (y, g)k â‰¤ min{Î´1 , Î´2 } must
also satisfy the following conditions:
Ax = yÌƒ,
(13)
xJ = aJ Â· v(gÌƒJ ) for some aJ â‰¤ 0, âˆ€J âˆˆ J1g (a), (14)
xJ = 0, âˆ€J âˆˆ J1g (b) âˆª J2g ,

(15)

kxkp â‰¤ R.

(16)

Using (15), it is clear that
d(x, C2 ) = 0.

(17)

Moreover, by (13) and Lemma 3, there exists a constant
Î¸0 > 0 such that
d(x, C3 ) â‰¤ Î¸0 kAx âˆ’ yk = Î¸0 kyÌƒ âˆ’ yk.

(18)

Now, by (14), (15), and Lemma 3, we have d(x, C1 (J)) =
0 for J âˆˆ J1g (b) and


 v(gJ )
xJ 

d(x, C1 (J)) â‰¤ kxJ kp Â· 
+
 kv(gJ )kp
kxJ kp 


 v(gJ )
v(gÌƒJ ) 

= kxJ kp Â· 
âˆ’
 kv(gJ )kp
kv(gÌƒJ )kp 
= Ï‰J1âˆ’q Â· kxJ kp Â· kv(gJ ) âˆ’ v(gÌƒJ )k
â‰¤ Î½J Ï‰J1âˆ’q Â· kxJ kp Â· kgJ âˆ’ gÌƒJ k
for J âˆˆ J1g (a), where the third line follows from the fact
that kv(g)kp = Ï‰ qâˆ’1 whenever kgkq = Ï‰, and the fourth
line is due to (6). Together with (16), the above yields
X
X
d(x, C1 (J)) â‰¤
Î½J Ï‰J1âˆ’q Â· kxJ kp Â· kgJ âˆ’ gÌƒJ k
JâˆˆJ1g

JâˆˆJ1g (a)

!
â‰¤

R

X

Î½J Ï‰J1âˆ’q

kgÌƒ âˆ’ gk.

(19)

JâˆˆJ

Substituting (17), (18), and (19) into (8), we obtain
d(x, Î£(y, g)) â‰¤ Î¸k(yÌƒ, gÌƒ) âˆ’ (y, g)k
for any x âˆˆ Î£(yÌƒ,ngÌƒ) with k(yÌƒ, gÌƒ) âˆ’ (y, g)k
o â‰¤ min{Î´1 , Î´2 },
P
1âˆ’q
0
where Î¸ = max Î¸ , R JâˆˆJ Î½J Ï‰J
. It follows that Î£
is ULC at (y, g) âˆˆ Rm Ã— Rn , as desired.

u
t

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

Seeing that Assumption 1 and Propositions 1 and 2 ensure
the boundedness of Î£(yÌ„, gÌ„), the following result is a direct
combination of Theorems 1 and 2:
Corollary 2 Under Assumption 1, the EB condition holds
for (1) when p âˆˆ (1, 2].

which shows that the EB condition fails for problem (20).

5. Convergence Rates of First-Order Methods

It can be verified that in this scenario, the set-valued mapping Î£ is not ULC at certain points. The key intuition is
that when p âˆˆ (2, âˆ), we have 0 < q/p < 1, which implies that the function s 7â†’ |s|q/p is not Lipschitz continuous at s = 0. As such, the inequality (6) fails to hold, which
means that Theorem 1 is no longer valid in this scenario.
In what follows, we will construct an explicit example to
demonstrate that under Assumption 1, the EB condition for
problem (1) fails to hold for any p âˆˆ (2, âˆ).

As mentioned in the Introduction, the EB condition (4) can
be used to derive strong convergence rate results for various first-order methods. In this section, we use the newlyestablished EB condition for `1,p -regularization to analyze
the convergence rates of the proximal gradient (PG) and
block coordinate gradient descent (BCGD) methods when
they are applied to solve problem (1). In what follows,
we say that a sequence {wk }kâ‰¥0 converges Q-linearly
(resp. R-linearly) to wâˆ if there exists a constant Ï âˆˆ (0, 1)
such that lim supkâ†’âˆ {kwk+1 âˆ’ wâˆ k/kwk âˆ’ wâˆ k} â‰¤ Ï
(resp. if there exist constants Î³ > 0 and Ï âˆˆ (0, 1) such
that kwk âˆ’ wâˆ k â‰¤ Î³ Â· Ïk for all k â‰¥ 0).

Example. Consider the following problem:

5.1. Proximal Gradient Method

4.3. EB Condition Fails when p âˆˆ (2, âˆ)

1
min2 kAx âˆ’ bk2 + kxkp ,
xâˆˆR 2

(20)

where A = [1, 0], b = 2. It is obvious that this problem
satisfies Assumption 1. In addition, the optimal value and
optimal solution set of (20) can be calculated explicitly.
Proposition 4 Consider problem (20) with p âˆˆ (2, âˆ).
The optimal value is v âˆ— = 3/2 and the optimal solution
set is given by X = {(1, 0)}.
The proof of Proposition 4 can be found in the supplementary material. Now, let {Î´k }kâ‰¥0 be a sequence converging
to zero; i.e., Î´k = o(1). For simplicity, we assume that
Î´k > 0 for all k â‰¥ 0. Consider the sequence {xk }kâ‰¥0 with
1

1

xk1 := 2 âˆ’ (1 âˆ’ Î´k ) q , xk2 :=

2 âˆ’ (1 âˆ’ Î´k ) q
1

(1 âˆ’ Î´k ) p

1

1

Â· Î´kp + Î´kq ,

where q is the HoÌˆlder conjugate of p. Since Î´k â†’ 0, the
sequence xk converges to X . Our goal now is to show that
kR(xk )k = o(d(xk , X )) when p âˆˆ (2, âˆ).
To begin, observe that xk1 converges to 1 at the rate Î˜(Î´k )
1/p
and xk2 converges to 0 at the rate Î˜(Î´k ) (note that when
1/p
p â‰¥ 1, Î´k = O(Î´k )). Thus, we have d(xk , X ) =
1/p
Î˜(Î´k ).
Next, we need to compute R(xk ). This is done in the following lemma, whose proof can be found in the supplementary material.
Lemma 6 For the sequence {xk }kâ‰¥0 defined above, we
1/q
have R(xk ) = (0, âˆ’Î´k ).
1/q

Since 1/p < 1/q when p âˆˆ (2, âˆ), we have Î´k =
1/p
o(Î´k ). It follows from Lemma 6 that when p âˆˆ (2, âˆ),
 1
 1

kR(xk )k = Î˜ Î´kq = o Î´kp = o d xk , X ,

The PG method is well suited for solving non-smooth composite optimization problems. Its adaptation for solving
`1,p -regularization is proposed in (Liu & Ye, 2009; 2010;
Zhang et al., 2013). Each iteration of the PG method involves the computation of a proximal operator. For problem (1), the proximal operator is defined as


1
2
proxP (x) := argmin P (z) + kz âˆ’ xk .
2
zâˆˆRn
It can be verified that x âˆˆ Rn is an optimal solution to (1)
if and only if it satisfies the following fixed-point equation:
x = proxP (x âˆ’ âˆ‡f (x)).
This motivates the following fixed-point iteration for solving (1):

xk+1 = proxÎ±k P xk âˆ’ Î±k âˆ‡f (xk ) ,
where Î±k > 0 is the stepsize. It has been shown that for
p âˆˆ [1, âˆ], proxP (x) can be computed efficiently using
the so-called `1,p -regularized Euclidean projection (EP1p )
method (Liu & Ye, 2009; 2010). We summarize the PG
method for solving (1) in Algorithm 1.
Algorithm 1 Proximal Gradient Method
Input: initial point x0
for k = 0 to N do
1. choose a stepsize Î±k > 0
2. compute y k = xk âˆ’ Î±k âˆ‡f (xk )
3. compute proxÎ±k P (y k ) using the EP1p method
4. set xk+1 = proxÎ±k P (y k )
end for
It is known that the sequence generated by the PG
method converges linearly if the EB condition (4) is satisfied (Zhang et al., 2013). By invoking Corollaries 1 and 2,
we obtain the following result:

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

Corollary 3 Consider the `1,p -regularized problem (1)
with Assumption 1 satisfied. Let L > 0 be the Lipschitz
constant of âˆ‡f . Let {xk }kâ‰¥0 be the sequence generated
by Algorithm 1. Suppose that the stepsizes {Î±k }kâ‰¥0 satisfy
inf Î±k > 0,
k

sup Î±k <
k

1
.
L

If p âˆˆ [1, 2] or p = âˆ, then {f (xk )}kâ‰¥0 converges Qlinearly to the optimal value v âˆ— and {xk }kâ‰¥0 converges
R-linearly to an element in X .
5.2. Block Coordinate Gradient Descent Method
The BCGD method is developed in (Tseng & Yun, 2009)
and is applied to the `1,p -regularized problem (1) in (Meier
et al., 2008; Liu et al., 2009). In each iteration of the BCGD
method, a block J âˆˆ J and a symmetric positive definite
matrix H are chosen. Then, a search direction vH (x; J),
which is defined as the minimizer of the problem
min âˆ‡f (x)T d + 21 dT Hd + P (x + d)
s.t. dj = 0, âˆ€ j âˆˆ
/ J,

(21)

is computed. Finally, the iterate is updated by moving
along the direction vH (x; J) with stepsize Î± > 0, where
Î± is chosen according to the Armijo rule (Tseng & Yun,
2009). We summarize the BCGD method in Algorithm 2.
Algorithm 2 Block Coordinate Gradient Descent Method
Input: initial point x0
for k = 0 to N do
1. choose a block J k âˆˆ J and a symmetric positive
definite matrix H k
2. solve problem (21) and obtain the search direction
vH k (xk ; J k )
3. choose a stepsize Î±k > 0 by the Armijo rule and
update xk+1 = xk + Î±k vH k (xk ; J k )
end for

As implied by Corollaries 3 and 4, the PG and BCGD methods for solving `1,p -regularized linear regression or logistic regression are theoretically guaranteed to attain a linear
rate of convergence when p âˆˆ [1, 2] or p = âˆ. By contrast, since the EB condition fails to hold when p âˆˆ (2, âˆ),
the PG and BCGD methods for solving the same class of
problems may not converge linearly.

6. Numerical Experiments
In this section, we perform numerical experiments to study
the convergence rates of the PG and BCGD methods for
solving `1,p -regularized linear regression and logistic regression on synthetic datasets. As we shall see, the results
corroborate our theoretical analyses in previous sections.
6.1. Example for which the EB Condition Fails
Recall the example we constructed in Section 4.3; i.e.,
problem (20). In spite of its small size, problem (20) is of
particular interest in experiments of convergence rates due
to the following reasons. First, it belongs to the class of
`1,p -regularized problems that satisfy Assumption 1. Second, the EB condition holds for (20) when p âˆˆ [1, 2] and
p = âˆ, while it fails when p âˆˆ (2, âˆ). Third, its optimal
value v âˆ— is known in advance (Proposition 4), so that we
can trace the curve log(f (xk ) âˆ’ v âˆ— ) precisely.
We implement the PG method (Algorithm 1) to solve (20)
with p = 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 4, âˆ. The stepsize is
chosen to be constant Î±k â‰¡ 0.5, which can be verified to
satisfy the conditions stated in Corollary 3. The convergence performance of the objective value is presented in
Figure 1. It is readily seen that when p âˆˆ [1, 2] or p = âˆ,
{f (xk )}kâ‰¥0 converges linearly to v âˆ— (Figure 1(a)). By contrast, when p âˆˆ (2, âˆ), the objective value converges at a
sublinear rate (Figure 1(b)). Our experiments suggest that
for the `1,p -regularized problem (1), a linear rate of convergence is in general not achievable if p âˆˆ (2, âˆ).
6.2. Synthetic Datasets

It has been shown in Theorem 2 of (Tseng & Yun, 2009)
that Algorithm 2 attains a linear rate of convergence if the
EB condition (4) is satisfied. By invoking again Corollaries 1 and 2, we obtain the following result:
Corollary 4 Consider the `1,p -regularized problem (1)
with Assumption 1 satisfied. Let {xk }kâ‰¥0 be the sequence
generated by Algorithm 2, where the blocks {J k }kâ‰¥0 cycle
over J and the stepsizes {Î±k }kâ‰¥0 satisfy
inf Î±k > 0,
k

sup Î±k â‰¤ 1.
k

If p âˆˆ [1, 2] or p = âˆ, then {f (xk )}kâ‰¥0 converges Qlinearly to the optimal value v âˆ— and {xk }kâ‰¥0 converges
R-linearly to an element in X .

In this section, we test the convergence rates of first-order
methods for solving `1,p -regularized regression with p âˆˆ
[1, 2] or p = âˆ on synthetic datasets. In particular, we
consider the PG method (Algorithm 1) for solving `1,p regularized linear regression and the BCGD method (Algorithm 2) for solving `1,p -regularized logistic regression.
`1,p -Regularized Linear Regression. We consider
d

min

XâˆˆRdÃ—k

X
1
kAX âˆ’ Y k2F + Ï„
kX (i) kp ,
2
i=1

(22)

where A âˆˆ RmÃ—d is a measurement matrix, Y âˆˆ RmÃ—k is
the response matrix, and Ï„ > 0 is a regularization parameter. In addition, we treat each row of X as a group and

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods
Convergence Performance of the Objective Value

2

10
p=1
p=1.25
p=1.5
p=1.75
p=2
p=inf

0

10

âˆ’2

10

p=1
p=1.5
p=2
p=inf

4

10

2

âˆ’4

log( f(xk) âˆ’ v* )

log( f(xk) âˆ’ v* )

Convergence Performance of the Objective Value

6

10

10

âˆ’6

10

âˆ’8

10

10

0

10

âˆ’2

10
âˆ’10

10

âˆ’4

10

âˆ’12

10

âˆ’14

10

âˆ’6

0

10

20

30

40

50

10

60

0

500

1000

1500

Iterations

2000

2500

3000

3500

4000

Iterations

(a)
Figure 2. The performance of the PG method for solving `1,p regularized linear regression.

Convergence Performance of the Objective Value

2

10

p=2.5
p=3
p=4

0

10

âˆ’4

10

âˆ’6

10

âˆ’8

10

âˆ’10

10

0

200

400

600

800

1000

Iterations

(b)
Figure 1. The PG method for solving problem (20).

use X (i) to denote the i-th row of X. We utilize the same
strategy as the experiments in (Liu & Ye, 2010). Precisely,
each entry of A is generated independently from the standard normal distribution. Moreover, we generate a jointly
sparse matrix X âˆ— âˆˆ RdÃ—k , where the entries of the first
d0 < d rows are being sampled from the normal distribution and the remaining entries are all set to 0. Then, we
let Y = AX âˆ— + Z, where Z âˆˆ RmÃ—k is the noise matrix whose entries are sampled from the normal distribution
with mean zero and standard deviation 0.1. Figure 2 illustrates the convergence performance of the PG method (Algorithm 1) for solving (22) with m = 50, d = 100, d0 =
30, k = 20, and Ï„ = 50. It reveals that the objective value
converge linearly to the optimal value when p âˆˆ [1, 2] or
p = âˆ. This confirms our result in Corollary 3.

first sample S matrices W1 , . . . , WS independently from
the standard Wishart distribution. Then, a jointly sparse
matrix X âˆ— is generated in the same way as in the experiment of `1,p -regularized linear regression. Finally, we let
ys = sgn(hWs , Xi), where s = 1, . . . , S. Figure 3 shows
the convergence performance of the BCGD method (Algorithm 2) for solving (23) with d = k = 50, S = 100,
d0 = 10, and Ï„ = 20. It is clear from the figure that the objective value of (23) converges linearly to the optimal value
when p âˆˆ [1, 2] or p = âˆ. This corroborates our result in
Corollary 4.

Convergence Performance of the Objective Value

6

10

p=1
p=1.5
p=2
p=inf

4

10

2

log( f(xk) âˆ’ v* )

log( f(xk) âˆ’ v* )

âˆ’2

10

10

0

10

âˆ’2

10

âˆ’4

10

âˆ’6

10

0

1000

2000

3000

4000

5000

6000

7000

8000

9000

Iterations

Figure 3. The performance of the BCGD method for solving `1,p regularized logistic regression.

`1,p -Regularized Logistic Regression. We consider
min

XâˆˆRdÃ—k

S
X
s=1

log(1 + exp(âˆ’ys hWs , Xi) + Ï„

d
X

kX (i) kp ,

Acknowledgements

i=1

(23)
where Ws âˆˆ RdÃ—k , ys âˆˆ {âˆ’1, 1}, and Ï„ > 0 is a regularization parameter. Here, hWs , Xi = trace(WsT X) and
X (i) denotes the i-th row of X. For the data generation, we

This work is supported in part by the Hong Kong Research
Grants Council (RGC) General Research Fund (GRF)
Project CUHK 14206814 and in part by a gift grant from
Microsoft Research Asia.

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

References
Bach, Francis, Jenatton, Rodolphe, Mairal, Julien, and
Obozinski, Guillaume. Optimization with sparsityR in Mainducing penalties. Foundations and Trends
chine Learning, 4(1):1â€“106, 2012.
Bach, Francis R. Consistency of the group lasso and multiple kernel learning. Journal of Machine Learning Research, 9:1179â€“1225, 2008.
Bauschke, Heinz H and Borwein, Jonathan M. On projection algorithms for solving convex feasibility problems.
SIAM Review, 38(3):367â€“426, 1996.
Beck, Amir and Teboulle, Marc. A fast iterative shrinkagethresholding algorithm for linear inverse problems.
SIAM Journal on Imaging Sciences, 2(1):183â€“202, 2009.
Combettes, Patrick L and Wajs, ValeÌrie R. Signal recovery by proximal forwardâ€“backward splitting. Multiscale
Modeling and Simulation, 4(4):1168â€“1200, 2005.
Dontchev, Asen L and Rockafellar, R Tyrrell. Implicit
Functions and Solution Mappings. Springer Monographs in Mathematics. Springer Science+Business Media, LLC, New York, 2009.
Eldar, Yonina C, Kuppinger, Patrick, and Bolcskei, Helmut.
Block-sparse signals: Uncertainty relations and efficient
recovery. IEEE Transactions on Signal Processing, 58
(6):3042â€“3054, 2010.
Fornasier, Massimo and Rauhut, Holger. Recovery algorithms for vector-valued data with joint sparsity constraints. SIAM Journal on Numerical Analysis, 46(2):
577â€“613, 2008.
Hale, Elaine T, Yin, Wotao, and Zhang, Yin. Fixedpoint continuation for `1 -minimization: Methodology
and convergence. SIAM Journal on Optimization, 19(3):
1107â€“1130, 2008.
Hong, Mingyi and Luo, Zhi-Quan. On the linear convergence of the alternating direction method of multipliers.
arXiv preprint arXiv:1208.3922, 2012.
Kloft, Marius, Brefeld, Ulf, Sonnenburg, SoÌˆren, and Zien,
Alexander. `p -norm multiple kernel learning. Journal of
Machine Learning Research, 12:953â€“997, 2011.
Kowalski, Matthieu. Sparse regression using mixed norms.
Applied and Computational Harmonic Analysis, 27(3):
303â€“324, 2009.
Liu, Han, Palatucci, Mark, and Zhang, Jian. Blockwise coordinate descent procedures for the multi-task lasso, with
applications to neural semantic basis discovery. In Proceedings of the 26th International Conference on Machine Learning, pp. 649â€“656, 2009.

Liu, Jun and Ye, Jieping. Efficient Euclidean projections
in linear time. In Proceedings of the 26th International
Conference on Machine Learning, pp. 657â€“664, 2009.
Liu, Jun and Ye, Jieping. Efficient `1 /`q norm regularization. arXiv preprint arXiv:1009.4766, 2010.
Luo, Zhi-Quan and Tseng, Paul. On the linear convergence
of descent methods for convex essentially smooth minimization. SIAM Journal on Control and Optimization,
30(2):408â€“425, 1992.
Luo, Zhi-Quan and Tseng, Paul. Error bounds and convergence analysis of feasible descent methods: A general
approach. Annals of Operations Research, 46(1):157â€“
178, 1993.
Meier, Lukas, van de Geer, Sara, and BuÌˆhlmann, Peter. The
group lasso for logistic regression. Journal of the Royal
Statistical Society: Series B (Statistical Methodology),
70(1):53â€“71, 2008.
Minty, George J. Monotone (nonlinear) operators in Hilbert
space. Duke Mathematical Journal, 29(3):341â€“346,
1962.
Minty, George J. On the monotonicity of the gradient of a
convex function. Pacific Journal of Mathematics, 14(1):
243â€“247, 1964.
Nesterov, Yurii. Introductory Lectures on Convex Optimization: A Basic Course. Kluwer Academic Publishers,
Boston, 2004.
Pang, Jong-Shi. A posteriori error bounds for the linearlyconstrained variational inequality problem. Mathematics
of Operations Research, 12(3):474â€“484, 1987.
Robinson, Stephen M. Some continuity properties of polyhedral multifunctions. In KoÌˆnig, H, Korte, B, and Ritter, K (eds.), Mathematical Programming at Oberwolfach, volume 14 of Mathematical Programming Study,
pp. 206â€“214. North-Holland Publishing Company, Amsterdam, 1981.
Rockafellar, R Tyrrell. Convex Analysis. Princeton University Press, Princeton, New Jersey, 1970.
So, Anthony Man-Cho. Non-asymptotic convergence
analysis of inexact gradient methods for machine
learning without strong convexity.
arXiv preprint
arXiv:1309.0113, 2013.
Tibshirani, Robert. Regression shrinkage and selection via
the lasso. Journal of the Royal Statistical Society: Series
B (Methodological), 58(1):267â€“288, 1996.
Tomioka, Ryota and Suzuki, Taiji. Sparsity-accuracy tradeoff in MKL. arXiv preprint arXiv:1001.2615, 2010.

`1,p -Norm Regularization: Error Bounds and Convergence Rate Analysis of First-Order Methods

Tseng, Paul. Convergence of a block coordinate descent
method for nondifferentiable minimization. Journal of
Optimization Theory and Applications, 109(3):475â€“494,
2001.
Tseng, Paul. Approximation accuracy, gradient methods, and error bound for structured convex optimization.
Mathematical Programming, 125(2):263â€“295, 2010.
Tseng, Paul and Yun, Sangwoon. A coordinate gradient
descent method for nonsmooth separable minimization.
Mathematical Programming, 117(1-2):387â€“423, 2009.
Vogt, Julia E and Roth, Volker. A complete analysis of
the `1,p group-lasso. In Proceedings of the 29th International Conference on Machine Learning, 2012.
Wang, Po-Wei and Lin, Chih-Jen. Iteration complexity
of feasible descent methods for convex optimization.
Journal of Machine Learning Research, 15:1523â€“1548,
2014.
Xiao, Lin and Zhang, Tong. A proximal-gradient homotopy method for the sparse least-squares problem. SIAM
Journal on Optimization, 23(2):1062â€“1091, 2013.
Yuan, Ming and Lin, Yi. Model selection and estimation in
regression with grouped variables. Journal of the Royal
Statistical Society: Series B (Statistical Methodology),
68(1):49â€“67, 2006.
Zhang, Haibin, Jiang, Jiaojiao, and Luo, Zhi-Quan. On
the linear convergence of a proximal gradient method
for a class of nonsmooth convex minimization problems.
Journal of the Operations Research Society of China, 1
(2):163â€“186, 2013.

