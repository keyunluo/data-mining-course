Global Convergence of Stochastic Gradient Descent for Some Non-convex
Matrix Problems
Christopher De Sa
Department of Electrical Engineering, Stanford University, Stanford, CA 94309

CDESA @ STANFORD . EDU

Kunle Olukotun
Department of Electrical Engineering, Stanford University, Stanford, CA 94309

KUNLE @ STANFORD . EDU

Christopher ReÃÅ
Department of Computer Science, Stanford University, Stanford, CA 94309

Abstract
Stochastic gradient descent (SGD) on a low-rank
factorization (Burer & Monteiro, 2003) is commonly employed to speed up matrix problems
including matrix completion, subspace tracking,
and SDP relaxation. In this paper, we exhibit a step size scheme for SGD on a low-rank
least-squares problem, and we prove that, under broad sampling conditions, our method converges globally from a random starting point
within O(‚àí1 n log n) steps with constant probability for constant-rank problems. Our modification of SGD relates it to stochastic power iteration. We also show experiments to illustrate the
runtime and convergence of the algorithm.

1. Introduction
We analyze an algorithm to solve the stochastic optimization problem

2 


minimize E AÃÉ ‚àí X 
(1)
F
subject to X ‚àà Rn√ón , rank (X) ‚â§ p, X  0,
where p is an integer and AÃÉ is a symmetric matrix drawn
from some distribution with bounded covariance. The solution to this problem is the matrix formed by zeroing
out all but the largest p positive eigenvalues of the matrix
E[AÃÉ]. This problem, or problems that can be transformed
to this problem, appears in a variety of machine learning
applications including matrix completion (Jain et al., 2013;
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

CHRISMRE @ STANFORD . EDU

Teflioudi et al., 2012; Chen et al., 2011), general data analysis (Zou et al., 2004), subspace tracking (Balzano et al.,
2010), principle component analysis (Arora et al., 2012),
optimization (Burer & Monteiro, 2005; JourneÃÅe et al.,
2010; Mishra et al., 2013; Horstmeyer et al., 2014), and recommendation systems (Gupta et al., 2013; Oscar Boykin,
2013-2014).
Sometimes, (1) arises under conditions in which the samples AÃÉ are sparse, but the matrix X would be too large to
store and operate on efficiently; a standard heuristic to use
in this case is a low-rank factorization (Burer & Monteiro,
2003). The idea is to substitute X = Y Y T and solve the
problem

2 

T
minimize E AÃÉ ‚àí Y Y 
(2)
F
subject to Y ‚àà Rn√óp .
By construction, if we set X = Y Y T , then X ‚àà Rn√ón ,
rank (X) ‚â§ p, and X  0; this allows us to drop these
constraints. Instead of having to store the matrix X (of size
n2 ), we only need to store the matrix Y (of size np).
In practice, many people use stochastic gradient descent
(SGD) to solve (2). Efficient SGD implementations can
scale to very large datasets (Recht & ReÃÅ, 2013; Niu et al.,
2011; Teflioudi et al., 2012; Agarwal et al., 2011; Bottou,
2010; Duchi et al., 2011; Bottou & Bousquet, 2008; Hu
et al., 2009). However, standard stochastic gradient descent
on (2) does not converge globally, in the sense that there
will always be some initial values for which the norm of
the iterate will diverge .
People have attempted to compensate for this with sophisticated methods like geodesic step rules (JourneÃÅe et al.,
2010) and manifold projections (Absil et al., 2008); however, even these methods cannot guarantee global convergence. Motivated by this, we describe Alecton, an algo-

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

rithm for solving (2), and analyze its convergence. Alecton
is an SGD-like algorithm that has a simple update rule with
a step size that is a simple function of the norm of the iterate Yk . We show that Alecton converges globally. We
make the following contributions:
‚Ä¢ We establish the convergence rate to a global optimum
of Alecton using a random initialization; in contrast,
prior analyses (CandeÃÄs et al., 2014; Jain et al., 2013)
have required more expensive initialization methods,
such as the singular value decomposition of an empirical average of the data.
‚Ä¢ In contrast to previous work that uses bounds on the
magnitude of the noise (Hardt & Price, 2014; Hardt,
2014), our analysis depends only on the variance of
the samples. As a result, we are able to be robust to
different noise models, and we apply our technique to
these problems, which did not previously have global
convergence rates:
‚Äì matrix completion, in which we observe entries
of A one at a time (Jain et al., 2013; Keshavan
et al., 2010) (Section 4.1),
‚Äì phase retrieval, in which we observe tr(uT Av)
for randomly selected u, v (CandeÃÄs et al., 2014;
CandeÃÄs & Li, 2014) (Section 4.3), and
‚Äì subspace tracking, in which A is a projection matrix and we observe random entries of a random
vector in its column space (Balzano et al., 2010)
(Section 4.4).
Our result is also robust to different noise models.
‚Ä¢ We describe a martingale-based analysis technique
that is novel in the space of non-convex optimization.
We are able to generalize this technique to some simple regularized problems, and we are optimistic that it
has more applications.
1.1. Related Work
Much related work exists in the space of solving low-rank
factorized optimization problems. Foundational work in
this space was done by Burer and Monteiro (Burer & Monteiro, 2003; 2005), who analyzed the low-rank factorization
of general semidefinite programs. Their results focus on the
classification of the local minima of such problems, and on
conditions under which no non-global minima exist. They
do not analyze the convergence rate of SGD.
Another general analysis in JourneÃÅe et al. (2010) exhibits a
second-order algorithm that converges to a local solution.
Their results use manifold optimization techniques to optimize over the manifold of low-rank matrices. These approaches have attempted to correct for falling off the manifold using Riemannian retractions (JourneÃÅe et al., 2010),

geodesic steps (Balzano et al., 2010), or projections back
onto the manifold. General non-convex manifold optimization techniques (Absil et al., 2008) tell us that first-order
methods, such as SGD, will converge to a fixed point, but
they provide no convergence rate to the global optimum.
Our algorithm only involves a simple rescaling, and we are
able to provide global convergence results.
Our work follows others who have studied individual problems that we consider. Jain et al. (2013) study matrix completion and provides a convergence rate for an exact recovery algorithm, alternating minimization; subsequent work
(Jain & Netrapalli, 2014) gives fast rates for projected gradient descent. CandeÃÄs et al. (2014) provide a similar result for phase retrieval. Sun & Luo (2014) give general
conditions under which various algorithms work for exact
matrix recovery. In contrast to these results, which require
expensive SVD-like operations to initialize, our results allow random initialization. Our provided convergence rates
apply to additional problems and SGD algorithms that are
used in practice (but are not covered by previous analysis).
However, our convergence rates are slower in their respective settings. This is likely unavoidable in our setting, as
we show that our convergence rate is optimal in this more
general setting .
A related class of algorithms that are similar to Alecton is
stochastic power iteration (Arora et al., 2012). These algorithms reconsider (1) as an eigenvalue problem, and uses
the familiar power iteration algorithm, adapted to a stochastic setting. Stochastic power iteration has been applied to a
wide variety of problems (Arora et al., 2012; John Goes &
Lerman, 2014). Oja (1985) show convergence of this algorithm, but provides no rate. Arora et al. (2013) analyze this
problem, and state that ‚Äúobtaining a theoretical understanding of the stochastic power method, or of how the step size
should be set, has proved elusive.‚Äù Our paper addresses this
by providing a method for selecting the step size, although
our analysis shows convergence for any sufficiently small
step size.
Shamir (2014) provide exponential-rate local convergence
results for a stochastic power iteration algorithm for PCA.
As they note, it can be used in practice to improve the
accuracy of an estimate returned by another, globallyconvergent algorithm such as Alecton.
Also recently, Balsubramani et al. (2013) and Hardt & Price
(2014) provide a global convergence rate for the stochastic
power iteration algorithm. Our result only depends on the
variance of the samples, while both their results require absolute bounds on the magnitude of the noise. This allows us
to analyze a different class of noise models, which enables
us to do matrix completion, phase retrieval, and subspace
tracking in the same model.

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

2. Algorithmic Derivation
We focus on the low-rank factorized stochastic optimization
h
iproblem (2). We can rewrite the objective as
E fÀú(Y ) , with sampled objective function

  2

 
fÀú(Y ) = tr Y Y T Y Y T ‚àí 2tr Y AÃÉY T + AÃÉ .
F

h i
In the analysis that follows, we let A = E AÃÉ , and let its
eigenvalues be Œª1 ‚â• Œª2 ‚â• ¬∑ ¬∑ ¬∑ ‚â• Œªn with corresponding
orthonormal eigenvectors u1 , u2 , . . . , un (such a decomposition is guaranteed since A is symmetric). The standard
stochastic gradient descent update rule for this problem is,
for some step size Œ±k ,
Yk+1 = Yk ‚àí Œ±k ‚àáfÀúk (Y )


= Yk ‚àí 4Œ±k Yk YkT Yk ‚àí AÃÉk Yk ,
where AÃÉk is the sample we use at timestep k.
The low-rank factorization introduces symmetry into the
problem. If we let

	
Op = U ‚àà Rp√óp | U T U = Ip
denote the set of orthogonal matrices in Rp√óp , then fÀú(Y ) =
fÀú(Y U ) for any U ‚àà Op . Previous work has used manifold optimization techniques to solve such symmetric problems (JourneÃÅe et al., 2010). Absil et al. (2008) state that
stochastic gradient descent on a manifold has the general
form
Àú
xk+1 = xk ‚àí Œ±k G‚àí1
xk ‚àáfk (xk ),
where Gx is the matrix such that for all u and v,
uT Gx v = hu, vix ,
where the right side of this equation denotes the Riemannian metric (do Carmo, 1992) of the manifold at x. For (2),
the manifold in question is
M=R

n√óp

/Op ,

which is the quotient manifold of Rn√óp under the orthogonal group action. According to Absil et al. (2008), this
manifold has induced Riemannian metric

hU, V iY = tr U Y T Y V T .
(3)
For Alecton, we are free to pick any Riemannian metric and
step size. Inspired by (3), we pick a new step size parameter
Œ∑, and let Œ±k = 14 Œ∑ and set

hU, V iY = tr U (I + Œ∑Y T Y )V T .

(We can think of this as an interpolation between the flat
metric and the quotient metric.) With this, the SGD update
rule becomes


‚àí1
Yk+1 = Yk ‚àí Œ∑ Yk YkT Yk ‚àí AÃÉk Yk I + Œ∑YkT Yk




= Yk I + Œ∑YkT Yk ‚àí Œ∑ Yk YkT Yk ‚àí AÃÉk Yk
‚àí1
¬∑ I + Œ∑YkT Yk


‚àí1
= I + Œ∑ AÃÉk Yk I + Œ∑YkT Yk
.
For p = 1, choosing a Riemannian metric to use with SGD
results in the same algorithm as choosing an SGD step size
that depends on the iterate Yk . The same update rule would
result if we substituted
‚àí1
1
Œ±k = Œ∑ 1 + Œ∑YkT Yk
4
into the standard SGD update formula. We can think of this
as the manifold results giving us intuition on how to set our
step size.
The reason why selecting this particular step size/metric is
useful in practice is that we can run the simpler update rule


YÃÑk+1 = I + Œ∑ AÃÉk YÃÑk .
(4)
If YÃÑ0 = Y0 , the iteration will satisfy the property that the
column space of Yk will always be equal to the column
space of YÃÑk , (since C(XY ) = C(X) for any invertible
matrix Y , where C(X) denotes the column space of X).
That is, if we just care about computing the column space
of Yk , we can do it using the much simpler update rule
(4). Intuitively, we have transformed an optimization problem operating in the whole space Rn to one operating on
the Grassmannian manifold; one benefit of Alecton is that
we don‚Äôt have to work on the actual Grassmannian, but
get some of the same benefits from a rescaling of the Yk
space. In this specific case, the Alecton update rule is akin
to stochastic power iteration, since it involves a repeated
multiplication by the sample; this would not hold for optimization on other manifolds.
We can use (4) to compute the column space (or ‚Äúangular component‚Äù) of the solution, before then recovering the
rest of the solution (the ‚Äúradial component‚Äù) using averaging. Doing this corresponds to Algorithm 1, Alecton.
Notice that, unlike most iterative algorithms for matrix recovery, Alecton does not require any special initialization
phase and can be initialized randomly.
Analysis Analyzing this algorithm is challenging, as the
low-rank decomposition also introduces symmetrical families of fixed points. Not all these points are globally optimal: in fact, a fixed point will occur whenever
X
YYT =
Œªi ui uTi
i‚ààC

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

Algorithm 1 Alecton: Solve stochastic matrix problem
Require: Œ∑ ‚àà R, K ‚àà N, L ‚àà N, and a sampling distribution A
. Angular component (eigenvector) estimation phase
Select Y0 uniformly in Rn√óm s.t. Y0T Y0 = I.
for k = 0 to K ‚àí 1 do
Select AÃÉk uniformly and independently at random
from the sampling distribution A.
Yk+1 ‚Üê Yk + Œ∑ AÃÉk Yk
end for
‚àí 1
YÃÇ ‚Üê YK YKT YK 2
. Radial component (eigenvalue) estimation phase
R0 ‚Üê 0
for l = 0 to L ‚àí 1 do
Select AÃÉl uniformly and independently at random
from the sampling distribution A.
Rl+1 ‚Üê Rl + YÃÇ T AÃÉl YÃÇ
end for
RÃÑ ‚Üê RL /L
1
return YÃÇ RÃÑ 2

for any set C of size less than p.
One consequence of the non-optimal fixed points is that the
standard proof of SGD‚Äôs convergence, in which we choose
a Lyapunov function and show that this function‚Äôs expectation decreases with time, cannot work. If such a Lyapunov
function were to exist, it would show that no matter where
we initialize the iteration, convergence to a global optimum
will still occur rapidly; this cannot be possible due to the
presence of the non-optimal fixed points. Thus, a standard
statement of global convergence, that convergence occurs
uniformly regardless of initial condition, cannot hold.
We therefore use martingale-based methods to show convergence. Specifically, our attack involves defining a
process xk with respect to the natural filtration Fk of
the iteration, such that xk is a supermartingale, that is
E [xk+1 |Fk ] ‚â§ xk . We then use the optional stopping
theorem (Fleming & Harrington, 1991) to bound both the
probability and rate of convergence of xk , from which we
derive convergence of the original algorithm. We describe
this analysis in the next section.

to measure convergence to the subspace spanned by some
number, q ‚â• p, of the most significant eigenvectors (in
most cases, q = p). For a particular q, let U be the projection matrix onto the subspace spanned by u1 , u2 , . . . , uq ,
and define ‚àÜ, the eigengap, as ‚àÜ = Œªq ‚àí Œªq+1 . We now
let  > 0 be an arbitrary tolerance, and define an angular
success condition for Alecton.
Definition 1. When running the angular phase of Alecton,
we define a quantity œÅk to measure success, and say that
success has occurred at timestep k if
œÅk = minp
z‚ààR

kU Yk zk
kYk zk

2

2

‚â• 1 ‚àí .

This condition requires that all members of the column
space of Yk are close to the desired subspace. We say that
success has occurred by time t if success has occurred for
some timestep k < t. Otherwise, we say the algorithm has
failed, and we let Ft denote this failure event.
To prove convergence, we need to put some restrictions on
the problem. Our theorem requires the following three conditions.
Condition 1 (Alecton Variance). A sampling distribution
A with expected value A satisfies the Alecton Variance
Condition (AVC) with parameters (œÉa , œÉr ) if for any y ‚àà
Rn and for any symmetric matrix W  0 that commutes
with A, if AÃÉ is sampled from A, the following bounds hold:
h
i
2
E y T AÃÉT W AÃÉy ‚â§ œÉa2 tr (W ) kyk
and
E



T

y AÃÉy

2 

4

‚â§ œÉr2 kyk .

In Section 4, we show several models that satisfy AVC.
Condition 2 (Alecton Rank). An instance of Alecton satisfies the Alecton Rank Condition if either p = 1 (rank-1
recovery), or each sample AÃÉ from A is rank-1 (rank-1 sampling).
Most of the noise models we analyze have rank-1 samples,
and so satisfy the rank condition.
Condition 3 (Alecton Step Size). Define Œ≥ as

3. Convergence Analysis
Œ≥=
First, we need a way to define convergence for the angular
phase. For most problems, we want C(Yk ) to be as close as
possible to the span of u1 , u2 , . . . , up . However, for some
cases, this is not what we want. For example, consider the
case where p = 1 but Œª1 = Œª2 . In this case, the algorithm
could not recover u1 , since it is indistinguishable from u2 .
Instead, it is reasonable to expect C(Yk ) to converge to the
span of u1 and u2 . To handle this case, we instead want

2nœÉa2 p2 (p + )
Œ∑.
‚àÜ

This represents a constant step size parameter that is independent of problem scaling. An instance of Alecton satisfies the Alecton Step Size Condition if Œ≥ ‚â§ 1.
Note that the step size condition is only an upper bound on
the step size. This means that, even if we do not know the
problem parameters exactly, we can still choose a feasible

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

step size as long as we can bound them. (However, smaller
step sizes imply slower convergence, so it is a good idea to
choose Œ∑ as large as possible.)

Definition 2. For some p, let R ‚àà Rp√óp be a random matrix the entries of which are independent standard normal
random variables. Define function Zp as

h
‚àí1 i
.
Zp (Œ≥) = 2 1 ‚àí E I + Œ≥p‚àí1 (RT R)‚àí1 
Theorem 1. Assume that we run an instance of Alecton
that satisfies the variance, rank, and step size conditions.
Then for any œá > 0, if we run for t timesteps where
 2
np
4nœÉa2 p2 (p + )
log
,
(5)
t‚â• 2
‚àÜ Œ≥(œá ‚àí Zp (Œ≥))
Œ≥q
then the probability that the angular phase has not succeeded is P (Ft ) ‚â§ œá. Also, after running for L steps in
the radial phase, for any constant œà it holds that


2
p2 œÉr2


.
P RÃÑ ‚àí YÃÇ T AYÃÇ  ‚â• œà ‚â§
Lœà
F
In particular, if œÉa ‚àÜ‚àí1 does not vary with n, this theorem implies convergence of the angular phase with constant probability after O(‚àí1 np3 log n) iterations and in
the same amount of time. Note that since we do not reuse
samples in Alecton, our rates do not differentiate between
sampling and computational complexity, unlike many other
algorithms . We also do not consider numerical error or
overflow: periodically re-normalizing the iterate may be
necessary to prevent these in an implementation of Alecton. Note that if we initialized with the SVD instead of
randomly, we could afford to pick a larger value of Œ≥ since
we start nearer to the optimum; the algorithm will therefore
converge quicker.
Since the upper bound expression uses Zp , which is obscure, we plot it here (Figure 1). We also can make a more
precise statement about the failure rate for p = 1.

0.7
0.6
Zp (Œ≥)

We will now define a useful function, then state our main
theorem that bounds the probability of failure.

Bound on Failure Rate of Alecton
0.8

0.5
0.4
0.3
0.2

p=1
p=2
p=5
p = 20
0.06
0.08

0.1
0

0

0.02

0.04

0.1

Œ≥

Figure 1. Value of Zp computed as average of 105 samples.

failure event fk at each timestep, that occurs if the iterate
gets ‚Äútoo close‚Äù to the unstable fixed points. Next, we define a sequence œÑk , where

 T
Y U Yk 
k


œÑk =  T
Y (Œ≥n‚àí1 p‚àí2 qI + (1 ‚àí Œ≥n‚àí1 p‚àí2 q)U ) Yk 
k

(where |X| denotes the determinant of X); the intuition
here is that œÑk is close to 1 if and only if success occurs,
and close to 0 when failure occurs. We show that, for some
constant R, if neither success nor failure occurs at time k,
E [œÑk+1 |Fk ] ‚â• œÑk (1 + R (1 ‚àí œÑk )) ;

(6)

here, Fk denotes the filtration at time k, which contains
all the events that have occurred up to time k (Fleming &
Harrington, 1991). If we let T denote the first time at which
either success or failure occurs, then this implies that œÑk is
a submartingale for k < T . We use the optional stopping
Theorem (Fleming & Harrington, 1991) (here we state a
discrete-time version).
Definition 3 (Stopping Time). A random variable T is a
stopping time with respect to a filtration Fk if {T ‚â§ k} ‚àà
Fk for all k. That is, we can tell whether T ‚â§ k using only
events that have occurred up to time k.

Lemma 1. For the case of rank-1 recovery,
r 
Œ≥ 
p
p
Œ≥
erfc
‚â§ 2œÄŒ≥.
Z1 (Œ≥) = 2œÄŒ≥ exp
2
2

Theorem 2 (Optional Stopping Theorem). If xk is a martingale (or submartingale) with respect to a filtration Fk ,
and T is a stopping time with respect to the same filtration, then xk‚àßT is also a martingale (resp. submartingale)
with respect to the same filtration, where k ‚àß T denotes the
minimum of k and T . In particular, for bounded submartingales, this implies that E [x0 ] ‚â§ E [xT ].

3.1. Martingale Technique

Applying this to the submartingale œÑk and time T results in

A proof for Theorem 1 and full formal definitions will appear in the appendix of this document, but since the method
is nonstandard for non-convex optimization (although it has
been used in Shamir (2011) to show convergence for convex problems), we will outline it here. First, we define a

E [œÑ0 ] ‚â§ E [œÑT ]
= E [œÑT |FT ] P (fT ) + E [œÑT |¬¨FT ] (1 ‚àí P (fT ))
‚â§ Œ¥P (fT ) + (1 ‚àí P (fT )).

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

This isolates the probability of the failure event occurring.
Next, we return to (6); subtracting 1 from both sides and
taking the logarithm results in
E [log (1 ‚àí œÑk+1 )|Fk ] ‚â§ log(1 ‚àí œÑk ) + log (1 ‚àí RœÑk )

For problems in which the matrix A is of constant rank,
and its eigenvalues do not vary with n, neither kAkF nor
tr (A) will vary with n. In this case, œÉa2 , œÉr2 , and ‚àÜ will
be constants, and the O(‚àí1 n log n) bound on convergence
time will hold.

‚â§ log(1 ‚àí œÑk ) ‚àí RŒ¥.
4.2. Rectangular Entrywise Sampling
So, if we let Wk = log(1 ‚àí œÑk ) + RŒ¥k, then Wk is a supermartingale. We again apply the optional stopping theorem
to produce
E [W0 ] ‚â• E [WT ] = E [log(1 ‚àí œÑT )] + RŒ¥E [T ] .
This isolates the expected value of the stopping time. Finally, we notice that success occurs before time t if T ‚â§ t
and fT does not occur. By the union bound, and Markov‚Äôs
inequality, this implies that

Entrywise sampling also commonly appear in rectangular
matrix recovery problems. In these cases, we are trying to
solve something like
2

minimize kM ‚àí XkF
subject to X ‚àà Rm√ón , rank (X) ‚â§ p.

Pfailure ‚â§ P (fT ) + t‚àí1 E [T ] .

To solve this problem using Alecton, we first convert it into
a symmetric matrix problem by constructing the block matrix


0
M
A=
;
MT 0

Substituting the isolated values for P (fT ) and E [T ] produces the result of Theorem 1.

it is known that recovering the dominant eigenvectors of A
is equivalent to recovering the dominant singular vectors of
M.

The radial part of the theorem follows from an application
of Chebychev‚Äôs inequality to the average of L samples of
yÃÇ T AÃÉyÃÇ ‚Äî we do not devote any discussion to it since averages are already well understood.

Entrywise sampling on M corresponds to choosing a random i ‚àà 1, . . . , m and j ‚àà 1, . . . , n, and then sampling AÃÉ
as
AÃÉ = mnMij (ei eTm+j + em+j eTi ).

4. Application Examples
4.1. Entrywise Sampling
One sampling distribution that arises in many applications (most importantly, matrix completion (CandeÃÄs &
Recht, 2009)) is entrywise sampling. This occurs when the
samples are independently chosen from the entries of A.
Specifically,
AÃÉ = n2 ei eTi Aej eTj ,
where i and j are each independently drawn from 1, . . . , n.
It is standard for these types of problems to introduce a
matrix coherence bound (Jain et al., 2013).
Definition 4. A matrix A ‚àà Rn√ón is incoherent with parameter ¬µ if and only if for every unit eigenvector ui of the
matrix, and for all standard basis vectors ej ,
 T 
ej ui  ‚â§ ¬µn‚àí 21 .
Under an incoherence assumption, we can provide a bound
on the second moment of AÃÉ, which is all that we need to
apply Theorem 1 to this problem.
Lemma 2. If A is incoherent with parameter ¬µ, and AÃÉ is
sampled uniformly from the entries of A, then the distribution of AÃÉ satisfies the Alecton variance condition with
2
2
parameters œÉa2 = ¬µ4 kAkF and œÉr2 = ¬µ4 tr (A) .

In the case where we can bound the entries of M (this is
natural for recommender systems), we can prove the following.
Lemma 3. If M ‚àà Rm√ón satisfies the entry bound
2

2
Mij
‚â§ Œæm‚àí1 n‚àí1 kM kF

for all i and j, then the rectangular entrywise sampling
distribution on M satisfies the Alecton variance condition
2
with parameters œÉa2 = œÉr2 = 2Œæ kM kF .
As above, for problems in which the magnitude of the entries of M is bounded and does not vary with problem size,
our big-O convergence time bound will still hold.
4.3. Trace Sampling
Another common sampling distribution arises from the matrix sensing problem (Jain et al., 2013). In this problem,
we are given the value of v T Aw for unit vectors v and w
selected uniformly at random. (CandeÃÄs et al. (2014) handle this problem for the more general complex case using
Wirtinger flow.) Using this, we can construct an unbiased
sample AÃÉ = n2 vv T AwwT ; this lets us bound the variance.
Lemma 4. If n > 50, and v and w are sampled uniformly
from the unit sphere in Rn , then for any positive semidefinite matrix A, if we let AÃÉ = n2 vv T AwwT , then the distribution of AÃÉ satisfies the Alecton variance condition with
2
2
parameters œÉa2 = 16 kAkF and œÉr2 = 16tr (A) .

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

If the eigenvalues of A do not vary with problem size, our
big-O convergence time bound will be the same.
In some cases of the trace sampling problem, instead of being given samples of the form uT Av, we know uT Au. In
this case, we need to use two independent samples uT1 Au1
and uT2 Au2 , and let u ‚àù u1 + u2 and v ‚àù u1 ‚àí u2 be
two unit vectors which we will use in the above sampling
scheme. Notice that since u1 and u2 are independent and
uniformly distributed, u and v will also be independent and
uniformly distributed (by the spherical symmetry of the underlying distribution). Furthermore, we can compute

Algorithm 2 Alecton One-at-a-time
Require: A sampling distribution A1
for i = 1 to p do
. Run rank-1 Alecton to produce output yi .
yi ‚Üê Alectonp=1 (Ai )
Generate sampling distribution Ai+1 such that, if AÃÉ0
is hsampled
from
i
h i Ai+1 and AÃÉ is sampled from Ai ,
0
E AÃÉ = E AÃÉ ‚àí yi yiT .
end for P
p
T
return
i=1 yi yi

uT Av = (u1 + u2 )T A(u1 ‚àí u2 ) = uT1 Au1 ‚àí uT2 Au2 .
This allows us to use our above trace sampling scheme even
with samples of the form uT Au.
4.4. Subspace Sampling
We now analyze the following more complicated distribution, which arises in subspace tracking (Balzano et al.,
2010). Our matrix A is a rank-r projection matrix, and each
sample consists of some randomly-selected entries from a
randomly-selected vector in its column space. Specifically,
we are given Qv and Rv, where v is selected uniformly at
random from C(A), and Q and R are independent random
diagonal projection matrices with expected value mn‚àí1 I.
With this, we can construct the unbiased sample
2

AÃÉ = rn m

‚àí2

T

Qvv R.

As in the entrywise case, we need to introduce a coherence
constraint to bound the second moment.
Definition 5. A subspace of Rn of dimension q with associated projection matrix U is incoherent with parameter ¬µ
2
if for all standard basis vectors ei , kU ei k ‚â§ ¬µrn‚àí1 .
Using this, we can prove the following facts about the second moment of this distribution.
Lemma 5. The subspace sampling distribution, when sampled from a subspace that is incoherent with parameter ¬µ,
satisfies the Alecton variance condition with parameters
œÉa2 = œÉr2 = r2 (1 + ¬µrm‚àí1 )2 .
Sometimes we are given just one random diagonal projection matrix S, and the product Sv. We can use this to construct a sample of the above form by randomly splitting the
given entries among Q and R in such a way that Q = QS
and R = RS, and Q and R are independent. We can then
construct an unbiased sample AÃÉ = rn2 m‚àí2 QSvv T SR,
which uses only the entries of v that we are given.
4.5. Noisy Sampling
Since our analysis depends only on a variance bound, it
extends naturally to the case in which the values of our

samples themselves are noisy. Using the additive property
of the variance for independent random variables, we can
show that additive noise only increases the variance of the
sampling distribution by a constant amount proportional to
the variance of the noise. Similarly, using the multiplicative property of the variance for independent random variables, multiplicative noise only multiplies the variance of
the sampling distribution by a constant factor proportional
to the variance of the noise. In either case, we can show
that the noisy sampling distribution satisfies AVC. Numerical imprecision can also be modeled in the same way.
4.6. Extension to Higher Ranks
It is possible to use multiple iterations of the rank-1 version
of Alecton to recover additional eigenvalue/eigenvector
pairs of the data matrix A one-at-a-time. This is a standard
technique for using power iteration algorithms to recover
multiple eigenvalues. Sometimes, this may be preferable
to using a single higher-rank invocation of Alecton (for example, we may not know a priori how many eigenvectors
we want). We outline this technique as Algorithm 2. If the
eigenvalues of A are independent of n and p, it will converge in O(‚àí1 pn log n) total SGD update steps.

5. Experiments
We experimentally verify our main claim, that Alecton
does converge quickly for practical datasets. No data was
collected for the radial phase of Alecton, since the performance of averaging is already well understood.
The first experiments were run on symmetric synthetic data
matrices A ‚àà Rn√ón each with ten random eigenvalues
Œªi > 0. Figure 2(a) illustrates the convergence of Alecton with p = q = 1 using three sampling distributions on
datasets with n = 104 . We ran Alecton starting from five
random initial values; the different plotted trajectories illustrate how convergence time can depend on the initial value.
Note that, due to the underlying symmetry of the quadratic
substitution, the multiple runs of the algorithm do not converge to the same value of Y but rather X = Y Y T .

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

0 100 200 300 400 500 600 700 800 900 1000
iterations (thousands)

(a) Angular convergence of three distributions on a synthetic dataset with
Œ∑ = 10‚àí5 .

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Iterations Until Convergence for Varying Rank

0.2

1.6

Iterations Until Convergence for Varying Data Size

Higher Ranks of Netflix Dataset
1.15

3
2.5
2
1.5
1
0.5
0

2

4

6
rank

12

(d) Iterations until convergence of angular phase for recovering higher-rank
estimates on large synthetic dataset.

1.1
rms error

3.5

average
8
10

Convergence Rates for Decreasing Step Size (n = 105 )
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
20
40
60
80
100
iterations (millions)

(c) Angular convergence of entrywise
sampling on a synthetic dataset for a
decreasing step size scheme.

100
iterations (tens of millions)

iterations (tens of millions)

0

Œ∑ = 1 √ó 10‚àí8
Œ∑ = 3 √ó 10‚àí8
Œ∑ = 1 √ó 10‚àí7
0.4 0.6 0.8
1
1.2 1.4
iterations (billions)

(b) Angular convergence of entrywise
sampling on a large synthetic dataset
for different step sizes.

4

0

œÅk

Convergence Rates for n = 106

trace
entrywise
subspace

œÅk

œÅk

Convergence Rates for n = 104
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

10

1.05
1
0.95
0.9

1

1e-01

average
1e+00
problem size n (millions)

(e) Iterations until convergence of angular phase for larger synthetic dataset
sizes.

0.85

0

20

40

train error
test error
60 80 100 120 140 160
runtime (s)

(f) RMS errors for higher-rank Alecton one-at-a-time algorithm.

Figure 2. Experiments ran on a single twelve-core machine (Intel Xeon E5-2697, 2.70GHz) with 256 GB of shared memory.

Figure 2(b) illustrates the performance of Alecton on a
larger dataset with n = 106 as the step size parameter Œ∑
is varied: a smaller value of Œ∑ yields slower, but more accurate convergence. Also, the smaller the value of Œ∑, the
more the initial value seems to affect convergence time.
Figure 2(c) shows convergence of a modified version of
Alecton in which the step size Œ∑ is decreased over time
(proportional to 1/k): we converge to the global optimum,
rather than to a noise floor as in the constant-Œ∑ case. Figure
2(d) shows the angular convergence time of Alecton on a
dataset with n = 104 as the rank of the model changes: the
convergence time increases as the rank increases. Figure
2(e) gives the angular convergence time of Alecton as the
dataset size changes. It illustrates the near-linear relationship between dataset size and convergence time.
Figure 2(f) demonstrates convergence results on real data
from the Netflix Prize problem (Funk, 2006). This problem involves recovering a matrix with 480,189 columns
and 17,770 rows from a training dataset containing
110,198,805 revealed entries. We used the rectangular entrywise distribution described above, and ran Alecton Oneat-a-time to recover the twelve most significant singular
vectors of the matrix, using 107 iterations for each run of
Alecton. Each point in Figure 2(f) represents the absolute
runtime and RMS errors after the recovery of some number
of eigenvectors. This plot illustrates that the runtime of this

algorithm does not increase disastrously as the number of
recovered eigenvectors expands.
5.1. Future Work
The Hogwild! algorithm (Niu et al., 2011) is a parallel,
lock-free version of SGD that performs similarly to sequential SGD on convex problems. It is an open question
whether a Hogwild! version of Alecton converges with a
good rate, but we are optimistic that it will.

6. Conclusion
This paper exhibited Alecton, a stochastic gradient descent algorithm applied to a non-convex low-rank factorized problem; it is similar to the algorithms used in practice to solve a wide variety of problems. We prove that
Alecton converges globally, and provide a rate of convergence. We do not require any special initialization step
but rather initialize randomly. Furthermore, our result depends only on the variance of the samples, and therefore
holds under broad sampling conditions that include both
matrix completion and matrix sensing, and is also able to
take noisy samples into account. We show these results using a martingale-based technique that is novel in the space
of non-convex optimization, and we are optimistic that this
technique can be applied to other problems in the future.

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

Acknowledgments
Thanks to Ben Recht, Mahdi Soltanolkotabi, Joel Tropp,
Kelvin Gu, and Madeleine Udell for helpful conversations.
Thanks also to Ben Recht and Laura Waller for datasets.
The authors acknowledge the support of: DARPA
Contract-Air Force, Xgraphs; Language and Algorithms
for Heterogeneous Graph Streams, FA8750-12-2-0335;
NSF Grant, BIGDATA: Mid-Scale: DA: Collaborative Research: Genomes Galore - Core Techniques, Libraries, and
Domain Specific Languages for High-Throughput DNA
Sequencing, IIS-1247701; NSF Grant, SHF: Large: Domain Specific Language Infrastructure for Biological Simulation Software, CCF-1111943; Dept. of Energy- Pacific Northwest National Lab (PNNL)- Integrated Compiler
and Runtime Autotuning Infrastructure for Power, Energy
and Resilience-Subcontract 108845; NSF Grant EAGERXPS:DSD:Synthesizing Domain Specific Systems-CCF1337375; Stanford PPL affiliates program, Pervasive Parallelism Lab: Oracle, NVIDIA, Huawei, SAP Labs;
DARPA XDATA Program under No. FA8750-12-20335 and DEFT Program under No. FA8750-13-20039; DARPAs MEMEX program and SIMPLEX program; the National Science Foundation (NSF) CAREER
Award under No. IIS-1353606; the Office of Naval Research (ONR) under awards No. N000141210041 and
No. N000141310129; the National Institutes of Health
Grant U54EB020405 awarded by the National Institute of
Biomedical Imaging and Bioengineering (NIBIB) through
funds provided by the trans-NIH Big Data to Knowledge
(BD2K, http://www.bd2k.nih.gov) initiative; the Sloan Research Fellowship; the Moore Foundation; American Family Insurance; Google; and Toshiba.
‚ÄúThe views and conclusions contained herein are those of
the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA, AFRL, NSF, ONR, NIH,
or the U.S. Government.‚Äù

References
Absil, P.-A., Mahony, R., and Sepulchre, R. Optimization
Algorithms on Matrix Manifolds. Princeton University
Press, Princeton, NJ, 2008. ISBN 978-0-691-13298-3.
Agarwal, Alekh, Chapelle, Olivier, Dudƒ±ÃÅk, Miroslav, and
Langford, John. A reliable effective terascale linear
learning system. CoRR, abs/1110.4198, 2011.
Arora, R., Cotter, A., Livescu, K., and Srebro, N. Stochastic optimization for PCA and PLS. In Communication,
Control, and Computing (Allerton), 2012 50th Annual
Allerton Conference on, pp. 861‚Äì868, Oct 2012.
Arora, Raman, Cotter, Andy, and Srebro, Nati. Stochas-

tic optimization of PCA with capped MSG. In Burges,
C.j.c., Bottou, L., Welling, M., Ghahramani, Z., and
Weinberger, K.q. (eds.), Advances in Neural Information
Processing Systems 26, pp. 1815‚Äì1823. 2013.
Balsubramani, Akshay, Dasgupta, Sanjoy, and Freund,
Yoav. The fast convergence of incremental PCA. In
NIPS, pp. 3174‚Äì3182, 2013.
Balzano, Laura, Nowak, Robert, and Recht, Benjamin. Online identification and tracking of subspaces from highly
incomplete information. In Communication, Control,
and Computing (Allerton), 2010 48th Annual Allerton
Conference on, pp. 704‚Äì711. IEEE, 2010.
Bottou, Lon. Large-scale machine learning with stochastic
gradient descent. In Proceedings of COMPSTAT‚Äô2010,
pp. 177‚Äì186. 2010.
Bottou, Lon and Bousquet, Olivier. The tradeoffs of large
scale learning. In IN: ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 20, pp. 161‚Äì
168, 2008.
Burer, Samuel and Monteiro, Renato DC. A nonlinear programming algorithm for solving semidefinite programs
via low-rank factorization. Mathematical Programming,
95(2):329‚Äì357, 2003.
Burer, Samuel and Monteiro, Renato DC. Local minima
and convergence in low-rank semidefinite programming.
Mathematical Programming, 103(3):427‚Äì444, 2005.
CandeÃÄs, Emmanuel, Li, Xiaodong, and Soltanolkotabi,
Mahdi. Phase retrieval via wirtinger flow: Theory and
algorithms. arXiv preprint arXiv:1407.1065, 2014.
CandeÃÄs, Emmanuel J. and Recht, Benjamin. Exact matrix
completion via convex optimization. FoCM, 9(6):717‚Äì
772, 2009. ISSN 1615-3375.
CandeÃÄs, EmmanuelJ. and Li, Xiaodong. Solving quadratic
equations via phaselift when there are about as many
equations as unknowns. FoCM, 14(5):1017‚Äì1026, 2014.
Chen, Caihua, He, Bingsheng, and Yuan, Xiaoming. Matrix completion via an alternating direction method.
IMAJNA, 2011.
do Carmo, M.P. Riemannian Geometry. Mathematics
(BirkhaÃàuser) theory. BirkhaÃàuser Boston, 1992. ISBN
9780817634902.
Duchi, John, Hazan, Elad, and Singer, Yoram. Adaptive
subgradient methods for online learning and stochastic
optimization. J. Mach. Learn. Res., 12:2121‚Äì2159, July
2011.

Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems

Fleming, Thomas R and Harrington, David P. Counting
processes and survival analysis. volume 169, pp. 56‚Äì57.
John Wiley & Sons, 1991.

Niu, Feng, Recht, Benjamin, ReÃÅ, Christopher, and Wright,
Stephen J. Hogwild: A lock-free approach to parallelizing stochastic gradient descent. In In NIPS, 2011.

Funk, Simon. Netflix Update: Try this at Home. 2006.

Oja, Erkki. On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix. Journal of Mathematical Analysis and Applications,
106, 1985.

Gupta, Pankaj, Goel, Ashish, Lin, Jimmy, Sharma, Aneesh,
Wang, Dong, and Zadeh, Reza. WTF: The who to follow
service at twitter. WWW ‚Äô13, pp. 505‚Äì514, 2013.
Hardt, Moritz. Understanding alternating minimization for
matrix completion. In Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on,
pp. 651‚Äì660. IEEE, 2014.
Hardt, Moritz and Price, Eric. The noisy power method:
A meta algorithm with applications. In Ghahramani,
Z., Welling, M., Cortes, C., Lawrence, N.d., and Weinberger, K.q. (eds.), Advances in Neural Information Processing Systems 27, pp. 2861‚Äì2869. Curran Associates,
Inc., 2014.
Horstmeyer, R., Chen, R. Y., Ou, X., Ames, B., Tropp,
J. A., and Yang, C. Solving ptychography with a convex
relaxation. ArXiv e-prints, dec 2014.

Oscar Boykin, Sam Ritchie, Ian O‚ÄôConnell Jimmy Lin.
Summingbird: A framework for integrating batch and
online mapreduce computations. In Proceedings of the
VLDB Endowment, volume 7, pp. 1441‚Äì1451, 20132014.
Recht, Benjamin and ReÃÅ, Christopher. Parallel stochastic gradient algorithms for large-scale matrix completion. Mathematical Programming Computation, 5(2):
201‚Äì226, 2013. ISSN 1867-2949.
Shamir, Ohad. Making gradient descent optimal for
strongly convex stochastic optimization.
CoRR,
abs/1109.5647, 2011.
Shamir, Ohad. A stochastic PCA algorithm with an exponential convergence rate. CoRR, abs/1409.2848, 2014.

Hu, Chonghai, Kwok, James T., and Pan, Weike. Accelerated gradient methods for stochastic optimization and
online learning. In Advances in Neural Information Processing Systems 22, pp. 781‚Äì789, 2009.

Sun, Ruoyu and Luo, Zhi-Quan. Guaranteed matrix completion via non-convex factorization. arXiv preprint
arXiv:1411.8003, 2014.

Jain, Prateek and Netrapalli, Praneeth. Fast exact matrix completion with finite samples. arXiv preprint
arXiv:1411.1087, 2014.

Teflioudi, Christina, Makari, Faraz, and Gemulla, Rainer.
Distributed matrix completion. 2013 IEEE 13th ICDM,
0:655‚Äì664, 2012. ISSN 1550-4786.

Jain, Prateek, Netrapalli, Praneeth, and Sanghavi, Sujay. Low-rank matrix completion using alternating minimization. In Proceedings of the Forty-fifth Annual ACM
STOC, pp. 665‚Äì674. ACM, 2013.

Zou, Hui, Hastie, Trevor, and Tibshirani, Robert. Sparse
principal component analysis. J. Comp. Graph. Stat.,
15:2006, 2004.

John Goes, Teng Zhang, Raman Arora and Lerman, Gilad. Robust stochastic principal component analysis. In
Proceedings of the 17th International Conference on Artificial Intelligence and Statistics, pp. 266‚Äì274, 2014.
JourneÃÅe, M., Bach, F., Absil, P.-A., and Sepulchre, R. Lowrank optimization on the cone of positive semidefinite
matrices. SIAM J. on Optimization, 20(5):2327‚Äì2351,
May 2010.
Keshavan, R.H., Montanari, A., and Oh, Sewoong. Matrix completion from a few entries. Information Theory,
IEEE Transactions on, 56(6):2980‚Äì2998, June 2010.
Mishra, Bamdev, Meyer, Gilles, Bach, Francis, and Sepulchre, Rodolphe. Low-rank optimization with trace norm
penalty. SIAM Journal on Optimization, 23(4):2124‚Äì
2149, 2013.

