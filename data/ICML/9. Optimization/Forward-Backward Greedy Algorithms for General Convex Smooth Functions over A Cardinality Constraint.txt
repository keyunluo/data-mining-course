Forward-Backward Greedy Algorithms for General Convex Smooth Functions
over A Cardinality Constraint

Ji Liu
Department of Computer Sciences, University of Wisconsin-Madison

JI - LIU @ CS . WISC . EDU

Ryohei Fujimaki
Department of Media Analytics, NEC Lab America, Inc.

RFUJIMAKI @ NEC - LABS . COM

Jieping Ye
Department of Computer Science and Engineering, Arizona State University

Abstract
We consider forward-backward greedy algorithms for solving sparse feature selection problems with general convex smooth functions.
A state-of-the-art greedy method, the ForwardBackward greedy algorithm (FoBa-obj) requires
to solve a large number of optimization problems, thus it is not scalable for large-size problems. The FoBa-gdt algorithm, which uses the
gradient information for feature selection at each
forward iteration, significantly improves the efficiency of FoBa-obj. In this paper, we systematically analyze the theoretical properties of
both algorithms. Our main contributions are:
1) We derive better theoretical bounds than existing analyses regarding FoBa-obj for general
smooth convex functions; 2) We show that FoBagdt achieves the same theoretical performance as
FoBa-obj under the same condition: restricted
strong convexity condition. Our new bounds are
consistent with the bounds of a special case (least
squares) and fills a previously existing theoretical gap for general convex smooth functions; 3)
We show that the restricted strong convexity condition is satisfied if the number of independent
samples is more than k̄ log d where k̄ is the sparsity number and d is the dimension of the variable; 4) We apply FoBa-gdt (with the conditional
random field objective) to the sensor selection
problem for human indoor activity recognition
and our results show that FoBa-gdt outperforms
other methods based on forward greedy selection
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

JIEPING . YE @ ASU . EDU

and L1-regularization.

1. Introduction
Feature selection has been one of the most significant issues
in machine learning and data mining. Following the success of Lasso (Tibshirani, 1994), learning algorithms with
sparse regularization (a.k.a. sparse learning) have recently
received significant attention. A classical problem is to estimate a signal β ∗ ∈ Rd from a feature matrix X ∈ Rn×d
and an observation y = Xβ ∗ + noise ∈ Rn , under the
assumption that β ∗ is sparse (i.e., β ∗ has k̄  d nonzero
elements). Previous studies have proposed many powerful
tools to estimate β ∗ . In addition, in certain applications, reducing the number of features has a significantly practical
value (e.g., sensor selection in our case).
The general sparse learning problems can be formulated as
follows (Jalali et al., 2011):
β̄ := arg min : Q(β; X, y)
β

s.t. :

kβk0 ≤ k̄. (1)

where Q(β; X, y) is a convex smooth function in terms of β
such as the least square loss (Tropp, 2004) (regression), the
Gaussian MLE (or log-determinant divergence) (Ravikumar et al., 2011) (covariance selection), and the logistic
loss (Kleinbaum & Klein, 2010) (classification). kβk0 denotes `0 -norm, that is, the number of nonzero entries of
β ∈ Rd . Hereinafter, we denote Q(β; X, y) simply as
Q(β).
From an algorithmic viewpoint, we are mainly interested
in three aspects for the estimator β̂: (i) estimation error
kβ̂ − β̄k; (ii) objective error Q(β̂) − Q(β̄); and (iii) feature
selection error, that is, the difference between supp(β̂) and
F̄ := supp(β̄), where supp(β) is a feature index set corresponding to nonzero elements in β. Since the constraint

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

defines a non-convex feasible region, the problem is nonconvex and generally NP-hard.
There are two types of approaches to solve this problem in the literature. Convex-relaxation approaches replace `0 -norm by `1 -norm as a sparsity penalty. Such
approaches include Lasso (Tibshirani, 1994), Danzig selector (Candès & Tao, 2007), and L1-regularized logistic regression (Kleinbaum & Klein, 2010). Alternative greedy-optimization approaches include orthogonal matching pursuit (OMP) (Tropp, 2004; Zhang, 2009),
backward elimination, and forward-backward greedy
method (FoBa) (Zhang, 2011a), which use greedy heuristic
procedure to estimate sparse signals. Both types of algorithms have been well studied from both theoretical and
empirical perspectives.
FoBa has been shown to give better theoretical properties
than LASSO and Dantzig selector for the least squared loss
function: Q(β) = 12 kXβ−yk2 (Zhang, 2011a). Jalali et al.
(2011) has recently extended it to general convex smooth
functions. Their method and analysis, however, pose computational and theoretical issues. First, since FoBa solves
a large number of single variable optimization problems in
every forward selection step, it is computationally expensive for general convex functions if the sub-problems have
no closed form solution. Second, though they have empirically shown that FoBa performs well for general smooth
convex functions, their theoretical results are weaker than
those for the least square case (Zhang, 2011a). More precisely, their upper bound for estimation error is looser and
their analysis requires more restricted conditions for feature selection and signal recovery consistency. The question of whether or not FoBa can achieve the same theoretical bound in the general case as in the least square case
motivates this work.
This paper addresses the theoretical and computational issues associated with the standard FoBa algorithm (hereinafter referred to as FoBa-obj because it solves single variable problems to minimize the objective in each forward
selection step). We study a new algorithm referred to as
“gradient” FoBa (FoBa-gdt) which significantly improves
the computational efficiency of FoBa-obj. The key difference is that FoBa-gdt only evaluates gradient information
in individual forward selection steps rather than solving a
large number of single variable optimization problems. Our
contributions are summarized as follows.
Theoretical Analysis of FoBa-obj and FoBa-gdt This paper presents three main theoretical contributions. First,
we derive better theoretical bounds for estimation error,
objective error, and feature selection error than existing
analyses for FoBa-obj for general smooth convex functions (Jalali et al., 2011) under the same condition: restricted strong convexity condition. Second, we show that

FoBa-gdt achieves the same theoretical performance as
FoBa-obj. Our new bounds are consistent with the bounds
of a special case, i.e., the least square case, and fills in the
theoretical gap between the general loss (Jalali et al., 2011)
and the least squares loss case (Zhang, 2011a). Our result
also implies an interesting result: when the signal noise ratio is big enough, the NP hard problem (1) can be solved
by using FoBa-obj or FoBa-gdt. Third, we show that the
restricted strong convexity condition is satisfied for a class
of commonly used machine learning objectives, e.g., logistic loss and least square loss, if the number of independent
samples is greater than k̄ log d where k̄ is the sparsity number and d is the dimension of the variable.
Application to Sensor Selection We have applied FoBagdt with the CRF loss function (referred to as FoBa-gdtCRF) to sensor selection from time-series binary location
signals (captured by pyroelectric sensors) for human activity recognition at homes, which is a fundamental problem in smart home systems and home energy management systems. In comparison with forward greedy and L1regularized CRFs (referred to as L1-CRF), FoBa-gdt-CRF
requires the smallest number of sensors for achieving comparable recognition accuracy. Although this paper mainly
focuses on the theoretical analysis for FoBa-obj and FoBagdt, we conduct additional experiments to study the behaviors of FoBa-obj and FoBa-gdt in the long version of this
paper (Liu et al., 2013).
1.1. Notation
Denote ej ∈ Rd as the j th natural basis in the space Rd .
The set difference A − B returns the elements that are in
A but outside of B. Given any integer s > 0, the restricted
strong convexity constants (RSCC) ρ− (s) and ρ+ (s) are
defined as follows: for any ktk0 ≤ s and t = β 0 − β, we
require
ρ+ (s) 2
ρ− (s) 2
ktk ≤ Q(β 0 ) − Q(β) − hOQ(β), ti ≤
ktk .
2
2
Similar definitions can be found in (Bahmani et al., 2011;
Jalali et al., 2011; Negahban et al., 2010; Zhang, 2009).
If the objective function takes the quadratic form Q(β) =
1
2
2 kXβ − yk , then the above definition is equivalent to the
restricted isometric property (RIP) (Candès & Tao, 2005):
ρ− (s)ktk2 ≤ kXtk2 ≤ ρ+ (s)ktk2 ,
where the well known RIP constant can be defined as δ =
max{1 − ρ− (s), ρ+ (s) − 1}. To give tighter values for
ρ+ (.) and ρ− (.), we only require RSCC to hold for all β ∈
Ds := {kβk0 ≤ s | Q(β) ≤ Q(0)} throughout this paper.
Finally we define β̂(F ) as β̂(F ) := arg minsupp(β)⊂F :
Q(β). Note that the problem is convex as long as Q(β) is a
convex function. Denote F̄ := supp(β̄) and k̄ := |F̄ |.

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

We make use of order notation throughout this paper. If a
and b are both positive quantities that depend on n or p, we
write a = O(b) if a can be bounded by a fixed multiple of
b for all sufficiently large dimensions. We write a = o(b)
if for any positive constant φ > 0, we have a ≤ φb for all
sufficiently large dimensions. We write a = Ω(b) if both
a = O(b) and b = O(a) hold.
Algorithm 1 FoBa ( FoBa-obj FoBa-gdt )
Require: δ > 0  > 0
Ensure: β (k)
1: Let F (0) = ∅, β (0) = 0, k = 0,
2: while TRUE do
3:
%% stopping determination
4:

(k)
+ αej ) < δ
if Q(β (k) ) − minα,j ∈F
/ (k) Q(β

5:
6:
7:

kOQ(β (k) )k∞ <  then
break
end if
%% forward step

8:

i(k) = arg mini∈F
/ (k) {minα Q(β

(k)

+ αei )}

(k)
i(k) = arg maxi∈F
)i |
/ (k) : |∇Q(β

9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:

F (k+1) = F (k) ∪ {i(k) }
β (k+1) = β̂(F (k+1) )
δ (k+1) = Q(β (k) ) − Q(β (k+1) )
k =k+1
%% backward step
while TRUE do
(k)
if mini∈F (k+1) Q(β (k) − βi ei ) − Q(β (k) ) ≥
(k)
δ /2 then
break
end if
(k)
i(k) = arg mini Q(β (k) − βi ei )
k =k−1
F (k) = F (k+1) − {i(k+1) }
β (k) = β̂(F (k) )
end while
end while

2. Related Work
Tropp (2004) investigated the behavior of the orthogonal
matching pursuit (OMP) algorithm for the least square
case, and proposed a sufficient condition (an `∞ type condition) for guaranteed feature selection consistency. Zhang
(2009) generalized this analysis to the case of measurement noise. In statistics, OMP is known as boosting
(Buhlmann, 2006) and similar ideas have been explored in
Bayesian network learning (Chickering & Boutilier, 2002).
Shalev-Shwartz et al. (2010) extended OMP to the general
convex smooth function and studied the relationship between objective value reduction and output sparsity. Other

greedy methods such as ROMP (Needell & Vershynin,
2009) and CoSaMp (Needell & Tropp, 2008) were studied
and shown to have theoretical properties similar to those
of OMP. Zhang (2011a) proposed a Forward-backward
(FoBa) greedy algorithm for the least square case, which is
an extension of OMP but has stronger theoretical guarantees as well as better empirical performance: feature selection consistency is guaranteed under the sparse eigenvalue
condition, which is an `2 type condition weaker than the
`∞ type condition. Note that if the data matrix is a Gaussian random matrix, the `2 type condition requires the measurements n to be of the order of O(s log d) where s is the
sparsity of the true solution and d is the number of features,
while the `∞ type condition requires n = O(s2 log d);
see (Zhang & Zhang, 2012; Liu et al., 2012). Jalali et al.
(2011) and Johnson et al. (2012) extended the FoBa algorithm to general convex functions and applied it to sparse
inverse covariance estimation problems.
Convex methods, such as LASSO (Zhao & Yu, 2006) and
Dantzig selector (Candès & Tao, 2007), were proposed for
sparse learning. The basic idea behind these methods is
to use the `1 -norm to approximate the `0 -norm in order
to transform problem (1) into a convex optimization problem. They usually require restricted conditions referred to
as irrepresentable conditions (stronger than the RIP condition) for guaranteed feature selection consistency (Zhang,
2011a). A multi-stage procedure on LASSO and Dantzig
selector (Liu et al., 2012) relaxes such condition, but it is
still stronger than RIP.

3. The Gradient FoBa Algorithm
This section introduces the standard FoBa algorithm, that
is, FoBa-obj, and its variant FoBa-gdt. Both algorithms
start from an empty feature pool F and follow the same
procedure in every iteration consisting of two steps: a forward step and a backward step. The forward step evaluates
the “goodness” of all features outside of the current feature
set F , selects the best feature to add to the current feature
pool F , and then optimizes the corresponding coefficients
of all features in the current feature pool F to obtain a new
β. The elements of β in F are nonzero and the rest are zeros. The backward step iteratively evaluates the “badness”
of all features outside of the current feature set F , removes
“bad” features from the current feature pool F , and recomputes the optimal β over the current feature set F . Both algorithms use the same definition of “badness” for a feature:
the increment of the objective after removing this feature.
Specifically, for any features i in the current feature pool F ,
the “badness” is defined as Q(β − βi ei ) − Q(β), which is
a positive number. It is worth to note that the forward step
selects one and only one feature while the backward step
may remove zero, one, or more features. Finally, both algo-

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

rithms terminate when no “good” feature can be identified
in the forward step, that is, the “goodness” of all features
outside of F is smaller than a threshold.
The main difference between FoBa-obj and FoBa-gdt lies
in the definition of “goodness” in the forward step and their
respective stopping criterion. FoBa-obj evaluates the goodness of a feature by its maximal reduction of the objective
function. Specifically, the “goodness” of feature i is defined as Q(β) − minα Q(β + αei ) (a larger value indicates
a better feature). This is a direct way to evaluate the “goodness” since our goal is to decrease the objective as much
as possible under the cardinality condition. However, it
may be computationally expensive since it requires solving
a large number of one-dimensional optimization problems,
which may or may not be solved in a closed form. To improve computational efficiency in such situations, FoBa-gdt
uses the partial derivative of Q with respect to individual
coordinates (features) as its “goodness’ measure: specifically, the “goodness” of feature i is defined as |∇Q(β)i |.
Note that the two measures of “goodness” are always nonnegative. If feature i is already in the current feature set
F , its “goodness” score is always zero, no matter which
measure to use. We summarize the details of FoBa-obj
and FoBa-gdt in Algorithm 1: the plain texts correspond
to the common part of both algorithms, and the ones with
solid boxes and dash boxes correspond to their individual
parts. The superscript (k) denotes the k th iteration incremented/decremented in the forward/backward steps.
Gradient-based feature selection has been used in a forward greedy method (Zhang, 2011b). FoBa-gdt extends it
to a Forward-backward procedure (we present a detailed
theoretical analysis of it in the next section). The main
workload in the forward step for FoBa-obj is on Step 4,
whose complexity is O(T D), where T represents the iterations needed to solve minα : Q(β (k) + αej ) and D is
the number of features outside of the current feature pool
set F (k) . In comparison, the complexity of Step 4 in FoBa
is just O(D). When T is large, we expect FoBa-gdt to be
much more computationally efficient. The backward steps
of both algorithms are identical. The computational costs
of the backward step and the forward step are comparable
in FoBa-gdt (but not FoBa-obj), because their main work
loads are on Step 10 and Step 21 (both are solving β̂(.))
respectively and the times of running Step 21 is always less
than that of Step 10.

4. Theoretical Analysis
This section first gives the termination condition of Algorithms 1 with FoBa-obj and FoBa-gdt because the number of iterations directly affect the values of RSCC (ρ+ (.),
ρ− (.), and their ratio), which are the key factors in our
main results. Then we discuss the values of RSCC in a

class of commonly used machine learning objectives. Next
we present the main results of this paper, including upper
bounds on objective, estimation, and feature selection errors for both FoBa-obj and FoBa-gdt. We compare our results to those of existing analyses of FoBa-obj and show
that our results fill the theoretical gap between the least
square loss case and the general case.
4.1. Upper Bounds on Objective, Estimation, and
Feature Selection Errors
We first study the termination conditions of FoBa-obj and
FoBa-gdt, as summarized in Theorems 1 and 2 respectively.
+ (1)
2
Theorem 1. Take δ > 4ρ
ρ− (s)2 kOQ(β̄)k∞ in Algorithm 1
with FoBa-obj where s can be any positive integer satisfying s ≤ n and
!
#2
" s
ρ+ (s)
2ρ+ (1)
+1
. (2)
(s − k̄) > (k̄ + 1)
ρ− (s)
ρ− (s)

Then the algorithm terminates at some k ≤ s − k̄.
√

+ (1)
Theorem 2. Take  > 2 ρ2ρ
kOQ(β̄)k∞ in Algorithm 1
− (s)
with FoBa-gdt, where s can be any positive integer satisfying s ≤ n and Eq.(2). Then the algorithm terminates at
some k ≤ s − k̄.

To simply the results, we first assume that the condition number κ(s) := ρ+ (s)/ρ− (s) is bounded (so is
ρ+ (1)/ρ− (s) because of ρ+ (s) ≥ ρ+ (1)). Then both
FoBa-obj and FoBa-gdt terminate at some k proportional to
the sparsity k̄, similar to OMP (Zhang, 2011b) and FoBaobj (Jalali et al., 2011; Zhang, 2011a). Note that the value
of k in Algorithm 1 is exactly the cardinality of F (k) and
the sparsity of β (k) . Therefore, Theorems 1 and 2 imply
that if κ(s) is bounded, FoBa-obj and FoBa-gdt will output a solution with sparsity proportional to that of the true
solution β̄.
Most existing works simply assume that κ(s) is bounded
or have similar assumptions. We make our analysis more
complete by discussing the values of ρ+ (s), ρ− (s), and
their ratio κ(s). Apparently, if Q(β) is strongly convex and
Lipschitzian, then ρ− (s) is bounded from below and ρ+ (s)
is bounded from above, thus restricting the ratio κ(s). To
see that ρ+ (s), ρ− (s), and κ(s) may still be bounded under milder conditions, we consider a common structure for
Q(β) used in many machine learning formulations:
n

Q(β) =

1X
li (Xi. β, yi ) + R(β)
n i=1

(3)

where (Xi. , yi ) is the ith training sample with Xi. ∈ Rd
and yi ∈ R, li (., .) is convex with respect to the first argument and could be different for different i, and both li (., .)

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

and R(.) are twice differentiable functions. li (., .) is typically the loss function, e.g., the quadratic loss li (u, v) =
(u − v)2 in regression problems and the logistic loss
li (u, v) = log(1 + exp{−uv}) in classification problems.
R(β) is typically the regularization, e.g., R(β) = µ2 kβk2 .
Theorem 3. Let s be a positive integer less than n, and
+
λ− , λ+ , λ−
R , and λR be positive numbers satisfying
λ− ≤ ∇21 li (Xi. β, yi ) ≤ λ+ ,

+
2
λ−
R I  ∇ R(β)  λR I

(∇21 li (., .) is the second derivative with respect to the
first argument) for any i and β ∈ Ds . Assume that
−
λ−
> 0 and the sample matrix X ∈ Rn×d
R + 0.5λ
has independent sub-Gaussian isotropic random rows or
columns (in the case
√ of columns, all columns should also
satisfy kX.j k = n). If the number of samples satisfies
n ≥ Cs log d, then
+
ρ+ (s) ≤λ+
R + 1.5λ

(4a)

−
≥λ−
R + 0.5λ
+
λ+
R + 1.5λ
≤ −
λR + 0.5λ−

(4b)

ρ− (s)
κ(s)

=: κ

(4c)

1

hold with high probability , where C is a fixed constant.
Furthermore, define k̄, β̄, and δ (or ) in Algorithm 1 with
FoBa-obj (or FoBa-gdt) as in Theorem 1 (or Theorem 2).
Let
√
s = k̄ + 4κ2 ( κ + 1)2 (k̄ + 1)
(5)
and n ≥ Cs log d. We have that s satisfies (2) and Algorithm 1 with
√ FoBa-obj (or FoBa-gdt) terminates within at
most 4κ2 ( κ + 1)2 (k̄ + 1) iterations with high probability.
Roughly speaking, if the number of training samples is
large enough, i.e., n ≥ Ω(k̄ log d) (actually it could be
much smaller than the dimension d of the train data), we
have the following with high probability: Algorithm 1 with
FoBa-obj or FoBa-gdt outputs a solution with sparsity at
most Ω(k̄) (this result will be improved when the nonzero
elements of β̄ are strong enough, as shown in Theorems 4
and 5); s is bounded by Ω(k̄); and ρ+ (s), ρ− (s), and κ(s)
are bounded by constants. One important assumption is
that the sample matrix X has independent sub-Gaussian
isotropic random rows or columns. In fact, this assumption
is satisfied by many natural examples, including Gaussian
and Bernoulli matrices, general bounded random matrices
whose entries are independent bounded random variables
with zero mean and unit variances. Note that from the definition of “sub-Gaussian isotropic random vectors” (Vershynin, 2011, Definitions 19 and 22), it even allows the
dependence within rows or columns but not both. Another
−
important assumption is λ−
> 0, which means
R + 0.5λ
1
“With high probability” means that the probability converges
to 1 with the problem size approaching to infinity.

−
that either λ−
R or λ is positive (both of them are nonnegative from the convexity assumption). WePcan simply verify
n
that (i) for the quadratic case Q(β) = n1 i=1 (Xi. β−yi )2 ,
we have λ− = 1 and λ−
R = 0; (ii) for the logistic
Pn case with
bounded data matrix X, that is Q(β) = n1 i=1 log(1 +
exp{−Xi. βyi }) + µ2 kβk2 , we have λ−
R = µ > 0 and
λ− > 0 because Ds is bounded in this case.

Now we are ready to present the main results: the upper
bounds of estimation error, objective error, and feature selection error for both algorithms. ρ+ (s), ρ+ (1), and ρ− (s)
are involved in all bounds below. One can simply treat them
as constants in understanding the following results, since
we are mainly interested in the scenario when the number
of training samples is large enough. We omit proofs due to
space limitations (the proofs are provided in the long version of this paper (Liu et al., 2013)). The main results for
FoBa-obj and FoBa-gdt are presented in Theorems 4 and 5
respectively.
Theorem 4. Let s be any number that satisfies (2) and
choose δ as in Theorem 1 for Algorithm 1 with FoBa-obj.
Consider the output β (k) and its support set F (k) . We have
16ρ2+ (1)δ ¯
∆,
ρ2− (s)
2ρ+ (1)δ ¯
∆,
Q(β (k) ) − Q(β̄) ≤
ρ− (s)
ρ− (s)2 (k)
¯
|F − F̄ | ≤|F̄ − F (k) | ≤ 2∆,
8ρ+ (1)2
√
4 ρ (1)δ
¯ := |{j ∈ F̄ − F (k) : |β̄j | <
where γ = ρ−+(s) and ∆
γ}|.
kβ (k) − β̄k2 ≤

Theorem 5. Let s be any number that satisfies (2) and
choose  as in Theorem 2 for Algorithm 1 with FoBa-gdt.
Consider the output β (k) and its support set F (k) . We have
kβ (k) − β̄k2 ≤
Q(β (k) ) − Q(β̄) ≤

82 ¯

∆,
ρ2− (s)
2

¯
∆,
ρ− (s)

ρ− (s)2 (k)
¯
|F − F̄ | ≤|F̄ − F (k) | ≤ 2∆,
8ρ+ (1)2
where γ =

√
2 2
ρ− (s)

¯ := |{j ∈ F̄ − F (k) : |β̄j | < γ}|.
and ∆

Although FoBa-obj and FoBa-gdt use different criteria to
evaluate the “goodness” of each feature, they actually guarantee the same properties. Choose 2 and δ in the order of Ω(k∇Q(β̄)k2∞ ). For both algorithms, we have that
the estimation error kβ (k) − β̄k2 and the objective error
¯
Q(β (k) ) − Q(β̄) are bounded by Ω(∆k∇Q(
β̄)k2∞ ), and
(k)
the feature selection errors |F − F̄ | and |F̄ − F (k) | are
¯ k∇Q(β̄)k∞ and ∆
¯ are two key factors
bounded by Ω(∆).

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

in these bounds. k∇Q(β̄)k∞ roughly represents the noise
¯ defines the number of weak channels of the true
level2 . ∆
solution β̄ in F̄ . One can see that if all channels of β̄ on F̄
are strong enough, that is, |β̄j | > Ω(k∇Q(β̄)k∞ ) ∀j ∈ F̄ ,
¯ turns out to be 0. In other words, all errors (estimation
∆
error, objective error, and feature selection error) become 0,
when the signal noise ratio is big enough. Note that under
this condition, the original NP hard problem (1) is solved
exactly, which is summarized in the following corollary:
Corollary 1. Let s be any number that satisfies (2) and
choose δ (or ) as in Theorem 1 (or 2) for Algorithm 1 with
FoBa-gdt (or FoBa-obj). If
8ρ+ (1)
|β̄j |
≥ 2
ρ− (s)
k∇Q(β̄)k∞

∀j ∈ F̄ ,

then problem (1) can be solved exactly.
One may argue that since it is difficult to set δ or , it is still
hard to solve (1). In practice, one does not have to set δ or
 and only needs to run Algorithm 1 without checking the
stopping condition until all features are selected. Then the
most recent β (k̄) gives the solution to (1).
4.2. Comparison for the General Convex Case
Jalali et al. (2011) analyzed FoBa-obj for general convex
smooth functions and here we compare our results to theirs.
They chose the true model β ∗ as the target rather than the
true solution β̄. In order to simplify the comparison, we assume that the distance between the true solution and the
true model is not too great3 , that is, we have β ∗ ≈ β̄,
supp(β ∗ ) = supp(β̄), and k∇Q(β ∗ )k∞ ≈ k∇Q(β̄)k∞ .
We compare our results from Section 4.1 and the results in
(Jalali et al., 2011). In the estimation error comparison, we
have from our results:
kβ (k) − β ∗ k ≈ kβ (k) − β̄k
¯ 1/2 k∇Q(β̄)k∞ ) ≈ Ω(∆
¯ 1/2 k∇Q(β ∗ )k∞ )
≤Ω(∆
and from the results in (Jalali et al., 2011): kβ (k) − β ∗ k ≤
Ω(k̄k∇Q(β ∗ )k∞ ). Note that ∆1/2 ≤ k̄ 1/2  k̄. Therefore, under our assumptions with respect to β ∗ and β̄, our
analysis gives a tighter bound. Notably, when there are
a large number of strong channels in β̄ (or approximately
¯  k̄.
β ∗ ), we will have ∆
Let us next consider the condition required for feature selection consistency, that is, supp(F(k) ) = supp(F̄) =
2

To see this, we can consider the least square case (with
standard noise assumption and each column of the measuren×d
ment
is normalized to 1): k∇Q(β̄)k∞ ≤
p matrix X ∈ R
−1
Ω( n log dσ) holds with high probability, where σ is the standard derivation.
3
This assumption is not absolutely fair, but holds in many
cases, such as in the least square case, which will be made clear
in Section 4.3.

supp(β ∗ ). We have from our results:
kβ̄j k ≥ Ω(k∇Q(β̄)k∞ ) ∀j ∈ supp(β ∗ )
and from the results in (Jalali et al., 2011):
kβj∗ k ≥ Ω(k̄k∇Q(β ∗ )k∞ ) ∀j ∈ supp(β ∗ ).
When β ∗ ≈ β̄ and k∇Q(β ∗ )k∞ ≈ k∇Q(β̄)k∞ , our
results guarantee feature selection consistency under a
weaker condition.
4.3. A Special Case: Least Square Loss
We next consider the least square case: Q(β) = 12 kXβ −
yk2 and shows that our analysis for the two algorithms in
Section 4.1 fills in a theoretical gap between this special
case and the general convex smooth case.
Following previous studies (Candès & Tao, 2007; Zhang,
2011b; Zhao & Yu, 2006), we assume that y = Xβ ∗ + ε
where the entries in ε are independent random sub-gaussian
variables, β ∗ is the true model with the support set F̄ and
the sparsity number k̄ := |F̄ |, and X ∈ Rn×d is normalized as kX.i k2 = 1 for all columns i = 1, · · · , d. We then
have following inequalities with high probability (Zhang,
2009):
p
k∇Q(β ∗ )k∞ = kX T εk∞ ≤ Ω( n−1 log d), (6)
p
k∇Q(β̄)k∞ ≤ Ω( n−1 log d),
(7)
p
∗
kβ̄ − β k2 ≤ Ω( n−1 k̄),
(8)
q
kβ̄ − β ∗ k∞ ≤ Ω( n−1 log k̄),
(9)
implying that β̄ and β ∗ are quite close when the true model
is really sparse, that is, when k̄  n.
An analysis for FoBa-obj in the least square case (Zhang,
2011a) has indicated that the following estimation error
bound holds with high probability:
kβ (k) − β ∗ k2 ≤ Ω(n−1 (k̄+
p
log d|{j ∈ F̄ : |βj∗ | ≤ Ω( n−1 log d)}|))

(10)

as well as the following
pcondition for feature selection consistency: if |βj∗ | ≥ Ω( n−1 log d) ∀j ∈ F̄ , then
supp(β (k) ) = supp(β ∗ )

(11)

Applying the analysis for general convex smooth cases in
(Jalali et al., 2011) to the least square case, one obtains the
following estimation error bound from Eq. (6)
kβ (k) − β ∗ k2 ≤ Ω(k̄ 2 kOQ(β ∗ )k2∞ ) ≤ Ω(n−1 k̄ 2 log d)
and the following p
condition of feature selection consistency: if |βj∗ | ≥ Ω( k̄n−1 log d) ∀ j ∈ F̄ , then
supp(β (k) ) = supp(β ∗ ).

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

Entrance

Machine learning technologies for smart home systems and
home energy management systems have recently attracted
much attention. Among the many promising applications
such as optimal energy control, emergency alerts for elderly persons living alone, and automatic life-logging, a
fundamental challenge for these applications is to recognize human activity at homes, with the smallest number of
sensors. The data mining task here is to minimize the number of sensors without significantly worsening recognition
accuracy. We used pyroelectric sensors, which return binary signals in reaction to human motion.
Fig. 1 shows our experimental room layout and sensor locations. The numbers represent sensors, and the ellipsoid
around each represents the area covered by it. We used
40 sensors, i.e., we observe a 40-dimensional binary time
series. A single person lives in the room for roughly one
month, and data is collected on the basis of manually tagging his activities into the pre-determined 14 categories
summarized in Table 5. For data preparation reasons, we
use the first 20% (roughly one week) samples in the data,
and divide it into 10% for training and 10% for testing. The
numbers of training and test samples are given in Table 1.
Pyroelectric sensors are preferable over cameras for two
practical reasons: cameras tend to create a psychological
barrier and pyroelectric sensors are much cheaper and easier to implement at homes. Such sensors only observe

32
40
Hall

11 10

9

8

1
13

12

35

23
19 3

Living Room

39

38

7

2
6

Bath

Powder
Room

5. Application: Sensor Selection for Human
Activity Recognition

33
34

which is consistent with the results in Eq. (10). The last
inequality in Theorem 5 also implies that feature selectionpconsistency is guaranteedp
as well, as long as |β̄j | >
Ω( n−1 log d) (or |βj∗ | > Ω( n−1 log d)) for all j ∈ F̄ .
This requirement agrees with the results in Eq. (11).

30

Bed Room

Our results in Theorems 4 and 5 bridge this gap when combined with Eqs. (8) and (9). The first inequalities in Theorems 4 and 5 indicate that
kβ (k) − β ∗ k2 ≤ (kβ (k) − β̄k + kβ̄ − β ∗ k)2

≤Ω n−1 (k̄ + log d | {j ∈ F̄ − F (k) :

p
[from Eq. (8)]
|β̄j | < Ω(n−1/2 log d)}|)

≤Ω n−1 (k̄ + log d | {j ∈ F̄ − F (k) :

p
[from Eq. (9)]
|βj∗ | < Ω(n−1/2 log d)}|)

31

Closet

Closet

One can observe that the general analysis gives a looser
bound for estimation error and requires a stronger condition
for feature selection consistency than the analysis for the
special case.

24

36
37
29

Master Bed Room

22

25

28

21

26

27

Kitchen

20

4

5

18

14
15

16

17

Balcony

Figure 1. Room layout and sensor locations.

noisy binary location information. This means that, for
high recognition accuracy, history (sequence) information
must be taken into account. The binary time series data
follows a linear-chain conditional random field (CRF) (Lafferty et al., 2001; Sutton & McCallum, 2006). Linear-chain
CRF gives a smooth and convex loss function; see the long
version of this paper (Liu et al., 2013) for more details of
CRF.
Our task then is sensor selection on the basis of noisy binary time series data, and to do this we apply our FoBagdt-CRF (FoBa-gdt with CRF objective function). Since it
is very expensive to evaluate the CRF objective value and
its gradient, FoBa-obj becomes impractical in this case (a
large number of optimization problems in the forward step
make it computationally very expensive). Here, we consider a sensor to have been “used” if at least one feature related to it is used in the CRF. Note that we have 14 activitysignal binary features (i.e., indicators of sensor/activity simultaneous activations) for each single sensor, and therefore we have 40 × 14 = 560 such features in total. In
addition, we have 14 × 14 = 196 activity-activity binary
features (i.e., indicators of the activities at times t − 1 and
t). Here we only enforced sparsity on the first type of features.
First we compare FoBa-gdt-CRF with Forward-gdt-CRF
(Forward-gdt with CRF loss function) and L1-CRF4 in
terms of test recognition error over the number of sensors
selected (see the top of Fig. 2). We can observe that
• The performance for all methods improves when the um4
L1-CRF solves the optimization problem with CRF loss +
L1 regularization. Since it is difficult to search the whole L1 regularization parameter value space, we investigated a number of
discrete values.

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint
Table 1. Activities in the sensor data set
ID

Activity

train / test samples

1
2
3
4
5
6
7
8
9
10
11
12
13
14

Sleeping
Out of Home (OH)
Using Computer
Relaxing
Eating
Cooking
Showering (Bathing)
No Event
Using Toilet
Hygiene (brushing teeth, etc.)
Dishwashing
Beverage Preparation
Bath Cleaning/Preparation
Others

81K / 87K
66K / 42K
64K / 46K
25K / 65K
6.4K / 6.0K
5.2K / 4.6K
3.9K / 45.0K
3.4K / 3.5K
2.5K / 2.6K
1.6K / 1.6K
1.5K /1.8K
1.4K / 1.4K
0.5K / 0.3K
6.5K / 2.1K

Total

-

270K / 270K

Table 2. Sensor IDs selected by FoBa-gdt-CRF.
# of sensors=10
# of sensors=15

{1, 4, 5, 9, 10, 13, 19, 28, 34, 38}
{# of sensors=10} + {2, 7, 36, 37, 40}

are well recognized in both cases. In other words, FoBagdt-CRF is likely to select sensors (features) which contribute to the discrimination of high frequency activities.
• The error rates for activities {5, 7, 9} significantly improve when the number of sensors increases from 10 to
15. Activities 7 and 9 are Showering and Using Toilet,
and the use of additional sensors {36, 37, 40} seems to
have contributed to this improvement. Also, a dinner table was located near sensor 2, which is why the error rate
w.r.t. activity 5 (Eating) significantly decreases from the
case # of sensors=10 to # of sensors=15 by including
sensor 2.

6. Conclusion

Figure 2. Top: comparisons of FoBa-gdt-CRF, Forward-gdt-CRF
and L1-CRF. Bottom: test error rates (FoBa-gdt-CRF) for individual activities.

ber of sensors increases.
• FoBa-gdt-CRF and Forward-gdt-CRF achieve comparable performance. However, FoBa-gdt-CRF reduces the
error rate slightly faster, in terms of the number of sensors.
• FoBa-gdt-CRF achieves its best performance with 14-15
sensors while Forward-gdt-CRF needs 17-18 sensors to
achieve the same error level. We obtain sufficient accuracy by using fewer than 40 sensors.
• FoBa-gdt-CRF consistently requires fewer features than
Forward-gdt-CRF to achieve the same error level when
using the same number of sensors.
We also analyze the test error rates of FoBa-gdt-CRF for
individual activities. We consider two cases with the number of sensors being 10 and 15, and report their test error
rates for each individual activity in the bottom of Fig. 2.
We observe that:
• The high frequency activities (e.g., activities {1,2,3,4})

This paper considers two forward-backward greedy methods, including a state-of-the-art greedy method FoBa-obj
and its variant FoBa-gdt which is more efficient than FoBaobj, for solving sparse feature selection problems with
general convex smooth functions. We systematically analyze the theoretical properties of both algorithms. Our
main contributions include: (i) We derive better theoretical
bounds for FoBa-obj and FoBa-gdt than existing analyses
(Jalali et al., 2011) for general smooth convex functions.
Our result also suggests that the NP hard problem (1) can
be solved by FoBa-obj and FoBa-gdt if the signal noise ratio is big enough; (ii) Our new bounds are consistent with
the bounds of a special case (least squares) (Zhang, 2011a)
and fill a previously existing theoretical gap for general
convex smooth functions (Jalali et al., 2011); (iii) We provide the condition to satisfy the restricted strong convexity
condition in commonly used machine learning problems;
(iv) We apply FoBa-gdt (with the conditional random field
objective) to the sensor selection problem for human indoor activity recognition and our results show that FoBagdt can successfully remove unnecessary sensors and is
able to select more valuable sensors than other methods (including the ones based on forward greedy selection and L1regularization). In the future work, we plan to extend FoBa
algorithms to minimize a general convex smooth function
over a low rank constraint.

7. Acknowledgements
We would like to sincerely thank Professor Masamichi Shimosaka of the University of Tokyo for providing sensor
data collected in his research and Professor Stephen Wright
of the University of Wisconsin-Madison for constructive
comments and helpful advice. The majority of the work
reported here was done during the internship of the first author at NEC Laboratories America, Cupertino, CA.

Forward-Backward Greedy Algorithms for General Convex Smooth Functions over A Cardinality Constraint

References
Bahmani, S., Boufounos, P., and Raj, B. Greedy sparsityconstrained optimization. ASILOMAR, pp. 1148–1152,
2011.
Buhlmann, P. Boosting for high-dimensional linear models. Annals of Statistics, 34:559–583, 2006.
Candès, E. J. and Tao, T. Decoding by linear programming. IEEE Transactions on Information Theory, 51
(12):4203–4215, 2005.
Candès, E. J. and Tao, T. The Dantzig selector: statistical estimation when p is much larger than n. Annals of
Statistics, 35(6):2313–2351, 2007.
Chickering, D. M. and Boutilier, C. Optimal structure identification with greedy search. Journal of Machine Learning Research, 3:507–554, 2002.
Jalali, A., Johnson, C. C., and Ravikumar, P. D. On learning
discrete graphical models using greedy methods. NIPS,
2011.
Johnson, C. C., Jalali, A., and Ravikumar, P. D. Highdimensional sparse inverse covariance estimation using
greedy methods. Journal of Machine Learning Research
- Proceedings Track, 22:574–582, 2012.
Kleinbaum, D. G. and Klein, M. Logistic regression.
Statistics for Biology and Health, pp. 103–127, 2010.
Lafferty, J. D., McCallum, A., and Pereira, F. C. N. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. ICML, pp. 282–289,
2001.

Ravikumar, P., Wainwright, M. J., Raskutti, G., and Yu,
B. High-dimensional covariance estimation by minimizing `1 -penalized log-determinant divergence. Electronic
Journal of Statistics, 5:935–980, 2011.
Shalev-Shwartz, S., Srebro, N., and Zhang, T. Trading accuracy for sparsity in optimization problems with sparsity constraints. SIAM Journal on Optimization, 20(6):
2807–2832, 2010.
Sutton, C. and McCallum, A. An introduction to conditional random fields for relational learning. Introduction
to Statistical Relational Learning, pp. 93–128, 2006.
Tibshirani, R. Regression shrinkage and selection via the
lasso. Journal of the Royal Statistical Society, Series B,
58:267–288, 1994.
Tropp, J. A. Greed is good: algorithmic results for sparse
approximation. IEEE Transactions on Information Theory, 50(10):2231–2242, 2004.
Vershynin, R. Introduction to the non-asymptotic analysis
of random matrices. arXiv:1011.3027, 2011.
Zhang, C.-H. and Zhang, T. A general theory of concave regularization for high dimensional sparse estimation problems. Statistical Science, 27(4), 2012.
Zhang, T. On the consistency of feature selection using
greedy least squares regression. Journal of Machine
Learning Research, 10:555–568, 2009.
Zhang, T. Adaptive forward-backward greedy algorithm
for learning sparse representations. IEEE Transactions
on Information Theory, 57(7):4689–4708, 2011a.

Liu, J., Wonka, P., and Ye, J. A multi-stage framework
for dantzig selector and LASSO. Journal of Machine
Learning Research, 13:1189–1219, 2012.

Zhang, T. Sparse recovery with orthogonal matching pursuit under RIP. IEEE Transactions on Information Theory, 57(9):6215–6221, 2011b.

Liu, J., Fujimaki, R., and Ye, J. Forward-backward greedy
algorithms for general convex smooth functions over a
cardinality constraint. arXiv:1401.0086, 2013.

Zhao, P. and Yu, B. On model selection consistency of
lasso. Journal of Machine Learning Research, 7:2541–
2563, 2006.

Needell, D. and Tropp, J. A. CoSaMP: Iterative signal
recovery from incomplete and inaccurate samples. Applied and Computational Harmonic Analysis, 26:301–
321, 2008.
Needell, D. and Vershynin, R. Uniform uncertainty principle and signal recovery via regularized orthogonal
matching pursuit. Foundations of Computational Mathematics, 9(3):317–334, 2009.
Negahban, S., Ravikumar, P. D., Wainwright, M. J., and Yu,
B. A unified framework for high-dimensional analysis
of M-estimators with decomposable regularizers. CoRR,
abs/1010. 2731, 2010.

