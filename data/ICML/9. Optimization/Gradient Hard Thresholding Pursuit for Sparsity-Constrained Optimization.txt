Gradient Hard Thresholding Pursuit for Sparsity-Constrained Optimization

Xiao-Tong Yuan
XTYUAN 1980@ GMAIL . COM
Department of Statistical Science, Cornell University, Ithaca, NY 14853, USA
Dept. of Statistics & Biostatistics, Dept. of Computer Science, Rutgers University, Piscataway, NJ 08854, USA
Ping Li
PINGLI @ STAT. RUTGERS . EDU
Dept. of Statistics & Biostatistics, Dept. of Computer Science, Rutgers University, Piscataway, NJ 08854, USA
Tong Zhang
Dept. of Statistics & Biostatistics, Rutgers University, Piscataway, NJ 08854, USA

Abstract

learning (Jalali et al., 2011) where the likelihood of samples drawn from an underlying probabilistic model is used
to measure data fidelity.

Hard Thresholding Pursuit (HTP) is an iterative
greedy selection procedure for finding sparse solutions of underdetermined linear systems. This
method has been shown to have strong theoretical guarantees and impressive numerical performance. In this paper, we generalize HTP from
compressed sensing to a generic problem setup
of sparsity-constrained convex optimization. The
proposed algorithm iterates between a standard
gradient descent step and a hard truncation step
with or without debiasing. We prove that our
method enjoys the strong guarantees analogous
to HTP in terms of rate of convergence and
parameter estimation accuracy. Numerical evidences show that our method is superior to the
state-of-the-art greedy selection methods when
applied to learning tasks of sparse logistic regression and sparse support vector machines.

1. Introduction
In this paper, we focus on the following generic sparsityconstrained optimization problem
min f (x),

x∈Rp

s.t. ∥x∥0 ≤ k,

TZHANG @ STAT. RUTGERS . EDU

(1)

where f : Rp 7→ R is a smooth and convex cost function. Among others, several examples falling into this
model include: (i) Sparsity-constrained linear regression
model (Tropp & Gilbert, 2007) where the residual error is
used to measure data reconstruction error; (ii) Sparsityconstrained logistic regression model (Bahmani et al.,
2013) where the sigmoid loss is used to measure prediction error; (iii) Sparsity-constrained graphical models
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

However, due to the non-convex cardinality constraint,
the problem (1) is generally NP-hard even for quadratic
cost functions (Natarajan, 1995). Thus, one must instead seek approximate solutions. In particular, the special case of (1) in least square regression models has
gained significant attention in the area of compressed sensing (Donoho, 2006). A vast body of greedy selection
algorithms for compressing sensing have been proposed
including matching pursuit (Mallat & Zhang, 1993), orthogonal matching pursuit (Pati et al., 1993), compressive
sampling matching pursuit (Needell & Tropp, 2009), hard
thresholding pursuit (Foucart, 2011), iterative hard thresholding (Blumensath & Davies., 2009) and subspace pursuit (Dai & Milenkovic, 2009). Those methods successively select the locations of nonzero entries and estimate
their values via exploring the residual error from the previous iteration. Comparing to first-order convex optimization methods developed for ℓ1 -regularized sparse learning (Beck & Teboulle, 2009; Langford et al., 2009), those
greedy selection algorithms often exhibit similar accuracy
guarantees but more attractive computational efficiency.
The least square error used in compressed sensing, however, is not an appropriate measure of discrepancy in a variety of applications beyond signal processing. For example,
in statistical machine learning the log-likelihood function
is commonly used in logistic regression problems (Bishop,
2006) and graphical models learning (Jalali et al., 2011;
Ravikumar et al., 2011). It is thus desirable to investigate theory and algorithms applicable to a broader class
of sparsity-constrained learning problems as given in (1).
To this end, several forward selection algorithms have
been proposed to select nonzero entries in a sequential
fashion (Kim & Kim, 2004; Shalev-Shwartz et al., 2010;
Yuan & Yan, 2013). This category of methods date back

Gradient Hard Thresholding Pursuit

to the Frank-Wolfe method (Frank & Wolfe, 1956). The
forward greedy selection method has also been generalized to minimize a convex objective over the linear hull
of a collection of atoms (Yuan & Yan, 2013). To make the
greedy selection procedure more adaptive, Zhang (2008)
proposed a forward-backward algorithm which takes backward steps adaptively whenever beneficial. Jalali et al.
(2011) applied this forward-backward selection algorithm
to learn the structure of a sparse graphical model. More
recently, Bahmani et al. (2013) proposed a gradient hardthresholding method which generalizes compressive sampling matching pursuit (Needell & Tropp, 2009) from compressed sensing to general sparsity-constrained optimization problems. The hard-threshholding-type methods
have also been shown to be statistically and computationally efficient for sparse principal component analysis (Yuan & Zhang, 2013; Ma, 2013).
1.1. Our contribution
In this paper, inspired by the success of Hard Thresholding Pursuit (HTP) (Foucart, 2011; 2012) in compressed
sensing, we propose the Gradient Hard Thresholding Pursuit (GraHTP) method to encompass the sparse estimation
problems arising from applications with general nonlinear models. At each iteration, GraHTP performs standard
gradient descent followed by a hard truncation operation
which first selects the top k (in magnitude) entries of the resultant vector and then (optionally) conducts debiasing on
the selected entries. We prove that under mild conditions
GraHTP (with or without debiasing) has strong theoretical guarantees analogous to HTP in terms of convergence
rate and parameter estimation accuracy. We have applied
GraHTP to two popular machine learning models, sparse
logistic regression and sparse support vector machines, verifying that the guarantees of HTP are valid for these models. Empirically we demonstrate that GraHTP is comparable or superior to the state-of-the-art greedy selection methods in these two sparse learning models.
1.2. Notation and outline
Notation: In the following, x ∈ Rp is a vector and F is an
index set. We denote [x]i its i-th entry, xF the restriction of
x to index set F , and xk the restriction of x to the top k (in
modulus) entries, supp(x) the index set of non-zero entries
of x, supp(x,√k) the index set of its top k (in modulus) en∑d
tries, ∥x∥ = x⊤ x the Euclidean norm, ∥x∥1 = i=1 |xi |
the ℓ1 -norm, and ∥x∥0 the number of nonzero of vector x.
Outline: We present in §2 the GraHTP algorithm. The convergence guarantees of GraHTP are provided in §3. The
specializations of GraHTP in logistic regression and support vector machines are investigated in §4. Monte-Carlo
simulations and experimental results on real data are pre-

sented in §5. Finally, we conclude the paper in §6.

2. Gradient Hard Thresholding Pursuit
GraHTP is an iterative greedy selection procedure for approximately optimizing the non-convex problem (1). A
high level summary of GraHTP is described in the top panel
of Algorithm 1. The procedure generates a sequence of
intermediate k-sparse vectors x(0) , x(1) , . . . from an initial
sparse approximation x(0) (typically x(0) = 0). At the t-th
iteration, the first step (S1), x̃(t) = x(t−1) − η∇f (x(t−1) ),
computes the gradient descent at the point x(t−1) with stepsize η. Then in the second step (S2), the k coordinates
of the vector x̃(t) that have the largest magnitude are chosen as the support in which pursuing the minimization will
be most effective. In the third step (S3), we find a vector with this support that minimizes the objective function, which becomes x(t) for the next iteration. This last
step, often referred to as debiasing, has been shown to improve the performance in other algorithms too (see, e.g.,
Shalev-Shwartz et al., 2010). The iterations continue until the algorithm reaches a terminating condition, e.g., on
the change of the cost function or the change of the estimated minimum from the previous iteration. A natural
criterion here is F (t) = F (t−1) (see S2 for the definition of
F (t) ), since then x(τ ) = x(t) for all τ ≥ t, although there
is no guarantee that this should occur. It will be assumed
throughout the paper that the cardinality k is known. In
practice this quantity may be regarded as a tuning parameter of the algorithm via, for example, cross-validations.
In the standard form of GraHTP, the debiasing step S3 requires to minimize f (x) over the support F (t) . If this step
is judged too costly, we may consider instead a fast variant of GraHTP, where the debiasing is replaced by a simple
(t)
truncation operation x(t) = x̃k . This leads to the Fast
GraHTP (FGraHTP) described in the bottom panel of Algorithm 1. It is interesting to note that FGraHTP can be
regarded as a projected gradient descent procedure for optimizing the non-convex problem (1). Its per-iteration computational overload is almost equal to that of the standard
gradient descent procedure. While in this paper we only
study the Fast GraHTP outlined in Algorithm 1, we should
mention that other fast variants of GraHTP can also be considered. For instance, to reduce the computational cost of
S3, we can take a restricted Newton step or a restricted gradient descent step to calculate x(t) .
We close this section by pointing out that, in the special
case where the cost function is the squared error f (x) =
1
2
2 ∥y − Ax∥ , GraHTP reduces to HTP (Foucart, 2011).
Specifically, the gradient descent step S1 reduces to x̃(t) =
x(t−1) + ηA⊤ (y − Ax(t−1) ) and the debiasing step S3 reduces to the orthogonal projection x(t) = arg min{∥y −
Ax∥, supp(x) ⊆ F (t) }. In the meanwhile, FGraHTP re-

Gradient Hard Thresholding Pursuit

duces to IHT (Blumensath & Davies., 2009) in which the
iteration becomes x(t) = (x(t−1) + ηA⊤ (y − Ax(t−1) ))k .
Algorithm 1: Gradient Hard Thresholding Pursuit
(GraHTP).
Initialization: x(0) with ∥x(0) ∥0 ≤ k (typically
x(0) = 0), t = 1.
Output: x(t) .
repeat
(S1) Compute x̃(t) = x(t−1) − η∇f (x(t−1) );
(S2) Let F (t) = supp(x̃(t) , k) be the indices of
x̃(t) with the largest k absolute values;
(S3) Compute
x(t) = arg min{f (x), supp(x) ⊆ F (t) };
t = t + 1;
until halting condition holds;
——————–⋆ Fast GraHTP ⋆——————–
repeat
Compute x̃(t) = x(t−1) − η∇f (x(t−1) );
(t)
Compute x(t) = x̃k as the truncation of x̃(t)
with top k (in magnitude) entries preserved;
t = t + 1;
until halting condition holds;

C(s, ζ, ρs ) and the conditions of restricted strong convexity/smoothness which are extensively used in the
analysis of previous greedy selection methods (Zhang,
2008; Shalev-Shwartz et al., 2010; Yuan & Yan, 2013;
Bahmani et al., 2013).
Definition 2 (Restricted Strong Convexity/Smoothness).
For any integer s > 0, we say f (x) is restricted ms strongly convex and Ms -strongly smooth if there exist
∃ms , Ms > 0 such that for all ∥x − y∥0 ≤ s,
ms
Ms
∥x − y∥2 ≤ ∆f (x, y) ≤
∥x − y∥2 ,
2
2

(2)

where ∆f (x, y) := f (x) − f (y) − ⟨∇f (y), x − y⟩ is the
Bregman divergence associated with f for x, y.
The following proposition connects condition C(s, ζ, ρs )
to the restricted strong convexity/smoothness conditions.
Proposition 1. Assume that f is a differentiable function.
(a) If f satisfies Condition C(s, ζ, ρs ), then for all ∥x −
y∥0 ≤ s the following two inequalities hold:
1 + ρs
1 − ρs
∥x−y∥ ≤ ∥∇F f (x)−∇F f (y)∥ ≤
∥x−y∥,
ζ
ζ
1 + ρs
∥x − y∥2 .
2ζ
(b) If f is ms -strongly convex and Ms -strongly smooth,
then f satisfies condition C(s, ζ, ρs ) with any
√
ζ < 2ms /Ms2 , ρs = 1 − 2ζms + ζ 2 Ms2 .
∆f (x, y) ≤

3. Theoretical Analysis
In this section, we analyze the theoretical properties of
GraHTP and FGraHTP. We first study the convergence of
these two algorithms. Then we investigate their sparse recovery performance in terms of convergence rate and parameter estimation accuracy. The technical proofs of the
main theoretical results can be found in an extended version of this paper online available at arxiv:1311.5750.
We require the following key technical condition under
which the convergence and parameter estimation accuracy
of GraHTP/FGraHTP can be guaranteed. To simplify the
notation in the following analysis, we abbreviate ∇F f =
(∇f )F and ∇s f = (∇f )s (Recall the definition of xF and
xs of a vector x in §1.2).
Definition 1 (Condition C(s, ζ, ρs )). For any integer s >
0, we say f satisfies Condition C(s, ζ, ρs ) if for any index
set F with cardinality |F | ≤ s and any x, y with supp(x) ∪
supp(y) ⊆ F , the following inequality holds for some ζ >
0 and 0 < ρs < 1:
∥x − y − ζ∇F f (x) + ζ∇F f (y)∥ ≤ ρs ∥x − y∥.
Remark 1. In the special case where f (x) is least square
loss function and ζ = 1, Condition C(s, ζ, ρs ) reduces to
the well-known Restricted Isometry Property (RIP) condition in compressed sensing.
We may establish the connections between condition

Remark 2. Part (a) of Proposition 1 indicates that if
Condition C(s, ζ, ρs ) holds, then f is strongly smooth.
Part (b) of Proposition 1 shows that the strong smoothness/convexity conditions imply Condition C(s, ζ, ρs ).
Therefore, Condition C(s, ζ, ρs ) is no stronger than the
strong smoothness/conveixy conditions.
3.1. Convergence
We now analyze the convergence properties of GraHTP and
FGraHTP. First and foremost, we make a simple observation about GraHTP: since there is only a finite number
of subsets of {1, ..., p} of size k, the sequence defined by
GraHTP is eventually periodic. The importance of this observation lies in the fact that, as soon as the convergence
of GraHTP is established, then we can certify that the limit
is exactly achieved after a finite number of iterations. We
establish below the convergence of GraHTP and FGraHTP
under proper conditions.
Theorem 1. Assume f satisfies Condition C(2k, ζ, ρ2k )
and the step-size η < ζ/(1 + ρ2k ). Then the sequence
{x(t) } defined by GraHTP terminates after a finite number
of iterations. Moreover, the sequence {f (x(t) )} defined by
FGraHTP converges.

Gradient Hard Thresholding Pursuit

Remark 3. Since ρ2k ∈ (0, 1), we have that the convergence results in Theorem 1 hold whenever the step-size
η < ζ/2. If f is m2k -strongly convex and M2k -strongly
smooth, then from Part(b) of Proposition 1, we know that
2
Theorem 1 holds if we choose the step-size η < m2k /M2k
.
3.2. Sparse recovery performance
The following theorem is our main result on the parameter
estimation accuracy of GraHTP and FGraHTP when the
target solution is sparse.
Theorem 2. Let x̄ be an arbitrary k̄-sparse vector and k ≥
k̄. Let s = 2k + k̄. Assume f satisfies Condition C(s, ζ, ρs )
and the step size η < ζ.
√
(a) If µ1 = 2(1 − η/ζ + (2 − η/ζ)ρs )/(1 − ρs ) < 1, then
at iteration t, GraHTP will recover an approximation x(t)
satisfying
∥x(t) − x̄∥ ≤ µt1 ∥x(0) − x̄∥ +

2η + ζ
∥∇k f (x̄)∥.
(1 − µ1 )(1 − ρs )

(b) If µ2 = 2(1 − η/ζ + (2 − η/ζ)ρs ) < 1, then at iteration
t, FGraHTP will recover an approximation x(t) satisfying
∥x(t) − x̄∥ ≤ µt2 ∥x(0) − x̄∥ +

2η
∥∇s f (x̄)∥.
1 − µ2

Note that we did not make any attempt to optimize the constants (µ1 , µ2 ) in Theorem 2, which are relatively loose. In
the following discussion, we ignore the constants and focus
on the main message Theorem 2 conveys.
Part (a) of Theorem 2 indicates that under proper conditions, the estimation error of GraHTP to a target sparse vector x̄ is determined by the multiple of ∥∇k f (x̄)∥, and the
rate of convergence before reaching this error level is geometric. Particularly, if the sparse vector x̄ is sufficiently
close to an unconstrained minimum of f then the estimation error floor is negligible because ∇k f (x̄) has small
magnitude. In the ideal case where ∇f (x̄) = 0 (i.e., the
sparse vector x̄ is an unconstrained minimum of f ), this result guarantees that we can recover x̄ to arbitrary precision.
In this case, if we further assume that η satisfies the conditions in Theorem 1, then exact recovery is guaranteed in a
finite number of iterations which is at most
⌈ (
)⌉
ln mini |[x̄]i |/∥x(0) − x̄∥
.
T =
ln µ1
Indeed, we have ∥x(T ) − x̄∥ ≤ mini |[x̄]i | and together
with k ≥ k̄ we know that supp(x̄) ⊆ supp(x(T ) ), and thus
x(T ) = x̄ due to the global optimality of x̄.
Part (b) of Theorem 2 shows that FGraHTP enjoys a similar
geometric rate of convergence and the estimation error is
determined by the multiple of ∥∇s f (x̄)∥ with s = 2k + k̄.

The shrinkage rates µ1 < 1 (see Part (a)) and µ2 < 1
(see Part (b)) respectively control the convergence rate of
GraHTP and FGraHTP. For GraHTP, the condition µ1 < 1
implies
√
√
((2 2 + 1)ρs + 2 − 1)ζ
√
√
η>
.
(3)
2 + 2ρs
By combining √this condition with η < ζ, we can see
that ρs < 1/( 2 + 1) is a necessary condition to√guarantee µ1 < 1. On the other side, if ρs < 1/( 2 +
1), then we can always find a step-size η < ζ satisfying (3) such that µ1 < 1. This condition of ρs is
analogous to the RIP condition for estimation from noisy
measurements in compressed sensing (Candès et al., 2006;
Needell & Tropp, 2009; Foucart, 2011). Indeed, in this
setup our GraHTP algorithm reduces to HTP which requires weaker RIP condition than prior compressed sensing algorithms. The guarantees of GraHTP and HTP for
compressed sensing are almost identical, although we did
not make any attempt√to optimize the RIP sufficient con√
stants, which are 1/( 2 + 1) (for GraHTP) versus 1/ 3
(for HTP).√We would like to emphasize that the condition
ρs < 1/( 2 + 1) derived for GraHTP also holds in fairly
general setups beyond compressed sensing. For FGraHTP
we have very similar discussions.
For the general sparsity-constrained optimization problem, we note that a similar estimation error bound has
been established for the GraSP (Gradient Support Pursuit) method (Bahmani et al., 2013) which is another hardthresholding-type method. At time stamp t, GraSP first
conducts debiasing over the union of the top k entries of
x(t−1) and the top 2k entries of ∇f (x(t−1) ), then it selects
the top k entries of the resultant vector and updates their
values via debiasing, which becomes x(t) . Our GraHTP
is connected to GraSP in the sense that the k largest absolute elements after the gradient descent step (see S1 and
S2 of Algorithm 1) will come from some combination of
the largest elements in x(t−1) and the largest elements in
the gradient ∇f (x(t−1) ). Although the convergence rate
are of the same order, the per-iteration cost of GraHTP is
cheaper than GraSP: at each debiasing step, GraSP minimizes the objective over a support of size 3k while that size
for GraHTP is k. FGraHTP is even cheaper for iteration as
it does not need any debiasing operation. We will compare the actual numerical performance of these methods in
our empirical study. We also point out that our FGraHTP
algorithm is identical 1 to the nonlinear-IHT investigated
in (Blumensath, 2013). The estimation error bound there,
however, is different from ours in the sense that the bound
there is dependent on the objective value at the target solu1
Our work was initially submitted in May 2013, which was
later posted online at arxiv:1311.5750. We appreciate Blumensath for pointing out to us that FGraHTP in arxiv:1311.5750 is
closely related to the new work (Blumensath, 2013).

Gradient Hard Thresholding Pursuit

tion; whereas ours is dependent on the restricted norm of
gradient at the target solution. As we will show in the next
section, our bound is especially useful when applied to analyze the statistical efficiency of sparse learning problems.
Also, the results in (Blumensath, 2013) are obtained under
a stronger condition of restricted strict convexity property
which implies the C(s, ζ, ρs ) condition in our analysis.
Last but not least, the bounds in Theorem 2 are relying on
the values of ζ and ρs . Also, the step-size η is required
to satisfy certain conditions relying on (ζ, ρs ) to guarantee
the convergence. As we will show in the next section, the
values of ζ and ρs can be estimated from data, and thus is
η, for several popular machine learning models.

It is well-known that l(w) is convex. Unfortunately,
in high-dimensional setting, i.e., n < p, the problem
can be underdetermined and thus its minimum is not
unique. A conventional way to avoid singularity is to impose ℓ2 -regularization, resulting in the following sparsityconstrained ℓ2 -regularized logistic regression problem:
min f (w) = l(w) +
w

λ
∥w∥2 ,
2

subject to ∥w∥0 ≤ k, (6)

where λ > 0 is the regularization strength parameter. Obviously f (w) is λ-strongly convex and hence it has a unique
minimum. The presence of the cardinality constraint enforces the solution to be sparse.
4.1.1. V ERIFYING CONDITION C(s, ζ, ρs )

4. Applications to Sparsity-Constrained
M-estimation
In this section, we will specialize GraHTP/FGraHTP to Mestimation (maximum likelihood type estimator) which is a
poplar class of statistical learning models. Given a set of n
independently drawn data samples {x(i) }ni=1 , the essential
form of the M-estimation problem is defined as to minimize
the following risk function averaged over the samples:
1∑
ϕ(x(i) | w),
n i=1

Let U = [u(1) , ..., u(n) ] ∈ Rp×n be the design matrix and
σ(z) = 1/(1 + exp(−z)) be the sigmoid function. In the
case of ℓ2 -regularized logistic loss, we have
∇f (w) = U a(w)/n + λw,
where the vector a(w) ∈ Rn is given by [a(w)]i =
−2v (i) (1 − σ(2v (i) w⊤ u(i) )). The following result verifies
f (w) satisfies Condition C(s, ζ, ρs ) under mild conditions.

n

f (w) =

where and ϕ is a cost function and w is a set of adjustable
parameters. The sparsity-constrained M-estimation problem is then given by:
min f (w),
w

subject to ∥w∥0 ≤ k.

(4)

In the subsequent subsections, we will consider two instances of this model: sparse logistic regression and sparse
support vector machines (SVMs).
4.1. Sparsity-constrained ℓ2 -regularized logistic
regression
Logistic regression is one of the most popular models in
statistics and machine learning (Bishop, 2006). In this
model the relation between the random feature vector u ∈
Rp and its associated random binary label v ∈ {−1, +1} is
determined by the conditional probability
P(v|u; w̄) =

exp(2v w̄⊤ u)
,
1 + exp(2v w̄⊤ u)

(5)

where w̄ ∈ Rp denotes a parameter vector. Given a set of
n independently drawn data samples {(u(i) , v (i) )}ni=1 , logistic regression learns the parameters w so as to minimize
the logistic loss given by
1∑
log(1 + exp(−2v (i) w⊤ u(i) )).
n i=1
n

l(w) :=

Proposition 2. Given an integer s, let Rs :=
maxi ∥(u(i) )s ∥. Then the ℓ2 -regularized logistic loss satisfies Condition C(s, ζ, ρs ) with any
√
√
2λ
√
ζ<
, ρs = 1 − 2ζλ + ζ 2 (4 sRs2 + λ)2 .
(4 sRs2 + λ)2
Remark 4. Since Rs is known for a given data and λ is
fixed in the model, Proposition 2 indicates that the values of
ζ and ρs can be explicitly calculated
way.
√in a2 data-driven
2
For
example,
we
may
set
ζ
=
λ/(4
sR
+
λ)
and
ρ
s =
s
√
√
1 − λ2 /(4 sRs2 + λ)2 to guarantee the C(s, ζ, ρs ) condition. By Theorem 2, these two√values further guide us to
select the step-size η = O(λ/(4 sRs2 + λ)2 ).
4.1.2. B OUNDING THE ESTIMATION ERROR
We are going to bound ∥∇s f (w̄)∥ which we obtain from
Theorem 2 that controls the estimation error bounds of
GraHTP (with s = k) and FGraHTP (with s = 2k + k̄). In
the following deviation, we assume that the joint density of
the random vector (u, v) ∈ Rp+1 is given by the following
exponential family distribution:
(
)
P(u, v; w̄) = exp v w̄⊤ u + B(u) − A(w̄) ,
where A(w̄) is the log-partition function. The term B(u)
characterizes the marginal behavior of u. Obviously, the
conditional distribution of v given u, P(v | u; w̄), is
given by the logistical model (5). By trivial algebra
we can obtain the following standard result which shows

Gradient Hard Thresholding Pursuit

that the first derivative of the logistic loss l(w) yields
the cumulants of the random variables v[u]j (see, e.g.,
Wainwright & Jordan, 2008):
}
∂l
1 ∑ { (i) (i)
=
−v [u ]j + Ev [v[u(i) ]j | u(i) ] .
∂[w]j
n i=1
n

Here the expectation Ev [· | u] is taken over the conditional
distribution (5). We introduce the following sub-Gaussian
condition on the random variate v[u]j .
Assumption 1. For all j, we assume that there exists
constant
σ >
(
) 0 such that for all η, E[exp(ηv[u]j )] ≤
exp σ 2 η 2 /2 .
This assumption holds when [u]j are sub-Gaussian (e.g.,
Gaussian or bounded) random variables. The following
result establishes the bound of ∥∇s f (w̄)∥.

the f (w) defined in (7) as regularized L2 -hinge loss in the
remaining text.
4.2.1. V ERIFYING CONDITION C(s, ζ, ρs )
It is easy to verify that
{
}
1∑
max 0, 1 − v (i) w⊤ u(i) v (i) u(i)
n i=1
n

∇f (w) =

−

+λw.
Similar to Proposition 2, we can prove the following result
which confirms that L2 -hinge loss f (w) satisfies Condition
C(s, ζ, ρs ) under mild conditions.
Proposition 4. Given an integer s, let Rs :=
maxi ∥(u(i) )s ∥. Then the L2 -hinge loss satisfies Condition
C(s, ζ, ρs ) with any

Proposition 3. If Assumption 1 holds, then with probability
at least 1 − 4p−1 ,
√
∥∇s f (w̄)∥ ≤ 4σ s ln p/n + λ∥w̄s ∥.
√
Remark 5. If we choose λ = O( ln p/n), then with overwhelming √
probability, the term ∥∇s f (w̄)∥ vanishes at the
rate of O( s ln p/n). This bound is superior to the bound
provided by Bahmani et al. (2013, Section 4.2) which is
non-vanishing.

Similar to the arguments in Remark 4, this proposition suggests that the values of ζ and ρs can be selected in a datadriven way and these values in turn guide us to select the
step-size η = O(λ/(Rs + λ)2 ).

4.2. Sparsity-constrained SVMs

4.2.2. B OUNDING THE ESTIMATION ERROR

We now consider applying our algorithms to fast and scalable parameter learning of linear SVMs with sparsity constraint. SVMs usually map instance vectors into a highdimensional (even infinite-dimensional) space, and solve
the dual problem with a nonlinear kernel. However, dual
approaches may face trouble dealing with explosion of
variables when datasets scale up. Moreover in practical domains such as document analysis, data come intrinsically
with high dimensions (e.g., bag of words), so that SVMs
with/without nonlinear mappings often yield similar performance. As concluded in (Chappelle, 2007), when the
goal is to find an approximate solution, primal linear optimizations are superior. Henceforth we focus on linear
SVMs in the primal form. Particularly, we are interested
in the following sparsity-constrained L2 -SVMs:

Recall that ∀i, ∥(u(i) )s ∥ ≤ Rs . For any k̄-sparse vector
w̄, it is known from Theorem 2 that the estimation error is
controlled by

λ
min f (w) = h(w) + ∥w∥2 , subject to ∥w∥0 ≤ k, (7)
w
2
where
n
})2
{
1 ∑(
h(w) :=
max 0, 1 − v (i) w⊤ u(i)
2n i=1
is the L2 -hinge loss. For this class of SVMs, the objective
f (w) is smooth and λ-strongly convex, and the cardinality constraint enforces the solution to be sparse. We refer

ζ<

2λ
,
(Rs + λ)2

ρs =

√
1 − 2ζλ + ζ 2 (Rs + λ)2 .

{
}
1∑
max 0, 1 − v (i) w̄⊤ u(i) Rs
n i=1
n

∥∇s f (w̄)∥

≤

+λ∥w̄s ∥.
If the samples can be well separated by w̄, then ∥∇s f (w̄)∥
tends to be small. More preciously, let U (n) be the number
of points in {(u(i) , v (i) )}ni=1 with margin v (i) w̄⊤ u(i) < 1,
then we have ∥∇s f (w̄)∥ ≤ (U (n)Rs2 /n + λ)∥w̄s ∥ +
U (n)Rs /n. By choosing λ = O(U (n)/n), we will
have ∥∇s f (w̄)∥ = O(U (n)/n) which vanishes as long as
U (n)/n vanishes with respect to n.

5. Experimental Results
This section is devoted to evaluating the empirical performance of GraHTP and FGraHTP when these two methods are applied to sparse logistic regression and sparse L2 SVMs learning tasks. All the considered algorithms are
implemented in Matlab 7.12 running on a desktop with Intel Core i7 3.2G CPU and 16G RAM.

Gradient Hard Thresholding Pursuit

5.1. Sparsity-constrained logistic regression

n=1000
0.3
Estimation error

0.3
0.25
GraHTP
FGraHTP
GraSP
FBS
FoBa

0.2
0.15
0.1

0.2

0.4

0.6
n/p

0.8

Results. Figure 1(a) presents the estimation errors of the
considered algorithms. From the left panel of Figure 1(a)
(for Case 1) we observe that: (i) when cardinality k is fixed,
the estimation errors of all the considered algorithms tend
to decrease as sample size n increases; and (ii) in this case,
GraHTP and FGraHTP are comparable and they significantly outperform the other considered algorithms. From
the right panel of Figure 1(a) (for Case 2) we observe that:
(i) when n is fixed, the estimation errors of all the considered algorithms tend to increase as k increases; and (ii)
in this case, GraHTP and FGraHTP are comparable and
they are significantly superior to the other considered algorithms. Figure 1(b) shows the execution time of the considered algorithms. From this group of results we observe that
in most cases, GraHTP/FGraHTP and GraSP are comparable and they are faster than FBS and FoBa. Also, the overall computational time of GraHTP/FGraHTP and GraSP is
relatively insensitive to k. This is potentially because as k
increases, fewer iterations are needed to converge.

200

300
k

400

500

400

500

(a) Estimation Error
6

4

n=1000
25

GraHTP
FGraHTP
GraSP
FBS
FoBa

2

0.2

For each case, we compare GraHTP and FGraHTP
with three state-of-the-art greedy selection methods:
GraSP (Bahmani et al., 2013) as a hard-thresholding-type
method, FBS (Forward Basis Selection) (Yuan & Yan,
2013) as a forward-selection-type method, and
FoBa (Zhang, 2008) as an adaptive forward backward selection method. Note that all these considered
algorithms have geometric rate of convergence. We will
compare the computational efficiency of these methods in
this study. Theorem 2 suggests that under proper conditions GraHTP/FGraHTP are insensitive to initialization.
Therefore, we simply initialize w(0) = 0 and set the
stopping criterion as ∥w(t) − w(t−1) ∥/∥w(t−1) ∥ ≤ 10−4 .

GraHTP
FGraHTP
GraSP
FBS
FoBa

0.2

k=100

0

2. Case 2: Sample size n is fixed and cardinality k
is varying: we test with n = 1000 and k ∈
{100, 150, ..., 500}.

0.25

0.15
100

1

CPU (in second)

1. Case 1: Cardinality k is fixed and sample size
n is varying: we test with k = 100 and n ∈
{100, 200, ..., 1000}.

Estimation error

We consider a synthetic data model in which the sparse
parameter w̄ is a p = 1000 dimensional vector that has
k̄ = 100 nonzero entries drawn independently from the
standard Gaussian distribution. Each data sample u is a
normally distributed vector. The data labels, v ∈ {−1, 1},
are then generated randomly according to the Bernoulli distribution P(v = 1|u; w̄) = exp(2w̄⊤ u)/(1 + exp(2w̄⊤ u)).
We fix the regularization parameter λ = 10−4 in the objective of (6). We are interested in the following two cases:

CPU (in second)

5.1.1. M ONTE -C ARLO SIMULATION

k=100
0.35

0.4

0.6
n/p

0.8

1

20
15

GraHTP
FGraHTP
GraSP
FBS
FoBa

10
5
0
100

200

300
k

(b) CPU Running Time

Figure 1. Logistic regression on simulated data: estimation error
and CPU time of the considered algorithms.

5.1.2. R EAL DATA
The algorithms are also compared on two real datasets:
rcv1.binary (p = 47, 236) and news20.binary (p =
1, 355, 191). For rcv1.binary, a training subset of size
20,242 and a testing subset of size 20,000 are used. For
news20.binary, a training subset of size 10,000 and a testing subset of size 9,996 are used. We test with sparsity
parameters k ∈ {100, 200, ..., 1000} and fix the regularization parameter λ = 10−5 . All the considered algorithms are initialized with w(0) = 0 and terminated when
∥w(t) − w(t−1) ∥/∥w(t−1) ∥ ≤ 10−4 or t > k.
Figure 2 shows the evolving curves of empirical logistic
loss for k ∈ {200, 1000}. It can be observed that on both
datasets, GraHTP and GraSP converge much sharper than
FGraHTP/FBS/FoBa. The testing classification errors and
CPU running time of the considered algorithms are provided in Figure 3: (i) in terms of accuracy, all the considered methods are comparable, although GraSP is slightly
more favorable; and (ii) in terms of overall execution time,
FGraHTP and GraHTP are the top two ones and their computational advantage becomes significant on the relatively
larger data news20.binary. To summarize, GraHTP and
FGraHTP achieve favorable trade-offs between accuracy
and efficiency on the considered data.
5.2. Sparsity-constrained L2 -SVMs
For this empirical study, we consider the same two real
datasets and experimental protocols as used in the previous
experiment. We fix the regularization parameter λ = 10−4

Gradient Hard Thresholding Pursuit

0.2

GraHTP
FGraHTP
GraSP
FBS
FoBa

0.6
0.4
0.2

Classification error

0.4

0.1

0.8

Logistic loss

Logistic loss

0.6

Classification Error

k = 1000
GraHTP
FGraHTP
GraSP
FBS
FoBa

CPU Time

GraHTP
FGraHTP
GraSP
FBS
FoBa

0.08

0.06

100
CPU time (in second)

k = 200
0.8

80
60
40
20

0.04

20
30
Iterations

40

50

10

20
30
Iterations

40

0
200

50

400

600
k

0.4

0.8

Logistic loss

Logistic loss

k = 1000
GraHTP
FGraHTP
GraSP
FBS
FoBa

0.2

200

Classification Error
0.16

GraHTP
FGraHTP
GraSP
FBS
FoBa

0.6
0.4
0.2

Classification error

k = 200

0.6

1000

400

600
k

800

1000

800

1000

(a) rcv1.binary

(a) rcv1.binary
0.8

800

0.14
0.12

CPU Time

4

GraHTP
FGraHTP
GraSP
FBS
FoBa

0.1
0.08

10
CPU time (in second)

10

GraHTP
FGraHTP
GraSP
FBS
FoBa

3

10

GraHTP
FGraHTP
GraSP
FBS
FoBa

2

10

0.06

10

20
30
Iterations

40

50

10

20
30
Iterations

40

50

200

400

600
k

Figure 2. Logistic regression on real data: ℓ2 -regularized logistic
loss versus number of iterations.

Classification Error

0.08

0.06

CPU time (in second)

Classification error

GraHTP
FGraHTP
GraSP
FBS
FoBa

GraHTP
FGraHTP
GraSP
FBS
FoBa

80
60
40
20

0.04

0
200

400

600
k

800

1000

200

400

600
k

800

1000

800

1000

(a) rcv1.binary
Classification Error

0.15

0.1

200

400

600
k

800

CPU Time

4

GraHTP
FGraHTP
GraSP
FBS
FoBa

1000

10
CPU time (in second)

Classification error

0.2

3

10

GraHTP
FGraHTP
GraSP
FBS
FoBa

2

10

200

200

400

600
k

400

600
k

Figure 4. L2 -SVMs on real data: Classification error and CPU
running time of the considered algorithms.

6. Conclusions

CPU Time
100

1000

(b) news20.binary

(b) news20.binary

0.1

800

(b) news20.binary

Figure 3. Logistic regression on real data: Classification error and
CPU running time of the considered algorithms.

and set the initial vector w(0) = 0 for all the considered
algorithms. The testing classification errors and CPU running time of the considered algorithms are provided in Figure 4. From these figures, we make very similar observations as from the previous experiment: GraHTP/FGraHTP
make better trade-off between computational efficiency and
classification accuracy on the used datasets.

In this paper, we have proposed GraHTP as a generalization of HTP from compressed sensing to a generic setup
of sparsity-constrained minimization. The main idea is to
force the gradient descent iteration to be sparse via hard
truncation. Theoretically, we have proved that under mild
conditions, GraHTP converges geometrically in finite steps
of iteration and its estimation error is controlled by the restricted norm of gradient at the target sparse solution. We
have also proposed and analyzed the FGraHTP algorithm
as a fast variant of GraHTP without the debiasing step. Empirically, we compared GraHTP and FGraHTP with several
representative greedy selection methods when applied to
sparse logistic regression and sparse SVMs learning tasks.
Our theoretical results and empirical evidences show that
simply combing gradient descent with a truncation operation, with or without debiasing, leads to efficient and accurate computational procedures for estimating sparsityconstrained models.

Acknowledgements
The authors thank the constructive review comments
from NIPS 2013 and ICML 2014. Xiao-Tong Yuan
was a postdoctoral research associate supported by NSFDMS 0808864, NSF-EAGER 1249316, ONR-N00014-131-0764 and NUIST-Startup S8113029001. Ping Li is supported by ONR-N00014-13-1-0764, AFOSR-FA9550-131-0137, NSF III 1360971, and NSF BIGDATA 1419210.
Tong Zhang is supported by NSF-IIS 1016061, NSF-DMS
1007527, and NSF-IIS 1250985.

Gradient Hard Thresholding Pursuit

References
Bahmani, S., Raj, B., and Boufounos, P. Greedy sparsityconstrained optimization. Journal of Machine Learning
Research, 14:807–841, 2013.
Beck, A. and Teboulle, Marc. A fast iterative shrinkagethresholding algorithm for linear inverse problems.
SIAM Journal on Imaging Sciences, 2(1):183–202, 2009.
Bishop, C.M. Pattern Recognition and Machine Learning.
Springer-Verlag New York, Inc., Secaucus, NJ, USA,
2006. ISBN 978-0-387-31073-2.
Blumensath, T. Compressed sensing with nonlinear observations and related nonlinear optimization problems.
IEEE Transactions on Information Theory, 59(6):3466–
3474, 2013.
Blumensath, T. and Davies., M. E. Iterative hard thresholding for compressed sensing. Applied and Computational
Harmonic Analysis, 27(3):265–274, 2009.
Candès, E. J., Romberg, J. K., and Tao, T. Stable signal recovery from incomplete and inaccurate measurements. Communications on Pure and Applied Mathematics, 59(8):1207–1223, 2006.
Chappelle, O. Training a support vector machine in the
primal. Neural Computation, 19(5):1155–1178, 2007.
Dai, W. and Milenkovic, O. Subspace pursuit for compressive sensing signal reconstruction. IEEE Transactions
on Information Theory, 55(5):2230–2249, 2009.
Donoho, D. L. Compressed sensing. IEEE Transactions on
Information Theory, 52(4):1289–1306, 2006.
Foucart, S. Hard thresholding pursuit: An algorithm for
compressive sensing. SIAM Journal on Numerical Analysis, 49(6):2543–2563, 2011.
Foucart, S. Sparse recovery algorithms: sufficient conditions in terms of restricted isometry constants. In
Approximation Theory XIII: San Antonio 2010, volume
13 of Springer Proceedings in Mathematics, pp. 65–77,
2012.

Langford, J., Li, L., , and Zhang, T. Sparse online learning via truncated gradient. Journal of Machine Learning
Research, 10:777–801, 2009.
Ma, Z. Sparse principal component analysis and iterative
thresholding. Annals of Statistics, 41(2):772–801, 2013.
Mallat, S. and Zhang, Zhifeng. Matching pursuits with
time-frequency dictionaries. IEEE Transactions on Signal Processing, 41(12):3397–3415, 1993.
Natarajan, B. K. Sparse approximate solutions to linear
systems. SIAM Journal on Computing, 24(2):227–234,
1995.
Needell, D. and Tropp, J. A. Cosamp: iterative signal recovery from incomplete and inaccurate samples.
IEEE Transactions on Information Theory, 26(3):301–
321, 2009.
Pati, Y.C., Rezaiifar, R., and Krishnaprasad, P.S. Orthogonal matching pursuit: Recursive function approximation
with applications to wavelet decomposition. In Proceedings of the 27th Annual Asilomar Conference on Signals,
Systems, and Computers, pp. 40–44, 1993.
Ravikumar, P., Wainwright, M. J., Raskutti, G., and Yu,
B. High-dimensional covariance estimation by minimizing ℓ1 -penalized log-determinant divergence. Electronic
Journal of Statistics, 5:935–980, 2011.
Shalev-Shwartz, Shai, Srebro, Nathan, and Zhang, Tong.
Trading accuracy for sparsity in optimization problems
with sparsity constraints. SIAM Journal on Optimization,
20:2807–2832, 2010.
Tropp, J. and Gilbert, A. Signal recovery from random
measurements via orthogonal matching pursuit. IEEE
Transactions on Information Theory, 53(12):4655–4666,
2007.
Wainwright, M.J. and Jordan, M.I. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1-2):1–305,
2008.

Frank, M. and Wolfe, P. An algorithm for quadratic programming. Naval Res. Logist. Quart., 5:95–110, 1956.

Yuan, X.-T. and Yan, S. Forward basis selection for pursuing sparse representations over a dictionary. IEEE Transactions on Pattern Analysis And Machine Intelligence,
35(12):3025–3036, 2013.

Jalali, A., Johnson, C. C., and Ravikumar, P. K. On learning discrete graphical models using greedy methods. In
Proceedings of the 25th Annual Conference on Neural
Information Processing Systems (NIPS’11), 2011.

Yuan, X.-T. and Zhang, T. Truncated power method for
sparse eigenvalue problems. Journal of Machine Learning Research, 14:899–925, 2013.

Kim, Yongdai and Kim, Jinseog. Gradient lasso for feature selection. In Proceedings Of The Twenty-First International Conference On Machine Learning (ICML’04),
2004.

Zhang, T. Adative forward-backward greedy algorithm for
sparse learning with linear models. In Proceedings of
the 22nd Annual Conference on Neural Information Processing Systems (NIPS’08), 2008.

