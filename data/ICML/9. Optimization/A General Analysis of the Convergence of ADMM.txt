A General Analysis of the Convergence of ADMM

RKN @ EECS . BERKELEY. EDU
LESSARD @ BERKELEY. EDU
BRECHT @ EECS . BERKELEY. EDU
APACKARD @ BERKELEY. EDU

Robert Nishihara
Laurent Lessard
Benjamin Recht
Andrew Packard
Michael I. Jordan
University of California, Berkeley, CA 94720 USA

JORDAN @ EECS . BERKELEY. EDU

et al. (2014); Wang & Banerjee (2012); Zhang et al. (2012);
Meshi & Globerson (2011); Wang et al. (2013); Aslan et al.
(2013); Forouzan & Ihler (2013); Romera-Paredes & Pontil (2013); Behmardi et al. (2014); Zhang & Kwok (2014).
See Boyd et al. (2011) for an overview.

Abstract
We provide a new proof of the linear convergence
of the alternating direction method of multipliers (ADMM) when one of the objective terms is
strongly convex. Our proof is based on a framework for analyzing optimization algorithms introduced in Lessard et al. (2014), reducing algorithm convergence to verifying the stability of
a dynamical system. This approach generalizes
a number of existing results and obviates any
assumptions about specific choices of algorithm
parameters. On a numerical example, we demonstrate that minimizing the derived bound on the
convergence rate provides a practical approach
to selecting algorithm parameters for particular
ADMM instances. We complement our upper
bound by constructing a nearly-matching lower
bound on the worst-case rate of convergence.

Part of the appeal of ADMM is the fact that, in many contexts, the algorithm updates lend themselves to parallel implementations. The algorithm is given in Algorithm 1. We
refer to ρ > 0 as the step-size parameter.
Algorithm 1 Alternating Direction Method of Multipliers
1: Input: functions f and g, matrices A and B, vector c,
parameter ρ
2: Initialize x0 , z0 , u0
3: repeat
4:
xk+1 = arg minx f (x) + ρ2 kAx + Bzk − c + uk k2
5:
zk+1 = arg minz g(z) + ρ2 kAxk+1 + Bz − c + uk k2
6:
uk+1 = uk + Axk+1 + Bzk+1 − c.
7: until meet stopping criterion

1. Introduction
The alternating direction method of multipliers (ADMM)
seeks to solve the problem
minimize f (x) + g(z)
subject to Ax + Bz = c,

(1)

with variables x ∈ Rp and z ∈ Rq and constants A ∈
Rr×p , B ∈ Rr×q , and c ∈ Rr . ADMM was introduced in
Glowinski & Marroco (1975) and Gabay & Mercier (1976).
More recently, it has found applications in a variety of
distributed settings such as model fitting, resource allocation, and classification. A partial list of examples includes
Bioucas-Dias & Figueiredo (2010); Wahlberg et al. (2012);
Bird (2014); Forero et al. (2010); Sedghi et al. (2014); Li
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

A popular variant of Algorithm 1 is over-relaxed ADMM,
which introduces an additional parameter α and replaces
each instance of Axk+1 in the z and u updates in Algorithm 1 with
αAxk+1 − (1 − α)(Bzk − c).
The parameter α is typically chosen to lie in the interval (0, 2], but we demonstrate in Section 8 that a larger set
of choices can lead to convergence. Over-relaxed ADMM
is described in Algorithm 2. When α = 1, Algorithm 2 and
Algorithm 1 coincide. We will analyze Algorithm 2.
The conventional wisdom that ADMM works well without any tuning (Boyd et al., 2011), for instance by setting ρ = 1, is often not borne out in practice. Algorithm 1
can be challenging to tune, and Algorithm 2 is even harder.
We use the machinery developed in this paper to make reasonable recommendations for setting ρ and α when some
information about f is available (Section 8).

A General Analysis of the Convergence of ADMM

Algorithm 2 Over-Relaxed Alternating Direction Method
of Multipliers
1: Input: functions f and g, matrices A and B, vector c,
parameters ρ and α
2: Initialize x0 , z0 , u0
3: repeat
4:
xk+1 = arg minx f (x) + ρ2 kAx + Bzk − c + uk k2
5:
zk+1 = arg minz g(z)+ ρ2 kαAxk+1 −(1−α)Bzk +
Bz − αc + uk k2
6:
uk+1 = uk + αAxk+1 − (1 − α)Bzk + Bzk+1 − αc
7: until meet stopping criterion
In this paper, we give an upper bound on the linear rate of
convergence of Algorithm 2 for all ρ and α (Theorem 7),
and we give a nearly-matching lower bound (Theorem 8).
Importantly, we show that we can prove convergence rates
for Algorithm 2 by numerically solving a 4×4 semidefinite
program (Theorem 6). When we change the parameters of
Algorithm 2, the semidefinite program changes. Whereas
prior work requires a new proof of convergence for every
change to the algorithm, our work automates that process.

Lemma 1. Suppose that f ∈ Sd (m, L), where 0 < m ≤
L < ∞. Suppose that b1 = ∇f (a1 ) and b2 = ∇f (a2 ).
Then

> 


a1 − a2
−2mLId (m + L)Id a1 − a2
≥ 0.
b1 − b2
(m + L)Id
−2Id
b1 − b2
Proof. The Lipschitz continuity of ∇f implies the cocoercivity of ∇f , that is
(a1 − a2 )> (b1 − b2 ) ≥

1
L kb1

− b2 k 2 .

2
Note that f (x) − m
2 kxk is convex and its gradient is Lipschitz continuous with parameter L − m. Applying the cocoercivity condition to this function and rearranging gives

(m+L)(a1 −a2 )> (b1 −b2 ) ≥ mLka1 −a2 k2 +kb1 −b2 k2 ,
which can be put in matrix form to complete the proof.
Lemma 2. Suppose that f ∈ Sd (0, ∞), and suppose
that b1 ∈ ∂f (a1 ) and b2 ∈ ∂f (a2 ). Then

> 
a1 − a2
0d
b1 − b2
Id

Id
0d



a1 − a2
≥ 0.
b1 − b2

Our work builds on the integral quadratic constraint framework introduced in Lessard et al. (2014), which uses ideas
from robust control to analyze optimization algorithms that
can be cast as discrete-time linear dynamical systems. Related ideas, in the context of feedback control, appear in
Corless (1990); D’Alto & Corless (2013). Our work provides a flexible framework for analyzing variants of Algorithm 1, including those like Algorithm 2 created by the introduction of additional parameters. In Section 7, we compare our results to prior work.

When M is a matrix, we use κM to denote the condition number of M . For example, κA = σ1 (A)/σp (A),
where σ1 (A) and σp (A) denote the largest and smallest
singular values of the matrix A. When f ∈ Sd (m, L), we
L
denote the condition number of f . We denote
let κf = m
the Kronecker product of matrices M and N by M ⊗ N .

2. Preliminaries and Notation

3. ADMM as a Dynamical System

Let R denote the extended real numbers R ∪ {+∞}. Suppose that f : Rd → R is convex and differentiable, and
let ∇f denote the gradient of f . We say that f is strongly
convex with parameter m > 0 if for all x, y ∈ Rd , we have

We group our assumptions together in Assumption 3.

f (x) ≥ f (y) + ∇f (y)> (x − y) +

m
2 kx

− yk2 .

When ∇f is Lipschitz continuous with parameter L, then
f (x) ≤ f (y) + ∇f (y)> (x − y) +

L
2 kx

− yk2 .

For 0 < m ≤ L < ∞, let Sd (m, L) denote the set of differentiable convex functions f : Rd → R that are strongly
convex with parameter m and whose gradients are Lipschitz continuous with parameter L. We let Sd (0, ∞) denote the set of convex functions Rd → R. In general, we
let ∂f denote the subdifferential of f . We denote the ddimensional identity matrix by Id and the d-dimensional
zero matrix by 0d . We will use the following results.

Lemma 2 is simply the statement that the subdifferential of
a convex function is a monotone operator.

Assumption 3. We assume that f and g are convex, closed,
and proper. We assume that for some 0 < m ≤ L < ∞, we
have f ∈ Sp (m, L) and g ∈ Sq (0, ∞). We assume that A
is invertible and that B has full column rank.
The assumption that f and g are closed (their sublevel sets
are closed) and proper (they neither take on the value −∞
nor are they uniformly equal to +∞) is standard.
We begin by casting over-relaxed ADMM as a discretetime dynamical system with state sequence (ξk ), input sequence (νk ), and output sequences (wk1 ) and (wk2 ) satisfying the recursions
ξk+1 = (Â ⊗ Ir )ξk + (B̂ ⊗ Ir )νk
wk1
wk2

(2a)

1

1

(2b)

2

2

(2c)

= (Ĉ ⊗ Ir )ξk + (D̂ ⊗ Ir )νk
= (Ĉ ⊗ Ir )ξk + (D̂ ⊗ Ir )νk

A General Analysis of the Convergence of ADMM

for particular matrices Â, B̂, Ĉ 1 , D̂1 , Ĉ 2 , and D̂2 (whose
dimensions do not depend on any problem parameters).
First define the functions fˆ, ĝ : Rr → R via

sk+1 = arg min ĝ(s)
s

fˆ = (ρ−1 f ) ◦ A−1
ĝ = (ρ

−1

g) ◦ B + Iim B ,

L
L̂ = 2
σp (A)

+ 21 kαrk+1 − (1 − α)sk + s − αc + uk k2 .

(3)

†

where B † is any left inverse of B and where Iim B is
the {0, ∞}-indicator function of the image of B. We define κ = κf κ2A and to normalize we define
m
m̂ = 2
σ1 (A)

where βk+1 = ∇fˆ(rk+1 ). In the same spirit, we rewrite
the update rule for z as

1
2

ρ = (m̂L̂) ρ0 .

(4)

It follows that there exists some γk+1 ∈ ∂ĝ(sk+1 ) such that
0 = γk+1 + αrk+1 − (1 − α)sk + sk+1 − αc + uk .
It follows then that
sk+1 = −αrk+1 + (1 − α)sk + αc − uk − γk+1
= sk − (1 − α)uk + αβk+1 − γk+1 ,

Note that under Assumption 3,
1
− 12
2
fˆ ∈ Sp (ρ−1
, ρ−1
0 κ
0 κ )

(5a)

ĝ ∈ Sq (0, ∞).

(5b)

where the second equality follows by substituting in (7).
Combining (7) and (8) to simplify the u update, we have
uk+1 = uk + αrk+1 − (1 − α)sk + sk+1 − αc

To define the relevant sequences, let the sequences
(xk ), (zk ), and (uk ) be generated by Algorithm 2 with
parameters α and ρ. Define the sequences (rk ) and (sk )
by rk = Axk and sk = Bzk and the sequence (ξk ) by
 
s
ξk = k .
uk

Proposition 4. There exist sequences (βk ) and (γk )
with βk = ∇fˆ(rk ) and γk ∈ ∂ĝ(sk ) such that when we
define the sequence (νk ) by


βk+1
νk =
,
γk+1
then (ξk ) and (νk ) satisfy (2a) with the matrices




1 α−1
α −1
Â =
B̂ =
.
0 −1
0
0

xk+1 = A

arg min f (A
r

−1

r) +

ρ
2 kr

2

+ sk − c + uk k .

Multiplying through by A, we can write
rk+1 = arg min fˆ(r) + 12 kr + sk − c + uk k2 .
r

This implies that
0 = ∇fˆ(rk+1 ) + rk+1 + sk − c + uk ,
and so
rk+1 = −sk − uk + c − βk+1 ,

(9)

Together, (8) and (9) confirm the relation in (2a).
Corollary 5. Define the sequences (βk ) and (γk ) as in
Proposition 4. Define the sequences (wk1 ) and (wk2 ) via


rk+1 − c
=
βk+1

wk2




sk+1
=
.
γk+1

Then the sequences (ξk ), (νk ), (wk1 ), and (wk2 ) satisfy (2b)
and (2c) with the matrices




−1 0
−1 −1
D̂1 =
Ĉ 1 =
1 0
0
0




(10)
1 α−1
α −1
Ĉ 2 =
D̂2 =
.
0
0
0 1

(6)

Proof. Using the fact that A has full rank, we rewrite the
update rule for x from Algorithm 2 as
−1

= −γk+1 .

wk1

We define the sequence (νk ) as in Proposition 4.

(8)

(7)

4. Convergence Rates from Semidefinite
Programming
Now, in Theorem 6, we make use of the perspective developed in Section 3 to obtain convergence rates for Algorithm 2. This is essentially the same as the main result of
Lessard et al. (2014), and we include it because it is simple
and self-contained.
Theorem 6. Suppose that Assumption 3 holds. Let the
sequences (xk ), (zk ), and (uk ) be generated by running
1
Algorithm 2 with step size ρ = (m̂L̂) 2 ρ0 and with overrelaxation parameter α. Suppose that (x∗ , z∗ , u∗ ) is a fixed
point of Algorithm 2, and define
 
 
z
z
ϕk = k
ϕ∗ = ∗ .
uk
u∗

A General Analysis of the Convergence of ADMM

is satisfied, where Â and B̂ are defined in (6),
where Ĉ 1 , D̂1 , Ĉ 2 , and D̂2 are defined in (10), and
where M 1 and M 2 are given by

1 
1
−2ρ−2
ρ−1
(κ− 2 + κ 2 )
1
0
0
M = −1 − 1
1
−2
ρ0 (κ 2 + κ 2 )


0 1
M2 =
.
1 0

For fixed values of α, ρ0 , m̂, L̂, and τ , the feasibility of (11)
is a semidefinite program with variables P , λ1 , and λ2 . We
perform a binary search over τ to find the minimal rate τ
such that the linear matrix inequality in (11) is satisfied.
The results are shown in Figure 1 for a wide range of condition numbers κ, for α = 1.5, and for several choices
of ρ0 . In Figure 2, we plot the values −1/ log τ to show the
number of iterations required to achieve a desired accuracy.
1

Convergence rate τ

Fix 0 < τ < 1, and suppose that there exist a 2 × 2 positive
definite matrix P  0 and nonnegative constants λ1 , λ2 ≥
0 such that the 4 × 4 linear matrix inequality
 >

Â P Â − τ 2 P Â> P B̂
0
B̂ > P Â
B̂ > P B̂
 1
>  1 1
 1
 (11)
Ĉ
D̂1
λ M
0
Ĉ
D̂1
+
0
λ2 M 2 Ĉ 2 D̂2
Ĉ 2 D̂2

0.6
ε = 0.5
ε = 0.25
ε=0

0.4

Then for all k ≥ 0, we have
√

0.8

100

101

kϕk − ϕ∗ k ≤ κB κP kϕ0 − ϕ∗ kτ .

such that (ξ∗ , ν∗ , w∗1 , w∗2 ) is a fixed point of the dynamics of (2) and satisfying β∗ = ∇fˆ(r∗ ), γ∗ ∈ ∂ĝ(s∗ ).
Now, consider the Kronecker product of the right hand side
of (11) and
 Ir . Multiplying this on the left and on the
right by (ξj − ξ∗ )> (νj − ν∗ )> and its transpose, respectively, we find
>

0 ≥ (ξj+1 − ξ∗ ) P (ξj+1 − ξ∗ )
+ λ1 (wj1 − w∗1 )> M 1 (wj1 − w∗1 )

(12)

Lemma 1 and (5a) show that the third term on the right
hand side of (12) is nonnegative. Lemma 2 and (5b) show
that the fourth term on the right hand side of (12) is nonnegative. It follows that

Inducting from j = 0 to k − 1, we see that
(ξk − ξ∗ )> P (ξk − ξ∗ ) ≤ τ 2k (ξ0 − ξ∗ )> P (ξ0 − ξ∗ ),

The conclusion follows.

√

κP kξ0 − ξ∗ kτ k .

105

102
ε = 0.5
ε = 0.25
ε=0

100
100

101

102

103

104

105

Condition number κ
Figure 2. For α = 1.5 and for several choices of ε in ρ0 = κε , we
compute the minimal rate τ such that the linear matrix inequality
in (11) is satisfied, and we plot −1/ log τ as a function of κ.

Note that when ρ0 = κε , the matrix M 1 is given by

(ξj+1 − ξ∗ )> P (ξj+1 − ξ∗ ) ≤ τ 2 (ξj − ξ∗ )> P (ξj − ξ∗ ).

kξk − ξ∗ k ≤

104

104

+ λ2 (wj2 − w∗2 )> M 2 (wj2 − w∗2 ).

for all k. It follows that

103

Figure 1. For α = 1.5 and for several choices of ε in ρ0 = κε ,
we plot the minimal rate τ for which the linear matrix inequality
in (11) is satisfied as a function of κ.

Number of iterations

Proof. Define rk , sk , βk , γk , ξk , νk , wk1 , and wk2 as before.
Choose r∗ = Ax∗ , s∗ = Bz∗ , and


 
 
 
r −c
s
s
β
w∗1 = ∗
w∗2 = ∗
ξ∗ = ∗
ν∗ = ∗
β∗
γ∗
u∗
γ∗

− τ 2 (ξj − ξ∗ )> P (ξj − ξ∗ )

102

Condition number κ

k

M1 =

−2κ−2ε
1
κ
+ κ 2 −ε



− 21 −ε


1
1
κ− 2 −ε + κ 2 −ε
,
−2

and so the linear matrix inequality in (11) depends only
on κ and not on m̂ and L̂. Therefore, we will consider
1
step sizes of this form (recall from (4) that ρ = (m̂L̂) 2 ρ0 ).
The choice ε = 0 is common in the literature (Giselsson
& Boyd, 2014), but requires the user to know the strongconvexity parameter m̂. We also consider the choice ε =

A General Analysis of the Convergence of ADMM

0.5, which produces worse guarantees, but does not require
knowledge of m̂.
One weakness of Theorem 6 is the fact that the rate we
produce is not given as a function of κ. To use Theorem 6
as stated, we first specify the condition number (for example, κ = 1000). Then we search for the minimal τ such
that (11) is feasible. This produces an upper bound on the
convergence rate of Algorithm 2 (for example, τ = 0.9).
To remedy this problem, in Section 5, we demonstrate how
Theorem 6 can be used to obtain the convergence rate of
Algorithm 2 as a symbolic function of the step size ρ and
the over-relaxation parameter α.

last row and column consist of zeros. We wish to prove
that M is positive semidefinite for all sufficiently large κ.
To do so, we consider the cases ε ≥ 0 and ε < 0 separately,
though the two cases will be nearly identical. First suppose
that ε ≥ 0. In this case, the nonzero entries of M are
specified by
3

M11 = ακ1−2ε + 4κ 2 −ε
3

3

M12 = α2 κ1−2ε − ακ1−2ε + 12κ 2 −ε − 4ακ 2 −ε
3

M13 = 4κ + 8κ 2 −ε
3

M22 = 8κ2 − 4ακ2 + ακ1−2ε + 4κ 2 −ε
3

M23 = 4κ + 8κ2 − 4ακ2 + 8κ 2 −ε

5. Symbolic Rates for Various ρ and α
In Section 4, we demonstrated how to use semidefinite programming to produce numerical convergence rates. That
is, given a choice of algorithm parameters and the condition number κ, we could determine the convergence rate
of Algorithm 2. In this section, we show how Theorem 6
can be used to prove symbolic convergence rates. That
is, we describe the convergence rate of Algorithm 2 as a
function of ρ, α, and κ. In Theorem 7, we prove the linear convergence of Algorithm 2 for all choices α ∈ (0, 2)
1
and ρ = (m̂L̂) 2 κε , with ε ∈ (−∞, ∞). This result generalizes a number of results in the literature. As two examples, Giselsson & Boyd (2014) consider the case ε = 0 and
Deng & Yin (2012) consider the case α = 1 and ε = 0.5.
The rate given in Theorem 7 is loose by a factor of four
relative to the lower bound given in Theorem 8. However,
weakening the rate by a constant factor eases the proof by
making it easier to find a certificate for use in (11).
Theorem 7. Suppose that Assumption 3 holds. Let the sequences (xk ), (zk ), and (uk ) be generated by running Algorithm 2 with parameter α ∈ (0, 2) and with step size ρ =
1
(m̂L̂) 2 κε , where ε ∈ (−∞, ∞). Define x∗ , z∗ , u∗ , ϕk ,
and ϕ∗ as in Theorem 6. Then for all sufficiently large κ,
we have

k
α
kϕk − ϕ∗ k ≤ Ckϕ0 − ϕ∗ k 1 − 0.5+|ε| ,
2κ

3

3

M33 = 8κ + 8κ2 − 4ακ2 + 8κ 2 −ε + 8κ 2 +ε .
We show that each of the first three leading principal minors of M is positive for sufficiently large κ. To understand
the behavior of the leading principal minors, it suffices to
look at their leading terms. For large κ, the first leading
principal minor (which is simple M11 ) is dominated by
3
the term 4κ 2 −ε , which is positive. Similarly, the second
leading principal minor is dominated by the term 16(2 −
7
α)κ 2 −ε , which is positive. When ε > 0, the third leading
principal minor is dominated by the term 128(2 − α)κ5 ,
which is positive. When ε = 0, the third leading principal
minor is dominated by the term 64α(2 − α)2 κ5 , which is
positive. Since these leading coefficients are all positive,
it follows that for all sufficiently large κ, the matrix M is
positive semidefinite.
Now suppose that ε < 0. In this case, the nonzero entries
of M are specified by
3

3

3

3

M11 = 8κ 2 −ε − 4κ 2 +ε + ακ1+2ε
3

M12 = 8κ 2 −ε + 4κ 2 +ε − 4ακ 2 +ε − ακ1+2ε + α2 κ1+2ε
3

M13 = 4κ + 8κ 2 −ε
3

3

M22 = 8κ2 − 4ακ2 + 8κ 2 −ε − 4κ 2 +ε + ακ1+2ε
3

M23 = 4κ + 8κ2 − 4ακ2 + 8κ 2 −ε
3

3

M33 = 8κ + 8κ2 − 4ακ2 + 8κ 2 −ε + 8κ 2 +ε .

Proof. We claim that for all sufficiently large κ, the linear
matrix inequality in (11) is satisfied with the rate τ = 1 −
α
and with certificate
2κ0.5+|ε|


1
α−1
λ1 = ακε−0.5 λ2 = α P =
.
α−1
1

As before, we show that each of the first three leading
principal minors of M is positive. For large κ, the first
leading principal minor (which is simple M11 ) is domi3
nated by the term 8κ 2 −ε , which is positive. Similarly,
the second leading principal minor is dominated by the
7
term 32(2 − α)κ 2 −ε , which is positive. The third leading
principal minor is dominated by the term 128(2 − α)κ5 ,
which is positive. Since these leading coefficients are all
positive, it follows that for all sufficiently large κ, the matrix M is positive semidefinite.

The matrix on the right hand side of (11) can be expressed
as − 41 ακ−2 M , where M is a symmetric 4×4 matrix whose

The result now follows from Theorem 6 by noting that P
has eigenvalues α and 2 − α.

where

r
C = κB

n

o
α
max 2−α
, 2−α
.
α

A General Analysis of the Convergence of ADMM

Note that since the matrix P doesn’t depend on ρ, the proof
holds even when the step size changes at each iteration.

rate given exactly by (16), which is lower bounded by the
expression in (15) when ε ≥ 0.

6. Lower Bounds

Now suppose that ε < 0. Choosing δ = L and λ = L,
after multiplying the numerator and denominator of (14)
by κ0.5−ε , we see that T has eigenvalue

Let Q be a d-dimensional symmetric positive-definite matrix whose largest and smallest eigenvalues are L and m
respectively. Let f (x) = 12 x> Qx be a quadratic and
let g(z) = 2δ kzk2 for some δ ≥ 0. Let A = Id , B = −Id ,
and c = 0. With these definitions, the optimization problem in (1) is solved by x = z = 0. The updates for Algorithm 2 are given by
xk+1 = ρ(Q + ρI)−1 (zk − uk )
ρ
(αxk+1 + (1 − α)zk + uk )
zk+1 =
δ+ρ
uk+1 = uk + αxk+1 + (1 − α)zk − zk+1 .

(13a)
(13b)
(13c)

Solving for zk in (13b) and substituting the result into (13c)
gives uk+1 = ρδ zk+1 . Then eliminating xk+1 and uk from
(13b) using (13a) and the fact that uk = ρδ zk allows us to
express the update rule purely in terms of z as


ρ − αρ + δ
αρ(ρ − δ)
−1
(Q + ρI) +
I zk .
zk+1 =
ρ+δ
ρ+δ
|
{z
}
T

Note that the eigenvalues of T are given by
1−

αρ(λ + δ)
,
(ρ + δ)(λ + ρ)

(14)

Theorem 8. Suppose that Assumption 3 holds. The worstcase convergence rate of Algorithm 2, when run with step
1
size ρ = (m̂L̂) 2 κε and over-relaxation parameter α, is
lower-bounded by
2α
.
1 + κ0.5+|ε|

α
.
1 + κ0.5+ε

(1 +

+ 1)

≥ 1−

2α
. (17)
1 + κ0.5−ε

When initialized with z as the eigenvector corresponding
to this eigenvalue, Algorithm 2 will converge linearly with
rate given exactly by the left hand side of (17), which is
lower bounded by the expression in (15) when ε < 0.
Figure 3 compares the lower bounds given by (16) with
the upper bounds given by Theorem 6 for α = 1.5 and
1
for several choices of ρ = (m̂L̂) 2 κε satisfying ε ≥ 0.
The upper and lower bounds agree visually on the range of
choices ε depicted, demonstrating the practical tightness of
the upper bounds given by Theorem 6 for a large range of
choices of parameter values.

104

ε = 0.5 upper
ε = 0.25 upper
ε = 0 upper

102

ε = 0.5 lower
ε = 0.25 lower
ε = 0 lower

100

101

102

103

104

105

Condition number κ
Figure 3. For α = 1.5 and for several choices ε in ρ0 = κε , we
plot −1/ log τ as a function of κ, both for the lower bound on τ
given by (16) and the upper bound on τ given by Theorem 6. For
each choice of ε in {0.5, 0.25, 0}, the lower and upper bounds
agree visually. This agreement demonstrates the practical tightness of the upper bounds given by Theorem 6 for a large range of
choices of parameter values.

(15)

7. Related Work

Proof. First consider the case ε ≥ 0. Choosing δ = 0
and λ = m, from (14), we see that T has eigenvalue
1−

2α
κ0.5−ε )(κ−0.5+ε

100

where λ is an eigenvalue of Q. We will use this setup to
construct a lower bound on the worst-case convergence rate
of Algorithm 2 in Theorem 8.

1−

1−

Number of iterations

In this section, we probe the tightness of the upper bounds
on the convergence rate of Algorithm 2 given by Theorem 6. The construction of the lower bound in this section
is similar to a construction given in Ghadimi et al. (2015).

(16)

When initialized with z as the eigenvector corresponding
to this eigenvalue, Algorithm 2 will converge linearly with

Several recent papers have studied the linear convergence
of Algorithm 1 but do not extend to Algorithm 2. Deng &
Yin (2012) prove a linear rate of convergence for ADMM
in the strongly convex case. Iutzeler et al. (2014) prove the
linear convergence of a specialization of ADMM to a class
of distributed optimization problems under a local strongconvexity condition. Hong & Luo (2012) prove the linear

A General Analysis of the Convergence of ADMM

More generally, there are a number of results for operator splitting methods in the literature. Lions & Mercier
(1979) and Eckstein & Ferris (1998) analyze the convergence of several operator splitting schemes. More recently, Patrinos et al. (2014a;b) prove the equivalence of
forward-backward splitting and Douglas–Rachford splitting with a scaled version of the gradient method applied
to unconstrained nonconvex surrogate functions (called the
forward-backward envelope and the Douglas–Rachford envelope respectively). Goldstein et al. (2012) propose an
accelerated version of ADMM in the spirit of Nesterov,
and prove a O(1/k 2 ) convergence rate in the case where f
and g are both strongly convex and g is quadratic.
The theory of over-relaxed ADMM is more limited. Eckstein & Bertsekas (1992) prove the convergence of overrelaxed ADMM but do not give a rate. More recently,
Davis & Yin (2014a;b) analyze the convergence rates of
ADMM in a variety of settings. Giselsson & Boyd (2014)
prove the linear convergence of Douglas–Rachford splitting in the strongly-convex setting. They use the fact that
ADMM is Douglas–Rachford splitting applied to the dual
problem (Eckstein & Bertsekas, 1992) to derive a linear
convergence rate for over-relaxed ADMM with a specific
choice of step size ρ. Eckstein (1994) gives convergence results for several specializations of ADMM, and found that
over-relaxation with α = 1.5 empirically sped up convergence. Ghadimi et al. (2015) give some guidance on tuning
over-relaxed ADMM in the quadratic case.
Unlike prior work, our framework requires no assumptions
on the parameter choices in Algorithm 2. For example,
Theorem 6 certifies the linear convergence of Algorithm 2
even for values α > 2. In our framework, certifying a convergence rate for an arbitrary choice of parameters amounts
to checking the feasibility of a 4 × 4 semidefinite program,
which is essentially instantaneous, as opposed to formulating a proof.

8. Selecting Algorithm Parameters
In this section, we show how to use the results of Section 4
to select the parameters α and ρ in Algorithm 2 and we
show the effect on a numerical example.
Recall that given a choice of parameters α and ρ and given
the condition number κ, Theorem 6 gives an upper bound
on the convergence rate of Algorithm 2. Therefore, one approach to parameter selection is to do a grid search over
the space of parameters for the choice that minimizes the
upper bound provided by Theorem 6. We demonstrate

this approach numerically for a distributed Lasso problem,
but first we demonstrate that the usual range of (0, 2) for
the over-relaxation parameter α is too limited, that more
choices of α lead to linear convergence. In Figure 4, we
plot the largest value of α found through binary search such
that (11) is satisfied for some τ < 1 as a function of κ.
Proof techniques in prior work do not extend as easily to
values of α > 2. In our framework, we simply change
some constants in a small semidefinite program.
4

3.5

Largest α

convergence of a generalization of ADMM to a multiterm
objective in the setting where each term can be decomposed
as a strictly convex function and a polyhedral function. In
particular, this result does not require strong convexity.

3

2.5

2
100

101

102

103

104

105

Condition number κ
Figure 4. As a function of κ, we plot the largest value of α such
that (11) is satisfied for some τ < 1. In this figure, we set ε = 0
in ρ0 = κε .

8.1. Distributed Lasso
Following Deng & Yin (2012), we give a numerical demonstration with a distributed Lasso problem of the form
minimize

N
X
1
kAi xi − bi k2 + kzk1
2µ
i=1

subject to xi − z = 0 for all i = 1, . . . , N.
Each Ai is a tall matrix with full column rank, and so the
first term in the objective will be strongly convex and its
gradient will be Lipschitz continuous. As in Deng & Yin
(2012), we choose N = 5 and µ = 0.1. Each Ai is
generated by populating a 600 × 500 matrix with independent standard normal entries and normalizing the columns.
We generate each bi via bi = Ai x0 + εi , where x0 is a
sparse 500-dimensional vector with 250 independent standard normal entries, and εi ∼ N (0, 10−3 I).
In Figure 5, we compute the upper bounds on the convergence rate given by Theorem 6 for a grid of values of α
and ρ. Each line corresponds to a fixed choice of α, and
we plot only a subset of the values of α to keep the plot
manageable. We omit points corresponding to parameter
values for which the linear matrix inequality in (11) was
not feasible for any value of τ < 1.
In Figure 6, we run Algorithm 2 for the same values of α

A General Analysis of the Convergence of ADMM
1,000

0.98

0.96

0.94

0.92
10−1

Number of iterations

Convergence rate τ

1

α=1
α = 1.5
α = 1.9
α=2
α = 2.025
α = 2.05
α = 2.075
100

101

800
600
400
200
0
10−1

Step-size parameter ρ
Figure 5. We compute the upper bounds on the convergence rate
given by Theorem 6 for eighty-five values of α evenly spaced
between 0.1 and 2.2 and fifty values of ρ geometrically spaced
between 0.1 and 10. Each line corresponds to a fixed choice of α,
and we show only a subset of the values of α to keep the plot
manageable. We omit points corresponding to parameter values
for which (11) is not feasible for any value of τ < 1. This analysis
suggests choosing α = 2.0 and ρ = 1.7.

and ρ. We then plot the number of iterations needed for zk
to reach within 10−6 of a precomputed reference solution.
We plot lines corresponding to only a subset of the values
of α to keep the plot manageable, and we omit points corresponding to parameter values for which Algorithm 2 exceeded 1000 iterations. For the most part, the performance
of Algorithm 2 as a function of ρ closely tracked the performance predicted by the upper bounds in Figure 5. Notably,
smaller values of α seem more robust to poor choices of ρ.
The parameters suggested by our analysis perform close to
the best of any parameter choices.

9. Discussion
We showed that a framework based on semidefinite programming can be used to prove convergence rates for the
alternating direction method of multipliers and allows a
unified treatment of the algorithm’s many variants, which
arise through the introduction of additional parameters. We
showed how to use this framework for establishing convergence rates, as in Theorem 6 and Theorem 7, and how to
use this framework for parameter selection in practice, as
in Section 8. The potential uses are numerous. This framework makes it straightforward to propose new algorithmic
variants, for example, by introducing new parameters into
Algorithm 2 and using Theorem 6 to see if various settings
of these new parameters give rise to improved guarantees.
In the case that Assumption 3 does not hold, the most likely
cause is that we lack the strong convexity of f . One ap-

α=1
α = 1.5
α = 1.9
α=2
α = 2.025
α = 2.05
α = 2.075

100

101

Step-size parameter ρ
Figure 6. We run Algorithm 2 for eighty-five values of α evenly
spaced between 0.1 and 2.2 and fifty value of ρ geometrically
spaced between 0.1 and 10. We plot the number of iterations
required for zk to reach within 10−6 of a precomputed reference
solution. We show only a subset of the values of α to keep the plot
manageable. We omit points corresponding to parameter values
for which Algorithm 2 exceeded 1000 iterations.

proach to handling this is to run Algorithm 2 on the modified function f (x) + 2δ kxk2 . By completing the square in
the x update, we see that this amounts to an extremely minor algorithmic modification (it only affects the x update).
It should be clear that other operator splitting methods such
as Douglas–Rachford splitting and forward-backward splitting can be cast in this framework and analyzed using the
tools presented here.

Acknowledgments
This research is supported in part by NSF CISE Expeditions award CCF-1139158, LBNL award 7076018,
DARPA XData award FA8750-12-2-0331, AFOSR award
FA9550-12-1-0339, NASA grant NRA NNX12AM55A,
ONR grants N00014-11-1-0688 and N00014-14-1-0024,
US ARL and US ARO grant W911NF-11-1-0391, NSF
awards CCF-1359814 and CCF-1217058, NSF grant DGE1106400, a Sloan Research Fellowship, and gifts from
Amazon Web Services, Google, SAP, The Thomas and
Stacey Siebel Foundation, Adatao, Adobe, Apple, Blue
Goji, Bosch, C3Energy, Cisco, Cray, Cloudera, EMC,
Ericsson, Facebook, Guavus, Huawei, Informatica, Intel,
Microsoft, NetApp, Pivotal, Samsung, Splunk, Virdata,
VMware, and Yahoo!.

References
Aslan, Ö., Cheng, H., Zhang, X., and Schuurmans, D. Convex two-layer modeling. In Advances in Neural Informa-

A General Analysis of the Convergence of ADMM

tion Processing Systems, pp. 2985–2993, 2013.
Behmardi, B., Archambeau, C., and Bouchard, G. Overlapping trace norms in multi-view learning. arXiv preprint
arXiv:1404.6163, 2014.
Bioucas-Dias, J. M. and Figueiredo, M. A. T. Alternating
direction algorithms for constrained sparse regression:
application to hyperspectral unmixing. In Hyperspectral Image and Signal Processing: Evolution in Remote
Sensing, pp. 1–4. IEEE, 2010.
Bird, S. Optimizing Resource Allocations for Dynamic Interactive Applications. PhD thesis, University of California, Berkeley, 2014.
Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eckstein, J.
Distributed optimization and statistical learning via the
alternating direction method of multipliers. Foundations
and Trends in Machine Learning, 3(1):1–122, 2011.
Corless, M. Guaranteed rates of exponential convergence
for uncertain systems. Journal of Optimization Theory
and Applications, 64(3):481–494, 1990.
D’Alto, L. and Corless, M. Incremental quadratic stability. Numerical Algebra, Control and Optimization, 3(1):
175–201, 2013.
Davis, D. and Yin, W. Convergence rate analysis of several splitting schemes. arXiv preprint arXiv:1406.4834,
2014a.
Davis, D. and Yin, W. Convergence rates of relaxed
Peaceman-Rachford and ADMM under regularity assumptions. arXiv preprint arXiv:1407.5210, 2014b.

Forouzan, S. and Ihler, A. Linear approximation to ADMM
for MAP inference. In Asian Conference on Machine
Learning, pp. 48–61, 2013.
Gabay, D. and Mercier, B. A dual algorithm for the solution of nonlinear variational problems via finite element
approximation. Computers & Mathematics with Applications, 2(1):17–40, 1976.
Ghadimi, E., Teixeira, A., Shames, I., and Johansson, M.
Optimal parameter selection for the alternating direction method of multipliers (ADMM): Quadratic problems. IEEE Transactions on Automatic Control, 60(3):
644–658, 2015.
Giselsson, P. and Boyd, S. Diagonal scaling in Douglas–
Rachford splitting and ADMM. In IEEE Conference on
Decision and Control, pp. 5033–5039, 2014.
Glowinski, R. and Marroco, A. Sur l’approximation,
par éléments finis d’ordre un, et la résolution,
par pénalisation-dualité d’une classe de problèmes
de Dirichlet non linéaires.
ESAIM: Mathematical Modelling and Numerical Analysis-Modélisation
Mathématique et Analyse Numérique, 9(R2):41–76,
1975.
Goldstein, T., O’Donoghue, B., and Setzer, S. Fast alternating direction optimization methods. CAM report, pp.
12–35, 2012.
Hong, M. and Luo, Z.-Q. On the linear convergence of
the alternating direction method of multipliers. arXiv
preprint arXiv:1208.3922, 2012.

Deng, W. and Yin, W. On the global and linear convergence of the generalized alternating direction method of
multipliers. Technical report, DTIC Document, 2012.

Iutzeler, F., Bianchi, P., Ciblat, Ph., and Hachem, W. Linear
convergence rate for distributed optimization with the alternating direction method of multipliers. In IEEE Conference on Decision and Control, pp. 5046–5051, 2014.

Eckstein, J. Parallel alternating direction multiplier decomposition of convex programs. Journal of Optimization
Theory and Applications, 80(1):39–62, 1994.

Lessard, L., Recht, B., and Packard, A. Analysis and design
of optimization algorithms via integral quadratic constraints. arXiv preprint arXiv:1408.3595, 2014.

Eckstein, J. and Bertsekas, D. P. On the Douglas–Rachford
splitting method and the proximal point algorithm for
maximal monotone operators. Mathematical Programming, 55(1-3):293–318, 1992.

Li, M., Andersen, D. G., Smola, A. J., and Yu, K. Communication efficient distributed machine learning with the
parameter server. In Advances in Neural Information
Processing Systems, pp. 19–27, 2014.

Eckstein, J. and Ferris, M. C. Operator-splitting methods
for monotone affine variational inequalities, with a parallel application to optimal control. INFORMS Journal
on Computing, 10(2):218–235, 1998.

Lions, P.-L. and Mercier, B. Splitting algorithms for the
sum of two nonlinear operators. SIAM Journal on Numerical Analysis, 16(6):964–979, 1979.

Forero, P. A., Cano, A., and Giannakis, G. B. Consensusbased distributed support vector machines. The Journal
of Machine Learning Research, 11:1663–1707, 2010.

Meshi, O. and Globerson, A. An alternating direction
method for dual MAP LP relaxation. In Machine Learning and Knowledge Discovery in Databases, pp. 470–
483. Springer, 2011.

A General Analysis of the Convergence of ADMM

Patrinos, P., Stella, L., and Bemporad, A. Douglas–
Rachford splitting: complexity estimates and accelerated
variants. In IEEE Conference on Decision and Control,
pp. 4234–4239, 2014a.
Patrinos, P., Stella, L., and Bemporad, A. Forwardbackward truncated Newton methods for large-scale
convex composite optimization.
arXiv preprint
arXiv:1402.6655, 2014b.
Romera-Paredes, B. and Pontil, M. A new convex relaxation for tensor completion. In Advances in Neural Information Processing Systems, pp. 2967–2975, 2013.
Sedghi, H., Anandkumar, A., and Jonckheere, E. Multistep stochastic ADMM in high dimensions: Applications to sparse optimization and matrix decomposition.
In Advances in Neural Information Processing Systems,
pp. 2771–2779, 2014.
Wahlberg, B., Boyd, S., Annergren, M., and Wang, Y. An
ADMM algorithm for a class of total variation regularized estimation problems. In IFAC Symposium on System
Identification, pp. 83–88, 2012.
Wang, H. and Banerjee, A. Online alternating direction
method. In International Conference on Machine Learning, pp. 1119–1126, 2012.
Wang, H., Banerjee, A., Hsieh, C.-J., Ravikumar, P. K., and
Dhillon, I. S. Large scale distributed sparse precision estimation. In Advances in Neural Information Processing
Systems, pp. 584–592, 2013.
Zhang, C., Lee, H., and Shin, K. G. Efficient distributed
linear classification algorithms via the alternating direction method of multipliers. In International Conference
on Artificial Intelligence and Statistics, pp. 1398–1406,
2012.
Zhang, R. and Kwok, J. Asynchronous distributed ADMM
for consensus optimization. In International Conference
on Machine Learning, pp. 1701–1709, 2014.

