An Adaptive Accelerated Proximal Gradient Method and its Homotopy
Continuation for Sparse Optimization

Qihang Lin
The University of Iowa, Iowa City, IA 52245 USA

QIHANG - LIN @ UIOWA . EDU

Lin Xiao
Microsoft Research, Redmond, WA 98052 USA

Abstract
We first propose an adaptive accelerated proximal gradient (APG) method for minimizing
strongly convex composite functions with unknown convexity parameters. This method incorporates a restarting scheme to automatically estimate the strong convexity parameter and
achieves a nearly optimal iteration complexity. Then we consider the â„“1 -regularized leastsquares (â„“1 -LS) problem in the high-dimensional
setting. Although such an objective function
is not strongly convex, it has restricted strong
convexity over sparse vectors. We exploit this
property by combining the adaptive APG method
with a homotopy continuation scheme, which
generates a sparse solution path towards optimality. This method obtains a global linear rate of
convergence and its overall iteration complexity
has a weaker dependency on the restricted condition number than previous work.

1. Introduction
We consider first-order methods for minimizing composite
objective functions, i.e., the problem of
n
o
Ï†(x)
,
f
(x)
+
Î¨(x)
,
(1)
minimize
n
xâˆˆR

where f (x) and Î¨(x) are lower-semicontinuous, proper
convex functions (Rockafellar, 1970, Section 7). We assume that f is differentiable on an open set containing
dom Î¨ and its gradient âˆ‡f is Lipschitz continuous on
dom Î¨, i.e., there exists a constant Lf such that
kâˆ‡f (x) âˆ’ âˆ‡f (y)k2 â‰¤ Lf kx âˆ’ yk2, âˆ€ x, y âˆˆ dom Î¨. (2)
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

LIN . XIAO @ MICROSOFT. EDU

We also assume Î¨(x) is simple (Nesterov, 2013), meaning
that for any y âˆˆ dom Î¨, the following auxiliary problem
can be solved efficiently or in closed-form:

L
2
TL (y) = arg min âˆ‡f (y) x + kx âˆ’ yk2 + Î¨(x) .
2
x
(3)
This is the case, e.g., when Î¨(x) = Î»kxk1 for any Î» > 0,
or Î¨(x) is the indicator function of a closed convex set that
admits an easy projection mapping.


T

The so-called proximal gradient (PG) method simply uses (3) as its update rule: x(k+1) = TL (x(k) ), for k =
0, 1, 2, . . ., where L is set to Lf or determined by a linear search procedure. The iteration complexity for the PG
method is O(Lf /Ç«) (Nesterov, 2004; 2013), which means, to obtain an Ç«-optimal solution (whose objective value is
within Ç« of the optimum), the PG method needsp
O(Lf /Ç«)

iterations. A far better iteration complexity, O Lf /Ç« ,
can be obtained by accelerated proximal gradient (APG)
methods (Nesterov, 2013; Beck & Teboulle, 2009; Tseng,
2008).
The iteration complexities above imply that both PG and
APG methods have a sublinear convergence rate. However,
if f is strongly convex, i.e., there exists a constant Âµf > 0
(the convexity parameter) such that
f (x) â‰¥ f (y) + hâˆ‡f (y), x âˆ’ yi +

Âµf
kx âˆ’ yk22 ,
2

(4)

for all x, y âˆˆ dom Î¨, then both PG and APG methods will achieve a linear convergence rate with the iteration
âˆš
complexities being O(Îºf log(1/Ç«)) and O( Îºf log(1/Ç«))
(Nesterov, 2004; 2013), respectively. Here, Îºf = Lf /Âµf
is called condition number of the function f . Since Îºf is
typically a large number, the iteration complexity of the
APG methods can be significantly better than that of the
PG method for ill-conditioned problems. However, in order to obtain this better complexity, the APG methods need
to use the convexity parameter Âµf , or a lower bound of it,

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

explicitly in their updates. In many applications, an effective lower bound of Âµf can be hard to estimate.
To address this problem, our first contribution in this paper is an adaptive APG method for solving problem (1)
when f is strongly convex but Âµf is unknown. This method
incorporates a restart scheme that can automatically estian iteration complexity of
mate Âµf on the fly and achieves

âˆš
O Îºf log Îºf Â· log(1/Ç«) .

Even if f is not strongly convex (Âµf = 0), problem (1) may
have special structure that may still allow the development
of first-order methods with linear convergence. This is the
case for the â„“1 -regularized least-squares (â„“1 -LS) problem,
defined as
minimize
x

Ï†Î» (x) ,

1
kAx âˆ’ bk22 + Î»kxk1 ,
2

(5)

where A âˆˆ RmÃ—n and b âˆˆ Rm are the problem data, and
Î» > 0 is a regularization parameter. The problem has important applications in machine learning, signal processing, and statistics; see, e.g., Tibshirani (1996); Chen et al.
(1998); Bruckstein et al. (2009). We are especially interested in solving this problem in the high-dimensional case
(m < n) and when the solution, denoted as xâ‹† (Î»), is sparse.
In terms of the general model in (1), we have f (x) =
(1/2)kAx âˆ’ bk22 and Î¨(x) = Î»kxk1 . Here f (x) has a
constant Hessian âˆ‡2 f (x) = AT A, and we have Lf =
Ïmax (AT A) and Âµf = Ïmin (AT A) where Ïmax (Â·) and
Ïmin (Â·) denote the largest and smallest eigenvalues, respectively, of a symmetric matrix. Under the assumption
m < n, the matrix AT A is singular, hence Âµf = 0 (i.e., f is
not strongly convex). Therefore, we only expect sublinear
convergence rates (at least globally) when using first-order
optimization methods.
Nevertheless, even in the case of m < n, when the solution xâ‹† (Î») is sparse, the PG method often exhibits fast
convergence when it gets close to the optimal solution. Indeed, local linear convergence can be established for the
PG method provided that the active submatrix (columns
of A corresponding to the nonzero entries of the sparse iterates) is well conditioned (Luo & Tseng, 1992; Hale et al.,
2008; Bredies & Lorenz, 2008). To explain this more formally, we define the restricted eigenvalues of A at the sparsity level s as
 T T

x A Ax
Ï+ (A, s) = sup
: x 6= 0, kxk0 â‰¤ s ,
xT x
 T T

x A Ax
Ïâˆ’ (A, s) = inf
: x 6= 0, kxk0 â‰¤ s ,
xT x
(6)
where s is a positive integer and kxk0 denotes the number
of nonzero entries of a vector x âˆˆ Rn . From the above

definitions, we have
Âµf â‰¤ Ïâˆ’ (A, s) â‰¤ Ï+ (A, s) â‰¤ Lf ,

âˆ€ s > 0.

As discussed before, we have Âµf = 0 for m < n. But it is
still possible that Ïâˆ’ (A, s) > 0 holds for some s < m.
In this case, we say that the matrix A satisfies the restricted eigenvalue condition at the sparsity level s. Let
supp(x) = {j : xj 6= 0}, and assume that x, y âˆˆ Rn
satisfy |supp(x) âˆª supp(y)| â‰¤ s. Then it can be shown
(Xiao & Zhang, 2013, Lemma 3) that
f (x) â‰¥ f (y) + hâˆ‡f (y), x âˆ’ yi +

Ïâˆ’ (A, s)
kx âˆ’ yk22 .
2

The above inequality gives the notion of restricted strong
convexity (cf. strong convexity defined in (4)). Intuitively, if
the iterates of the PG method become sparse and their supports do not fluctuate much from each other, then restricted
strong convexity leads to (local) linear convergence. This
is exactly what happens when the PG method speeds up
while getting close to the optimal solution.
Moreover, such a local linear convergence can be exploited
by a homotopy continuation strategy to obtain much faster
global convergence (Hale et al., 2008; Wright et al., 2009;
Xiao & Zhang, 2013). The basic idea is to solve the â„“1 -LS
problem (5) with a large value of Î» first, and then gradually decreases the value of Î» until the target regularization is reached. For each value of Î», Xiao & Zhang (2013)
employ the PG method to solve (5) up to an adequate precision, and then use the resulting approximate solution to
warm start the PG method for (5) with the next value of Î».
It is shown (Xiao & Zhang, 2013) that under suitable assumptions for sparse recovery (mainly the restricted eigenvalue condition), an appropriate homotopy strategy can ensure all iterates of the PG method be sparse, hence linear
convergence at each stage can be established. As a result,
the overall iteration complexity of such a proximal-gradient

e Îºs log(1/Ç«) where Îºs dehomotopy (PGH) method is O
notes the restricted condition number at some sparsity level
s > 0, i.e.,
Îºs , Îº(A, s) =

Ï+ (A, s)
,
Ïâˆ’ (A, s)

e hides additional log(Îºs ) factors.
and the notation O(Â·)

(7)

Our second contribution in this paper is to show that, by
using the adaptive APG method developed in this paper in
a homotopy continuation scheme, we can further improve
the iteration complexity
for solving the â„“1 -LS problem to

e âˆšÎºsâ€² log(1/Ç«) , where the sparsity level sâ€² is slightly
O
larger than the one for the PGH method. We note that this
result is not a trivial extension from the convergence results
for the PGH method in Xiao & Zhang (2013). In particular,
the adaptive APG method does not have the property of

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

monotone decreasing, which was important for the analysis
of the PGH method. In order to overcome this difficulty, we
had to show a â€œnon-blowoutâ€ property of our adaptive APG
method, which is interesting in its own right.

2. An APG method for minimizing strongly
convex functions
The main iteration of the APG method is based on a
composite gradient mapping introduced by Nesterov in
(Nesterov, 2013). For any fixed point y and a given constant L > 0, we define a local model of Ï†(x) around y
using a quadratic approximation of f but keeping Î¨ intact:
ÏˆL (y; x) = f (y) + âˆ‡f (y)T (x âˆ’ y) +

L
kx âˆ’ yk22 + Î¨(x).
2

According to (3), we have
TL (y) = arg min ÏˆL (y; x).

(8)

x

Then the composite gradient mapping of f at y is defined
as
gL (y) = L(y âˆ’ TL (y)).
Following (Nesterov, 2013), we also define a local Lipschitz parameter
SL (y) =

kâˆ‡f (TL (y)) âˆ’ âˆ‡f (y)k2
.
kTL (y) âˆ’ yk2

With the machinery of composite gradient mapping,
Nesterov (2004; 2013) developed several variants of the
APG methods. As discussed in the introduction, compared
to the PG method, the iteration complexity of the accelerated methods have a better dependence on the accuracy Ç«
when f is not strongly convex, and a better dependence on
the condition number Îºf when f is strongly convex. However, in contrast with the PG method, the better complexity
bound of the APG method in the strongly convex case relies on the knowledge of the convexity parameter Âµf , or an
effective lower bound of it, both of which can be hard to
obtain in practice.
To address this problem, we propose an adaptive APG
method that can be applied without knowing Âµf and still
obtains a linear convergence rate. To do so, we first present
an APG method in Algorithm 1 and in Algorithm 2 upon which the development of the adaptive APG method is
based. We name this method scAPG, where â€œscâ€ stands for
â€œstrongly convex.â€
To use this algorithm, we need to first choose an initial
optimistic estimate Lmin for the Lipschitz constant Lf :
0 < Lmin â‰¤ Lf , and two adjustment parameters Î³dec â‰¥ 1
and Î³inc > 1. In addition, this method requires an input parameter Âµ > 0, which is an estimate of the true convexity

Algorithm 1 {xÌ‚, MÌ‚ } â† scAPG(x(0) , L0 , Âµ, Ç«Ì‚)
parameter: Lmin â‰¥ Âµ > 0, Î³dec â‰¥ 1
x(âˆ’1) â† x(0)
Î±âˆ’1 = 1
repeat
( for k = 0, 1, 2, . . .)
{x(k+1) , Mk , Î±k , g (k) , Sk }
â† AccelLineSearch(x(k) , x(kâˆ’1) , Lk , Âµ, Î±kâˆ’1 )
Lk+1 â† max{Lmin, Mk /Î³dec }
until Ï‰(x(k+1) ) â‰¤ Ç«Ì‚
xÌ‚ â† x(k+1)
MÌ‚ â† Mk
Algorithm 2 {x(k+1) , Mk , Î±k , g (k) , Sk }
â† AccelLineSearch(x(k) , x(kâˆ’1) , Lk , Âµ, Î±kâˆ’1 )
parameter: Î³inc > 1
L â† Lk /Î³inc
repeat
L â† LÎ³
pinc
Âµ
Î±k â† L
k (1âˆ’Î±kâˆ’1 )
(k)
y (k) â† x(k) + Î±
âˆ’ x(kâˆ’1) )
Î±kâˆ’1 (1+Î±k ) (x
x(k+1) â† TL (y (k) )
until Ï†(x(k+1) ) â‰¤ ÏˆL (y (k) ; x(k+1) )
Mk â† L
g (k) â† Mk (y (k) âˆ’ x(k+1) )
Sk â† SL (y (k) )

parameter Âµf . The scAPG method generates the following
three sequences:
r
Âµ
,
Î±k =
Mk
Î±k (1 âˆ’ Î±kâˆ’1 ) (k)
y (k) = x(k) +
(x âˆ’ x(kâˆ’1) ), (9)
Î±kâˆ’1 (1 + Î±k )
x(k+1) = TMk (y (k) ).
where Mk is found by the line-search procedure in Algorithm 2. The line search procedure starts with an estimated Lipschitz constant Lk , and increases its value by the
factor Î³inc until Ï†(x(k+1) ) â‰¤ ÏˆMk (y (k) ; x(k+1) ), which
is sufficient to guarantee the convergence. In each iteration of Algorithm 1, the scAPG method tries to start the
line search at a smaller initial value by setting Lk+1 to be
min{Lmin , Mk /Î³dec }.
The scAPG algorithm can be considered as an extension
of the constant step scheme of Nesterov (2004) for minimizing composite functions
pin (1) when Âµf > 0. Indeed, if
Mk = Lf , we have Î±k = Âµf /Lf for all k and the update
for y (k) becomes
p
âˆš
Lf âˆ’ Âµf (k)
(k)
(k)
(kâˆ’1)
y =x +p
),
(10)
âˆš (x âˆ’ x
L f + Âµf

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

which is the same as Algorithm (2.2.11) in Nesterov
(2004). Note that, one can not directly apply Algorithm 1
or Nesterovâ€™s constant scheme to problems without strongly convexity by simply setting Âµ = 0.
Another difference from Nesterovâ€™s method is that Algorithm 1 has an explicit stopping criterion based on the optimality residue Ï‰(x(k+1) ), which is defined as
Ï‰(x) , min kâˆ‡f (x) + Î¾kâˆ ,
Î¾âˆˆâˆ‚Î¨(x)

(11)

where âˆ‚Î¨(x) is the subdifferential of Î¨ at x. The optimality residue measures how close a solution x is to the
optimality condition of (1) in the sense that Ï‰(xâ‹† ) = 0 if
and only if xâ‹† is an solution to (1).
The following theorem states that, if Âµ is a positive lower
bound of Âµf , the scAPG converges geometrically and it has
âˆš
an iteration complexity O( Îºf log(1/Ç«)).
Theorem 1. Suppose xâ‹† is the optimal solution of (1) and
0 < Âµ â‰¤ Âµf . Then Algorithm 1 guarantees that
h
i
Âµ
Ï†(x(k) )âˆ’Ï†(xâ‹† ) â‰¤ Ï„k Ï†(x(0) )âˆ’Ï†(xâ‹† )+ kx(0) âˆ’xâ‹† k22 ,
2
(12)
i
h
Âµ
Âµ (k)
ky âˆ’xâ‹† k22 â‰¤ Ï„k Ï†(x(0) )âˆ’Ï†(xâ‹† )+ kx(0) âˆ’xâ‹† k22 ,
2
2
(13)
where
Ï„k =
Moreover,



1
Qkâˆ’1

Ï„k â‰¤

i=0

k = 0,
(1 âˆ’ Î±i ) k â‰¥ 1.


r
1âˆ’

Âµ
Lf Î³inc

k

(14)

.

In addition to the geometric convergence of Ï†(x(k) ), this
theorem states that the auxiliary sequence y (k) also converges to the unique optimizer xâ‹† with a geometric rate.
If Âµ does not satisfies Âµ â‰¤ Âµf , Theorem 1 may not hold
anymore. However, we can show that, in this case, Algorithm 1 will at least not blowout. More precisely, we show
that Ï†(x(k) ) â‰¤ Ï†(x(0) ) for all k â‰¥ 1 as long as Âµ â‰¤ Lmin,
which can be easily enforced in implementation of the algorithm.
Lemma 1. Suppose 0 < Âµ â‰¤ Lmin. Then Algorithm 1
guarantees that
Ï†(x(k+1) ) â‰¤ Ï†(x(0) ) âˆ’


Mk 
x(k+1) âˆ’ x(k) 2 .
2
2

(15)

The non-blowout property is also critical in our analysis of
the homotopy method for solving the â„“1 -LS problem presented in Section 4. In particular, it helps to show the sparsity of x(k) once x(0) is sparse. (All proofs for our results
are given in the supporting materials).

3. An Adaptive APG method with restart
When applied to strongly convex minimization problems, Nesterovâ€™s constant step scheme (10) needs to use Lf
and Âµf as input parameters. Thanks to the line-search technique, Algorithm 1 does not need to know Lf explicitly.
However, it still need to know the convexity parameter Âµf
or a nontrivial lower bound of it in order to guarantee the
geometric convergence rate given in Theorem 1.
Compared to line search on Lf , estimating Âµf on-the-fly
is much more sophisticated. Nesterov (2013) suggested a
restarting scheme to estimate Âµf , which does not require
any lower bound of Âµf , and can be shown to have linear
convergence (up to a logarithmic factor). In this section,
we adapt his restarting technique to Algorithm 1 and obtain
an adaptive APG method. This method has the same convergence guarantees as Nesterovâ€™s scheme. However, there
are two important differences, which we will elaborate on
at the end of this section.
We first describe the basic idea of the restart scheme for
estimating Âµf . Suppose we simply run Algorithm 1 with
a guessed value Âµ. At each iteration, we can check if the
inequality (12) is satisfied. If not, we must have Âµ > Âµf according to Theorem 1, and therefore need to reduce Âµ to ensure Algorithm 1 converges in a linear rate. However, (12)
can not be evaluated because xâ‹† is unknown. Fortunately,
we can show in the following lemma that, if Âµ â‰¤ Âµf , the
norm of the gradient mapping g (k) = gMk (y (k) ) generated
in Algorithm 1 also decreases at a linear rate.
Lemma 2. Suppose 0 < Âµ â‰¤ Âµf and the initial point x(0) of Algorithm 1 is obtained by calling Algorithm 2, i.e., {x(0) , Mâˆ’1 , Î±âˆ’1 , g (âˆ’1) , Sâˆ’1 } â†
AccelLineSearch(xini , xini , Lini , Âµ, 1) with an arbitrary xini âˆˆ Rn and Lini â‰¥ Lmin . Then, for any k â‰¥ 0
in Algorithm 1, we have


âˆš
gM (y (k) ) â‰¤ 2 2Ï„k Mk
k
2
Âµ




Sâˆ’1 
g (âˆ’1)  .
1+
2
Mâˆ’1

(16)

Unlike the inequality (12), the inequality (16) can be
checked explicitly and, if it does not hold, we know Âµ > Âµf
and need to reduce Âµ.
Now we are ready to develop the adaptive APG method.
Let Î¸sc âˆˆ (0, 1) be a desired shrinking factor. We check the
following two conditions at iteration k of Algorithm 1:




â€¢ A: gMk (y (k) )2 â‰¤ Î¸sc g (âˆ’1) 2 .


âˆš
Sâˆ’1
â‰¤ Î¸sc .
â€¢ B: 2 2Ï„k MÂµk 1 + M
âˆ’1
If A is satisfied first, then we restart Algorithm 1 with
x(k+1) as the new starting point, set k = 0, and update
the three quantities g (âˆ’1) , Sâˆ’1 and Mâˆ’1 accordingly (again use Î±âˆ’1 = 1 and Ï„0 = 1). If A is not satisfied but

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

Algorithm 3 {xÌ‚, MÌ‚ , ÂµÌ‚} â† AdapAPG (xini , Lini, Âµ0 , Ç«Ì‚)
parameter:Lmin â‰¥ Âµ0 , Î³dec â‰¥ 1, Î³sc > 1, Î¸sc âˆˆ (0, 1)
{x(0) , Mâˆ’1 , Î±âˆ’1 , g (âˆ’1) , Sâˆ’1 }
â† AccelLineSearch(xini , xini , Lini , Âµ0 , 1)
(âˆ’1)
x
â† x(0) , Lâˆ’1 â† Mâˆ’1 , Âµ â† Âµ0
Î±âˆ’1 â† 1, Ï„0 â† 1, k â† 0
repeat
{x(k+1) , Mk , Î±k , g (k) , Sk }
â† AccelLineSearch(x(k) , x(kâˆ’1) , Lk , Âµ, Î±kâˆ’1 )
Ï„k+1 â† Ï„k (1 âˆ’ Î±k )
if condition A holds, then
x(0) â† x(k+1) , x(âˆ’1) â† x(k+1) , Lâˆ’1 = Mk
g (âˆ’1) â† g (k) , Mâˆ’1 â† Mk , Sâˆ’1 â† Sk
kâ†0
else
if condition B holds, then
Âµ â† Âµ/Î³sc
kâ†0
else
Lk+1 â† max{Lmin, Mk /Î³dec }
k â†k+1
end if
end if
until Ï‰(x(k+1) ) â‰¤ Ç«Ì‚
xÌ‚ â† x(k+1) , MÌ‚ â† Mk , ÂµÌ‚ â† Âµ
B is satisfied first, it means that Âµ is larger than Âµf . In
fact, if Âµ â‰¤ Âµf , then combining condition B with Lemma
2 would imply that A also holds. This contradiction indicates that if B is satisfied first, we must have Âµ > Âµf , and
we have to reduce Âµ, say by a factor Î³sc > 1. In this case,
we restart Algorithm 1 still at x(0) and keep g (âˆ’1) , Sâˆ’1
and Mâˆ’1 unchanged. If neither conditions are satisfied, we
continue Algorithm 1 to its next iterate until the optimality
residue is smaller than a prescribed value. We present the
above procedure formally in Algorithm 3, whose iteration
complexity is given by the following theorem.
Theorem 2. Assume Âµ0 > Âµf > 0. Let g ini denotes the
first g (âˆ’1) computed by Algorithm 3, and NA and NB the
number of times that conditions
A and
 B are satisfied,
l
 ini rem
Lf
spectively. Then NA â‰¤ log1/Î¸sc 1+ Lmin kg Ç«Ì‚ k2
 m
l
and the total number of iteraand NB â‰¤ logÎ³sc ÂµÂµf0
tions is at most
(NA +NB )

s

Lf Î³inc Î³sc
ln 8
Âµf



Lf Î³inc Î³sc
Âµf Î¸sc

2 

1+

Lf
Lmin

2 !

Note that if 0 < Âµ0 â‰¤ Âµf , then NB = 0.
The total number of iterations given in Theorem 2 is
asymptotically

 Îº 


f
1/2
1/2
O Îºf log(Îºf ) log
+ O Îºf log(Îºf ) .
Ç«Ì‚

.

This is the same complexity as for the restart scheme proposed by Nesterov for his accelerated dual gradient (ADG)
method (Nesterov, 2013, Section 5.3). Despite using a similar restart scheme and having the same complexity bound,
here we elaborate on some important differences between
our method from Nesterovâ€™s.
â€¢ Nesterovâ€™s ADG method exploits strong convexity
in Î¨ instead of f . In order to use it under our assumption (that f is strongly convex), one needs to relocate
a strong convexity term from f to Î¨, and this relocated term needs to be adjusted whenever the estimate Âµ
is reduced.
â€¢ The restart scheme suggested in (Nesterov, 2013, Section 5.3) uses an extra line-search at each iteration,
solely for the purpose of computing the gradient mapping at x(k) . Our method directly use the gradient
mapping at y (k) , which does not require the extra linesearch, therefore the computational cost per iteration
is lower.

4. Homotopy continuation for sparse
optimization
In this section, we focus on the â„“1 -regularized least-squares
(â„“1 -LS) problem (5) in the high-dimensional setting i.e.,
with m < n. This is a special case of (1), but the function f (x) = (1/2)kAx âˆ’ bk22 is not strongly convex when
m < n. Therefore, we only expect a sublinear convergence
rate (at least globally) when using traditional first-order optimization methods.
Nevertheless, as explained in the introduction, one can use
a homotopy continuation strategy to obtain much faster
convergence. The key idea is to solve the â„“1 -LS problem with a large regularization parameter Î»0 first, and then
gradually decreases the value of Î» until the target regularization is reached. In Xiao & Zhang (2013), the PG method
is employed to solve the â„“1 -LS problem for a fixed Î» up to
an adequate precision, then the solution is used to warm
start the next stage. It was shown that under a restricted
eigenvalue condition on A, such a homotopy scheme guarantees that all iterates generated by the method are sufficiently sparse, which implies restricted strong convexity. As a result, a linear rate of convergence can be established for each homotopy stage, and the overall complexity
e s log(1/Ç«)) for certain sparsity level s, where Îºs is
is O(Îº
the restricted condition number defined in (7), and the noe hides additional log(Îºs ) factors.
tation O(Â·)

In this section, we show that, by combining the adaptive
APG method (Algorithm 3) with the same homotopy continuation scheme, the iteration complexity for solving
 the
e âˆšÎºsâ€² log(1/Ç«) , with
â„“1 -LS problem can be improved to O
sâ€² slightly larger than s.

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

Algorithm 4 xÌ‚(tgt) â† APGHomotopy(A, b, Î»tgt , Ç«, L0 , ÂµÌ‚0 )
input:A âˆˆ RmÃ—n , b âˆˆ Rn , L0 â‰¥ ÂµÌ‚0 > 0
parameter: Î· âˆˆ (0, 1), Î´ âˆˆ (0, 1)
initialize: Î»0 â† kAT bkâˆ , xÌ‚(0) â† 0, MÌ‚0 â† L0
N â† âŒŠln(Î»0 /Î»tgt ) / ln(1/Î·)âŒ‹
for K = 0, 1, 2, . . . , N âˆ’ 1 do
Î»K+1 â† Î·Î»K
Ç«Ì‚K+1 â† Î´Î»K+1
{xÌ‚(K+1) , MÌ‚K+1 , ÂµÌ‚K+1 }

â† AdapAPG xÌ‚(K) , MÌ‚K , ÂµÌ‚K , Ç«Ì‚K+1 , Î»K+1
end for

{xÌ‚(tgt) , MÌ‚tgt } â† AdapAPG xÌ‚(N ) , MÌ‚N , ÂµÌ‚N , Ç«, Î»tgt
return:xÌ‚(tgt)
The APG homotopy method is presented in Algorithm 4.
To avoid confusion over the notations, we use Î»tgt to denote the target regularization parameter in (5). The method
starts with Î»0 = kAT bkâˆ which is the smallestÎ» such that
the â„“1 -LS problem has the trivial solution 0 (by examining the optimality condition). This method has two extra
parameters Î· âˆˆ (0, 1) and Î´ âˆˆ (0, 1). They control the
algorithm as follows:
â€¢ The sequence of values for the regularization parameter is determined as Î»k = Î· k Î»0 for k = 1, 2, . . ., until
the target value Î»tgt is reached.
â€¢ For each Î»k except Î»tgt , we solve problem (5) with
a proportional precision Î´Î»k . For the last stage with
Î»tgt , we solve to the absolute precision Ç«.
Our convergence analysis of the APG homotopy method
is based on the following assumption, which involves the
restricted eigenvalues defined in (6).
Assumption 1. Suppose b = AxÌ„ + z. Let SÌ„ = supp(xÌ„)
and sÌ„ = |SÌ„|. There exist Î³ > 0 and Î´ â€² âˆˆ (0, 0.2] such that
Î³ > (1 + Î´ â€² )/(1 âˆ’ Î´ â€² ) and


Î³ +1
kAT zkâˆ .
Î»tgt â‰¥ 4 max 2,
(1 âˆ’ Î´ â€² )Î³ âˆ’ (1 + Î´ â€² )
(17)
Moreover, we assume there exists an integer sÌƒ such that
Ïâˆ’ (A, sÌ„ + 3sÌƒ) > 0 and

24 Î³inc Ï+ (A, sÌ„ + 3sÌƒ) + 3Ï+ (A, sÌƒ)
sÌƒ >
(1 + Î³)sÌ„. (18)
Ïâˆ’ (A, sÌ„ + sÌƒ)
We also assume that Lmin â‰¤ Î³inc Ï+ (A, sÌ„ + 3sÌƒ).
According to Zhang & Huang (2008), the above assumption implies kxâ‹† (Î»)SÌ„ c k0 â‰¤ sÌƒ whenever Î» â‰¥ Î»tgt (here
SÌ„ c denotes the complement of the support set SÌ„). We
will show that by choosing the parameters Î· and Î´ in Algorithm 4 appropriately, these conditions also imply that

all iterates along the solution path are sparse. We note
that Assumption 1 is very similar to Assumption 1 in
Xiao & Zhang (2013) (they differ only in the constants in
the conditions), and interpretations and remarks made there
also apply here. More specifically,
â€¢ The existence of sÌƒ satisfying the conditions like (18)
is necessary and standard in sparse recovery analysis.
It is closely related to the restricted isometry property (RIP) of CandeÌ€s & Tao (2005) which assumes that
there exist some s > 0, and Î½ âˆˆ (0, 1) such that
Îº(A, s) < (1 + Î½)/(1 âˆ’ Î½). See Xiao & Zhang (2013,
Section 3) for an example of sufficient RIP conditions.
Another sufficient condition is Îº(A, sÌ„ + 3sÌƒ) â‰¤ C sÌƒ/sÌ„
with C = 1/(24(1 + Î³)(3 + Î³inc )), which is more
accessible but can be very conservative.
â€¢ The RIP-like condition (18) can be much stronger than
the corresponding conditions established in the sparse
recovery literature (see, e.g., Li & Mo (2011) and references therein), which are only concerned about the
recovery property of the optimal solution xâ‹† . In contrast, our condition needs to guarantee sparsity for all
iterates along the solution path, thus is â€œdynamicâ€ in
nature. In particular, in addition to the matrix A, it
also depends on algorithmic parameters Î³inc , Î· and Î´
(Theorem 4 will relate Î· to Î´ and Î´ â€² ).
Our first result below concerns the local linear convergence
of Algorithm 3 when applied to solve the â„“1 -LS problem
at each stage of the homotopy method. Basically, if the
starting point x(0) is sparse and the optimality condition
is satisfied with adequate precision, then all iterates along
the solution path are sparse. This implies that restricted
strong convexity holds and Algorithm 3 actually has linear
convergence.
Theorem 3. Suppose Assumption 1 holds. If the initial
point xini in Algorithm 3 satisfies
 ini 
x c  â‰¤ sÌƒ,
Ï‰(xini ) â‰¤ Î´ â€² Î»,
(19)
SÌ„ 0

 (k) 
then for all k â‰¥ 0, we have xSÌ„ c 0 â‰¤ sÌƒ. Moreover, all the
three conclusions of Theorem 2 holds by replacing Lf and
Âµf with Ï+ (A, sÌ„ + 3sÌƒ) and Ïâˆ’ (A, sÌ„ + 3sÌƒ), respectively.
Our next result gives the overall iteration complexity of the
APG homotopy method in Algorithm 4. To simplify presentation, we let sâ€² = sÌ„ + 3sÌƒ, and use the following notations:
Ï+ (sâ€² )
Ïâˆ’ (sâ€² )

= Ï+ (A, sÌ„ + 3sÌƒ),
= Ïâˆ’ (A, sÌ„ + 3sÌƒ),

Îºsâ€²

= Îº(A, sÌ„ + 3sÌƒ) =

Ï+ (A, sÌ„ + 3sÌƒ)
.
Ïâˆ’ (A, sÌ„ + 3sÌƒ)

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

Roughly speaking, if the parameters Î´ and Î· are chosen
appropriately, then the total number of proximal-gradient
steps in Algorithm 4 for finding an Ç«-optimal solution is
e âˆšÎºsâ€² ln(1/Ç«)).
O(
Theorem 4. Suppose Assumption 1 holds for some Î´ â€² ,
Î³ and sÌƒ, and the parameters Î´ and Î· in Algorithm 4
1+Î´
â‰¤ Î· < 1. Let N =
are chosen such that 1+Î´
â€²


âˆ’1
ln (Î»0 /Î»tgt ) / ln Î·
as in the algorithm. Then:

1. Condition (19) holds for each call of Algorithm 3. For
K = 0, . . . , N âˆ’ 1, the number of gradient steps in
each call of Algorithm 3 is no more than
 


C
âˆš
Îºsâ€² Î³inc Î³sc
+D
log Î¸1
sc
Î´
2 
2 !

Ï+ (sâ€² )
Îºsâ€² Î³inc Î³sc
1+
,
Ã— ln 8
Î¸sc
Lmin


p
(sâ€² )
where C = 1 + ÏL+min
8Î³inc Îºsâ€² (1 + Î³)sÌ„ and

l
m
0
D = logÎ³sc Ïâˆ’ÂµÌ‚(s
+1. It is independent of Î»K .
â€²)
(K)

2. For each K â‰¥ 0, the outer iterates xÌ‚
Ï†Î»tgt (xÌ‚(K) ) âˆ’ Ï†â‹†Î»tgt â‰¤ Î· 2(K+1)

satisfies

4.5(1 + Î³)Î»20 sÌ„
,
Ïâˆ’ (A, sÌ„ + sÌƒ)

and the following bound on sparse recovery holds
âˆš
2Î»0 sÌ„
.
kxÌ‚(K) âˆ’ xÌ„k2 â‰¤ Î· K+1
Ïâˆ’ (A, sÌ„ + sÌƒ)
3. When Algorithm 4 terminates, the total number
of

e âˆšÎºsâ€² ln(1/Ç«) , Moreproximal-gradient steps is O
over, the output xÌ‚(tgt) satisfies
(tgt)

Ï†Î»tgt (xÌ‚

)âˆ’

Ï†â‹†Î»tgt

4(1 + Î³)Î»tgt sÌ„
Ç«.
â‰¤
Ïâˆ’ (A, sÌ„ + sÌƒ)


e âˆšÎºsâ€² ln(1/Ç«) complexity of the APG homotopy
Our O
e (Îºs ln(1/Ç«)) complexity of PGH
method improves the O
in the dependence on restricted condition number. We
note that this result is not a simple extension of those in
Xiao & Zhang (2013). In particular, the AdapAPG method
do not have the property of monotone decreasing, which
is key for establishing the complexity of the PGH method
in Xiao & Zhang (2013). Instead, our proof relies on the
non-blowout property (Lemma 1) to show that all iterates
along the solution path are sparse (details are given in the
supporting materials).

5. Numerical experiments
In this section, we present preliminary numerical experiments to support our theoretical analysis. In addition to

the PG and PGH methods (Xiao & Zhang, 2013), we also
compare our method with FISTA (Beck & Teboulle, 2009)
and its homotopy variants.
We implemented FISTA with an adaptive line-search over
the Lipschitz constant Lf , but it does not use or estimate the convexityp
parameter Âµf . Hence it has a sublinear complexity O( Lf /Ç«). In our experiments, we also compare with a simple restart scheme for FISTA suggested by Oâ€™Donoghue & CandeÌ€s (2012): restart FISTA
whenever it exhibits nonmonotone behaviors. In particular, we implemented the gradient scheme: restart whenever gLk (y (kâˆ’1) )T (x(k) âˆ’ x(kâˆ’1) ) > 0, where x(k) and
y (k) are two sequences generated by FISTA, similar to
those in our AdapAPG method. Oâ€™Donoghue & CandeÌ€s
(2012) show that for strongly convex pure quadratic functions, this restart scheme
 leads to the optimal complexiâˆš
ty of O Îºf ln(1/Ç«) . However, their analysis does not
hold for the â„“1 -LS problem or other non-quadratic functions. We call this method FISTA+RS (meaning FISTA
with ReStart).
For our AdapAPG method (Algorithm 3) and APG homotopy method (Algorithm 4), we use the following values of
the parameters unless otherwise stated:
parameters
values

Î³inc
2

Î³dec
2

Î¸sc
0.1

Î³sc
10

Î·
0.8

Î´
0.2

To make the comparison clear, we generate an illconditioned random matrix A following the experimental
setup in Agarwal et al. (2012):
â€¢ Generate a random matrix B âˆˆ RmÃ—n with Bij following i.i.d. standard normal distribution.
â€¢ Choose Ï‰ âˆˆ [0, 1), and for i âˆš= 1, . . . , m, generate
each row Ai,: by Ai,1 = Bi,1 / 1 âˆ’ Ï‰ 2 and Ai,j+1 =
Ï‰Ai,j + Bi,j for j = 2, . . . , n.
T
It can be shown
i of E[A A] lie within
h that the eigenvalues
2
1
the interval (1+Ï‰)
2 , (1âˆ’Ï‰)2 (1+Ï‰) . If Ï‰ = 0, then A = B

and the covariance matrix AT A is well conditioned. As
Ï‰ â†’ 1, it becomes progressively more ill-conditioned. In
our experiments, we generate the matrix A with m = 1000,
n = 5000, and Ï‰ = 0.9.

Figure 1 shows the computational results of the four different methods: PG, FISTA, FISTA+RS, AdapAPG, and
their homotopy continuation variants (denoted by â€œ+Hâ€).
For each method, we initialize the Lipschitz constant by
L0 = maxjâˆˆ{1,...,n} kA:,j k22 . For the AdapAPG method,
we initialize the estimate of convexity parameter with two
different values, Âµ0 = L0 /10 and Âµ0 = L0 /100, and denote their results by AdapAPG1 and AdapAPG2, respectively.

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization
6

10

5000

PG
FISTA
FISTA+RS
AdapAPG1
AdapAPG2

3

Ï†(x(k) ) âˆ’ Ï†â‹†

10

0

10

PG
FISTA
FISTA+RS
AdapAPG1
AdapAPG2

4000

5

10

4

10

kx(k) k0

3000

âˆ’3

10

AdapAPG1Mk
AdapAPG1 Âµ
AdapAPG2Mk
AdapAPG2 Âµ

3

10

2000
2

10

âˆ’6

10

1000

1

10

âˆ’9

10

0

500

1000

1500

2000

2500

0
0

3000

500

1000

k

2000

2500

3000

0

500

1000

k

6

10

1500

2000

2500

3000

k

5000

PG+H
FISTA+H
FISTA+RS+H
AdapAPG1+H
AdapAPG2+H

3

10

Ï†(x(k) ) âˆ’ Ï†â‹†

1500

0

10

PG+H
FISTA+H
FISTA+RS+H
AdapAPG1+H
AdapAPG2+H

4000

5

10

4

10

kx(k) k0

3000

âˆ’3

10

AdapAPG1+HMk
AdapAPG1+H Âµ
AdapAPG2+HMk
AdapAPG2+H Âµ

3

10

2000
2

10

âˆ’6

10

1000

1

10

âˆ’9

10

0

300

600

900

1200

1500

1800

0
0

300

600

k

900

1200

1500

k

1800

0

300

600

900

1200

1500

1800

k

Figure 1. Solving an ill-conditioned â„“1 -LS problem. AdapAPG1 starts with Âµ0 = L0 /10, and AdapAPG2 uses Âµ0 = L0 /100.

From the top-left plot, we observe that PG, FISTA+RS and
AdapAPG all go through a slow plateau before reaching
fast local linear convergence. FISTA without restart does
not exploit the strong convexity and is the slowest asymptotically. Their homotopy continuation variants shown in
the bottom-left plot are much faster. Each vertical jump
on the curves indicates a change in the value of Î» in the
homotopy scheme. In particular, it is clear that all except FISTA+H enter the final homotopy stage with fast linear convergence. In the final stage, the PGH method has
a rather flat slope due to ill-conditioning of the A matrix;
in contrast, FISTA+RS and AdapAPG have much steeper
slopes due to their accelerated schemes. AdapAPG1 started with a modest slope, and then detected that the Âµ value
was too big and reduced it by a factor of Î³sc = 10, which
resulted in the same fast convergence rate as AdapAPG2
after that.
The two plots in the middle show the sparsity of each iterates along the solution paths of these methods. We observe
that FISTA+RS and AdapAPG entered fast local convergence precisely when their iterates became sufficiently sparse, i.e., when kx(k) k0 became close to that of the final
solution. In contrast, the homotopy variants of these algorithms kept all iterates sparse by using the warm start
from previous stages. Therefore, restricted strong convexity hold along the whole path and linear convergence was
maintained at each stage.
The right column shows the automatic tuning of the lo-

cal Lipschitz constant Mk and the restricted convexity parameter Âµ. We see that the homotopy methods (bottomright plot) have relatively smaller Mk and larger Âµ than the
ones without using homotopy continuation (top-right plot),
which means much better conditioning along the iterates.
In particular, the homotopy AdapAPG method used fewer
number of reductions of Âµ, for both initializations of Âµ0 .
Overall, we observe that for the â„“1 -LS problem, the homotopy continuation scheme is very effective in speeding up
different methods. Even with the overhead of estimating
and tuning Âµ, the AdapAPG+H method is close in efficiency compared with the FISTA+RS+H method. If the initial
guess of Âµ is not far off, then AdapAPG+H gives the best
performance. Finally, we note that unlike the AdapAPG
method, the optimal complexity of the FISTA+RS method
has not been established for minimizing general strongly
convex functions (including â„“1 -LS). Although often quite
competitive in practice, we have observed non-quadratic
cases in which FISTA+RS demonstrate less desirable convergence (see examples in the supporting materials and also
comments in Oâ€™Donoghue & CandeÌ€s (2012)).

References
Agarwal, A., Negahban, S. N., and Wainwright, M. J.
Fast global convergence of gradient methods for highdimensional statistical recovery. The Annals of Statistics,
40(5):2452â€“2482, 2012.

An Adaptive APG method and its Homotopy Continuation for Sparse Optimization

Beck, A. and Teboulle, M. A fast iterative shrinkagethreshold algorithm for linear inverse problems. SIAM
Journal on Imaging Sciences, 2(1):183â€“202, 2009.

Xiao, L. and Zhang, T. A proximal-gradient homotopy
method for the sparse least-squares problem. SIAM Journal on Optimization, 23(2):1062â€“1091, 2013.

Bredies, K. and Lorenz, D. A. Linear convergence of iterative soft-thresholding. Journal of Fourier Analysis and
Applications, 14:813â€“837, 2008.

Zhang, C.-H. and Huang, J. The sparsity and bias of the lasso selection in highâ€“dimensional linear regression. Annals of Statistics, 36:1567â€“1594, 2008.

Bruckstein, A. M., Donoho, D. L., and Elad, M. From
sparse solutions of systems of equations to sparse modeling of signals and images. SIAM Review, 51(1):34â€“81,
2009.
CandeÌ€s, E. J. and Tao, T. Decoding by linear programming. IEEE Transactions on Information Theory, 51
(12):4203â€“4215, December 2005.
Chen, S. S., Donoho, D. L., and Saunders, M. A. Atomic
decomposition by basis pursuit. SIAM Journal on Scientific Computing, 20(1):33â€“61, 1998.
Hale, E. T., Yin, W., and Zhang, Y. Fixed-point continuation for â„“1 -minimization: Methodology and convergence. SIAM Journal on Optimization, 19(3):1107â€“
1130, 2008.
Li, S. and Mo, Q. New bounds on the restricted isometry constant Î´2k . Applied and Computational Harmonic
Analysis, 31(3):460â€“468, 2011.
Luo, Z.-Q. and Tseng, P. On the linear convergence of descent methods for convex essentially smooth minimization. SIAM Journal on Control and Optimization, 30(2):
408â€“425, 1992.
Nesterov, Y. Introductory Lectures on Convex Optimization: A Basic Course. Kluwer, Boston, 2004.
Nesterov, Y. Gradient methods for minimizing composite
functions. Mathematical Programming, Series B, 140:
125â€“161, 2013.
Oâ€™Donoghue, B. and CandeÌ€s, E. J. Adaptive restart for accelerated gradient schemes. Manuscript, April 2012. To
appear in Foundations of Computational Mathematics.
Rockafellar, R. T. Convex Analysis. Princeton University
Press, 1970.
Tibshirani, R. Regression shrinkage and selection via the
lasso. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 58:267â€“288, 1996.
Tseng, P. On accelerated proximal gradient methods for
convex-concave optimization. Manuscript, 2008.
Wright, S. J., Nowad, R. D., and Figueiredo, M. A. T. Sparse reconstruction by separable approximation. IEEE
Transactions on Signal Processing, 57(7):2479â€“2493,
July 2009.

