The Benefits of Learning with Strongly Convex Approximate Inference

Ben London
University of Maryland, College Park, MD 20742 USA
Bert Huang
Virginia Tech, Blacksburg, VA 24061 USA
Lise Getoor
University of California, Santa Cruz, CA 95064 USA

Abstract
We explore the benefits of strongly convex free
energies in variational inference, providing both
theoretical motivation and a new meta-algorithm.
Using the duality between strong convexity and
stability, we prove a high-probability bound on
the error of learned marginals that is inversely
proportional to the modulus of convexity of the
free energy, thereby motivating free energies
whose moduli are constant with respect to the
size of the graph. We identify sufficient conditions for Ω(1)-strong convexity in two popular variational techniques: tree-reweighted and
counting number entropies. Our insights for the
latter suggest a novel counting number optimization framework, which guarantees strong convexity for any given modulus. Our experiments
demonstrate that learning with a strongly convex free energy, using our optimization framework to guarantee a given modulus, results in
substantially more accurate marginal probabilities, thereby validating our theoretical claims and
the effectiveness of our framework.

1. Introduction
Though marginal inference in general graphical models is
an intractable problem, many approximations have been
proposed using the variational free energy. Much of this
research has focused on the convexity of the free energy.
When it is convex, convergence to a global minimum is
guaranteed. Less attention has been paid to when the free
energy is strongly convex (i.e., has curvature), and what
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

BLONDON @ CS . UMD . EDU

BHUANG @ VT. EDU

GETOOR @ SOE . UCSC . EDU

benefits this offers. In this work, we show that learning
with a strongly convex free energy results in more accurate marginal probabilities. Our contributions include: a
theoretical motivation for using strongly convex free energies, a framework for optimizing the strength of convexity
in many variational methods, and experimental evaluation.
We frame our theoretical analysis in stability, which measures the inference algorithm’s robustness to perturbation.
One way to characterize stability is the Lipschitz gradient condition (Hiriart-Urruty & Lemaréchal, 2001), which
is the dual of strong convexity. Using this duality and
the variational form of the log-partition function, we show
that strongly convex free energies result in more stable
marginals. Further, we argue that a simply convex free
energy cannot satisfy this stability guarantee. Using our
stability result, we prove an error bound for the marginals
of a model that is learned using strongly convex variational
inference. The error bound is inversely proportional to the
modulus of convexity (i.e., amount of curvature) of the free
energy, thereby highlighting an important consideration for
strongly convex free energies: the modulus should be constant with respect to the size of the graph, |G|.
Based on the above insights, we aim to identify free energies that are strongly convex, and when their respective
moduli of convexity are constant with respect to |G|. We
consider two popular variational methods: tree-reweighted
(Wainwright et al., 2005) and counting number (Heskes,
2006) entropies. Using the notion of contraction, we give
model-dependent conditions under which the negative treereweighted entropy is Ω(1)-strongly convex. We then propose new sufficient conditions to characterize the modulus of convexity for counting number entropies. We use
this to derive a novel counting number optimization that
yields κ-strongly convex free energies, for any κ > 0, independent of the model parameters. This optimization can
“strongly convexify” any entropy approximation that can
be expressed via counting numbers, which includes many

The Benefits of Learning with Strongly Convex Approximate Inference

used in practice (e.g., Bethe and tree-reweighted).
We demonstrate the practical impact of our theory in a set
of experiments on challenging grid-structured models. Our
empirical results suggest that strongly convex free energies
can dramatically improve the quality of marginal inference,
and that our counting number optimization reduces the error of learned marginals by over 40%. These findings indicate that having a tunable modulus can offer substantial
benefit in practice.
1.1. Related Work
Our theoretical motivation, which connects strong convexity and stability to error bounds, is primarily related to two
previous studies. Wainwright (2006) argued that, when approximate inference is necessary, using an inconsistent M estimator is sometimes better than using the true model. He
motivated this conclusion with an error bound that leverages the stability of strongly convex variational inference.
Whereas Wainwright’s bound is asymptotic, and tied to a
specific generative process, our error bound is general and
holds with high probability over draws of a finite training
set. Moreover, our results are more explicit about the role
of the modulus of convexity, which highlights the importance of it being independent of the graph size. The other
related line of work is from London et al. (2013; 2014),
who derived PAC learning bounds for structured prediction. Their bounds crucially rely on a form of “collective”
stability that is guaranteed by L1 strongly convex free energies. We distinguish our error bound from these by our
proof technique, which uses L2 strong convexity, and that
we are interested in learning accurate marginals, not just
maximizing the marginal probability of the correct label.
The study of convex free energies in approximate inference has a long history. Approaches can be broadly categorized by their approximation of the negative entropy term.1
Wainwright et al.’s (2005) tree-reweighted approximation
decomposes the entropy into a convex combination of tree
entropies, each of which is convex. Wainwright (2006)
later showed that this approximation is in fact strongly convex, though his lower bound on the modulus decreases as
a function of the size of the graph. Another decomposition approach, due to Globerson & Jaakkola (2007), replaces the entropy with a sum of conditional entropies.
This approximation is provably convex, but not strongly
convex. Heskes (2006) proposed general sufficient conditions, based on counting (or, “over-counting”) numbers, to
establish the convexity of the Bethe and Kikuchi approximations. This work inspired a wave of research in counting number-based approximations (e.g., Weiss et al., 2007;
Hazan & Shashua, 2008; Meltzer et al., 2009; Meshi et al.,
1

Since most of these approximations use the same local relaxation of the marginal polytope, we focus on the entropy.

2009). Hazan & Shashua (2008) used a slight modification
of Heskes’s conditions to guarantee strict convexity, which
guarantees a unique global minimum, but does not identify
a modulus. To our knowledge, our sufficient conditions are
the first to identify when the counting number entropy is
strongly convex, with a known modulus.

2. Background and Notation
We first introduce notation and review some concepts that
will be used in our analysis. We consider the following class of Markov random fields (MRFs). Let Y ,
{e1 , . . . , e` } denote a set of ` labels, represented by the
`-dimensional standard basis (a.k.a. “one-hot”) vectors.
Let Y , (Y1 , . . . , Yn ) denote a set of random variables,
each with domain Y. Let G , (V, E) denote an undirected graph, whose edges correspond to interactions between variables. We refer to |G| , |V| + |E| as the size of
the graph. The model is parameterized by a set of potential
functions, organized according to the nodes and edges of
G. Given an assignment, y ∈ Y n , let θv (yv ) denote the
potential for node v ∈ V being in state yv ∈ Y, and let
θe (ye ) denote the potential for edge e = {u, v} ∈ E being
in state ye = yu ⊗ yv . Since yv and ye are standard basis vectors, we can represent the potentials as vectors, such
that θv (yv ) = θv · yv and θe (ye ) = θe · ye . With
θ , ((θv )v∈V , (θe )e∈E ) and ŷ , ((yv )v∈V , (ye )e∈E ) ,
we can then express
potential for y as a dot
P the aggregate P
product, θ · ŷ = v∈V θv (yv ) + e∈E θe (ye ). This describes a log-linear distribution,

p(Y = y; θ) , exp θ · ŷ − Φ(θ) ,
P
where Φ(θ) , log y0 exp(θ · ŷ0 ) is a normalizing function known as the log-partition function.
The log-partition is convex in θ, and has a well-known
variational form (Wainwright & Jordan, 2008), Φ(θ) =
maxµ∈M θ · µ − Φ∗ (µ), where M is the marginal polytope—the set of all consistent marginal vectors—and Φ∗
is the convex conjugate of Φ. In the model we consider,
Φ∗ (µ) is equal to the negative entropy of the distribution
consistent with marginals µ.2 The negative of the quantity being maximized is often referred to as the free energy,
E(µ; θ) , −θ · µ + Φ∗ (µ). The gradient of Φ(θ) is the
maximizing µ (i.e., minimizer of E), which corresponds to
the marginal distributions of Y1 , . . . , Yn . We denote this by
µ(θ) , arg min E(µ; θ) = ∇Φ(θ).
µ∈M

Unfortunately, for general graph structures, M may require an exponential number of constraints, and Φ∗ may
2

See Wainwright & Jordan (2008) for a precise definition.

The Benefits of Learning with Strongly Convex Approximate Inference

lack an explicit form. Many variational methods address
these problems by relaxing M to an outer bound that uses
a polynomial number of “local” constraints, and replacing
Φ∗ with a tractable approximation, Φ̃∗ . The local marginal
polytope, M̃ ⊇ M, is typically defined as follows:
(
)
P`
j
∀v ∈ V,
µ̃
=
1
;
j=1 v
M̃ , µ̃ :
.
P`
ij
j
∀e ∈ E, ∀v ∈ e,
i=1 µ̃e = µ̃v
We call each µ̃ ∈ M̃ a set of pseudomarginals. With a
slight abuse of notation, let Ẽ(µ̃; θ) , −θ · µ̃ + Φ̃∗ (µ̃) denote a variational free energy for Φ̃∗ and M̃, let Φ̃(θ) ,
maxµ̃∈M̃ −Ẽ(µ̃; θ) denote the convex conjugate of Φ̃∗
(i.e., the approximate log-partition), and let
µ̃(θ) , arg min Ẽ(µ̃; θ) = ∇Φ̃(θ)
µ̃∈M̃

denote the pseudomarginals of the variational distribution,

p̃(Y = y; θ) , exp θ · ŷ − Φ̃(θ) .
It is common in structured prediction to condition the distribution of Y on some observed variables, X. Evidence
X = x is incorporated into the potential functions, so that
p (Y = y | X = x; θ) , exp (θ(x) · ŷ − Φ(θ(x))). For
simplicity of exposition, we will not discuss conditional
distributions, though most of our analysis also holds for
conditional distributions with small modifications.

3. A Case for Strong Convexity
Because the dot product is linear, the convexity of the free
energy is determined by the convexity of the conjugate
function, Φ∗ , or Φ̃∗ for approximations. Some approximations are known to be convex, yet few studies discuss the
strength of convexity, by which we mean the following.
Definition 1. A differentiable function, ϕ : S → R, of a
convex set, S, is κ-strongly convex w.r.t. a norm3 , k · k, if
and only if, for all s, s0 ∈ S,
κ
2
ks − s0 k + h∇ϕ(s), s0 − si ≤ ϕ(s0 ) − ϕ(s).
2

(1)

The modulus of convexity, κ, measures the curvature of ϕ.
The true conjugate function, Φ∗ , is a strongly convex function of the full probability table. Since the marginals are a
linear function of the probability table, Φ∗ is also a strongly
convex function of M—albeit with an unknown modulus.
Approximations of Φ∗ that are simply convex ignore this
fact, and may result in less accurate marginals.
The purpose of this section is to motivate the use of strongly
convex free energies. We start by connecting strong convexity to stability, showing that strong convexity is both
3

Unless specified, assume strong convexity w.r.t. the 2-norm.

sufficient (Section 3.1) and necessary (Section 3.2) for uniform stability, which can be used to derive bounds on the
quality of learned marginals (Section 3.3). More importantly, the theory suggests that the modulus of convexity is
crucial, and that one should prefer moduli that are independent of the size of the graph (Section 3.4). Proofs from this
section are deferred to Appendix B.
3.1. Strong Convexity Guarantees Stability
There is a well-known duality between strong convexity
and the Lipschitz continuity of the gradient.
Definition 2. A differentiable function, ϕ : S → R, has a
λ-Lipschitz continuous gradient if and only if, for all s, s0 ∈
S,
k∇ϕ(s) − ∇ϕ(s0 )k2 ≤ λ ks − s0 k2 .
(2)
Lemma 1 (Hiriart-Urruty & Lemaréchal, 2001, Theorem
4.2.1). Let ϕ : S → R denote a differentiable function,
and ϕ? : S ? → R its convex conjugate. If ϕ? is κ-strongly
convex, then ϕ has a (1/κ)-Lipschitz continuous gradient.
Since the gradient of Φ̃ corresponds to the pseudomarginals
of the distribution, a strongly convex conjugate function
lets us bound the stability of approximate marginal inference. This is summarized in the following lemma.4
Lemma 2. Assume that Ẽ uses a κ-strongly convex conjugate function, Φ̃∗ . Then, for any θ and θ 0 ,



1 
µ̃(θ) − µ̃(θ 0 ) ≤ p1
θ − θ 0  . (3)
p
2
2
|G|
κ |G|
Lemma 2 upper-bounds the root-mean-squared difference
between the respective pseudomarginals of θ and θ 0 . Ob√
serve that one can trivially upper-bound this quantity by 2
by assuming that the marginals are completely different. In
contrast, the right-hand side of Eq. 3 shrinks as a function
2
of the size of the
 |G|, and the L distance between
 graph,
0
the potentials, θ − θ 2 , provided κ is lower-bounded by
a function that is independent of these terms. Of course,
since the potentials
have length O(|G|), their L2 distance
p
could be O( |G|); but there are some cases in which the
distance could be small. In Section 3.3, we discuss one
such scenario and use it to derive a bound on the root-meansquared error (RMSE) of learned pseudomarginals.
3.2. Convexity Alone Does Not Guarantee Stability
Strong convexity is central to Lemma 2. In fact, there is
good reason to believe that strong convexity is a necessary
condition for uniform stability. To understand why, we return to the relationship between strong convexity and Lipschitz gradients. Lemma 1 states that the former property
implies the latter; however, the converse is also true.
4
Wainwright derived a similar result (2006, Lemma 6). Our
lemma is more explicit about the role of the modulus of convexity.

The Benefits of Learning with Strongly Convex Approximate Inference

Lemma 3 (Hiriart-Urruty & Lemaréchal, 2001, Theorem
4.2.2). Let ϕ : S → R denote a differentiable function, and
ϕ? : S ? → R its convex conjugate. If ϕ has a λ-Lipschitz
continuous gradient, then ϕ? is (1/λ)-strongly convex.

the true marginals, µ(θ ? ), is proportional to the distance
between θ̂ m and θ̄, divided by the modulus of convexity,
κ. As θ̂ m converges to θ̄, the RMSE decreases at a rate
that is inversely proportional to κ.

This establishes an equivalence between strong convexity
and Lipshitz gradients: ϕ has a (1/κ)-Lipschitz continuous gradient if and only if ϕ? is κ-strongly convex. In the
context of variational inference, this means that Eq. 3 holds
if and only if Φ̃∗ is strongly convex. Mere convexity (i.e.,
κ = 0) is insufficient for guaranteeing stability. In fact, for
any simply convex Φ̃∗ , it may be possible to construct an
example in which marginal inference is not stable.

Convergence of M-estimators has been studied extensively.
Many of these works (e.g., Bickel et al., 2009; Kakade
et al., 2010; Ravikumar et al., 2011; Negahban et al., 2012;
Bradley & Guestrin, 2012; Meng et al., 2014) rely on a
restricted eigenvalue (RE) assumption. Essentially, this
assumes that the eigenvalues of ∇2 L( · ; θ)—which is independent of Y, and therefore the same as ∇2 Lm (θ)—
evaluated in the vicinity of θ̄, are bounded away from zero;
meaning, the NLL is strongly convex in a region around θ̄.
We will further assume that, with probability ≥ 1 − δ over
draws of the training set, both θ̄ and θ̂ m (which is a random variable) are contained in a convex set within which
∇2 L( · ; θ) is positive definite, thereby implying that the
NLL is strongly convex in this set. The minimum eigenvalue of the Hessian (hence, the modulus of convexity) may
depend on δ, m and G, but should be bounded away from
zero by a constant as m → ∞. This requirement will always be met if ∇2 L( · ; θ̄) is positive definite.

For instance, consider the extreme case in which Φ̃∗ is linear in M̃. This means that Ẽ is also linear. Mangasarian
& Shiau (1987) prove by counterexample that solutions to
linear programs are not Lipschitz continuous (a form of stability) with respect to perturbations in the objective coefficients (in this case, the potentials). Therefore, inference
with a linear conjugate function cannot have non-trivial
uniform stability.
3.3. Stability Yields Learning Guarantees
Eq. 3 is especially meaningful in the context of learning.
Suppose we are trying to learn a distribution, p(Y; θ ? ), parameterized by some potentials, θ ? . We assume that the
class of models to which θ ? belongs is known, and that the
variable interactions, defined by a graph G, are fixed. Our
goal is to estimate θ ? given m independent draws from the
distribution, (y(1) , . . . , y(m) ). To do so, we minimize the
negative log-likelihood (NLL) of the variational distribution, p̃, induced by an approximate log-partition, Φ̃. The
approximation is for efficiency, since we make repeated
evaluations of the objective during learning. Assume that
Φ̃∗ , the convex conjugate of Φ̃, is κ-strongly convex. Let
L(Y; θ) , − ln p̃(Y; θ) denote the NLL under p̃, and let
m

Lm (θ) ,

1 X
L(y(j) ; θ).
m j=1

(4)

Let
θ̄ , arg min E [L(Y; θ)] ,

(5)

Assumption 1. Assume that there exists a constant, γ̄ > 0,
such that the minimum eigenvalue of ∇2 L( · ; θ̄) is at least
γ̄. Further, for any δ ∈ (0, 1) and m ≥ 1, there exists a
convex set, S ⊆ R|θ| , encompassing both θ̄ and θ̂ m , and
a function, γ(δ, m, G) = Ω(1), such that, with probability
≥ 1 − δ over draws of m i.i.d. examples, the minimum
eigenvalue of ∇2 L( · ; θ) : θ ∈ S is at least γ(δ, m, G).
Combining Assumption 1 and Lemma 2, we can prove a
high-probability error bound on the marginals of a model
learned with strongly convex variational inference.
√
Proposition 1. Let Λm , 1/ m. Assume that Φ̃∗
is
convex, that Assumption 1 holds, and that
 κ-strongly

θ̄  ≤ 1. Then, for any δ ∈ (0, 1), with probability
∞
at least 1 − 2δ over draws of m i.i.d. examples,


q


2`2 |G|
1

? 
` 2 + 2 ln δ
µ̃(θ̂ m ) − µ(θ )
2
p
√
.
≤
κ γ(δ, m, G) m
|G|

(7)

θ

and

2

θ̂ m , arg min Lm (θ) + Λm kθk2 .

(6)

θ

If Λm → 0 as m → ∞, then θ̄ = limm→∞ θ̂ m .
Because Lm uses the approximate log-partition, θ̂ m is not a
consistent estimator. In other words, in the limit of infinite
data, θ̂ m may be different from θ ? . Nonetheless, we have
that µ(θ ? ) = µ̃(θ̄), as shown in Appendix B.2. In light
of this, substituting θ̂ m and θ̄ into Eq. 3, we have that the
RMSE of the learned marginals, µ̃(θ̂ m ), with respect to

Like most error bounds, Eq. 7 has an inverse dependence on
the square root of m, so the bound decreases as the training
set grows. What is interesting about our bound is that it
incorporates the modulus of convexity, κ, of the variational
free energy. Because of the inverse dependence on κ, the
bound

 tightens as κ grows. Note that the upper bound for
θ̄  can be replaced with any constant. We also note that
∞
Proposition 1 is easily adapted for the mean-absolute error
(MAE), since the RMSE upper-bounds the MAE.

The Benefits of Learning with Strongly Convex Approximate Inference

3.4. Prefer a Constant Modulus
Eqs. 3 and 7 have an inverse dependence on the modulus
of convexity. We should therefore prefer higher values,
leading to sharper bounds. However, stronger convexity
might mean that the approximation is looser. For instance,
one can trivially boost the modulus by scaling the conjugate function with a temperature parameter. This reduces
the bounds, but creates a totally entropic distribution. One
therefore wonders whether there is a “right” amount of convexity that trades off stability for marginal accuracy.
One criterion stands out: the modulus should not have an
inverse dependence on |G|. This insight is the most important takeaway of this section. When learning large graphical models, it is usually the case that the number of examples is small relative to the size of the graph. In this
setting, κ can have great impact. If
√ κ = Ω(1/ |G|), then
m), which is vacuous
the learning
rate
(Eq.
7)
is
Õ
(|G|
/
√
for |G| > √
m. In contrast, if κ = Ω(1), then the learning
rate is Õ (1/ m). This observation motivates the study of
Ω(1)-strongly convex free energies in the next section.

are the node and edge local entropies. (Eq. 8 is also the
Bethe entropy.) For a distribution, ρ, over T (G), the treereweighted entropy is given by
X
H TR (µ̃) ,
ρ(T ) HT (µ̃)
(9)
T ∈T (G)

=

X

1−


X
ρ(e) Hv (µv ) +
ρ(e)He (µe ).

X
e:v∈e

v∈V

e∈E

Wainwright (2006) showed that if each edge, e ∈ E, has
positive marginal probability, ρ(e) > 0 (i.e., e appears in at
least one tree, T , with ρ(T ) > 0), then −H TR is at least
Ω(1/ |G|)-strongly convex. Unfortunately, this modulus
decreases as a function of the size of the graph. This is
partly because Wainwright’s analysis considers all models
in the exponential family. Here, we prove a more optimistic
lower bound for models that exhibit good contraction.
Definition 3. Fix a graph, G , (V, E), and potentials,
θ, which induce a probability density, p. For any (u, v) :
{u, v} ∈ E, define the contraction coefficient as
ϑθ (u, v) ,

4. Strongly Convex Variational Inference
In light of Section 3.4, we would like to identify strongly
convex free energies for which the modulus of convexity is lower-bounded by a function that does not decrease
with |G|. In this section, we present new guarantees for
two popular variational methods. First, we provide modeldependent conditions under which the tree-reweighted negative entropy is Ω(1)-strongly convex (Section 4.1). To
prove this result, we prove a similar claim for the negative
entropy of a tree-structured model (given in Appendix C.1).
We also analyze the class of counting number entropies
(which subsumes tree-reweighting), proving an interesting
relationship between the counting numbers and the modulus of convexity (Section 4.2). Using this insight, we then
provide a counting number optimization that guarantees κstrong convexity, for any κ > 0, independent of the model.
4.1. Tree-Reweighting
The tree-reweighted entropy (Wainwright et al., 2005) is a
convex combination of tree entropies. In this section, we
give conditions under which its modulus of convexity is
lower-bounded by a function of the parameters and structural properties, independent of graph size.
Fix a graph, G, and let T (G) denote its spanning trees. For
a tree T , (V, ET ) ∈ T (G), its entropy is given by
X
X
HT (µ̃) ,
(1 − deg(v))Hv (µ̃v ) +
He (µ̃e ), (8)
v∈V

e∈ET

where deg(v) is the degree of node v, and Hv (µ̃v ) ,
P`
P`
ij
− j=1 µ̃jv log µ̃jv and He (µ̃e ) , − i,j=1 µ̃ij
e log µ̃e

sup kp (Yu | Yv = y; θ) − p (Yu | Yv = y 0 ; θ)kTV .

y,y 0 ∈Y

Denote the maximum of the contraction coefficients by
ϑ?θ ,

sup

ϑθ (u, v).

(u,v):{u,v}∈E

The contraction coefficients measure the dependence between adjacent variables in a graphical model. A contraction coefficient of 1 implies determinism, and 0 implies
independence. In Appendix C.2, we describe an efficient
procedure for computing the contraction coefficients in a
tree-structured model.
Roughly speaking, the contraction coefficients are determined by the ratio of “local” signal to “relational” signal. If
the local signal is strong, Yv has little influence on Yu . For
models with a sufficiently high ratio of local-to-relational
signal, dependence decays with graph distance at a geometric rate. In this case, one can show that −HT is Ω(1)strongly convex (see Appendix C.1). Using this result, we
obtain the following.
Proposition 2. Fix a graph, G , (V, E), with maximum
degree independent of |V|. Fix a distribution, ρ, over the
spanning trees, T (G), such that there exists a constant,
C > 0 : ∀ e ∈ E, ρ(e) ≥ C, that lower-bounds the
edge probabilities. Let Θ ⊆ R|θ| denote the set of potentials such that each tree T ∈ T (G) : ρ(T ) > 0, with
maximum degree ∆T , has maximum contraction coefficient
ϑ?θ,T ≤ 1/∆T . Let M̃(Θ) , {µ̃(θ) : θ ∈ Θ} denote the
set of pseudomarginals realizable under any θ ∈ Θ. Then,
−H TR is Ω(1)-strongly convex in M̃(Θ).

The Benefits of Learning with Strongly Convex Approximate Inference

The proof is given in Appendix D.1. See Appendix D.2 for
implications of Proposition 2 for a grid-graph model.
Proposition 2 guarantees Ω(1)-strong convexity, but it still
does not identify the modulus. Further, it is modeldependent, and may not hold for certain potentials. Therefore, applying Proposition 1 to tree-reweighted variational
inference is only meaningful when learning in a constrained model space that admits good contraction. In the
next section, we describe a technique to tune the modulus
to any specified value, regardless of the model.
4.2. Counting Number Optimization
Counting number techniques decompose the entropy into a
weighted sum of node and edge local entropies. For c ,
((cv )v∈V , (ce )e∈E ), the counting number entropy is
X
X
H c (µ̃) ,
cv Hv (µ̃v ) +
ce He (µ̃e ).
(10)
v∈V

min

c, α≥0

2

kc − cB k2

s.t. ∀v ∈ V, cv +

Note that H generalizes the Bethe entropy (Eq. 8), which
is given by cv = 1 − deg(v) and ce = 1. We can also
recreate the tree-reweighted entropy (Eq. 9) with cv = 1 −
P
e:v∈e ρ(e) and ce = ρ(e). In this section, we show how
to find counting numbers that preserve strong convexity,
with a modulus that is lower-bounded by a given value.
Since −Hv and −He are convex, it is clear from Eq. 10 that
−H c is convex for nonnegative counting numbers. Heskes (2006) derived more sophisticated sufficient conditions
for convexity by reparameterizing the counting numbers.
Specifically, −H c is convex if there exist nonnegative auxiliary counting numbers, (αv ≥ 0)v∈V , (αe ≥ 0)e∈E and
(αv,e ≥ 0)e∈E,v∈e , such that
X
∀v ∈ V, cv = αv −
αv,e ,
(11)
e:v∈e

∀e ∈ E, ce = αe +

X

αv,e .

(12)

v:v∈e

The effect of the auxiliary counting numbers, in particular, αv,e , is to shift weight between the regular counting
numbers, cv and ce . Heskes’ conditions mean that cv can
be negative and still guarantee convexity. We can further
show that −H c is strongly convex whenever αe is uniformly lower-bounded; αv and αv,e , however, are only required to be nonnegative.
Proposition 3. Fix a graph, G , (V, E), and assume that
every node is in at least one edge. If c satisfies Eqs. 11
and 12 for some κ > 0, (αv ≥ 0)v∈V , (αe ≥ κ)e∈E and
(αv,e ≥ 0)e∈E,v∈e , then −H c , is (κ/3)-strongly convex.
The proof is given in Appendix E.1.
Proposition 3 lets us characterize the strong convexity of
a range of algorithms that optimize counting numbers. For

(13)
X

αv,e ≥ 0 ;

e:v∈e

e∈E

c

and

example, observing that the Bethe approximation often outperformed tree-reweighting in practice, Meshi et al. (2009)
proposed a “convexified” Bethe approximation. Their algorithm finds a set of counting numbers that best approximates the Bethe counting numbers, cB , while satisfying
Heskes’ convexity conditions (Eqs. 11 and 12). They also
proposed
P incorporating a constraint that, for all v ∈ V,
cv + e:v∈e ce = 1; this ensures that the counting numbers
are variable-valid for a fully factored (i.e., edgeless) model.
Via Proposition 3, adding a constraint that αe ≥ 3κ ensures that the resulting negative entropy is κ-strongly convex. This yields the following constrained quadratic program (QP), which we refer to as the strongly convexified
Bethe approximation:

∀e ∈ E, ce −

X

αv,e ≥ 3κ ;

v:v∈e

∀v ∈ V, cv +

X

ce = 1.

e:v∈e

Note that Eq. 13 only depends on the graph structure; it is
independent of the potentials. Thus, the QP only needs to
be solved once, prior to learning, for each example in the
training set. Moreover, examples that have the same structure can use the same counting numbers. Certain graphs,
such as regular graphs, may admit an analytic solution to
Eq. 13, thereby avoiding numerical optimization.
We can strongly convexify any desired counting numbers.
For instance, Hazan & Shashua (2008) proposed a convex
counting number optimization that encourages ce = 1 uniformly. With a small modification to Eq. 13, we can make
Hazan & Shashua’s method strongly convex. We can also
optimize the tree-reweighted entropy. Though −H TR is already Ω(1)-strongly convex for certain models (per Proposition 2), it may be difficult to identify the modulus. By
substituting the tree-reweighted counting numbers for cB
in the objective, we can ensure that −H TR is at least κstrongly convex, for any given κ, independent of the model.
For certain graphs and values of κ, the variable validity
constraint may make the optimization infeasible. In these
cases, we propose switching to a slackened QP, described
in Appendix E.2. This QP adds a free parameter, C, that
trades off between fitting the target counts and satisfying
variable validity. We explore this trade-off in Section 5.3.

5. Experiments
Our empirical evaluation tests the hypothesis that strongly
convex free energies result in better learned marginals, as
suggested by Proposition 1. Evaluations of approximate

The Benefits of Learning with Strongly Convex Approximate Inference

inference techniques typically use the true model to measure the discrepancy in the marginals. That is, given the
model that generated the data, θ ? , most studies measure
kµ(θ ? ) − µ̃(θ ? )k, where µ̃(θ ? ) uses the true model with
approximate inference. While this isolates the quality of
the approximation, it ignores the fact that approximate inference is typically used both at train and test time. It
is therefore valuable to test the quality of the approximation using a model that is learned with said approximation.
Wainwright (2006) called this “learning the ‘wrong’ graphical model,” since the learned model may not converge to
the true model. We prefer to call it “learning the ‘right’
graphical model for the ‘wrong’ inference,” since it finds
the best parameters for the given variational method. We
therefore report scores for both true and learned models.
5.1. Data Generator
Our synthetic data generator is based on those used in prior
work (e.g., Hazan & Shashua, 2008; Meshi et al., 2009)
to evaluate approximate marginal inference. We generate
data from an (8 × 8) non-toroidal grid-structured model, in
which each node, v, is associated with a binary variable,
Yv ∈ {e1 , e2 }. The model is defined by the following process, for either “attractive” or “mixed” potentials. First, we
fix ωs > 0 and ωp > 0. For each node,
 1  we flip a fair
coin, cv ∈ {±1}, and let wv , ωs cv −1 . If the model
 1 −1 
is “attractive,” we uniformly set we , ωp vec −1
,
1
where vec( · ) converts a matrix to a vector; if “mixed,”
we flip another
 1 −1fair
 coin, ce ∈ {±1}, and set we ,
ωp ce vec −1
. To create local perturbations (i.e., ev1
idence), we draw a uniformly random xv ∼ U[0, 1] for each
node. Given these, we let
x + x 
u
v
,
∀v, θv , wv xv , and ∀e = {u, v}, θe , we
2
and define the data distribution as
X
X
p (Y = y; θ) ,
θv · yv +
θe · (yu ⊗ yv ).
v∈V

e∈E

This is equivalent to an Ising model with field potentials
θv ∼ U[−ωs , ωs ], and interaction potentials θe ∼ U[0, ωp ],
for attractive, or θe ∼ U[−ωp , ωp ], for mixed.

Of the four, only the last three are guaranteed to be convex;
LBP is not convex on a grid. TRBP is in fact strongly convex, though the true modulus depends on the model, and
may be difficult to identify. Hazan & Shashua’s method actually enforces strict convexity, but since the modulus can
be arbitrarily close to zero, we consider it effectively just
convex. We also compare strongly convexified versions
of C-Bethe, TRBP and C-Unif, using our counting number optimization. This results in counting numbers that are
provably κ-strongly convex, for a given κ > 0. We denote these versions by SC-Bethe, SC-TRBP and SC-Unif,
respectively, and indicate the value of κ whenever relevant.
For each value of ωs ∈ {0.05, 1} and ωp ∈
{0.1, 0.2, 0.5, 1, 2, 5}, we generate 20 models using the
above synthetic generator. Each model acts as a learning
trial. For each model, we compute the true marginal probabilities using exact (junction tree) inference and sample
100 joint assignments to Y. We use these samples to train
a model for each variational method (and value of κ), using L-BFGS to minimize the regularized NLL
√ (Eq. 6). The
regularization parameter, Λm , is set to 1/ m, per Proposition 1. We then compute the node marginals using variational inference with the true (i.e., generating) and learned
models. For each set of approximate marginals, we compute the root-mean-squared error (RMSE) with respect to
the true, exact marginals. We report the average RMSE
over 20 trials.
Our experiments are implemented in MATLAB, using
data structures from Mark Schmidt’s Undirected Graphical Models (UGM) toolkit (2013b). To optimize the
learning objective, we use Schmidt’s implementation of LBFGS with Wolfe line search (2013a). For exact inference
and sampling, we use UGM’s junction tree implementation. For all variational inference algorithms, we use our
own implementation of counting number belief propagation (CBP), based on Schwing et al.’s (2011) message updates; this can optimize any variational method whose entropy can be expressed with counting numbers. To optimize the counting number QP (Eq. 13, or Eq. 23 in Appendix E.2), we use MATLAB’s quadprog, with the interior point method. To measure statistical significance, we
use a paired t-test, with rejection threshold .05.

5.2. Experiment Design
5.3. Results
We use four variational methods from the literature:
LBP: The Bethe approximation (i.e., “loopy” BP).
C-Bethe: Meshi et al.’s (2009) convexified Bethe, which
is equivalent to Eq. 13 with κ = 0.
TRBP: Wainwright et al.’s (2005) tree-reweighted BP,
with the tree distribution described in Appendix D.2.
C-Unif: Hazan & Shashua’s (2008) convex counting number optimization, which prefers ce = 1 uniformly.

Due to space restrictions, we defer the full catalog of figures to Appendix F. Figure 1 highlights select plots.
Strong Convexity Improves Marginal Inference. Figures 2a-d plot the RMSE of the node marginals as a function of the interaction parameter, ωp . Inference is performed with the true model. The SC methods use the post
hoc optimal value of κ (and C) in the counting number optimization. All methods perform about the same for ωs = 1

The Benefits of Learning with Strongly Convex Approximate Inference

0.3
0.2

0.4

Node Marginal RMSE

0.4

0.3
0.2

0.2
0.18
0.16
0.14
0.12

0.1

0.2

0.5

ω

1

2

p

(a) Model, Attract, ωs = .05

5

0

0.15
0.14
0.13
0.12
0.11
0.1
0.09
0.08

0.08
0

LBP
C−Bethe
SC−Bethe
TRBP
SC−TRBP
C−Unif
SC−Unif

0.16

0.1

0.1

0.1

0.17

LBP
C−Bethe
SC−Bethe
TRBP
SC−TRBP
C−Unif
SC−Unif

0.22

Node Marginal RMSE

LBP
C−Bethe
SC−Bethe
TRBP
SC−TRBP
C−Unif
SC−Unif

0.5

Node Marginal RMSE

Node Marginal RMSE

0.5

0.24

0.6

LBP
C−Bethe
SC−Bethe
TRBP
SC−TRBP
C−Unif
SC−Unif

0.6

0.1

0.2

0.5

ω

1

2

p

(b) Model, Mixed, ωs = .05

5

0.07
0.1

0.2

0.5

ω

1

2

p

(c) Learned, Attract, ωs = 1

5

0.1

0.2

0.5

ω

1

2

5

p

(d) Learned, Mixed, ωs = 1

Figure 1. Select plots of RMSE (averaged over 20 trials) of the approximate node marginals w.r.t. the true marginals, as a function of the
interaction parameter, ωp . Data is generated with either “attractive” or “mixed” potentials. Figs. (a)-(b) use the true model for inference,
and (c)-(d) use the learned model. The black dotted line is LBP; color dotted lines are the convex baselines, and solid lines are their SC
counterparts, using the post hoc optimal value of κ (and C for κ ≥ .1). See Section 5.3 for discussion and Appendix F for all figures.

and ωp ≤ 2. LBP has a slight advantage for mixed potentials with ωp ≤ 1, which concurs with previous conclusions
(e.g., Meshi et al., 2009) that LBP performs well when
there is strong local signal. Focusing on ωs = .05, the convex methods offer significant improvement over LBP for
ωp ≥ 1 with attractive and ωp ≥ 2 with mixed potentials.
This shows that convexity helps when there is low localto-relational signal. In particular, we note that the strongly
convex methods (TRBP and all SC variants) exhibit dramatically lower error in this setting (see Figures 1a-b), with
over 10x improvement over LBP.
Strong Convexity Improves Learned Marginals. Figures 2e-h also plot RMSE as a function of ωp , but using the learned model to compute the marginals. The SC
methods yield statistically significant improvements in almost all data models. Figures 1c-d highlight the improvement, which is most prominent when ωs = 1. In certain cases, SC reduces the error of the convex baselines by
over 40%. These results support the hypothesis of Proposition 1, that using a variational free energy that is provably
Ω(1)-strongly convex can significantly improve the quality
of learned marginals. Moreover, the SC counting number
optimization can even improve TRBP—which is already
strongly convex, though the modulus is model-dependent.
Tuning κ in the SC Methods. The value of κ used in
the SC counting number optimization can have great impact on the quality of the marginals. The theory in Section 3 suggests that increasing the modulus of convexity
improves stability and marginal accuracy; however, altering κ affects the quality of the entropy approximation,
hence, the marginals. Thus, there is a trade-off that needs
to be explored. In Figures 3 and 4, we plot the RMSE
of the marginals as a function of κ, using the true and
learned models respectively, for select values of ωs and
ωp . Since values of κ ≥ .1 result in non-variable-valid
counting numbers for this grid, we use the slackened QP
and report the score for the post hoc optimal C. We learn

the following from these plots. When the true potentials
are given, and the model has low local-to-relational signal
(ωs = .05, ωp ≥ 2), any modulus of convexity above a certain threshold yields significant improvement. When using
variational inference for training, if there is low local signal (ωs = .05), use the highest value of κ that supports
variable validity. Since the local signal is weak, it is even
more important to be variable-valid. If local signal is strong
(ωp = 1), one can relax variable validity and push κ further.
Slackened Variable Validity. When using a value of κ
that requires slackening variable validity, this requires selecting a value for the slack parameter, C. The quality of
the slackened solution can vary with C, since this parameter controls the trade-off between variable validity and fitting the target counts. Figures 5 and 6 show select plots of
RMSE as a function of C, focusing on the Bethe and treereweighted approximations. Data is generated using mixed
potentials. In general, we find that the optimal value of C
depends on κ, with lower values of κ favoring lower values
of C. This is likely because lower C makes it easier for
the QP solver to reduce the slack variables. When training
with κ ≥ .1, a good rule of thumb is to set C fairly high;
we found that C = 100 works well overall.

6. Conclusion
We have shown, both theoretically and empirically, that
variational inference with a strongly convex free energy can
improve the accuracy of marginal probabilities. We proved
sufficient conditions under which two popular variational
methods are strongly convex, and proposed a novel counting number optimization that guarantees κ-strong convexity, for any κ. Our results indicate that using this approach
to specify a modulus can dramatically reduce the error
of approximate marginal inference, suggesting substantial,
tangible benefit to applications of graphical models.

The Benefits of Learning with Strongly Convex Approximate Inference

Acknowledgements
This work was supported by the National Science Foundation (NSF), under grant number IIS1218488, and by the Intelligence Advanced Research Projects Activity (IARPA),
via Department of Interior National Business Center
(DoI/NBC) contract number D12PC00337. The U.S. Government is authorized to reproduce and distribute reprints
for governmental purposes notwithstanding any copyright
annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should
not be interpreted as necessarily representing the official
policies or endorsements, either expressed or implied, of
NSF, IARPA, DoI/NBC, or the U.S. Government.

References

Mangasarian, O. and Shiau, T. Lipschitz continuity of solutions of linear inequalities, programs and complementarity problems. SIAM Journal on Control and Optimization, 25(3):583–595, 1987.
Meltzer, T., Globerson, A., and Weiss, Y. Convergent message passing algorithms – a unifying view. In Uncertainty in Artificial Intelligence, 2009.
Meng, Z., Eriksson, B., and Hero III, A. Learning latent
variable Gaussian graphical models. In International
Conference on Machine Learning, pp. 1269–1277, 2014.
Meshi, O., Jaimovich, A., Globerson, A., and Friedman, N.
Convexifying the Bethe free energy. In Uncertainty in
Artificial Intelligence, 2009.

Bickel, P., Ritov, Y., and Tsybakov, A. Simultaneous analysis of Lasso and Dantzig selector. Annals of Statistics,
37(4), 2009.

Negahban, S., Ravikumar, P., Wainwright, M., and Yu, B.
A unified framework for high-dimensional analysis of
m-estimators with decomposable regularizers. Statistical Science, 27(4):538–557, 2012.

Bradley, J. and Guestrin, C. Sample complexity of composite likelihood. In Artificial Intelligence and Statistics,
2012.

Ravikumar, P., Wainwright, M., Raskutti, G., and Yu,
B. High-dimensional covariance estimation by minimizing `1 -penalized log-determinant divergence. Electronic
Journal of Statistics, 5:935–980, 2011.

Globerson, A. and Jaakkola, T. Approximate inference using conditional entropy decompositions. In Artificial Intelligence and Statistics, pp. 130–138, 2007.

Schmidt, M. minFunc. http://www.di.ens.fr/
˜mschmidt/Software/minFunc, 2013a.

Hazan, T. and Shashua, A. Convergent message-passing
algorithms for inference over general graphs with convex
free energies. In Uncertainty in Artificial Intelligence,
2008.
Heskes, T. Convexity arguments for efficient minimization
of the Bethe and Kikuchi free energies. Journal of Artificial Intelligence Research, 26:153–190, 2006.
Hiriart-Urruty, J. and Lemaréchal, C. Fundamentals of
Convex Analysis. Grundlehren Text Editions. Springer
Berlin Heidelberg, 2001.
Kakade, S., Shamir, O., Sindharan, K., and Tewari,
A. Learning exponential families in high-dimensions:
Strong convexity and sparsity. In Artificial Intelligence
and Statistics, 2010.
London, B., Huang, B., Taskar, B., and Getoor, L. Collective stability in structured prediction: Generalization
from one example. In Intl. Conference on Machine
Learning, 2013.
London, B., Huang, B., Taskar, B., and Getoor, L. PACBayesian collective stability. In Artificial Intelligence
and Statistics, 2014.

Schmidt, M. UGM: Matlab code for undirected graphical
models. http://www.di.ens.fr/˜mschmidt/
Software/UGM, 2013b.
Schwing, A., Hazan, T., Pollefeys, M., and Urtasun, R.
Distributed message passing for large scale graphical
models. In Computer Vision and Pattern Recognition,
2011.
Wainwright, M. Estimating the “wrong” graphical model:
Benefits in the computation-limited setting. Journal of
Machine Learning Research, 7:1829–1859, 2006.
Wainwright, M. and Jordan, M. Graphical Models, Exponential Families, and Variational Inference. Now Publishers Inc., 2008.
Wainwright, M., Jaakkola, T., and Willsky, A. A new class
of upper bounds on the log partition function. IEEE
Trans. on Information Theory, 51(7):2313–2335, 2005.
Weiss, Y., Yanover, C., and Meltzer, T. MAP estimation,
linear programming and belief propagation with convex
free energies. In Uncertainty in Artificial Intelligence,
2007.

