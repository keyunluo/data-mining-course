A reversible infinite HMM using normalised random measures

Konstantina Palla
University of Cambridge, Trumpington Street, CB2 1PZ
David A. Knowles
Stanford University, 353 Serra Mall, CA 94305-9025
Zoubin Ghahramani
University of Cambridge, Trumpington Street, CB2 1PZ

Abstract
We present a nonparametric prior over reversible
Markov chains. We use completely random measures, specifically gamma processes, to construct
a countably infinite graph with weighted edges.
By enforcing symmetry to make the edges undirected we define a prior over random walks on
graphs that results in a reversible Markov chain.
The resulting prior over infinite transition matrices is closely related to the hierarchical Dirichlet
process but enforces reversibility. A reinforcement scheme has recently been proposed with
similar properties, but the de Finetti measure is
not well characterised. We take the alternative
approach of explicitly constructing the mixing
measure, which allows more straightforward and
efficient inference at the cost of no longer having
a closed form predictive distribution. We use our
process to construct a reversible infinite HMM
which we apply to two real datasets, one from
epigenomics and one ion channel recording.

1. Introduction
Consider a sequence of states X1 , . . . , XT sampled from
a reversible Markov chain. A Markov chain is said to be
reversible if the probability of the chain is the same observed either forwards or backwards in time. Reversibility is a realistic assumption in various settings. For instance, reversible Markov chains are appropriate to model
the time-reversal dynamics in physical systems, such as the
transitions of a macromolecule conformation at fixed temperature or chemical dynamics in protein folding. In these
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

KP 376@ CAM . AC . UK

DAVIDKNOWLES @ CS . STANFORD . EDU

ZOUBIN @ ENG . CAM . AC . UK

settings, the system transitions between hidden states over
time emitting a sequence of observations Y1 , . . . , YT . Our
aim is to recover the process and hidden state sequence that
gave rise to this observed data. To do this we define a prior
over reversible Markov chains.
There is a close connection between reversible Markov
chains and random walks on graphs. More specifically, a
random walk on a weighted undirected graph produces a
reversible Markov chain. In a random walk on a graph, the
traveller jumps to the next node (state) with probability proportional to the corresponding edge weight. Our aim is to
put a prior over the unknown transition matrix (analogously
the weights) that guides the walk. Much research has
gone into connecting random walks on graphs to reversible
Markov chains with seminal works by Diaconis and Freedman (1980) and Diaconis and Coppersmith (1986). The
latter assumes an edge reinforced random walk (ERRW)
where the edge weight is increased by one each time an
edge is crossed. The process is defined for a finite state
space and, in the limit, gives weights that are distributed
according to an explicitly characterised mixing measure,
which can be a conjugate prior for the reinforcement process. In the more recent work of Bacallado et al. (2013),
the authors define a three-parameter random walk with reinforcement, named the (θ, α, β) scheme, which generalizes the linearly edge reinforced random walk to countably infinite spaces. However, a closed form for the prior
(mixing measure) is lacking and inference in this model
is challenging. In this work, we assume countably infinite state space and take the alternative approach of explicitly constructing the prior over the transition matrix. Inference can be then performed using relatively straightforward
Markov Chain Monte Carlo methods. We use the resulting
reversible Markov chain as the hidden sequence in a Hidden Markov model whose utility we validate on two real
world datasets.
The paper is organized as follows. In Section 2, we briefly

A reversible infinite HMM using normalised random measures

provide some background on the Gamma process which is
central to our model definition. In Section 3, we describe
the process proposed in this manuscript. We discuss its theoretical properties in Section 4 and provide a de Finetti representation for the process in Section 5. The finite version
of the model and its HMM extension appear in Sections
6 and 7 and inference, performed via a Gibbs sampler, is
described in Section 8. In Section 9 we study our model’s
performance on real datasets and in Section 10 we conclude
our work and provide a short discussion about future directions.

2. The Gamma Process
To facilitate understanding, we briefly review the Gamma
process ΓP (α0 , µ0 ) over a space X . A realization G0 ∼
ΓP is a positive measure on the space X , which can be represented as a countable weighted sum of atoms. Each atom
i at xi ∈ X has corresponding weight wi ∈ (0, ∞). The
atoms and weights are distributed according to a Poisson
process over the product space X × [0, ∞) with intensity
measure
ν(dw, dx) = ρ(dw)µ0 (dx) = a0 w−1 e−a0 w dw µ0 (dx).
(1)
where µ0 is the base measure and α0 is the concentration
parameter. ν is known as the Lévy measure of the gamma
process, and because of this representation the gamma process is a Lévy process. In this paper, we assume that the
base measure is the Lebesgue measure. A sample from this
Poisson process will yieldRa countably infinite collection of
atoms {xi , wi }∞
i=1 since X ×[0,∞) ν(dw, dx) = ∞. We
assume µ0 is diffuse (non-atomic) and so, we can write:
G0 :=

∞
X

wi δxi ∼ ΓP (α0 , µ0 )

(2)

i=1

Intuitively, G0 (A) sums up the values of wi with xi ∈ A.
It can be shown that the distribution of G0 (A), where
A ⊆ X , is Gamma(α0 µ0 (A), α0 ), hence the name of the
process. The gamma process is a completely random measure (Kingman, 1967) and as such for any disjoint and measurable partition A1 , . . . , An of X the random variables
{G0 (A1 ), . . . , G0 (An )} are mutually independent gamma
variables.

3. Model Description
Given a measurable space {X , F}, with a set X and a σalgebra F of subsets of X , our aim is to construct a model,
a sample from which will give rise to a reversible Markov
chain of states X1 , . . . , Xt , . . . , XT . At each time point t
the chain is at a state x denoted as Xt = x. We require
that the set S := {xi ∈ X , i ∈ N} is countable. We

construct the prior by deploying the gamma process in a
hierarchical fashion; we use a gamma process to sample
the states and given these states, we construct the transition
matrix by sampling from another gamma process.
More carefully, let ΓP(α0 , µ0 ) be a gamma process on X ,
with concentration parameter α0 and base measure µ0 , as
given by Equation 1. A sample G0 from this process corresponds to the set of atoms S = {xi ∈ X , i ∈ N} and their
associated weights {wi }∞
i=1 as in Equation 2. Note that by
construction the cardinality of the set {xi }∞
i=1 is countably
infinite and there is a one-to-one mapping of the atoms in
S to the set of natural numbers N. We define a new gamma
process ΓP(α, µ) on the product space S × S, with concentration parameter α and atomic base measure
µ(xi , xj ) = G0 (xi )G0 (xj )

(3)

where S is the support of G0 . The base measure µ is atomic
and as such, assigns non-zero mass on atoms on the product space S × S. Since G0 is discrete a.s., G will also be
discrete so we can write
XX
G=
Jij δxi xj ,
(4)
i

j

where, from the definition of the Gamma process with fixed
points of discontinuity (xi , xj ), we have
Jij |G0 ∼ Gamma(αµ(xi , xj ), α) = Gamma(αwi wj , α)
(5)
where αwi wj is the shape and α the rate of the gamma distribution. To avoid notation overload, we also use J to represent the weight matrix which when normalised per row,
gives the transition matrix P such that Pij = P (xi , xj ) =
PJij
is the probability of transitioning to state xj given
κ Jiκ
that the chain is in state xi currently. The transition matrix
PP
is stochastic, that is, its entries are all non-negative and
Pij = 1, for all xi ∈ S. By the additive property
j:xj ∈S

of the gamma process, each row Jj in the weight matrix is
still a sample from a gamma process in the restricted space
{xj } × S with base measure µ, so
X
G({xj }, ·) =
Jji δxi
(6)
i

To generate the sequence X1 , . . . , Xn , we draw an initial
state X1 ∼ G̃0 , where G̃0 is the normalised random measure derived from G0 , i.e. G̃0 = G0 /G0 (X ) and sample
the transition Xn−1 → Xn , as follows:
Xn |Xn−1 , G ∼

G(Xn−1 , ·)
= P (Xn−1 , ·)
G(Xn−1 , S)

(7)

The process can be thought of as a weighted random walk
on a graph, with vertex set S and edge set {(x, y) ∈

A reversible infinite HMM using normalised random measures

α

α

Table 1. HDP, HGP and SHGP

µ0

α0

µ0

α0

HDP

HGP

SHGP

G00 ∼ DP(α0 µ0 )
Jj ∼ DP(α0 G00 )

G0 ∼ ΓP (α0 , µ0 )
J˜j ∼ ΓP (α̃, G0 )

G0 ∼ ΓP (α0 , µ0 )
Jj ∼ ΓP (αwj , G0 )

G0

G0
G

G
E

X

(a) SHGP

the per-row normalisation of which gives the transition matrix. As such, the SHGP allows for a direct treatment of
the weigths, the symmetry in Equation 8 is imposed and
reversibility arises. The normalised, non-symmetrised version of the proposed process is equivalent to the HDP with
appropriate priors on the concentration parameters: details
can be found in the supplementary material.

X

Y

(b) SHGP - HMM

Figure 1. (a) Graphical model for SHGP and (b) SHGP as part of
an HMM where the time series X and Y are represented as single
nodes.

X 2 ; Jij > 0}. J : S × S → (0, ∞) is a function that
puts non-negative weight to each edge in the graph.
The above random walk has not yet yielded a reversible
Markov chain. To achieve this reversibility we modify (5)
so that Jij is symmetric, i.e.
Jij = Jji |G0 ∼ Gamma(αwi wj , α)

(8)

The function J is now symmetric and the new G defined using symmetric J is no longer a draw from a completely random measure because of the dependency induced by this
symmetry. However, each row is still marginally a draw
from a completely random measure. The resulting transition matrix P is a sample from the prior, the construction
of which was just described.
We note here that the choice of the shape value for each Jij
weight might not be restricted to the product of the corresponding w’s. Depending on the dataset at hand, the choice
might vary. We call the proposed model Symmetric Hierarchical Gamma Process and use the acronym SHGP. A
graphical representation of the model is presented in Figure
1(a).
Relation to Hierarchical Dirichlet process. The construction of the proposed SHGP prior closely relates to
the Hierarchical Dirichlet process (Teh et al., 2006). Both
processes use random measures in a hierarchical way:
the HDP uses the Dirichlet process, while the SHGP the
Gamma process as seen in Table 1, where Jj refers to the
j-th row of the weight matrix. Moreover, both processes
when used for the infinite Hidden Markov models (Beal
et al., 2003), put a prior on the transition matrix P but in
a different fashion; the HDP directly defines a prior over
P , while the SHGP puts a prior on the weight matrix J,

Relation to Hierarchical Gamma process. Interesting
is the relation of the SHGP to the simple Hierarchical
Gamma process (HGP) also seen in Table 1. Both processes use the Gamma process in a hierarchical way. The
HGP does not assume symmetry in the weights but this
can be easily imposed. However, the random variable Jij
is sampled from Gamma distributions with different shape
parameters. More specifically
Jij = Jji |G0 ∼ Gamma(α̃wi ) for the HGP
Jij = Jji |G0 ∼ Gamma(αwi wj ) for the SHGP

(9)

As seen in Equation 9, in SHGP the base weights of both
the nodes i and j contribute to the edge weight Jij , as opposed to the HGP where only one of the base weights influences the shape. As already stated earlier in this Section,
this is a modelling choice that depends on whether or not
contribution of both nodes is desired. More details about
the relation amongst SHGP, HGP and HDP can be found in
the supplementary material.

4. Theoretical Properties
In this section, we describe important theoretical properties of the induced Markov chain given the sample from
the SHGP process. The theory used, is the theory applied
on Markov chains on countably infinite space since the induced Markov chain falls in this category.
Reversibility. In order to prove that the induced Markov
chain is reversible, it is sufficient to prove that detailed balance holds, that is
π(xi )Pij = π(xj )Pji

(10)
P
κ Jiκ
P P
l
κ Jlκ

where π is the probability defined by π(xi ) =
and P is the stochastic transition matrix induced by the
rows of the symmetrised J.

A reversible infinite HMM using normalised random measures

Proof :
We have
P
Jij
κ Jiκ PJij
π(xi )Pij = P P
=P P
l
κ Jlκ
κ Jiκ
l
κ Jlκ
P
J
Jji
J
κ jκ P ji
=P P
=P P
J
lκ
l
κ
l
κ Jlκ
κ Jjκ
= π(xj )Pji ,

(11)

as a result of (8). As a straighforward corollary, π is the
invariant measure of the chain.
Is the normalization constant per row finite? When
defining the transition matrix P , it is crucial that the sum
of each row in the weight matrix J is almost surely (a.s.)
finite, since this ensures that the normalization is a welldefined operation. In other words, we P
want to
 ensure that


for every row j in the weight
matrix
J
i ji < ∞ holds
P

a.s. To start with, the sum  i wi  converges a.s., that is
X 

wi  < ∞,

a.s.

(12)

i

if the well-known condition on the Levy measure ρ(dw)
that
Z
(1 − e−w )ρ(dw) < ∞,
(13)
R+

holds. For a Gamma process where ρ(dw) = a0 w−1 e−a0 w
it is easy to prove that the above condition holds and as such
the sum in (12) converges. Since the weights wi are defined
over the space [0, ∞), we ensure that wi ≥ 0 always. Consequently,P
we can drop the absolute value notation and simply write i wi < ∞. Moreover, since thePmeasure over
w is continuous, P (wi = 0) = 0 for ∀i and i wi > 0 a.s.
P
The sum in each row i in the weight matrix is j Jij . Each
element Jij of this sum is a gamma distributed variable
sampled from the gamma distribution Gamma(αwi wj , α).
Recall here that the variables Jij and Jji are being sampled from the same Gamma distribution. This, along with
the property that the sum of gamma distributed variables
with the same rate parameter is a gamma distributed variable with the shape equal to the sum of the shape parameters of the individual gamma variables and the same rate
gives the following marginally
X
X
Jji ∼ Gamma(αwj
wi , α)
(14)
i

state in a finite number of steps with positive probability. In other words, when a Markov chain is irreducible,
the sample path (the state sequence) cannot get trapped in
smaller subsets of the state space. That is, for any two states
xi , xj ∈ X there exists an integer t, such that the transition
probability from xi to xj at time step t is positive, that is
Pijt > 0. It is easy to see that the proposed generative process produces an irreducible Markov chain almost surely.
Looking at the weight matrix, we see that the elements are
gamma distributed variables with support Jij ∈ (0, ∞),
and thus are positive almost surely. This, along with the existence (and finiteness) of the normalization constant shows
that the probability of moving from one state to any other in
one step is always positive and the chain is irreducible. Let
Tii := {t ≥ 1 : Piit > 0} be the set of times when it is possible for the chain to return to starting state Xi . The period
of the state Xi is defined to be the greatest common divisor
of Tii . For an irreducible chain, the period of it is defined to
be the period which is common for all the states. We note
that the transition matrix is strictly positive and as a result
the chain can be in any state in one step. This implies that
all the states have period 1 and the chain is aperiodic.
Convergence. We showed that the generated Markov
chain has an invariant probability distribution π. A state
xi is positive recurrent if the expected amount of time
to return to state i given that the chain started in state
xi has finite first moment that is, E(τii ) < ∞, where
τij := min{n ≥ 1 : Xn = xj |X0 = xi } is the time
(after time 0) until reaching state xj given X0 = xi . An irreducible Markov chain with transition matrix P is positive
recurrent if and only if there exists a probability distribution
π on X such that π = πP [Theorem 21.12, (Levin et al.,
2006)]. As such, the generated Markov chain {S1 , S2 . . . }
is positive recurrent. Irreducibility, aperiodicity and positive recurrence ensure that the invariant distribution π is
unique and for all x ∈ X [Theorem 21.14, (Levin et al.,
2006)] ,
lim ||P t (x, ·) − π||T V = 0

t→+∞

(15)

where T V denotes the total variation distance between the
two distributions. Equation (15) describes the convergence
of the chain as t → +∞ and states that every row in the
transition matrix P t converges to the stationary distribution
π eventually. In other words, the invariant distribution π is
also the limit distribution of the chain.

i

P

Since
we have ensured that 0 <
i wi < ∞ a.s., then
P
J
is
finite
a.s.,
ensuring
that
the
normalization
for evji
i
ery row in the weight matrix is a well-defined operation.
Irreducibility and aperiodicity. A Markov chain is irreducible if it is possible to get from any state to any other

5. de Finetti Representation
Diaconis and Freedman (1980) defined a type of exchangeability for Markov chains, known as Markov exchangeability and it is defined for sequences X1 , X2 , . . . in a countable space X as follows:

A reversible infinite HMM using normalised random measures

Definition 1 A process on a countable space X is Markov
exchangeable if the probability of observing a path
X1 , . . . , Xn is only a function of X1 and the transition
counts C(x, y) := |{X1 = x, Xi+1 = y; 1 ≤ i < n}|
for all x, y ∈ X .
In other words, a sequence is Markov exchangeable if
the initial state X1 and the transition counts are sufficient
statistics. Intuitively, this means that two different state
sequences are equiprobable under the joint distribution, if
they begin with the same value and preserve the transition
counts between unique values. They also proved the following
Theorem 1 (Diaconis and Freedman, 1980) A process is
Markov exchangeable and returns to every state visited infinitely often (recurrent), if and only if it is a mixture of
recurrent Markov chains.
In the previous Sections, we defined a prior over transition
matrices using a hierarchy of gamma processes. We also
proved that the induced Markov chains (given the transition matrix sampled from the prior) are recurrent. The use
of the prior let us write the state sequence as a mixture of
recurrent Markov chains and using Theorem 1 we can state
that the sequence {Xn } generated by the proposed process
and defined on a countably infinite space S is Markov exchangeable and recurrent.
Proposition 1 For some measure ϕ on S × P, where P is
the space of stochastic matrices on S × S, the distribution
of (Xi )i∈N , can be represented as
p(X1 , . . . , Xn ) =

Z n−1
Y

P (Xi , Xi+1 )ϕ(X1 , dP ) (16)

P i=1

Equation (16) shows the de Finetti representation of the
proposed process. The de Finetti measure is the distribution ϕ over the product of the space S and the space of
stochastic matrices P.

6. Finite Model
The inference simplifies considerably if we consider the
finite state model which gives the countably infinite state
model in the limit. More carefully, we assume that we have
a finite number of states K and we prove that as K → ∞,
the model converges in distribution to the countably infinite
model.
The infinite divisibility property of the gamma process G0
on X states that for each K = 1, 2, . . . there exists a sequence of i.i.d. random variables G0 (A1 ) + · · · + G0 (AK )
such that
d

G0 (X ) = G0 (A1 ) + · · · + G0 (AK )

(17)

d

where = is equality in distribution. Due to the additive property of the Gamma distribution, for any finite, disjoint and measurable
partition A1 , . . . , AK of
SK
X such that X =
A
,
the
variable G0 (X ) with
i
i=1
law Gamma(α0 µ0 (X ), α0 ) can be written as the sum
of K Gamma distributed variables each one following the law Gamma(α0 µ0 (Aj ), α0 ), that is G0 (X ) =
PK
j=1 G0 (Aj ). The additive property of µ0 ensures that
PK
µ0 (X ) =
i=1 µ0 (Ai ) and as such the shape parameter
of the Gamma distribution of G0 (X ) will be equal to the
PK
α0 j=1 µ0 (Aj ). As K → ∞ we recover the infinite case
and Equation (17) holds. For simplicity, we assume that
(X )
.
µ0 (Aj ) = µ0K
By restricting the process to the finite case, we facilitate inference without compromising the properties of the model
since K can always be chosen sufficiently large. Putting
everyting together, the generative process in the finite case
is as follows:
G0 =

K
X

w i δ xi

i=1

wi ∼ Gamma(α0 µ0 (xi ), α0 )
G=

K X
K
X

Jij δxi ,xj

i=1 j=1

Jij = Jji ∼ Gamma(αwi wj , α)

(18)

7. The SHGP Hidden Markov model
In typical sequential data analysis we are more interested
in using a Markov chain as the hidden state sequence in a
Hidden Markov model (HMM) rather than viewing X as
observations themselves. This allows a broad range of data
types to be modelled: the examples we will demonstrate
here include univariate continuous and multivariate count
data. Thus we use the SHGP to construct a Hidden Markov
model. Consider a sequence of observations {Yt ∈ Y :
t = 1, . . . , T } which we will assume to be independent
conditioned on the latent state sequence X. For simplicity
consider Xt ∈ {1, . . . , K} under the finite SHGP, and a
parametric family of observation models F (·|θ), then
Yt |Xt , θ ∼iid F (·|θXt )
where {θk , k = 1, · · · , K} are the state emission parameters. In the case of multinomial outputs θk is a probability
vector, the concatenation of which is known as the emission
matrix. The SHGP gives the prior over the hidden state sequence as shown in Figure 1(b). We present multinomial,
Poisson and Gaussian observation models F (.), the details
for which are given in the supplementary material.

A reversible infinite HMM using normalised random measures

8. Inference
As with many other Bayesian models, exact inference
is intractable so we employ Markov Chain Monte Carlo
(MCMC) for posterior inference over the latent variables
of the model as seen in Figure 1(b). A detailed description of the sampling steps is provided in the supplementary
material. The sampler iterates as follows:
Sampling the concentration parameters, α0 and α. We
used slice sampling by (Neal, 2003) to infer the parameters
α0 and α using Gamma priors α0 ∼ Gamma(s0 , r0 ) and
α ∼ Gamma(s, r), where {s0 , r0 } and {s, r} are the pairs
of shape and rate parameters for α0 and α respectively.
Sampling the weight vector, G0 . The vector G0 is the
vector of the base weights G0 = [w1P
, . . . , wK ] in the corresponding random measure G0 =
k wk δxk . We used
slice sampler to sample each weight wk .
Sampling the weight matrix, J . The weight matrix J
contains the edge weights {Jij }. We used hybrid Monte
Carlo (Neal, 2011) to sample the elements of the matrix at
once instead of sampling each element at a time using slice
sampling. In the reversible case, only K(K + 1)/2 weights
are sampled because of the symmetry in J. We also show
results using NUTS (Hoffman and Gelman, 2011) although
we find this gives similar performance to HMC in this setting.
Sampling the state sequence, X. We use the forwardbackward algorithm (Scott, 2002) to sample the latent state
sequence X given the current state of all other variables in
the model. This is a dynamic programming algorithm that
efficiently computes the state posteriors over all the hidden
state variables Xt .
Sampling the emission matrix, E.
the emission matrix is

The posterior over

p(E|Y, X) ∝ p(Y |E, X)p(E)
The explicit form of the posterior depends on the output,
the observed Y , that is multinomial, Poisson or Gaussian.
In all cases, due to conjugacy, the emission matrix is sampled exactly.

9. Experiments
In this section we evaluate the SHGP by running the SHGP
Hidden Markov model on two real world datasets. The
datasets are especially chosen such that the underlying systems are reversible. For completion, we also ran SHGP assuming non-reversibility by not imposing symmetry in the
inferred weight matrix J. Moreover, we compare SHGP to

the infinite HMM which learns a transition matrix for the
hidden state sequence and does not account for reversibility. For the iHMM we use the beam sampler (Van Gael
et al., 2008).
Prediction. A principled way to evaluate a generative
model is by its ability to predict missing data values given
some observations. For SHGP we collect M samples from
the posterior {{E (1) , X (1) }, . . . , {E (M ) , X (M ) }} and estimate the predictive distribution of a missing entry in the
dataset Y as the average of the predictive distributions for
each of the collected samples. For the experiments we ran,
we used two different likelihoods, a Poisson and a Gaussian. The supplementary material provides a detailed description of the likelihood models.
9.1. ChIP-seq epigenetic marks
For this experiment we used ChIP-seq (chromatin immunoprecipitation sequencing) data, representing histone modifications and transcription factor binding in human neural
crest cell lines (see Park (2009) for a nice review). ChIPseq is a method to identify the sites in a DNA sequence
where specific proteins are bound. The workflow of ChIPseq is: 1) DNA is extracted from cells, 2) the proteins
of interest (POI) and DNA are chemically bound (“crosslinked”), 3) the DNA is fragmented using sonification, 4)
an appropriate antibody is used to filter out the DNA fragment bound to the POI using immunoprecipitation, 5) the
POI is removed from the DNA, 6) the DNA is sequenced.
The reads are finally mapped to a known reference sequence. Note that reversibility is reasonable here because
although individual genes have direction, the genome as a
whole has no particular direction.
The resulting observed sequence Ylt is a L × T matrix of
counts, representing how many reads for POI l mapped to
bin t, where a bin is a 100bp region of the genome (different
size bins could be used, but 100bp is commonplace). A
small section of our full L = 6 by T = 20000 dataset
Y , of length 300, along with the identifiers of the POIs is
shown in Figure 2.
ChiSeq results presented in Table 2. We ran 10 repeats,
each time holding out different 20% of the data Y and using different random initilisation. The likelihood model
used here is Poisson and the task was to predict the held
out values in Y. We see that in terms of predictive performance the reversible SHGP-HMM outperforms both the
non-reversible version of the model and the iHMM trained
using beam sampling. The “emission” matrix, the L by K
matrix of Poisson rates is shown in Figure 9.1 where we
identify expected states known as enhancers and promoters based on their activity levels for the different markers
(POIs).

A reversible infinite HMM using normalised random measures

Figure 3. Learnt emission matrix L × K for ChIP-seq dataset. Element Elk is the Poisson rate parameter for protein l in state k. Brighter
indicates higher values. Here we associate the states learnt in an supervised manner with known functional regulatory elements, see e.g.
Rada-Iglesias et al. (2010)

.
Table 2. ChipSeq results for 10 runs using different hold out patterns. We used a truncation level of K = 20, 1000 iterations and a
burnin of 700.

Model
Reversible
Non-reversible
iHMM

Alogirthm
HMC
Beam Sampler

Train error
0.9122 ± 0.0032
0.9127 ± 0.0033
0.9383 ± 0.0061

Test error
1.1158 ± 0.0097
1.1167 ± 0.0095
1.1365 ± 0.0107

200
H3K27ac
H3K27me3
H3K4me1
H3K4me3
p300
Pol2

read counts

150

100

50

0

0

50

100

150
genomic location (100bp)

200

250

300

Figure 2. ChipSeq data for a small region of chromosome 1. The
H... markers are histones with various chemical modifications,
PolII is RNA polymerase II and p300 is a transcription factor.

9.2. Single ion channel recordings
Patch clamp recordings are a well established experimental
method to measure conformational changes in ion channels, proteins embedded in lipid membranes of cells (such
as the cell surface membrane), which control the flow of
chemicals such as neurotransmitters across the membrane.
These changes are accompanied by changes in electrical
potential which can be measured. HMMs have been used
to analyse these recordings for many years (Becker et al.,
1994), but have usually ignored the prior knowledge that
the underlying physical system has time reversible dynamics. We incorporate this information using the SHGPHMM, analysing a 1MHz recording from the state-of-theart method of Rosenstein et al. (2013) of a single alamethicin channel. We subsample this time series by a factor
of 100 to obtain a T = 10, 000, 10KHz recording, which

Train log likelihood
−1.0488 ± 0.0009
−1.0494 ± 0.0009
−1.0727 ± 0.0041

Test log likelihood
−3.2422 ± 0.0023
−3.2478 ± 0.0022
−3.3047 ± 0.0027

we log transform and normalise. A small segment of the
recording, along with the fitted SHGP-HMM is shown in
Figure 6. Grey regions represent aritificial missingness
used to test the predictive performance of the models, as
shown in Table 3. Here we see that the reversible version of SHGP-HMM outperforms both the non-reversible
version and the iHMM using the beam sampler, showing
the advantage of using the prior knowledge that the transition matrix should be reversible. More specifically, the
reversible model performs slightly better in terms of test error than the non-reversible model, although this difference
is not quite significant based on paired t-test (p = 0.08).
In terms of test log likelihood the reversible version of the
model does perform significantly better however. The use
of HMC or NUTS does not significantly impact the results
in this case. The iHMM using the beam sampler does significantly worse in terms of train and test error, but not significantly better than the non-reversible HGP-HMM.
SHGP-HMM typically uses 5 to 7 states for this dataset. A
typical sample of J is shown in Figure 4 and the observation models for each state are illustrated in Figure 5. Comparing the histogram of currents to the learnt observation
models we see that some of the less common high energy
states are blurred into one, which could possibly be alleviated by more careful selection of priors. An additional
difficulty of ion channel recordings is that the current level
for a particular state tends to drift over time, which is not a
characteristic currently supported by our model.

A reversible infinite HMM using normalised random measures
2
1.5
1
0.5
0
−0.5
−1
−1.5
−2

0

200

400

600

800

1000

1200

1400

1600

1800

2000

Figure 6. Ion channel recording (blue) with predictive distribution mean (red) and one standard deviation (pink region) and missing
regions used for assessing predictive performance (grey). The predictive variance here includes the variance of the state observation
model and uncertainty over the state, calculated by averaging over multiple hidden state samples. As expected the predictive variance in
the missing regions is increased and mostly covers the true signal, suggesting the model is well calibrated.
Table 3. Ion channel results across 10 different random hold out patterns. For SHGP-HMM we used a truncation of K = 15, 1000
iterations and a burnin of 700. 50 inner iterations of HMC or NUTS were run per outer iteration.

Model
Reversible
Non-reversible
Reversible
Non-reversible
iHMM

Alogirthm
HMC
HMC
NUTS
NUTS
Beam sampler

Train error
0.023 ± 0.001
0.027 ± 0.007
0.024 ± 0.004
0.025 ± 0.005
0.038 ± 0.005

Test error
0.030 ± 0.002
0.033 ± 0.007
0.031 ± 0.003
0.032 ± 0.004
0.045 ± 0.004

Train log likelihood
2.204 ± 0.055
2.108 ± 0.084
2.190 ± 0.063
2.142 ± 0.086
2.134 ± 0.070

Test log likelihood
2.034 ± 0.058
1.970 ± 0.078
2.030 ± 0.062
1.989 ± 0.067
2.008 ± 0.058

600
frequency

1
2
3

400
200
0
−1.5

4

−1

−0.5

−1

−0.5

0

0.5

1

1.5

2

2.5

1.5

2

2.5

0.8

1

2

3

4

5

Figure 4. Learnt weight matrix J for the ion channel recording.
The states depicted are those i with Ji. /J.. > 0.01 where . denotes summation. The states are ordered by the mean of their
Gaussian observation model. Transitions between states 1 and 2
with the lowest current levels are the most common, followed by
between states 2 and 4.

density

0.6

5

0.4
0.2
0
−1.5

0
0.5
1
normalised current

Figure 5. Clusters found by the sHGP-HMM for the ion channel
dataset, shown relative to a histogram of levels across the recording. The smaller clusters at higher currents are often merged in
the model.

10. Discussion
Reversibility is a property met in various datasets, especially in ion channel recordings. In this paper, we have
introduced a hierarchical non-parametric model, SHGP,
which gives rise to reversible Markov chains. We have used
the SHGP to construct a Hidden Markov model allowing a
broad range of data types to be modelled. Our experimental
results on two different datasets suggest that accounting for

reversibility intrinsically in SHGP results in gains in empirical performance compared to non-reversible models. An
interesting direction for future work would be to apply the
SHGP to MCMC itself: in this settings, the second eigenvalue of the learnt transition matrix could be use as a measure of the mixing perform of the MCMC chain.

A reversible infinite HMM using normalised random measures

References
Bacallado, S., Favaro, S., and Trippa, L. (2013). Bayesian
nonparametric analysis of reversible markov chains. The
Annals of Statistics, 41(2):870–896.
Beal, M. J., Ghahramani, Z., and Rasmussen, C. E. (2003).
The infinite hidden markov model. Advances in Neural
Information Processing Systems 14, pages 577–584.
Becker, J. D., Honerkamp, J., Hirsch, J., Fröbe, U., Schlatter, E., and Greger, R. (1994). Analysing ion channels
with hidden markov models. Pflügers Archiv, 426(34):328–332.
Diaconis, P. and Coppersmith, D. (1986). Random walks
with reinforcement. Unpublished manuscript.
Diaconis, P. and Freedman, D. (1980). De Finetti’s theorem
for Markov chains. The Annals of Probability, 8(1):115–
130.
Hoffman, M. D. and Gelman, A. (2011). The no-u-turn
sampler: Adaptively setting path lengths in hamiltonian
monte carlo. arXiv preprint arXiv:1111.4246.
Kingman, J. F. C. (1967). Completely random measures.
Pacific J. Math, 21(1):59–78.
Levin, D. A., Peres, Y., and Wilmer, E. L. (2006). Markov
chains and mixing times. American Mathematical Society.
Neal, R. (2011). MCMC Using Hamiltonian Dynamics.
CRC Press.
Neal, R. M. (2003). Slice sampling. The Annals of Statistics, 31(3):705–741.
Park, P. J. (2009). Chip–seq: advantages and challenges
of a maturing technology. Nature Reviews Genetics,
10(10):669–680.
Rada-Iglesias, A., Bajpai, R., Swigut, T., Brugmann, S. A.,
Flynn, R. A., and Wysocka, J. (2010). A unique chromatin signature uncovers early developmental enhancers
in humans. Nature, 470(7333):279–283.
Rosenstein, J. K., Ramakrishnan, S., Roseman, J., and
Shepard, K. (2013). Single ion channel recordings with
CMOS-anchored lipid membranes. Nano letters.
Scott, S. L. (2002). Bayesian methods for hidden markov
models: Recursive computing in the 21st century. Journal of the American Statistical Association, 97:337–351.
Teh, Y. W., Jordan, M. I., Beal, M. J., and Blei, D. M.
(2006). Hierarchical Dirichlet processes. Journal of the
American Statistical Association, 101(476):1566–1581.

Van Gael, J., Saatci, Y., Teh, Y. W., and Ghahramani, Z.
(2008). Beam sampling for the infinite hidden markov
model. In Proceedings of the 25th International Conference on Machine Learning, ICML ’08, pages 1088–
1095, New York, NY, USA. ACM.

