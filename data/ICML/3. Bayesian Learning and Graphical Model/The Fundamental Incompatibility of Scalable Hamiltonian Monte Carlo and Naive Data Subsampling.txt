The Fundamental Incompatibility of
Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

Michael Betancourt
Department of Statistics, University of Warwick, Coventry, UK CV4 7AL

Abstract
Leveraging the coherent exploration of Hamiltonian flow, Hamiltonian Monte Carlo produces
computationally efficient Monte Carlo estimators, even with respect to complex and highdimensional target distributions. When confronted with data-intensive applications, however, the algorithm may be too expensive to implement, leaving us to consider the utility of
approximations such as data subsampling. In
this paper I demonstrate how data subsampling
fundamentally compromises the scalability of
Hamiltonian Monte Carlo.

With the preponderance of applications featuring enormous
data sets, methods of inference requiring only subsamples
of data are becoming more and more appealing. Subsampled Markov Chain Monte Carlo algorithms, (Neiswanger
et al., 2013; Welling & Teh, 2011), are particularly desired
for their potential applicability to most statistical models.
Unfortunately, careful analysis of these algorithms reveals
unavoidable biases unless the data are tall, or highly redundant (Bardenet et al., 2014; Teh et al., 2014; Vollmer
et al., 2015). Because redundancy can be defined only relative to a given model, the utility of these subsampled algorithms is then a consequence of not only the desired accuracy and also the particular model and data under consideration, severely restricting practicality.
Recently (Chen et al., 2014) considered subsampling
within Hamiltonian Monte Carlo (Duane et al., 1987; Neal,
2011; Betancourt et al., 2014b) and demonstrated that the
biases induced by naive subsampling lead to unacceptably
large biases. Ultimately the authors rectified this bias by
sacrificing the coherent exploration of Hamiltonian flow
for a diffusive correction, fundamentally compromising the
scalability of the algorithm with respect to the complexity
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

BETANALPHA @ GMAIL . COM

of the target distribution. An algorithm scalable with respect to both the size of the data and the complexity of the
target distribution would have to maintain the coherent exploration of Hamiltonian flow while subsampling and, unfortunately, these objectives are mutually exclusive in general.
In this paper I review the elements of Hamiltonian Monte
Carlo critical to its robust and scalable performance in practice and demonstrate how different subsampling strategies
all compromise those properties and consequently induce
poor performance.

1. Hamiltonian Monte Carlo in Theory
Hamiltonian Monte Carlo utilizes deterministic, measurepreserving maps to generate efficient Markov transitions
(Betancourt et al., 2014b). Formally, we begin by complementing a target distribution,
Ï€ âˆ exp[âˆ’V (q)] dn q,
with a conditional distribution over auxiliary momenta parameters,
Ï€q âˆ exp[âˆ’T (p, q)] dn p.
Together these define a joint distribution,
$H âˆ exp[âˆ’ (T (q, p) + V (q))] dn q dn p
âˆ exp[âˆ’H(q, p)] dn q dn p,
and a Hamiltonian system corresponding to the Hamiltonian, H(q, p). We refer to T (q, p) and V (q) as the kinetic
energy and potential energy, respectively.
The Hamiltonian immediately defines a Hamiltonian vector field,
~ = âˆ‚H âˆ‚ âˆ’ âˆ‚H âˆ‚ ,
H
âˆ‚p âˆ‚q
âˆ‚q âˆ‚p
and an application of the exponential map yields a Hamilto~
Ï„H
nian flow on the joint space, Ï†H
(Lee, 2013), which
Ï„ =e
exactly preserves the joint distribution under a pullback,

Ï†H
t âˆ— Ï€H = Ï€H .

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

Consequently, we can compose a Markov chain by sampling the auxiliary momenta,
q â†’ (q, p), p âˆ¼ Ï€q ,

(q, p) â†’ Ï†H
t (q, p)
and then projecting back down to the target space,
(q, p) â†’ q.
By construction, the trajectories generated by the Hamiltonian flow explore the level sets of the Hamiltonian function.
Because these level sets can also span large volumes of the
joint space, sufficiently-long trajectories can yield transitions far away from the initial state of the Markov chain,
drastically reducing autocorrelations and producing computationally efficient Monte Carlo estimators.
When the kinetic energy does not depend on position we
say that the Hamiltonian is separable, H(q, p) = T (p) +
V (q), and the Hamiltonian vector field decouples into a ki~,
netic vector field, T~ and potential vector field, V
~ = âˆ‚H âˆ‚ âˆ’ âˆ‚H âˆ‚
H
âˆ‚p âˆ‚q
âˆ‚q âˆ‚p
âˆ‚T âˆ‚
âˆ‚V âˆ‚
=
âˆ’
âˆ‚p âˆ‚q
âˆ‚q âˆ‚p
~
~ .
â‰¡ T + V
In this paper I consider only separable Hamiltonians, although the conclusions also carry over to the non-seperable
Hamiltonians, for example those arising in Riemannian
Hamiltonian Monte Carlo (Girolami & Calderhead, 2011).

2. Hamiltonian Monte Carlo in Practice
The biggest challenge of implementing Hamiltonian Monte
Carlo is that the exact Hamiltonian flow is rarely calculable in practice and we must instead resort to approximate
integration. Symplectic integrators, which yield numerical
trajectories that closely track the true trajectories, are of
particular importance to any high-performance implementation.
An especially transparent strategy for constructing symplectic integrators is to split the Hamiltonian into terms
with soluble flows which can then be composed together
(Leimkuhler & Reich, 2004; Hairer et al., 2006). For example, consider the symmetric Strang splitting,
~

~

Ï†V2 â—¦ Ï†T â—¦ Ï†V2


applying the Hamiltonian flow,



symmetric composition yields



~

Ï†V2 â—¦ Ï†T â—¦ Ï†V2 = e 2 V â—¦ eT â—¦ e 2 V ,
where  is a small interval of time known as the step size.
Appealing to the Baker-Campbell-Hausdorff formula, this

~

~



~

= e 2 V â—¦ e T â—¦ e 2 V



 ~
2 h ~ ~ i
~
V
~
T,V
+ O 3
= e 2 â—¦ exp T + V +
2
4

i
2 h
~


~
~ +
= exp
T~ , V
V + T~ + V
2
2
4


1 ~ ~ ~
2 h ~ ~ i
+
T,V
V , T + V +
2 2
2
4

3
+O 

i
i
i
2 h
2 h
2 h
~ +  T~ , V
~ + V
~ , T~ +  V
~ ,V
~
= exp H
4
4
8

3
+O 

~
= eH + O 3 .
Composing this symmetric composition with itself L =
Ï„ / times results in a symplectic integrator accurate to
second-order in the step size for any finite integration time,
Ï„,

L
e
V
T
V
Ï†H
,Ï„ â‰¡ Ï† 2 â—¦ Ï† â—¦ Ï† 2

 L
~
= eH + O 3

~
= e(L)H + (L) O 2

~
= e Ï„ H + Ï„ O 2

~
= e Ï„ H + O 2 .
Remarkably, the resulting numerical trajectories are confined to the level sets of a modified Hamiltonian given by an
O 2 perturbation of the exact Hamiltonian (Hairer et al.,
2006; Betancourt et al., 2014a).
Although such symplectic integrators are highly accurate,
they still introduce an error into the trajectories that can
bias the Markov chain and any resulting Monte Carlo estimators. In practice this error is typically compensated
with the application of a Metropolis correction, accepting a
point along the numerical trajectory only with probability



e
a(p, q) = min 1, exp H(q, p) âˆ’ H â—¦ Ï†H
.
,Ï„ (q, p)
A critical reason for the scalable performance of such an
implementation of Hamiltonian Monte Carlo is that the error in a symplectic integrator scales with the step size, .
Consequently a small bias or a large acceptance probability can be maintained by reducing the step size, regardless
of the complexity or dimension of the target distribution
(Betancourt et al., 2014a). If the symplectic integrator is
compromised, however, then this scalability and generality
is lost.

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

3. Hamiltonian Monte Carlo With
Subsampling
A common criticism of Hamiltonian Monte Carlo is that in
data-intensive applications the evaluation of potential vector field,
~ = âˆ’ âˆ‚V âˆ‚ ,
V
âˆ‚q âˆ‚p
and hence the simulation of numerical trajectories, can become infeasible given the expense of the gradient calculations. This expense has fueled a variety of modifications
of the algorithm aimed at reducing the cost of the potential
energy, often by any means necessary.
An increasingly popular strategy targets Bayesian applications where the data are independently and identically distributed. In this case the posterior can be manipulated into
a product of contributions from each subset of data,
Ï€(Î¸|y) âˆ Ï€(Î¸)

J
Y

Ï€(yj |Î¸) ,

j=1

and the potential energy likewise decomposes into a sum,
V (q) =

J
X

Vj (q)

j=1

=âˆ’

J 
X
1
j=1

J


log Ï€(Î¸) + log Ï€(yj |Î¸) ,

where each Vj depends on only a single subset. This decomposition suggests algorithms which consider not the
entirety of the data and the full potential energy, V , but
rather only a few subsets at a time.
Using only part of the data to generate a trajectory, however, compromises the structure-preserving properties of
the symplectic integrator and hence the scalability of its
accuracy. Consequently the performance of any such subsampling method depends critically on the details of the implementation and the structure of the data itself. Here I consider the performance of two immediate implementations,
one based on subsampling the data in between Hamiltonian
trajectories and one based on subsampling the data within
a single trajectory. As expected, the performance of both
methods leaves much to be desired.
3.1. Subsampling Data In Between Trajectories
Given any subset of the data, we can approximate the potential energy as V â‰ˆ J Vj and then generate trajectories
corresponding to the flow of the approximate Hamiltonian,
Hj = T +J Vj . In order to avoid parsing the entirety of the
data, the Metropolis correction at the end of each trajectory
can be neglected and the corresponding samples left biased.

Unlike the numerical trajectories from the full Hamiltonian, these subsampled trajectories are biased away from
the exact trajectories regardless of the chosen step size. In
particular, the bias of each step,


~

~



~

~

e 2 I Vj â—¦ eT â—¦ e 2 I Vj = eHj + O 3



âˆ’
âˆ’
â†’

~
= eHâˆ’âˆ†V j + O 3 ,

where

âˆ’âˆ’â†’
âˆ†Vj = âˆ’



âˆ‚V
âˆ‚Vj
âˆ’J
âˆ‚q
âˆ‚q



âˆ‚
,
âˆ‚p

(1)

persists over the entire trajectory,


e

 ~
2 J Vj

â—¦e

~
T

â—¦e

 ~
2 J Vj

L

=e


âˆ’
â†’ 
~ âˆ’
Ï„ Hâˆ’
âˆ†V j


+ O 2 .

As the dimension of the target distribution grows, the subsampled gradient, J âˆ‚Vj /âˆ‚q, drifts away from the true gradient, âˆ‚V /âˆ‚q, unless the data become increasingly redundant. Consequently the resulting trajectory introduces an
irreducible bias into the algorithm, similar in nature to the
asymptotic bias seen in subsampled Langevin Monte Carlo
(Teh et al., 2014; Vollmer et al., 2015), which then induces either a vanishing Metropolis acceptance probability
or highly-biased expectations if the Metropolis correction
is neglected (Figure 1).
Unfortunately, the only way to decrease the dependency on
redundant data is to increase the size of each subsample,
which immediately undermines any computational benefits.
Consider, for example, a simple application where we target a one-dimensional posterior distribution,
Ï€(Âµ|y) âˆ Ï€(y|Âµ) Ï€(Âµ) ,

(2)

with the likelihood
Ï€(y|Âµ) =

N
Y

N yn |Âµ, Ïƒ 2



n=1

and prior

Ï€(Âµ) = N Âµ|m, s2 .
Separating the data into J = N/B batches of size B and
decomposing the prior into J individual terms then gives
B Ïƒ 2 + N s2
Vj = const +
N Ïƒ 2 s2
 P
ï£«
jB
1
Ã— ï£­Âµ âˆ’

B


ï£¶2
xn N s2 + mÏƒ 2
ï£¸ .
Ïƒ 2 + N s2

n=(jâˆ’1)B+1

Here I take Ïƒ = 2, m = 0, s = 1, and generate N = 500
data points assuming Âµ = 1.

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

Stochastic

Stochastic
Exact

(a)

Exact

(b)

Figure 1. The bias induced by subsampling data in Hamiltonian Monte Carlo depends on how precisely the gradients of the subsampled
potential energies integrate to the gradient of the true potential energy. (a) When the subsampled gradient is close to the true gradient,
the stochastic trajectory will follow the true trajectory and the bias will be small. (b) Conversely, if the subsampled gradient is not close
to the true potential energy then the stochastic trajectory will drift away from the true trajectory and induce a bias. Subsampling between
trajectories requires that each subsampled gradient approximate the true gradient, while subsampling within a single trajectory requires
only that the average of the subsampled gradients approximates the true gradient. As the dimension of the target distribution grows,
however, an accurate approximation in either case becomes increasingly more difficult unless the data become correspondingly more
redundant relative to the complexity of the target distribution.

When the full data are used, numerical trajectories generated by the second-order symplectic integrator constructed
above closely follow the true trajectories (Figure 2a). Approximating the potential with a subsample of the data introduces the aforementioned bias, which shifts the stochastic trajectory away from the exact trajectory despite negligible error from the symplectic integrator itself (Figure
2b). Only when the size of each subsample approaches the
full data set, and the computational benefit of subsampling
fades, does the stochastic trajectory provide a reasonable
approximation to the exact trajectory (Figure 2c)
As noted above, geometric considerations suggest that this
bias should grow with the dimensionality of the target distribution. To see this, consider running subsampled Hamiltonian Monte Carlo on the multivariate generalization of
(2),
D
Y
Ï€(Âµd |yd ) ,
(3)
d=1

where the true Âµd are sampled from Âµd âˆ¼ N (0, 1) and trajectories are generated using a subsampled integrator with
step size, , a random integration time Ï„ âˆ¼ U (0, 2Ï€), and
no Metropolis correction. As a surrogate for the accuracy
of the resulting samples I will use the average Metropolis
acceptance probability of each new state using the full data.
When the full data are used in this model, the step size of
the symplectic integrator can be tuned to maintain constant
accuracy as the dimensionality of the target distribution, D,
increases. The bias induced by subsampling between trajectories, however, is invariant to the step size of the integrator and rapidly increases with the dimension of the target distribution. Here the data were partitioned into J = 25

batches of B = 20 data, the subsample used for each trajectory is randomly selected from the first five batches, and
the step size of the subsampled trajectory is reduced by
N/(J Â· B) = 5 to equalize the computational cost with
full data trajectories (Figure 3).
3.2. Subsampling Data within a Single Trajectory
Given that using a single subsample for an entire trajectory introduces an irreducible bias, we might next consider
subsampling at each step within a single trajectory, hoping that the bias from each subsample cancels in expectation. Ignoring any Metropolis correction, this is exactly
the naive stochastic gradient Hamiltonian Monte Carlo of
(Chen et al., 2014).
To understand the accuracy of this strategy consider building up such a stochastic trajectory one step at a time. Given
the first two randomly-selected subsamples, Vi and then Vj ,
the first two steps of the resulting integrator are given by
âˆ’
âˆ’
â†’
âˆ’
âˆ’
â†’

~
~
Hi
Hâˆ’
âˆ†V j
j
Ï†H
â—¦ eHâˆ’âˆ†V i + O 3
 â—¦ Ï† = e

 âˆ’â†’
âˆ’âˆ’â†’ 
~ âˆ’ âˆ’
= exp 2H
âˆ†V i + âˆ†V j

2 h ~ âˆ’âˆ’â†’ ~ âˆ’âˆ’â†’ i
+
H âˆ’ âˆ†V j , H âˆ’ âˆ†V i
2

+ O 3

âˆ’âˆ’â†’
âˆ’âˆ’â†’ 
Hi
j
~
Ï†H
 â—¦ Ï† = exp 2H âˆ’  âˆ†V i + âˆ†V j

2  h ~ ~ i h ~ ~ i
+
âˆ’ H, V\i âˆ’ V\j , H
2

+ O 3 ,

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

1

Exact Level Set
Modified Level Set

q

Average Acceptance Probability
Using Full Data

Full Data (J = 1, B = 500)

0.8

Full Data

0.6
0.4
0.2
Subsampled Between
Subsampled Within

0
1

10

100

1000

Dimension

p

(a)

Small Subset (J = 50, B = 10)
Exact Level Set
Modified Level Set
Exact Stochastic Level Set
Modified Stochastic Level Set

q

Figure 3. When the full data are used, high accuracy of Hamiltonian Monte Carlo samples, here represented by the average
Metropolis acceptance probability using the full data, can be
maintained even as the dimensional of the target distribution
grows. The biases induced when the data are subsampled, however, cannot be controlled and quickly devastate the accuracy of
the algorithm. Here the step size of the subsampled algorithms
has been decreased relative to the full data algorithm in order to
equalize the computational cost â€“ even in this simple example, a
proper implementation of Hamiltonian Monte Carlo can achieve
a given accuracy much more efficiently than subsampling.

p

(b)

âˆ’âˆ’â†’
where we have used the fact that the vector fields {âˆ†V j }
commute with each other. Similarly, the first three steps are
given by

Large Subset (J = 2, B = 250)
Exact Level Set
Modified Level Set
Exact Stochastic Level Set
Modified Stochastic Level Set

q

p

(c)
Figure 2. Even for the simple posterior (2), subsampling data in
between trajectories introduces significant pathologies. (a) When
the full data are used, numerical trajectories (dashed line) closely
track the exact trajectories (solid line). Subsampling of the data
introduces a bias in both the exact trajectories and corresponding
numerical trajectories. (b) If the size of each subsample is small
then this bias is large. (c) Only when the size of the subsamples
approaches the size of the full data, and any computational benefits from subsampling wane, do the stochastic trajectories provide
a reasonable emulation of the true trajectories.

Hj
Hi
k
Ï†H
 â—¦ Ï† â—¦ Ï†

 âˆ’â†’
âˆ’âˆ’â†’
âˆ’âˆ’â†’ 
~ âˆ’ âˆ’
= exp 3H
âˆ†V i + âˆ†V j + âˆ†V k
2  h ~ âˆ’âˆ’â†’ i hâˆ’âˆ’â†’ ~ i
+
âˆ’ H, âˆ†V i âˆ’ âˆ†V j , H
2

2 h
âˆ’âˆ’â†’
âˆ’âˆ’â†’
âˆ’âˆ’â†’ i

~
~
+
H âˆ’ âˆ†V k , 2H âˆ’ âˆ†V i âˆ’ âˆ†V j
2

+ O 3

 âˆ’â†’
âˆ’âˆ’â†’
âˆ’âˆ’â†’ 
~ âˆ’ âˆ’
= exp 3H
âˆ†V i + âˆ†V j + âˆ†V k
h âˆ’âˆ’â†’ i h âˆ’âˆ’â†’ i

~ âˆ†V i âˆ’ H,
~ âˆ†V k
âˆ’2 H,
+ O 3 ,

and, letting jl denote the subsample chosen at the l-th step,

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

the composition over an entire trajectory becomes
Hjl

â—¦L
l=1 Ï†

L

X âˆ’âˆ’â†’
~ âˆ’ (L) 1
âˆ†V jl
= exp (L) H
L
l=1
h âˆ’âˆ’â†’ i h âˆ’âˆ’â†’ i
~ âˆ†V j âˆ’ H,
~ âˆ†V j
+ (L)  H,
1
l

2
+ (L) O 
L

1 X âˆ’âˆ’â†’
âˆ†V jl
L
l=1
h âˆ’âˆ’â†’ i h âˆ’âˆ’â†’ i

~ âˆ†V j âˆ’ H,
~ âˆ†V j
+Ï„  H,
+ O 2
1
L



~ + Ï„ B 1 + Ï„ B 2 + O 2 ,
= exp Ï„ H

~ âˆ’Ï„
= exp Ï„ H

where

L

B1 = âˆ’

1 X âˆ’âˆ’â†’
âˆ†V jl
L

seems rather at odd with the original stochastic subsampling motivation.
Indeed, this symmetric composition is not stochastic at all
and actually corresponds to a rather elaborate symplectic
integrator where the potential energy from each subsample
generates its own flow, equivalent to the integrator in Split
Hamiltonian Monte Carlo (Shahbaba et al., 2014) with the
larger step size J. Removing intermediate steps from
this symmetric, stochastic trajectory (Figure 4a) reveals the
level set of the corresponding modified Hamiltonian (Figure 4b). Because this symmetric composition integrates the
full Hamiltonian system, the error is once again controllable and vanishes as the step size is decreased (Figure 4c).
Limiting the number of subsamples, however, leaves the
irreducible bias in the trajectories that cannot be controlled
by the tuning the step size (Figures 3, 5). Once more we are
left dependent on the redundancy of the data for any hope
of improved performance with subsampling.

l=1

and

h âˆ’âˆ’â†’ i h âˆ’âˆ’â†’ i
~ âˆ†V j âˆ’ H,
~ âˆ†V j
B2 =  H,
.
1
L

Once again, subsampling the data introduces bias into the
numerical trajectories.
Although the second source of bias, B2 , is immediately
rectified by appending the stochastic trajectory with an update from the initial subsample such that jL = j1 , the first
source of bias, B1 , is not so easily remedied. Expanding,
L

L

l=1

l=1


1 X âˆ’âˆ’â†’
1 X ~
~j
âˆ†V jl =
V âˆ’JV
l
L
L
~ âˆ’
=V

L
J X~
Vj
L n=1 l
L

=âˆ’

J X âˆ‚Vj
âˆ‚V
âˆ’
âˆ‚q
L
âˆ‚q
l=1

!

âˆ‚
,
âˆ‚p

we see that B1 vanishes only when the average gradient
of the selected subsamples yields the gradient of the full
potential. Averaging over subsamples may reduce the bias
compared to using a single subsample over the entire trajectory (1), but the bias still scales poorly with the dimensionality of the target distribution (Figure 1).
In order to ensure that the bias vanishes identically and independent of the redundancy of the data, we have to use
each subsample the same number of times within a single
trajectory. In particular, both biases vanish if we use each
subsample twice in a symmetric composition of the form


Hl
HL+1âˆ’l
â—¦L
â—¦ â—¦L
.
l=1 Ï†
l=1 Ï†
Because this composition requires using all of the subsamples it does not provide any computational savings and it

4. Conclusion
The efficacy of Markov Chain Monte Carlo for complex,
high-dimensional target distributions depends on the ability
of the sampler to explore the intricate and often meandering neighborhoods on which the probability is distributed.
Symplectic integrators admit a structure-preserving implementation of Hamiltonian Monte Carlo that is amazingly
robust to this complexity and capable of efficiently exploring the most complex target distributions. Subsampled
data, however, does not in general have enough information to enable such efficient exploration. This lack of information manifests as an irreducible bias that devastates the
scalable performance of Hamiltonian Monte Carlo.
Consequently, without having access to the full data there
is no immediate way of engineering a well-behaved implementation of Hamiltonian Monte Carlo applicable to
most statistical models. As with so many other subsampling algorithms, the adequacy of a subsampled Hamiltonian Monte Carlo implementation is at the mercy of the redundancy of the data relative to the complexity of the target
model, and not in the control of the user.
Unfortunately many of the problems at the frontiers of applied statistics are in the wide data regime, where data are
sparse relative to model complexity. Here subsampling
methods have little hope of success; we must focus our efforts not on modifying Hamiltonian Monte Carlo but rather
on improving its implementation with, for example, better
memory management and efficiently parallelized gradient
calculations.

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

Îµ = 0.05
Exact Level Set
Numerical Trajectory

Îµ = 0.05
Exact Level Set
Subsampled Trajectory
q

p

q

(a)

Îµ = 0.05
Exact Level Set
Modified Level Set
Numerical Trajectory

p
(a)
q

Îµ = 0.0005
p

Exact Level Set
Subsampled Trajectory

(b)

Îµ = 0.002
Exact Level Set
Numerical Trajectory

q

q

p

p

(c)
Figure 4. The symmetric composition of flows from each subsamples of the data eliminates all bias in the stochastic trajectory because it implicitly reconstructs a symplectic integrator. Refining
(a) all intermediate steps in a stochastic trajectory (b) to only those
occurring after a symmetric sweep of the subsamples reveals the
level set of the modified Hamiltonian corresponding to the implicit symplectic integrator. Because of the vanishing bias, (c) the
error in the stochastic trajectory can be controlled by taking the
step size to zero.

(b)
Figure 5. (a) Utilizing only a few subsamples within a trajectory
yields numerical trajectories biased away from the exact trajectories. (b) Unlike the error introduced by a full symplectic integrator, this bias is irreducible and cannot be controlled by tuning the
step size. The performance of such an algorithm is limited by the
size of the bias which itself depends on the redundancy of the data
relative to the target model.

The Fundamental Incompatibility of Scalable Hamiltonian Monte Carlo and Naive Data Subsampling

Acknowledgements
It is my pleasure to thank Simon Byrne, Mark Girolami,
Matt Hoffman, Matt Johnson, and Sam Livingstone for
thoughtful discussion and helpful comments, as well as
three anonymous reviewers for constructive assessments.
I am supported under EPSRC grant EP/J016934/1.

References
Bardenet, ReÌmi, Doucet, Arnaud, and Holmes, Chris. An
adaptive subsampling approach for MCMC inference in
large datasets. In Proceedings of The 31st International
Conference on Machine Learning, pp. 405â€“413, 2014.
Betancourt, Michael, Byrne, Simon, and Girolami, Mark.
Optimizing the integrator step size for hamiltonian
monte carlo. ArXiv e-prints, 1410.5110, 11 2014a.
Betancourt, Michael, Byrne, Simon, Livingstone, Samuel,
and Girolami, Mark. The geometric foundations of
Hamiltonian Monte Carlo. ArXiv e-prints, 1410.5110,
10 2014b.
Chen, Tianqi, Fox, Emily B, and Guestrin, Carlos. Stochastic gradient Hamiltonian Monte Carlo. Proceedings of
The 31st International Conference on Machine Learning, pp. 1683â€“1691, 2014.
Duane, Simon, Kennedy, A.D., Pendleton, Brian J., and
Roweth, Duncan. Hybrid Monte Carlo. Physics Letters
B, 195(2):216 â€“ 222, 1987.
Girolami, Mark and Calderhead, Ben. Riemann Manifold
Langevin and Hamiltonian Monte Carlo methods. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 73(2):123â€“214, 2011.
Hairer, E., Lubich, C., and Wanner, G. Geometric Numerical Integration: Structure-Preserving Algorithms for
Ordinary Differential Equations. Springer, New York,
2006.
Lee, John M. Introduction to Smooth Manifolds. Springer,
2013.
Leimkuhler, B. and Reich, S. Simulating Hamiltonian Dynamics. Cambridge University Press, New York, 2004.
Neal, R.M. MCMC using Hamiltonian dynamics. In
Brooks, Steve, Gelman, Andrew, Jones, Galin L., and
Meng, Xiao-Li (eds.), Handbook of Markov Chain
Monte Carlo. CRC Press, New York, 2011.
Neiswanger, Willie, Wang, Chong, and Xing, Eric. Asymptotically exact, embarrassingly parallel MCMC. arXiv
e-prints, 1311.4780, 2013.

Shahbaba, Babak, Lan, Shiwei, Johnson, Wesley O, and
Neal, Radford M. Split Hamiltonian Monte Carlo.
Statistics and Computing, 24(3):339â€“349, 2014.
Teh, Yee Whye, ThieÌry, Alexandre, and Vollmer, Sebastian. Consistency and fluctuations for stochastic gradient Langevin dynamics. ArXiv e-prints, 1409.0578, 09
2014.
Vollmer, Sebastian J., Zygalakis, Konstantinos C., ,
and Teh, Yee Whye. (non-)asymptotic properties of
stochastic gradient Langevin dynamics. ArXiv e-prints,
1501.00438, 01 2015.
Welling, Max and Teh, Yee W. Bayesian learning via
stochastic gradient Langevin dynamics. In Proceedings
of the 28th International Conference on Machine Learning (ICML-11), pp. 681â€“688, 2011.

