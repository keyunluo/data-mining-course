Linear and Parallel Learning of Markov Random Fields

Yariv Dror Mizrahi1
Misha Denil2
Nando de Freitas1,2,3
1
University of British Columbia, Canada
2
University of Oxford, United Kingdom
3
Canadian Institute for Advanced Research, CIFAR NCAP Program

Abstract
We introduce a new embarrassingly parallel parameter learning algorithm for Markov random
fields with untied parameters which is efficient
for a large class of practical models. Our algorithm parallelizes naturally over cliques and, for
graphs of bounded degree, its complexity is linear in the number of cliques. Unlike its competitors, our algorithm is fully parallel and for loglinear models it is also data efficient, requiring
only the local sufficient statistics of the data to
estimate parameters.

1. Introduction
Markov Random Fields (MRFs), also known as undirected probabilistic graphical models, are ubiquitous structured probability models that have significantly impacted
a large number of fields, including computer vision (Li,
2001; Szeliski et al., 2008), computational photography
and graphics (Agarwala et al., 2004), computational neuroscience (Ackley et al., 1985), bio-informatics (Yanover
et al., 2007), sensor networks (Liu & Ihler, 2012), social
networks (Strauss & Ikeda, 1990), Markov logic (Richardson & Domingos, 2006), natural language processing (Lafferty et al., 2001; Sutton & McCallum, 2012) and statistical physics (Kindermann & Snell, 1980). As pointed out
in Wainwright & Jordan (2008) there are also many applications in statistics, constraint satisfaction and combinatorial optimization, error-correcting codes and epidemiology.
Not surprisingly, many comprehensive treatments of this
important topic have appeared in the last four decades (Kindermann & Snell, 1980; Lauritzen, 1996; Bremaud, 2001;
Koller & Friedman, 2009; Murphy, 2012).
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

YARIV @ MATH . UBC . CA
MISHA . DENIL @ CS . OX . AC . UK
NANDO @ CS . OX . AC . UK

Despite the great success and impact of these models, fitting them to data remains a formidable challenge. Although
the log-likelihood is typically convex in the parameters, the
gradient of these models is intractable.
In many cases, maximum likelihood in these models is data
efficient in the sense that the data term in the gradient can
be easily precomputed, making its evaluation trivial during optimization. The main difficulty with maximum likelihood is that it is not model efficient since evaluating the
gradient involves computing expectations over the model
distribution. This requires evaluating a sum with exponentially many terms, which is intractable for even moderately
sized models. The intractability of exact maximum likelihood has prompted the introduction of many approximate
methods of parameter estimation (Besag, 1975; Hinton,
2000; Hyvärinen, 2005; Marlin et al., 2010; Varin et al.,
2011; Marlin & de Freitas, 2011; Swersky et al., 2011).
An important class of approximate method for this problem
are stochastic approximation methods, which approximate
the model term by drawing samples from the model distribution, typically via MCMC. This simulation is costly
and often many samples are required for accurate estimation. Moreover, in settings where the parameters or data
must be distributed across many machines such simulation
poses additional difficulties.
Another approach is to approximate the maximum likelihood objective with a factored alternative. The leading
method in this area is pseudo-likelihood. In this approach
the joint distribution over all variables in the MRF is replaced by a product of conditional distributions for each
variable. Replacing the joint distribution with a product
of conditionals eliminates the model term from the gradient of the pseudo-likelihood objective, which circumvents
the model inefficiency of maximum likelihood estimation.
However, pseudo-likelihood is not data efficient, since the
conditional distributions often depend on the actual data
and the current value of the parameters. We return to this
issue in more detail in Section 2.3.

Linear and Parallel Learning of Markov Random Fields

Applying pseudo likelihood in a distributed setting is also
difficult, because the conditional distributions share parameters. Several researchers have addressed this issue by
proposing to approximate pseudo-likelihood by disjointly
optimizing each conditional and combining the parameters using some form of averaging (Ravikumar et al., 2010;
Wiesel & Hero III, 2012; Liu & Ihler, 2012).
In this paper we introduce a new approach to parameter estimation in MRFs with untied parameters, which avoids the
model inefficiency of maximum likelihood for an important
class of models while preserving its data efficiency. Moreover, our algorithm is embarrassingly parallel and can be
implemented in a distributed setting without modification.
Our algorithm replaces the joint maximum likelihood problem with a collection of much smaller auxiliary maximum
likelihood problems which can be solved independently.
We prove that if the auxiliary problems satisfy certain conditions, the relevant parameters in the auxiliary problems
converge to the values of the true parameters in the joint
model. Our experiments show that good performance is
achieved in this case and that good performance is still
achieved when these conditions are not satisfied. Violating
the conditions for convergence sacrifices theoretical guarantees in exchange for even further computational savings
while maintaining good empirical performance.
Under a strong assumption, we prove that our algorithm is
exactly equal to maximum likelihood on the full joint distribution. While not directly applicable, this result provides
additional insight into why our approach is effective.
A similar method was recently, and independently, introduced in the context of Gaussian graphical models by
Meng et al. (2013). In that paper, the authors consider local neighbourhoods of nodes, whereas we consider neighbourhoods of cliques, and they rely on a convex relaxation
via the Schur complement to derive their algorithm for inverse covariance estimation. At the time of revising this
paper, the same authors have shown that the convergence
rate to the true parameters with their method is comparable
to centralized maximum likelihood estimation (Meng et al.,
2014).
Although our work and that of Meng et al. arrive at distributed learning via different paths, and while theirs is
restricted to (pair-wise) Gaussian graphical models, both
works show that it is possible to capitalize on graph structures beyond low tree-width to design algorithms that are
both data and model efficient and exhibit good empirical
performance.

2. Model Specification and Objectives
We are interested in estimating the parameter vector θ of a
positive distribution p(x | θ) > 0 that satisfies the Markov
properties of an undirected graph G. That is, a distribution that can be represented as a product of factors, one per
maximal clique,
p(x | θ) =

1 Y
ψc (xc | θ c ),
Z(θ)

(1)

c∈C

where C is the set of maximal cliques of G, ψc (xc | θ c ) ≥
0 is the potential function or factor associated with the
variables inPclique
Q c, and Z(θ) is the partition function:
Z(θ) =
x
c∈C ψc (xc | θ c ). In such models we often use exponential functions to represent the potentials,
ψc (xc | θ c ) = exp(−E(xc | θ c )), where E(xc | θ c ) ∈ R is
called the energy, which we will assume is chosen so that
the parameters are identifiable. The resulting joint distribution can then be written as a Gibbs distribution
p(x | θ) =

X
1
exp(−
E(xc | θ c )).
Z(θ)
c

When the energy is a linear function of the parameters, i.e.
E(xc | θ c ) = −θ Tc φc (xc ) where φc (xc ) is a feature vector derived from the values of the variables xc , we have a
maximum entropy or log-linear model (Wasserman, 2004;
Buchman et al., 2012; Murphy, 2012). The features in these
models are also referred to as local sufficient statistics.
Notation: We use x to refer to the vector of all variables
(nodes). When needed, we increase the precision in our
notation by using S to denote the set of all variables and use
xS for the vector of all variables in the MRF. We restrict the
symbols n and c so that xn refers to the n-th observation
of all the variables in the MRF, and xc refers to the subset
of variables associated with clique c. Finally xmn refers to
the n-th observation of node m.
2.1. Maximum Likelihood
There is (in general) no closed form solution for the maximum likelihood (ML) estimate of the parameters of an
MRF, so gradient-based optimizers are needed.
Consider the fully-observed maximum entropy model
p(x | θ) =

X
1
exp(
θ Tc φc (x))
Z(θ)
c

(2)

where c indexes the maximal cliques. The scaled loglikelihood is given by
`(θ) =

N
1 X
log p(xn | θ)
N n=1

Linear and Parallel Learning of Markov Random Fields

"
#
N
1 X X T
=
θ φ (xn ) − log Z(θ)
N n=1 c c c

clique can be pre-computed before parameter optimization
begins, making this term of the gradient extremely cheap
to evaluate during optimization.

which is a convex function of θ.
The derivative for the parameters of a particular clique, q,
is given by

N 
∂ log Z(θ)
1 X
∂`
φq (xn ) −
=
,
(3)
∂θ q
N n=1
∂θ q
where

 X
∂ log Z(θ)
= E φq (x) | θ =
φq (x)p(x | θ).
∂θ q
x

(4)

Equation (4) is the expectation of the feature φq (x) over
the model distribution. For many models of interest this
quantity is intractable.
The full derivative of the log-likelihood contrasts the model
expectation against the expected value of the feature over
the data,
N


∂`
1 X
φ (xn ) − E φq (x) | θ .
=
∂θ q
N n=1 q

(5)

At the optimum these two terms will be equal and the empirical distribution of the features will match the model predictions.
2.2. Maximum Pseudo-Likelihood
To surmount the intractable problem of computing expectations over the model distribution, pseudo-likelihood considers a simpler factorised objective function,
`P L (θ) =

N
M
1 XX
log p(xmn | x−mn , θ)
N n=1 m=1

(6)

The data term in the ML gradient is contrasted
with

 an expectation over the model distribution, E φq (x) | θ , which
is a sum over exponentially many configurations. For large
models this term is intractable.
We describe this situation by saying that ML estimation is
data efficient, since the terms involving only the data can
be computed efficiently. However, ML is not model efficient, since the model term in the gradient is intractable,
and the difficulty in evaluating it is the primary motivation
for the development of alternative objectives like pseudolikelihood.
Pseudo-likelihood addresses the model inefficiency of
ML by eliminating the model term from the gradient,
which makes pseudo-likelihood model efficient. However,
pseudo-likelihood is not data efficient, since computing the
gradient requires access to the full conditional distributions
p(x̄m
mn | x−mn , θ). Because of this the outer sum over data
examples must be computed for each gradient evaluation.
(Note that for binary models the full conditionals correspond to logistic regressions, so any advances in scaling
logistic regression to massive models and datasets would
be of use here.)
In the following section we introduce a Linear And Parallel
(LAP) algorithm, which uses a particular decomposition of
the graph to avoid the exponential cost in ML, but unlike
pseudo-likelihood LAP is fully parallel and maintains the
data efficiency of ML estimation. LAP is therefore both
model and data efficient.

3. Algorithm Description

where x−mn denotes all the components of the n-th data
vector, except for component m. (For models with sparse
connectivity, we only need to condition on the neighbors of
node m.) In the binary, log-linear case, the gradient of this
objective can be expressed in contrastive form,

The LAP algorithm operates by splitting the joint parameter estimation problem into several independent subproblems which can be solved in parallel. Once the subproblems have been solved, it combines the solutions to
each sub-problem together into a solution to the full problem.



∂`P L
1 X
m
=
p(x̄m
,
mn | x−mn , θ) φq (xn ) − φq (x̄n )
∂θ q
N n,m

For a fixed clique q we define its 1-neighbourhood
[
Aq =
c

where x̄m
n is the data vector x̄n with the m-th bit flipped.
That is, x̄imn = 1 − xmn if i = m and xmn otherwise
(Marlin et al., 2010).
2.3. Model and Data Efficiency
There are two terms in the gradient of
5. The first
PEquation
N
term is an empirical expectation, N1 n=1 φq (xn ), and depends only on the data. The value of this term for each

c∩q6=∅

to contain all of the variables of q itself as well as the variables with at least one neighbour in q.
LAP creates one sub-problem for each maximal clique in
the original problem by defining an auxiliary MRF over the
variables in Aq . Details on how to construct the auxiliary
MRF will be discussed later, for now we assume we have
an auxiliary MRF on Aq and that it contains a clique over

Linear and Parallel Learning of Markov Random Fields

Algorithm 1 LAP
Input: MRF with maximal cliques C
for q ∈ C do
Construct auxiliary MRF over the variables in Aq .
Estimate parameters α̂M L of auxiliary MRF.
L
Set θ̂ q ← α̂M
.
q
end for

(a)

(b)

the variables in q that is parametrized the same way as q in
the original problem.
LAP derives the parameter vector θ q for the full problem
by estimating parameters in the auxiliary MRF on Aq using
maximum likelihood and reading off the parameters for the
clique q directly. The steps of the algorithm are summarized in Algorithm 1.

(c)

In a log-linear model, when estimating the vector of parameters α of the auxiliary MRF by maximum likelihood, the
relevant derivative is
N


1 X
∂`Mq
φq (xAq n ) − E φq (xAq )|α .
=
∂αq
N n=1

This
is data efficient, since the sufficient statistics
Papproach
N
1
φ
(x
Aq n ) can be easily pre-computed. Moren=1 q
N
over, the data vector xn can be stored in a distributed fashion, with the node estimating the auxiliary MRF only needing access to the sub-vector xAq n . In addition, LAP
 is
model efficient since the expectation E φq (xAq )|α can
be easily computed when the number of variables in Aq is
small. To illustrate this point, consider the models shown
in Figure 1. For dense graphs, such as the restricted Boltzmann machine, the exponential cost of enumerating over
all the variables in Aq is prohibitive. However, for other
practical MRFs of interest, including lattices and Chimeras
(Denil & de Freitas, 2011), this cost is acceptable.
3.1. Construction of the Auxiliary MRF
The effectiveness of LAP comes from proper construction of the auxiliary MRF. As already mentioned, the auxiliary MRF must contain the clique q, which must be
parametrized in the same way as in the joint model. This
requirement is clear from the previous section, otherwise
the final step in Algorithm 1 would be invalid.
We will see in the analysis section that it is desirable for the
auxiliary MRF to be as close to the marginal distribution on
xAq as possible. This means we must include all cliques
from the original MRF which are subsets of Aq . Additionally, marginalization may introduce additional cliques not
present in the original joint distribution. It is clear that these
cliques can only involve variables in Aq \q, but determining
their exact structure in general can be difficult.

(d)

(e)

Figure 1. The left column shows several popular MRFs: (a) a restricted Boltzmann machine (RBM), (b) a chain graph, (c) a 2D Ising grid, (d) a Chimera 3 × 3 × 4 lattice, and (e) a 3-D
Ising lattice. The right hand side shows the corresponding 1neighborhoods Aq for cliques of interest (in green). Models (b) to
(e) have small 1-neighborhoods and can learned efficiently with
the LAP algorithm.

We consider three strategies for constructing auxiliary
MRFs, which are distinguished by how they induce clique
structures on Aq \ q. The three strategies are as follows.
Exact: Here we compute the exact structure of the marginal
distribution over Aq from the original problem. We have
chosen our test models to be ones where the marginal structure is readily computed.
Dense: For many classes of model the marginal over Aq

Linear and Parallel Learning of Markov Random Fields
2.2

0.0 2
10

3

10

4

10

5

10

Number of samples

6

10

1.4

0.7

0.0 2
10

3

10

4

10

5

10

6

10

Number of samples

LAP_D
LAP_E
LAP_P
PL

0.5

Estimator variance

0.1

19.7

0.7

LAP_D
LAP_E
LAP_P
PL
ML

Relative error

LAP_D
LAP_E
LAP_P
PL

Estimator variance

Relative error

0.2

0.2

0.0 2
10

3

10

4

10

5

10

Number of samples

6

10

LAP_D
LAP_E
LAP_P
PL
ML

13.2

6.6

0.0 2
10

3

10

4

10

5

10

6

10

Number of samples

Figure 2. Left: Relative error of parameter estimates compared to
maximum likelihood for LAP and pseudo-likelihood on a 4 × 4
Ising grid. Error bars show the standard deviation over several
runs. Right: Variance of the parameter estimates for each algorithm.

Figure 3. Left: Relative error of parameter estimates compared
to maximum likelihood for LAP and pseudo-likelihood on a 4 ×
4 × 4 Ising lattice. Error bars show the standard deviation over
several runs. Right: Variance of the parameter estimates for each
algorithm.

involves a fully parametrized clique over Aq \ q for nearly
every choice of q (for example, this is the case in lattice
models). The dense variant assumes that the marginal always has this structure. Making this choice will sometimes
over-parametrize the marginal, but avoids the requirement
of explicitly computing its structure.

for constructing the auxiliary MRF discussed in the previous section. In each plot, lines labeled PL correspond to
pseudo-likelihood and ML corresponds to maximum likelihood. LAP E, LAP D and LAP P refer respectively to LAP
with the exact, dense and pairwise strategies for constructing the auxiliary MRF.

Pairwise: Both the exact and dense strategies create high
order terms in the auxiliary MRF. While high order terms
do exist in the marginals of discrete MRFs, it is computationally inconvenient to include them, since the add many
parameters to each sub-problem. In the pairwise variant we
use the same graph structure as in dense, but here we introduce only unary and binary potentials over Aq \ q. This
results in a significant computational savings for each subproblem in LAP, but fails to capture the true marginal distribution in many cases (including all of the example problems we consider).

We compare LAP and pseudo-likelihood to maximum likelihood estimation on three different model classes. The first
is a 4 × 4 Ising grids with 4-neighborhoods, and the results
are shown in Figure 2. The second is a 4 × 4 × 4 Ising
lattice with 6-neighborhoods, which is shown in Figure 3.
Finally, we also consider a Chimera 3 × 3 × 3 model, with
results shown in Figure 4.

4. Experiments
In this section we describe some experiments designed to
show that the LAP estimator has good empirical performance. We focus on small models where exact maximum
likelihood is tractable in order to allow performance to be
measured. We chose to focus our experiments on demonstrating accuracy rather than scalability since the scaling
and data efficiency properties of LAP are obvious.
The purpose of the experiments in this section is to show
two things:

The procedure for all models is the same: we choose the
generating parameters uniformly at random from the interval [−1, 1] and draw samples approximately from the
model. We then fit exact maximum likelihood parameters based on these samples, and compare the parameters
obtained by pseudo-likelihood and LAP to the maximum
likelihood estimates. The left plot in each figure shows
the mean relative error of the parameter estimates using the
maximum likelihood estimates as ground truth. Specifically, we measure
err(θ) = kθM L k−1 · kθ − θM L k
for each estimate on each set of samples and average over
several runs.

2. LAP achieves good performance even when the exact
marginal structure is not used.

We also measure the variance of the estimates produced
by each algorithm over several runs. In this case we measure the variance of the estimates of each parameter separately and average these variances over all parameters in
the model. These measurements are shown in the right plot
in each figure. For reference we also show the variance of
the maximum likelihood estimates in these plots.

In all of our experiments we compare pseudo-likelihood
estimation against LAP using the three different strategies

In all of the experiments we see that the performance of
all of the LAP variants is basically indistinguishable from
pseudo-likelihood, except for small numbers of samples.

1. The accuracy of LAP estimates is not worse than its
main competitor, pseudo-likelihood; and

Linear and Parallel Learning of Markov Random Fields

5. Theory
In this section show that matching parameters in the
joint and the marginal distributions is valid, provided the
parametrisations are chosen correctly. We then prove consistency of the LAP algorithm and illustrate its connection
to ML.
Undirected probabilistic graphical models can be specified,
locally, in terms of Markov properties and conditional independence
and, globally, in terms of an energy function
P
E(x
|θ
). The Hammersley-Clifford theorem (Hamc
c
c
mersley & Clifford, 1971) establishes the equivalence of
these two representations.
One important fact that is often omitted is that the energy
function and the partition function are not unique. It is
however possible to obtain uniqueness, for both of these
functions, by imposing normalization with respect to a setting of the random variables of the potential. This gives rise
to the concept of normalized potential (Bremaud, 2001):
Definition 1. A Gibbs potential {E(xc |θ c )}c∈C is said to
be normalized with respect to zero if E(xc |θ c ) = 0 whenever there exists t ∈ c such that xt = 0.
(In this section, we use the term Gibbs potential, or simply
potential, to refer to the energy so as to match the nomenclature of (Bremaud, 2001).) The following theorem plays
a central role in understanding the LAP algorithm. The
proof can be found in (Griffeath, 1976; Bremaud, 2001):
Theorem 2. [Existence and Uniqueness of the normalized potential] There exists one and only one (Gibbs) potential normalized with respect to zero corresponding to a
Gibbs distribution.
5.1. The LAP Argument
Suppose we have a Gibbs distribution p(xS | θ) that factors
according to the clique system C, and let q ∈ C be a clique
of interest. Let the auxiliary MRF
X
1
exp(−
E(xc | αc ))
p(xAq | α) =
Z(α)
c∈Cq

have the same form as the marginal distribution on Aq (with
clique system Cq ) parametrised so that the potentials are
normalized with respect to zero.

7.3

0.5

LAP_D
LAP_E
LAP_P
PL

0.3

Estimator variance

Relative error

Interestingly, LAP P does not perform noticeably worse
than the other LAP variants on any of the problems we
considered here. This is interesting because LAP P approximates the marginal with a pairwise MRF, which is not sufficient to capture the true marginal structure in any of our
examples. LAP P is also the most efficient LAP variant
we tested, since the auxiliary MRFs it uses have the fewest
number of parameters.

0.2

0.0 2
10

4

3

10

10

5

10

6

10

LAP_D
LAP_E
LAP_P
PL
ML

4.9

2.4

0.0 2
10

Number of samples

3

10

4

10

5

10

6

10

Number of samples

Figure 4. Left: Relative error of parameter estimates compared to
ML for LAP and pseudo-likelihood on a Chimera 3×3×3 model.
Error bars show the standard deviation over several runs. Right:
Variance of the parameter estimates for each algorithm.

We can obtain the marginal from the joint in the following
way
X
p(xAq | θ) =
p(xS | θ)
xS\Aq

=

X
X
1
exp(−
E(xc | θ c ))
Z(θ) x
S\Aq

c∈C

X
1
=
exp(−E(xq | θ q ) −
E(xc | θ S\q ))
Z(θ)
c∈Cq \{q}

Proposition 3. If the parametrisations of p(xS | θ) and
p(xAq | α) are chosen to be normalized with respect to
zero, and if the parameters are identifiable with respect to
the potentials, then θ q = αq .
Proof. The terms E(xq | θ q ) and E(xq | αq ) appear as
separate factors in p(xAq | θ) and p(xAq | α) respectively.
By existence and uniqueness of the normalized potentials
(Theorem 2), we have
E(xq | αq ) = E(xq | θ q )
which implies that θ q = αq if the parameters are identifiable.
5.2. Consistency of LAP
Let θ ? be the true vector of parameters taken from the
unknown generating distribution p(xS | θ ? ) parametrized
such that the potentials are normalized with respect to zero.
Suppose we have N samples drawn iid from this distribuML

tion. Let θ̂
be the ML estimate of θ given the data and
let α̂M L the corresponding ML estimate for the auxiliary
MRF with true parameters α? .
Proposition 4. If the true marginal distributions are contained in the class of auxiliary MRFs, we have for all q that
L
α̂M
→ θ ?q as N → ∞.
q
Proof. Let q ∈ C be an arbitrary clique of interest. It is
L
sufficient to show that α̂M
→ θ ?q . By marginalization,
q

Linear and Parallel Learning of Markov Random Fields

we have

X

p(xAq | θ ? ) =

p(xS | θ ? ).

xS\Aq

By the lap argument (Proposition 3), we know that α?q =
θ ?q . Since ML is consistent under smoothness and identifiability assumptions (for example, see Fienberg & Rinaldo
(2012)), we also have α̂M L → α? , so
L
α̂M
→ θ ?q
q

Note that in the above proposition, the class of auxiliary
MRFs can be more general than the class of marginal
MRFs, but must contain the latter. Asymptotically, superfluous terms in the auxiliary MRF vanish to zero.
5.3. Relationship to ML
Here we prove that, under certain (strong) assumptions,
LAP is exactly equal to ML. The main result here will be
that under the required assumptions, estimation by ML and
marginalization commute.
Suppose we have a discrete MRF on xS which factorizes
according to the cliques C, and let q ∈ C be a particular
clique of interest.
We will make use of the following characterization of ML
estimates, which is proved in (Jordan, 2002).
Lemma 5. If a distribution p̂(xS ) satisfies that for each
c∈C

For an arbitrary clique c ∈ C, either c ⊂ S \ q or c ⊂ Aq ,
and we see that p̂(xc ) = p̃(xc ) by further marginalizing one
of the above expressions. This shows that our expression
for p̂(xS ) satisfies the criteria of Lemma 5, and is therefore
an ML estimate for p̃(xS ).
Suppose we have a family of distributions F on xS which
satisfy the Markov properties of the MRF, and suppose that
p̂(xS ) ∈ F where p̂(xS ) is defined as in Proposition 6.
Define the auxiliary family Fq associated with the clique q
as follows.
X
p(xS ) | p(xS ) ∈ F}
Fq = {
xS\Aq

That is, Fq is the family of distributions obtained by
marginalizing the family F over xS\Aq .
Proposition 7. The auxiliary family Fq contains the
marginal empirical distribution p̃(xAq ).
Moreover
p̂(xAq ) = p̃(xAq ) is an ML estimate for p̃(xAq ) in Fq .
Proof. Recall that p̂(xS ) from Proposition 6 is in F by assumption. Thus,
X
p̂(xS ) = p̃(xAq )
xS\Aq

is in Fq by definition. That p̂(xAq ) ∈ Fq is an ML estimate
follows since the log likelihood gradient in Equation 5 is
zero when the model and empirical distributions are equal.

p̂(xc ) = p̃(xc )
then p̂(xS ) is an ML estimate for the empirical distribution
p̃(xS ).

Suppose we can represent the family F as a Gibbs family,
i.e.

This characterization allows us to derive an explicit expression for an ML estimate of p̂(xS ).

F = F(Θ) = {p(xS | θ) | θ ∈ Θ}

Proposition 6. The distribution
p̃(xAq )p̃(xS\q )
p̂(xS ) =
p̃(xAq \q )

Proof. To see this we compute
p̂(xS ) =

xq

X p̃(xAq )p̃(xS\q )
xq

p̃(xAq \q )

p(xS |θ) =

X
1
exp(−
E(xc | θ c )) .
Z(θ)
c∈C

Moreover, suppose we have chosen this parametrisation so
that the potential functions are normalized with respect to
zero.

is an ML estimate for p̃(xS ).

X

for some domain of parameters Θ, where

= p̃(xS\q )

Since F is representable as a Gibbs family then the auxiliary family Fq is also representable as a Gibbs family with
Fq = Fq (Ψ) = {p(xAq | α) | α ∈ Ψ}

and
X
xS\Aq

p̂(xS ) =

X p̃(xAq )p̃(xS\q )
= p̃(xAq )
p̃(xAq \q )
x
S\Aq

for some domain of parameters Ψ. We will again suppose that this parametrisation is chosen so that the potential
functions are normalized with respect to zero.

Linear and Parallel Learning of Markov Random Fields

We have already shown that ML estimates for p̃(xS ) and
p̃(xAq ) exist in the families F and Fq , respectively. Since
we have chosen the parametrisations of these families to be
normalized we also have unique ML parameters θ̂ ∈ Θ
and α̂ ∈ Ψ such that p(xS | θ̂) ∈ F(Θ) is an ML estimate
for p̃(xS ) and p(xAq | α̂) ∈ F(Ψ) is an ML estimate for
p̃(xAq ).
We can now prove the main result of this section.
Theorem 8. Under the assumptions used in this section,
estimating the joint parameters by ML and integrating the
resulting ML distribution gives the same result as integrating the joint family of distributions and performing ML estimation in the marginal family. Concisely,
X
p(xS | θ̂) = p(xAq | α̂)

do not enjoy the same data and model efficiencies as LAP.
Finally, we proved that the proposed estimator is consistent.
This work opens up many directions for future work, including the application of LAP to model selection problems, models with latent variables, and models with tied
parameters. Since LAP is fully parallel, our experiments
focused on the question of statistical efficiency. However,
implementations on distributed computing platforms, such
as Apache Spark/Hadoop, would be very valuable. A further addition to the theory would be the derivation of PAC
bounds to improve our understanding of the sampling complexity of these estimators.

Acknowledgements

xS\Aq

Proof. We have the following sequence of equalities:
(1)

(2)

p(xS | θ̂) = p̂(xS ) =
(3)

=

p̃(xAq )p̃(xS\q )
p̃(xAq \q )

p̂(xAq )p̃(xS\q ) (4) p(xAq | α̂)p̃(xS\q )
=
p̃(xAq \q )
p̃(xAq \q )

The first equality follows from the parametrisation of F,
the second follows from Proposition 6, the third from
Proposition 7 and the fourth follows from the parametrisation of Fq . The theorem is proved by summing both sides
of the equality over xS\Aq .
Applying the LAP argument (Proposition 3) to Theorem 8
we see that θ̂ q = α̂q .
Remark: The assumption that p̂(xS ) ∈ F amounts to assuming that the empirical distribution of the data factors
according to the MRF. This is very unlikely to hold in practice for finite data. However, if the true model structure is
known then this property does hold in the limit of infinite
data.

6. Conclusion
We have presented a distributed learning algorithm for
practical MRFs, where the parameters of each clique can
be estimated in different machines. The algorithm is also
data efficient in log-linear models, since the estimation of
each clique parameter only requires access to local sufficient statistics of the data. Not only are the statistics local
to the 1-neighborhoods of each clique, but they can also be
precomputed.
Our experiments indicate that the LAP estimators behave
similarly to pseudo-likelihood and maximum likelihood for
large sample sizes. However, these alternative estimators

We would like to thank Alexandre Bouchard-Côté, Paul
Fearnhead, Joel Friedman, Eldad Haber, Fred Roosta, Luis
Tenorio and the anonymous reviewers for greatly helping
us to improve this work. We thank NSERC for financial
support.

Linear and Parallel Learning of Markov Random Fields

References
Ackley, D. H., Hinton, G., and Sejnowski, T.. A learning algorithm for Boltzmann machines. Cognitive Science, 9:147–169,
1985.
Agarwala, A., Dontcheva, M., Agrawala, M., Drucker, S., Colburn, A., Curless, B., Salesin, D., and Cohen, M. Interactive digital photomontage. In ACM SIGGRAPH, pp. 294–302,
2004.
Besag, J. Statistical analysis of non-lattice data. Journal of the
Royal Statistical Society. Series D, 24(3):179–195, 1975.
Bremaud, P. Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues. Springer-Verlag, 2001.
Buchman, D., Schmidt, M. W., Mohamed, S., Poole, D., and de
Freitas, N. On sparse, spectral and other parameterizations of
binary probabilistic models. Journal of Machine Learning Research - Proceedings Track, 22:173–181, 2012.

Marlin, B., Swersky, K., Chen, B., and de Freitas, N. Inductive
principles for restricted Boltzmann machine learning. In AIStats, pp. 509–516, 2010.
Meng, Z., Wei, D., Wiesel, A., and Hero III, A. O. Distributed
learning of Gaussian graphical models via marginal likelihoods. In AIStats, pp. 39–47, 2013.
Meng, Z., Wei, D., Wiesel, A., and Hero III, A. O. Marginal likelihoods for distributed parameter estimation of Gaussian graphical models. Technical report, arXiv:1303.4756, 2014.
Murphy, K. P. Machine Learning: A Probabilistic Perspective.
The MIT Press, 2012.
Ravikumar, P., Wainwright, M. J., and Lafferty, J. D. Highdimensional Ising model selection using `1 -regularized logistic
regression. Annals of Statistics, 38(3):1287–1319, 2010.
Richardson, M. and Domingos, P. Markov logic networks. Machine Learning, 62(1-2):107–136, 2006.

Denil, M. and de Freitas, N. Toward the implementation of a
quantum RBM. In NIPS Deep Learning and Unsupervised
Feature Learning Workshop, 2011.

Strauss, D. and Ikeda, M. Pseudolikelihood estimation for social
networks. Journal of the American Statistical Association, 85
(409):204–212, 1990.

Fienberg, S. E. and Rinaldo, A. Maximum likelihood estimation
in log-linear models. The Annals of Statistics, 40(2):996–1023,
2012.

Sutton, C. and McCallum, A. An introduction to conditional random fields. Foundations and Trends in Machine Learning, 4
(4):267–373, 2012.

Griffeath, D. Introduction to random fields. In Denumerable
Markov Chains, volume 40 of Graduate Texts in Mathematics,
pp. 425–458. Springer, 1976.

Swersky, K., Ranzato, M.A., Buchman, D., Marlin, B., and Freitas, N. On autoencoders and score matching for energy based
models. In ICML, pp. 1201–1208, 2011.

Hammersley, J. M. and Clifford, P. Markov fields on finite graphs
and lattices. Unpublished manuscript, 1971.

Szeliski, R., Zabih, R., Scharstein, D., Veksler, O., Kolmogorov,
V., Agarwala, Aseem, Tappen, M., and Rother, C. A comparative study of energy minimization methods for Markov random
fields with smoothness-based priors. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 30(6):1068–1080,
2008.

Hinton, G. Training products of experts by minimizing contrastive
divergence. Neural Computation, 14(8):1771–1800, 2000.
Hyvärinen, A. Estimation of non-normalized statistical models
using score matching. JMLR, 6:695–709, 2005.
Jordan, M.I. An introduction to probabilistic graphical models,
2002.
Kindermann, R. and Snell, J. L. Markov Random Fields and their
Applications. American Mathematical Society, 1980.
Koller, D. and Friedman, N. Probabilistic Graphical Models:
Principles and Techniques. MIT Press, 2009.
Lafferty, J. D., McCallum, A., and Pereira, F. C. N. Conditional
random fields: Probabilistic models for segmenting and labeling sequence data. In ICML, pp. 282–289, 2001.
Lauritzen, S.L. Graphical models. Oxford University Press, USA,
1996.
Li, S. Z. Markov random field modeling in image analysis.
Springer-Verlag, 2001.
Liu, Q. and Ihler, A. Distributed parameter estimation via pseudolikelihood. In ICML, 2012.
Marlin, B. and de Freitas, N. Asymptotic efficiency of deterministic estimators for discrete energy-based models: Ratio matching and pseudolikelihood. In UAI, pp. 497–505, 2011.

Varin, C., Reid, N., and Firth, D. An overview of composite likelihood methods. Statistica Sinica, 21:5–42, 2011.
Wainwright, M. J. and Jordan, M. I. Graphical models, exponential families, and variational inference. Foundations and Trends
in Machine Learning, 1(1-2):1–305, 2008.
Wasserman, L. All of Statistics. Springer, 2004.
Wiesel, A. and Hero III, A.O. Distributed covariance estimation
in Gaussian graphical models. IEEE Transactions on Signal
Processing, 60(1):211–220, 2012.
Yanover, C., Schueler-Furman, O., and Weiss, Y. Minimizing and
learning energy functions for side-chain prediction. In Speed,
Terry and Huang, Haiyan (eds.), Research in Computational
Molecular Biology, volume 4453 of Lecture Notes in Computer
Science, pp. 381–395. Springer, 2007.

