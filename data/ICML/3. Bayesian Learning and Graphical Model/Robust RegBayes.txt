Robust RegBayes: Selectively Incorporating
First-Order Logic Domain Knowledge into Bayesian Models

Shike Meiâ€ 
MEI @ CS . WISC . EDU
Jun ZhuÂ§
DCSZJ @ MAIL . TSINGHUA . EDU . CN
Xiaojin Zhuâ€ 
JERRYZHU @ CS . WISC . EDU
â€ 
Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA 53706
Â§
Dept. of Comp. Sci. & Tech., TNList Lab, State Key Lab of Intell. Tech. & Sys., Tsinghua University, China

Abstract
Much research in Bayesian modeling has been
done to elicit a prior distribution that incorporates domain knowledge. We present a novel and
more direct approach by imposing First-Order
Logic (FOL) rules on the posterior distribution.
Our approach unifies FOL and Bayesian modeling under the regularized Bayesian framework.
In addition, our approach automatically estimates
the uncertainty of FOL rules when they are produced by humans, so that reliable rules are incorporated while unreliable ones are ignored. We
apply our approach to latent topic modeling tasks
and demonstrate that by combining FOL knowledge and Bayesian modeling, we both improve
the task performance and discover more structured latent representations in unsupervised and
supervised learning.

1. Introduction
Incorporating domain knowledge into the learning process
is an effective way to improve the accuracy of predictive
tasks (Richardson & Domingos, 2006) or the interpretability of latent representations (Andrzejewski et al., 2011).
Bayesian methods provide a rigorous mathematical framework to incorporate domain knowledge via Bayesâ€™ rule.
Much research has been done on eliciting an informative
prior, either directly (Garthwaite et al., 2005) or indirectly
by imposing parameter constraints and confidence values (Mao & Lebanon, 2009). Furthermore, Bayesian methods naturally handle noise in domain knowledge, which is
especially important when domain knowledge is collected
from the crowd, e.g. (Raykar et al., 2010).
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

However, since the ultimate goal of Bayesian methods is
to infer a posterior distribution, it is arguably more direct to impose domain knowledge directly on the posterior
distribution. The regularized Bayesian framework (RegBayes) does this via posterior constraints (or equivalent
posterior regularization) using a variational representation
of Bayesâ€™ rule (Zhu et al., 2013b). RegBayes has had significant success in learning discriminative Bayesian models by conjoining max-margin learning and Bayesian nonparametrics (Zhu et al., 2011; Zhu, 2012). Nonetheless,
the domain knowledge considered in RegBayes so far has
been max-margin posterior constraints, which could be too
narrow and inapplicable to unsupervised learning. Furthermore, no existing RegBayes model has explicitly modeled
the noise in domain knowledge.
In this paper we introduce Robust RegBayes, a principled framework to robustly incorporate rich and uncertain
domain knowledge in both unsupervised and supervised
learning tasks. Our contributions are two-fold: First, we
greatly extend the scope of RegBayes domain knowledge
by allowing First-Order Logic (FOL) rules. To achieve this,
we use groundings of the FOL formulas and define features
as expected number of groundings in which the formula is
true. In producing FOL domain knowledge, domain experts are often able to focus on high-level modeling goals
of the application domain. Second, we explicitly model the
uncertainty in domain knowledge using a spike-and-slab
prior. This allows us to automatically and selectively incorporate high-quality domain knowledge while ignoring lowquality ones. Our experiments on Robust RegBayes, especially on various latent Dirichlet allocation (LDA) (Blei
et al., 2003) tasks, convincingly demonstrate improved task
performance and topic interpretability in both unsupervised
and supervised settings. Compared to First-Order Logic
LDA (FoldÂ·all, a state-of-the-art framework to incorporate
FOL rules into LDA) (Andrzejewski et al., 2011) which requires experts to manually set the weights of FOL rules,
Robust RegBayes automatically learns the weights. Com-

Distributions

ğ»

ğ‘ğ‘™

ğ›¾ğ‘™

4

Density

6

spike
slab

2

pared to max-margin supervised LDA that incorporates
word features (Zhu & Xing, 2010), it discovers more interpretable topics without sacrificing prediction accuracy.

8

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models

ğ‘‹

0

2. The Robust RegBayes Framework

0.0

2.1. RegBayes with FOL Domain Knowledge
We first review the RegBayes framework (Zhu et al.,
2013b). Consider a generic Bayesian latent variable model
with observed random variables X âˆˆ X and hidden variables H âˆˆ H. Standard Bayesian inference calculates the
posterior distribution p(H | X) from a prior p0 (H) and
a likelihood model. It is often difficult to make sure that
the posterior satisfies all domain knowledge constraints. In
contrast, the RegBayes framework allows domain knowledge to directly influence the posterior. RegBayes does so
by penalizing distributions that differ in the expected value
of feature functions. Each feature function, denoted as Ï†l ,
and the â€œbelief labelâ€ of the feature, denoted as Î³l , are induced from domain knowledge. Formally, the RegBayes
inference procedure is defined as a constrained optimization problem:
X
min
KL (q(H) k p(H | X)) + C
Î¾l (1)
q(H)âˆˆP,Î¾âˆˆRL
+

l


s.t. Eq(H) [Ï†l (H, X)] âˆ’ Î³l  â‰¤  + Î¾l ,

where P denotes the appropriate probability simplex;
p(H | X) is the posterior distribution via Bayesâ€™ rule;
Î¾ âˆˆ RL
+ is the vector of L slack variables, one for each
domain knowledge constraint;  is a small positive precision parameter; and C is a regularization parameter. The
key difference between RegBayes and standard Bayesian
model is that the â€œoptimal distributionâ€ q(H) obtained by
solving Eq (1) can be different from p(H | X). The standard Bayesian posterior is a special case of RegBayes, as
can be seen by setting C = 0.
Despite its success, the application of RegBayes so far has
been limited to max-margin constraints (Zhu et al., 2011).
Max-margin constraints cannot represent many kinds of
rich domain knowledge such as those for unsupervised
models. To substantially broaden the scope of knowledge
used in RegBayes, we consider FOL rules in this paper.
FOL is a particularly flexible and powerful knowledge representation. It has the additional benefit of insulating the
domain experts from the intricacy of Bayesian inference.
Formally, let Rl be the lth FOL rule represented in Conjunctive Normal Form with logical predicates over instantiations (h, x) of the variables (H, X). To tie the rule
to RegBayes, we define a feature function Ï†l to provide
finer resolution over the domain knowledge. Specifically,
let Gl be the set of groundings
of Rl , we define the feaP
ture function Ï†l = |G1l | gl âˆˆGl 1(gl (h, x)). Note that this

0.2

0.4

0.6

0.8

ğ›¾ğ‘™ğ‘š
ğ‘€ ğ¿

1.0

Label

(a)

(b)

Figure 1. (a) An example of the spike-slab likelihood p(Î³Ìƒlm |
Î³l , bl ), where the slab component is a uniform distribution on
[0, 1] (blue line) and the spike component is a truncated Gaussian with a small variance (red line). (b) The Robust RegBayes
model.

feature function takes value in [0, 1] (rather than {0, 1})
and captures the fraction of groundings where the rule is
true. We let the â€œgolden standardâ€ expectation of rule Rl
be Î³l = E [Ï†l (H, X)] under the desired distribution. Soliciting Î³l from domain experts is difficult and will be addressed in the next section.
Compared to Markov Logic Network (MLN) which has the
goal of modeling FOL rules in probabilistic terms, RegBayes FOL rules are meant to influence a separate Bayesian
model. Therefore, RegBayes truly combines FOL and
Bayesian modeling. Compared to some other prior work
on incorporating FOL into probabilistic models such as
Fold.all (Andrzejewski et al., 2011), one major advantage of RegBayes is to automatically learn the FOL rule
weights. These weights would be hard (if not impossible)
for humans to manually set, especially in a crowd setting.
RegBayes learns the rule weights from relatively easier-toobtain belief labels via solving a dual optimization problem, as we show next.
2.2. Robust RegBayes
The golden standard Î³l for each rule is rarely observed
precisely in reality. We solve the problem by treating
expert-supplied values of Î³l as noisy observations. Formally, let the FOL knowledge base collected from experts
be KB = {Rl , Î³Ìƒ l }L
l=1 . The KB consists of L FOL rules.
Each rule Rl is associated with a set of noisy observations
Î³Ìƒ l = {Î³Ìƒlm : Î³Ìƒlm âˆˆ [0, 1]}M
m=1 from M different human
experts, e.g., workers in a crowdsourcing setting. We interpret Î³Ìƒ as a degree of belief that the rule holds true over the
variables. Our KB is â€œsoft,â€ similar to that in FoldÂ·all (Andrzejewski et al., 2011).
Given the noisy knowledge base KB, we are interested
in modeling the reliability of the rules. Previous studies on learning from crowds (Raykar et al., 2010; Welinder et al., 2010) made various assumptions on the experts
and tasks. In this paper, for robustness we restrict ourselves to two levels of rule reliability: If Î³Ìƒlm is labeled
coherently by multiple experts and the belief is corroborated by the Bayesian latent variable model, we hypothe-

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models

size that it is reliable and should be incorporated into our
Bayesian models; otherwise, we deem the rule unreliable
and ignore it. This knowledge selection process can be formally characterized by introducing a binary selecting variable bl âˆˆ {0, 1} for each rule. We define a â€œnoisy belief
likelihoodâ€ p(Î³Ìƒlm | Î³l , bl ) as a spike-slab mixture of two
components, selected by bl : If bl = 0, we use a slab distribution to generate diverse beliefs; If bl = 1, we use a spike
distribution to generate coherent labels. See Figure 1(a).
Our Robust RegBayes framework is defined as:
min KL (q(H, Î³, b) k p(H, Î³, b | X, Î³Ìƒ)) + C
q,Î¾

X

Î¾l

l

(2)

where p(H, Î³, b | X, Î³Ìƒ) âˆ p0 (H)p0 (b, Î³)p(X | H)p(Î³Ìƒ |
Î³, b) is the posterior distribution via Bayesâ€™ rule. Figure 1(b) shows the graphical model for Robust RegBayes.
The prior distribution p0 (b, Î³) for bl and Î³l will be discussed in the section of application to LDA. We make two
observations. First, if we collapse the model by reducing
the uncertainty on (Î³, b) and holding them constant (i.e.,
bl = 1 and Î³Ìƒ l = Î³l ), Eq (2) reduces to RegBayes Eq (1).
In general, Robust RegBayes (2) takes the uncertainty of
domain knowledge into consideration and the binary selecting variable bl specifies the importance of each logic
constraint. For unreliable domain knowledge, the corresponding bl will have a small probability of being 1 and
thus the expectation Eq(bl ) [bl ] (i.e., the importance of the
logic) will be small. Second, the reliability of rules (b, Î³)
and the underline Bayesian model (H, X) influence each
other in the Robust RegBayes framework. This is represented with the dashed arrow in Figure 1(b). We will see
the influence more clearly later in the applications on LDA.
2.3. A Generic Inference Procedure
Since the KL divergence is convex with respect to q (Wainwright & Jordan, 2008) and the posterior constraints are
intrinsically linear, problem (2) is convex. Thus, we can
apply convex analysis tools to derive a generic solution.
Specifically, by introducing a set of dual variables Âµ we
obtain the optimal distribution:
q(H, Î³, b | Âµâˆ— ) =

p(H, Î³, b | X, Î³Ìƒ) Pl Âµâˆ—l bl (Ï†l (H,X)âˆ’Î³l )
e
Z(Âµâˆ— )

where Âµâˆ— is the optimum solution of the dual problem:
X
max L(Âµ) = âˆ’ log Z(Âµ) âˆ’ 
Âµl
(3)
Âµ

Despite its elegance, it is important to realize that the
generic inference procedure is in general intractable in latent variable models. One needs to utilize variational approximation or sampling techniques to find approximate
solutions. In the next section, we present a specific instantiation of Robust RegBayes to LDA models and detail one
way to perform efficient variational inference.

3. Application to LDA Models


 
s.t. Eq(bl ) bl Eq(H|bl ) [Ï†l (H, X)] âˆ’ Eq(Î³l |bl ) [Î³l ]
â‰¤  + Î¾l , Î¾l â‰¥ 0, âˆ€l = 1 . . . L

H or not. By solving the dual problem (3), we automatically learn the optimal weights Âµâˆ— . Then, by inferring bl
we selectively incorporate reliable FOL rules while ignoring unreliable ones.

3.1. Robust RegBayes Applied to LDA
We now give an instantiation of Robust RegBayes in learning LDA topics by incorporating FOL domain knowledge.
LDA posits that each document is drawn from an admixture of K topics. Each topic Ï•k is defined as a multinomial
distribution over a given vocabulary and follows a Dirichlet prior p(Ï•k | Î²) = Dir(Ï•k | Î²). For document d,
we draw a topic proportion Î¸ d from a Dirichlet distribution
p(Î¸ d | Î±) = Dir(Î¸ d | Î±). For the ith word in document
d, we draw a topic assignment zdi from the multinomial
parametrized by Î¸ d , p(zdi = k | Î¸ d ) = Î¸dk , and then
draw the word wdi from the selected topic Ï•zdi , that is
p(wdi | zdi , Ï•) = Ï•zdi ,wdi . The
 Q of LDA
Q joint distribution
is p(W, Z, Ï•, Î¸ | Î±, Î²) =
p(Ï•
|
Î²)
k
k
d p(Î¸ d |
Q
Î±) i p(zdi | Î¸ d )p(wdi | zdi , Ï•) where W = {wdi } are
the observed words, Z = {zdi }, Î¸ = {Î¸dk }, Ï• = {Ï•dk }
are the hidden variables. In Bayesian methods, we aim
to infer the posterior over hidden variables p(Z, Ï•, Î¸ |
W, Î±, Î²).
For domain knowledge, we assume that all the FOL rules
are defined over the instantiation of words W and hidden
topic assignments Z. To account for uncertainty in knowledge, we model the belief labels Î³Ìƒlm by a spike-slab likelihood (cf. Figure 1(a)), where we define the slab component as uniform[0, 1] and the spike component as a truncated Gaussian distribution in [0, 1] with the golden standard Î³l as the mean and variance Ïƒl2 . The variance Ïƒl2 is
determined by empirical Bayes.
Q The likelihood is then defined as p(Î³Ìƒ l | Î³l , bl ) = m N (Î³Ìƒlm ; Î³l , Ïƒl2 )bl . We set
non-informative uniform priors for both bl and Î³l .
With the above definitions, we have H = {Z, Î¸, Ï•} and
X = W. Plugging these variables to problem (2), we get
the optimization problem of learning robust logic LDA:

l

s.t. âˆ’C â‰¤ Âµl â‰¤ C,
and Z(Âµ) is the normalization factor for q. Note that Âµl is
the weight of logic rule l and the binary variable bl determines whether the rule affects the posterior distribution of

min KL (q(H, Î³, b) k p(H, Î³, b | W, Î³Ìƒ, Î±, Î²)) + C
q,Î¾

X
l


 
s.t. Eq(bl ) bl Eq(Z|bl ) [Ï†l (Z, W)] âˆ’ Eq(Î³l |bl ) [Î³l ]
â‰¤  + Î¾l , Î¾l â‰¥ 0, âˆ€l = 1 . . . L.

Î¾l

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models

âˆš
Î»l = S M log( 2Ï€Ïƒl ) +

3.2. Variational Approximation



To collapse the parameter space and improve inference accuracy, we first marginalize out the variables Ï• and Î¸ by
exploring the conjugacy between multinomial and Dirichlet in a way similar to (Teh et al., 2007). This marginalization does not affect our logic constraints since they are
not directly defined on Ï• or Î¸. In theory, we can apply
convex analysis tools to derive a closed-form expression of
the posterior distribution q as in Section 2.3 and solve the
dual problem of the generic form (3) for the dual parameters. Unfortunately, in practice it is intractable from the
posterior of logic LDA. Thus we resort to variational approximate methods, as detailed below.
Approximate Inference: Given the dual variables Âµ, we
need to compute the collapsed posterior q(Z, Î³, b | Âµ).
This can be done with variational methods. Specifically,
we
Q make
Q the mean field
Q assumption that qÌƒ(Z, Î³, b | Âµ) =
d
i qÌƒ(zdi | Ïˆ di )
l qÌƒ(Î³l | Ïl )qÌƒ(bl | Î»l ), where qÌƒ(zdi |
Ïˆ di ) is a discrete distribution with parameters Ïˆ di ; qÌƒ(Î³l |
Ïl ) is a point-mass function centered on Ïl ; and qÌƒ(bl | Î»l )
is a Bernoulli distribution. Then, the best approximation
can be found by minimizing the KL-divergence between
qÌƒ(Z, b, Î³ | Âµ) and the posterior distribution q(Z, Î³, b | Âµ)
with respect to variational parameters. It can be shown that
we have the following mean field update equations. For the
topic assignment variational parameter Ïˆ, we have:

h
k
Ïˆdi
âˆ exp EqÌƒ(Zâˆ’di )qÌƒ(b) log(Î±k + nâˆ’di
dkÂ· )
X
+log(Î²wdi + nâˆ’di
Î²v + nâˆ’di
Â·kwdi ) âˆ’ log(
Â·kÂ· )
v

+

X

i
Âµl bl Ï†l (Z, W) ,

l

P
where ndkv ,
i 1(zdi = k, wdi = v) is the number of times that word v is assigned to topic k in document d; P
the dot denotes summation over that index (e.g.,
ndkÂ· = v ndkv ); and âˆ’di denotes that word wdi is excluded in calculating the counts. Note that the last term incorporates the FOL logic constraints. Exact computation of
the expectations is still very expensive, however. We thus
make further approximations. The first three terms in the
exponential are the same as in the collapsed variational inference (CVI) algorithm for LDA and we can approximate
it effectively by zero-order information (Asuncion et al.,
2009). For the last term, we approximate it by using the
mode ZÌ‚ of the current distribution qÌƒ(Z). We get:
âˆ’di
P
Î±k + NÂ·dk
âˆ’di
k
l Âµl Î»l Ï†l (ZÌ‚,W) ,
(Î²
+
N
)e
Ïˆdi
âˆP
w
di
Â·kwdi
âˆ’di
Î²
+
N
v
v
Â·kÂ·
(4)
P
âˆ’di
k
where Ndkv , j6=i 1(wdj = v)Ïˆdj
. For the variational
parameters Ï and Î», letting S(x) , 1/(1+eâˆ’x ) denote the
sigmoid function, we have the mean-field update equations
(The dual variables Âµ are given):

P

2
m ((Î³Ìƒlm )
2Ïƒl2

+ Ïƒl2 )


+Âµl (EqÌƒ(Z) [Ï†l (Z, W)] âˆ’ Ïl ) ,
P
âˆ’Âµl Î»l Ïƒl2 + Î»l ( m Î³Ìƒlm )
Ïl =
.
M Î»l
Due to space limit, we briefly explain the intuition behind
Î»l update. It is influenced by both the coherence of belief labels (the first and second terms) and the difference
between the current expected feature value and the golden
standard for the rule (the third term). Therefore, Robust
RegBayes infers the reliability of each rule by considering
both noisy labels and the underline Bayesian latent variable
model.
Weight Learning: To learn the dual parameters Âµ (i.e.,
the weights of FOL rules), we perform stochastic gradient
descent (SGD) to the dual problem (3). Since the exact
calculation of the gradient is intractable, we approximate it
as follows:
X
âˆ‚Âµl log Z(Âµ) =
q(Z, Î³, b | Âµ)bl (Ï†l (Z, W) âˆ’ Î³l )
Z,Î³,b

â‰ˆ

X

qÌƒ(Z, Î³, b | Âµ)bl (Ï†l (Z, W) âˆ’ Î³l )

Z,Î³,b

â‰ˆ EqÌƒ(bl ) [bl ] (Ï†Ì‚l (ZÌ‚, W) âˆ’ EqÌƒ(Î³l ) [Î³l ]), (5)
where the first equality holds due to duality; the first approximation is due to variational approximation; the second approximation is due to approximating the expectation
of the logic rule. Here, we use the mode ZÌ‚ of the variational distribution qÌƒ(Z, Î³, b | Âµ) which is efficient since
Z is independent under the mean field assumption. Another approximation is made to calculate Ï†l (Z, W) when
the number of groundings is too large â€” we approximate
it by uniformly sampling the groundings for such rules, denoted as Ï†Ì‚l (Z, W). These approximations work well in
practice, as we show below.
With the approximate gradients, we update the weights by
the SGD rule:
Âµt+1
= P roj[âˆ’C,C] (Âµtl + Ï„t (âˆ’âˆ‚Âµl log Z(Âµ) + )), (6)
l
where P roj[s,t] (x) denotes the Euclidean projection of x
to the interval [s, t]; and Ï„t is the step length which satisfies
mild conditions to ensure convergence (Bottou & Bousquet, 2011). In our implementation we set Ï„t = (t + Ï„0 )âˆ’Îº
and tune parameters Ï„0 and Îº.

4. Experiments
We now present empirical results on learning both unsupervised and supervised topic models to demonstrate the efficacy of Robust RegBayes on incorporating noisy FOL do-

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models
Table 1. Datasets. Intuitively, seed rule anchors a specific word to a specific topic, which will attract similar words to the topic; cannotlink rule forces two specific words into different topics; doc seed rule is similar to seed rule, but only applies to specific documents.
See (Andrzejewski et al., 2011) for the formal definitions of seed, cannot-link, docseed, inclusion, and exclusion rules.

Dataset
COMP
COM
POL
HDG

#Documents
5,000
2,740
2,000
24,073

#Topics
20
25
20
50

Description

#FOL Rules

comp.* in 20 newsgroup data
U.S. House of Representatives
movie reviews
PubMed abstracts

8 seeds
3 seeds, 2 docseeds
1 cannot-link
8 seeds, 6 inclusion, 6 exclusion

main knowledge. In short, Robust RegBayes shows superior ability to discover latent semantic structures and make
accurate predictions in the supervised settings.
4.1. Experiments with Unsupervised Topic Models
We denote our Robust RegBayes applied to LDA as
â€œRLogicLDA.â€ A special case of RLogicLDA is to set
bl = 1 for all rules in Eq. (2), i.e., do not allow the model to
ignore any rules via the slab component. Equivalently, the
special case treats all rules as valid. We denote the special
case as â€œLogicLDA.â€ For baselines, we use (i) the vanilla
LDA using Gibbs sampling, and (ii) FoldÂ·all, a MAP estimator to incorporate FOL into LDA. FoldÂ·all requires experts to manually set the weights of rules. We adopt the
well-performing â€œMirâ€ method for FoldÂ·all and download
the authorsâ€™ implementation (Andrzejewski et al., 2011).
4.1.1. L OGIC LDA VS . LDA AND F OLDÂ·ALL
We first show that LogicLDA achieves similar performance
as FoldÂ·all (which has the benefit of expert-set rule weights)
by automatically learning rule weights. We use all four real
datasets in (Andrzejewski et al., 2011) and the same logic
rules. The logic rules contain â€œseed rulesâ€ which assign
specific words to specific topics, â€œcannot-link rulesâ€ which
force two words into separate topics, and so on. Details
are in Table 1. Since no belief labels Î³Ìƒl were provided with
their data, we define them by examining the meaning of the
logic rules: All the rules in COMP, CON and POL aim to
make the learned topics more understandable for humans,
we set all the belief labels of these rules at Î³Ìƒl = 1. For
HDG, the rules are given by biological experts and should
be satisfied according to the description. Thus, we also set
their belief labels at 1. As in (Andrzejewski et al., 2011),
we randomly split documents into training/testing sets by a
ratio of 8/2. For LogicLDA, we utilize the FOL rules during training and estimate the topics Ï• from the posterior
distribution qÌƒ(Z) as in (Asuncion et al., 2009). As in (Andrzejewski et al., 2011), the knowledge is assumed to be
encoded into the estimated topics. Therefore, for testing,
we do not utilize the logic rules and only optimize the variational bound given Ï• as in vanilla LDA (Blei et al., 2003).
We measure test set perplexity to evaluate LDA perfor-

mance (Blei et al., 2003). To show different methodsâ€™
ability in incorporating logic rules, we also measure the
proportion of satisfied logic rules. For fairness, all parameters are the same as in (Andrzejewski et al., 2011)
across all the methods in comparison, e.g. we use the same
symmetric Dirichlet parameters Î± = 1, Î² = 1 below.
For the extra parameters in our methods, we simply set
 = 0.001 and the regularization parameter C at a large
number (e.g., 1000000) so that the dual parameters Âµ never
reach the bounds in Eq (3). The SGD step length decays as
Ï„t = (t + 10)âˆ’0.5 by cross validation on the training data.
We run each method five times under random initialization
and report the average results in Table 2. LogicLDA is superior to LDA and FoldÂ·all by both measures: First, LogicLDA achieves the lowest test set perplexity in three out
of four data sets. These differences are statistically significant under 2-tailed paired t-test with significance level
p < 0.02. In addition, on the CON data set LogicLDA is
not significantly different than the best (LDA).
Second, LogicLDA and FoldÂ·all both achieve much higher
proportion of FOL rule satisfaction than LDA (except for
the POL data set, where all models achieve near 100% satisfaction). Importantly, LogicLDA does so by automatically learning the rule weights, while FoldÂ·all has to rely
on human experts to specify the weights.
4.1.2. RL OGIC LDA VS . L OGIC LDA: ROBUSTNESS
We examine the robustness of RLogicLDA by comparing
it with LogicLDA under the same settings as above, but
with potentially unreliable domain knowledge. To this end,
we intentionally design one potentially unreliable FOL rule
for each of the four datasets, see Table 3. We show each
designed rule to M = 20 volunteers and collected their
subjective belief label Î³Ìƒ lm on that rule. Specifically, each
volunteer can select their Î³Ìƒ lm between 0 and 1 with step
size 0.1 via a user interface. Table 3 shows the histogram
of Î³Ìƒ lm : a flat histogram indicates disagreements among the
volunteers and thus unreliable rule.
RLogicLDA performs better than LogicLDA in test set perplexity, as shown in Table 3. On COMP and HDG data
sets, the difference is statistically significant under 2-tailed
paired t-test (p < 0.02) while on CON and POL the dif-

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models
Table 2. Test set perplexity and proportion of satisfied logic rules on four datasets.

COMP
CON
POL
HDG

Proportion of Satisfied Logic Rules
LDA
FoldÂ·all
LogicLDA
0.00 Â± 0.00 1.00 Â± 0.00 0.97 Â± 0.01
0.07 Â± 0.04 0.67 Â± 0.03 0.70 Â± 0.00
1.00 Â± 0.00 1.00 Â± 0.00 1.00 Â± 0.00
0.60 Â± 0.01 0.95 Â± 0.00 0.96 Â± 0.01

Table 3. RLogicLDA is robust to unreliable domain knowledge
Test Set Perplexity
Satisfaction Proportion
Designed Rule
Histogram
LogicLDA
RLogicLDA
LogicLDA
RLogicLDA
seed: {problem,
windows, window,
available, files, mac,
1467 Â± 6
1446 Â± 6 0.39 Â± 0.16 0.07 Â± 0.06
apple, system, im} â†’
topic 1
4
3
2
0

1

COMP

Frequency

5

6

Data

Test Set Perplexity
LDA
FoldÂ·all
LogicLDA
1531 Â± 12 1537 Â± 11 1463 Â± 5
1206 Â± 6
1535 Â± 10 1216 Â± 11
3218 Â± 13 3220 Â± 13 3176 Â± 12
940 Â± 6
973 Â± 7
885 Â± 2

0.0

0.2

0.4

0.6

0.8

1.0

0.8

1.0

0.8

1.0

0.8

1.0

4
3
2

Frequency

1228 Â± 16

0.49 Â± 0.03

0.08 Â± 0.03

3173 Â± 13

3168 Â± 11

0.57 Â± 0.19

0.09 Â± 0.04

895 Â± 2

891 Â± 2

0.75 Â± 0.03

0.95 Â± 0.01

1

1228 Â± 9

0
0.0

0.2

0.4

0.6

Belief

4
3
2
1

must-link{acting,
make, performance,
character}: same topic

0

POL

Frequency

5

6

CON

seed: {bill, people, law,
health, tax, trade,
economy, budget,
pension} â†’ topic 7

5

6

Belief

0.0

0.2

0.4

0.6

4
3
2
1

cannot-link{human,
gene}: different topics

0

HDG

Frequency

5

6

Belief

0.0

0.2

0.4

0.6

Belief

ference is not significant. It achieves this by only listening to reliable rules. The empirical means of the belief labels for the four rules are 0.50, 0.40, 0.52 and 0.72 respectively. The satisfaction proportions of LogicLDA are close
to these empirical means â€“ it indiscriminately obeys all domain knowledge. In contrast, RLogicLDA is able to ignore
the first three rules it deems unreliable, while obeying the
fourth rule. This is reflected in RLogicLDAâ€™s proportions.
4.2. Experiments with Supervised Topic Models
We now show that robustly incorporating knowledge can
help achieve both higher prediction performance and better
interpretability of learned topics compared to other supervised LDA methods.
4.2.1. S ETTINGS AND D OMAIN K NOWLEDGE
We use the HotelReview dataset (Zhu & Xing, 2010) and
predict the global rating (an integer from 1 to 5) of each hotel review based on its content. As in (Zhu & Xing, 2010),
we treat it as a regression problem and normalize the ratings. The dataset contains 5,000 reviews and is equally
split into training and testing sets. Besides the global rating, each review also has the ratings of five aspects: value,
location, service, room, and cleanliness. Discovering the

latent correspondence between review contents and aspects
is an interesting research topic (Wang et al., 2010). Here,
we use seed rules to assign several representative words of
each aspect to a specific set of topics. Specifically, we assign words {value, price, quality, worth, resort} to topics
1 and 2 to seed the value aspect; {location, traffic, restaurant, beach} to topic 3 to seed the location aspect; {service,
food, breakfast, dinner} to topics 4â€“6 to seed the service aspect; and {door, floor, bed, stay, bathroom, room} to topics
7â€“10 to seed the room aspect. We ignore the cleanliness
aspect because we find reviews on cleanliness usually are
contained within the reviews on the room aspect and thus
redundant. Furthermore, to distinguish positive and negative aspects, we use a â€œsentiment seed ruleâ€ to assign 19
seed positive words to topics 1,3,5,7,9.1
Note that these rules represent our intention to relate topics
and aspects. Therefore, we set all belief labels for the five
rules to 1.0. Finally, as in Section 4.1.2, we also collect
empirical belief labels from M = 20 volunteers for one
reliable rule (the â€œNot ruleâ€) and one unreliable rule (the
â€œBut ruleâ€), see Table 4.
1
The 19 seed words are amazing, beach, beautiful, comfortable, enjoyed, excellent, fantastic, fresh, friendly, good, great,
large, lovely, nice, perfect, wonderful, best, recommend and enjoy.

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models
Table 4. Intentionally Designed Reliable and Unreliable Rules

Description

Histogram

Satisfaction Proportion
sLogicLDA
sRLogicLDA

mean(Î³Ìƒ lm )

p(bl = 1 | Î»l )

0.91

0.99

0.98 Â± 0.03

1.00 Â± 0.00

0.56

0.00

0.70 Â± 0.13

0.05 Â± 0.4

4
3
2

Frequency

1
0

0.2

0.4

0.6

0.8

1.0

0.8

1.0

4
3
2

Frequency

5

6

Belief

1

But rule

0.0

0

Not rule

seed: {adjectives with
negation within
distance 4 before it} â†’
the last topic
seed: {all words before
adversative transition
(e.g. â€œbutâ€) in
sentences} â†’ the last
topic

5

6

Rule

0.0

0.2

0.4

0.6

Belief

4.2.2. P REDICTION P ERFORMANCE
We build our supervised RLogicLDA (â€œsRLogicLDAâ€)
by adding the same max-margin posterior constraints as
in (Zhu et al., 2013a) to RLogicLDA. The parameter settings of , C and Î± are the same as in the unsupervised experiments. The other parameters (Î±, Î²) and the regularization parameter introduced by max-margin constraints (Zhu
et al., 2013a) are set by cross-validation on the training
set. For baselines, we compare with (i) maximum entropy
discrimination LDA regression (MedLDAr) (Zhu et al.,
2013a), a RegBayes model that incorporates max-margin
posterior regularization into LDA; (ii) supervised conditional topical random fields (sCTRF) (Zhu & Xing, 2010),
a feature based model that incorporates both single and
pairwise word features into MedLDAr.
We run each algorithm five times with random initialization
and random split, and report the average test set results in
Figure 2(a). Note with our setting sRLogicLDA requires at
least 10 topics to accommodate for the FOL rules, thus its
curve starts at #topics=10; while the baselines have no logic
rules and they start at #topic=3. We use predictive R2 (Zhu
& Xing, 2010) as the performance measure of regression.
sRLogicLDA achieves comparable performance as feature
based sCTRF, and outperforms MedLDAr. Note that sCTRF uses 15 features on words,2 while sRLogicLDA only
needs 7 simple logic rules. Therefore, incorporating domain knowledge as constraints is useful for prediction compared with feature engineering approaches.
4.2.3. T OPIC I NTERPRETABILITY
Tables 5,6 show the top 10 words of each topic learned by
sRLogicLDA and sCTRF with K = 15 topics.3 We manu-

ally judged which words represent the value, location, service and room aspects, respectively, and colored them orange, blue, cyan and red, respectively. When applicable,
we mark FOL seed words with an âˆ—.
sRLogicLDA has a clear correspondence between topics
and aspects due to the FOL rules. Topics T1â€“T10 obey the
grouping into the four aspects (denoted by vertical lines in
Table 5). The only exception is T7, which we suspect is
because the other three topics T8â€“T10 are sufficient in describing the room aspect. We also note that sRLogicLDA is
successful in attracting non FOL seeded, but aspect-related,
words into the topics (i.e., those colored words not marked
by an âˆ— in Table 5). In contrast, such a clear correspondence
is largely absent in sCTRF (Table 6). Its topics contain a
mix of room, location, service aspects, and the value aspect
is missing among the top topic words.
Finally, we study sRLogicLDAâ€™s ability to utilize the sentiment seed rule to attract additional positive words into specific topics. The set of positive topics, denoted as Tp =
{T 1, T 3, T 5, T 7, T 9}, is defined as the topics specified by
the sentiment seed rule. The set of other topics is denoted
as To . We hope to see that Tp attracts many more positive
sentiment words (excluding the 19 seed words which the
rule forces into Tp anyway), and that To attracts fewer positive sentiment words (including the 19 seed words since
any positive words in To is undesirable). To this end, we
first obtain a commonly-used positive word list W containing 2006 positive words.4 Note W includes the 19 seed
words. We measure the amount of positive words in To
by the P
averagePweights of words in W over these topics:
Ï•kw
Ao = kâˆˆTo |TowâˆˆW
. Let W\19 be the set W exclud|
ing the 19 seed words. P
We measure
the amount of positive
P
kâˆˆTp

2

The sCTRF features are: 9 Part-of-Speech features that categorize the words, 5 WordNet sentiment features, and 1 feature on
whether two words belong to the same phrase.
3
We observed similar phenomenon with other K. We did not
include the topics learned by MedLDAr for two reasons: first, as
Figure 2(a) shows MedLDAr has inferior predictive performance
compared to sCTRF and sRLogicLDA. Second, it was shown in
(Zhu & Xing, 2010) that MedLDAr produces less interpretable

wâˆˆW

Ï•kw

\19
words in Tp by Ap =
. Our hypothe|Tp |
sis is that, with the sentiment seed rule, Ap â‰¥ Ao . Note
that because of the exclusion of seed words from the computation of Ap , this hypothesis is a very strict comparison.

topics than sCTRF on the same data.
4
http://www.cs.uic.edu/âˆ¼liub/FBS/opinion-lexiconEnglish.rar.

3

5

10

15

20

25

# Topics

0.58

PredictiveR2

0.62

0.06
0.05
0.04
0.03

sRLogicLDA
sLogicLDA

0.54

0.02
0.01

positive word weights

0.00

0.60
0.55
0.50

sRLogicLDA
sCTRF
MedLDAr

0.45

PredictiveR2

0.65

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models

10

Ap

(a)

15

20

25

# Topics

Ao

(b)

(c)

Figure 2. (a) Predictive R2 of sRLogicLDA, sCTRF, and MedLDAr. (b) average weights of positive words in the positive topic set (Ap )
and the other topic set (Ao ); and (c) predictive R2 of sRLogicLDA and sLogicLDA.
Table 5. Top 10 words in Sampled Topics learned by sRLogicLDA
T1+
resort
free
*price
great
*worth
island
trip
beautiful
*quality
place

T2
nâ€™t
pay
but
money
check
time
back
car
expensive
lobby

T3+
*beach
*location
nice
street
parking
area
good
*restaurant
internet
great

T4
restaurant
fruit
*dinner
wine
served
morning
menu
evening
meal
eggs

T5+
pool
good
holiday
bar
entertainment
day
*food
euros
lovely
evening

T6
*breakfast
*food
*service
but
day
water
bar
buffet
drinks
lunch

T7+
but
nâ€™t
kids
people
time
nice
night
great
day
family

T8
*room
told
asked
desk
front
manager
*stay
called
call
back

T9+
*room
*bed
*bathroom
shower
*door
*floor
colorred*stay
bedroom
coffee
towels

T10
hotel
*room
rooms
*stay
hotels
night
booked
*floor
city
view

T11
staff
but
good
guests
time
however
bit
reviews
bar
found

T12
pool
view
area
balcony
small
chairs
spa
lounge
pools
ocean

T13
but
reception
small
area
however
road
car
park
tv
side

T14
but
hotel
staff
people
day
time
place
nâ€™t
back
night

T15
nâ€™t
night
looked
smell
work
air
left
dirty
carpet
back

Table 6. Topics learned by sCTRF in a randomly selected run
T1
nâ€™t
poor
dirty
bad
room
hotel
worst
back
small
awful

T2
room
nâ€™t
told
asked
hotel
back
manager
stay
called
night

T3
room
nâ€™t
told
hotel
back
front
desk
stay
asked
manager

T4
room
nâ€™t
hotel
stay
front
desk
back
night
rooms
door

T5
room
nâ€™t
hotel
stay
night
rooms
back
bed
front
time

T6
room
hotel
nâ€™t
stay
night
rooms
time
staff
bed
breakfast

T7
hotel
room
nâ€™t
night
stay
rooms
breakfast
staff
time
day

T8
hotel
room
nâ€™t
breakfast
staff
day
night
rooms
time
area

Fig 2(b) presents the average Ap and Ao from five randomized run. Ap is indeed statistically significantly larger than
Ao (2-tailed unpaired t-test with p < 0.02). Therefore, the
sentiment seed rule attracts more positive words to Tp .
Taken together, these results demonstrate that by incorporating FOL rules on aspect-topic relation, sRLogicLDA
learns topics with improved interpretability.
4.2.4. ROBUSTNESS
We examine sRLogicLDAâ€™s ability to automatically infer
robustness of FOL rules by comparing it with one variant:
sLogicLDAâ€”a special case of sRLogicLDA where all bl
are set to 1 (i.e., forced to use all FOL rules with no attempt
to infer their robustness).
First, Table 4 shows that sLogicLDA simply matches satisfaction proportions to the empirical mean of belief labels,
while sRLogicLDA is more sophisticated and achieves a
quite different proportion on the unreliable â€œBut rule.â€ This
demonstrates that sRLogicLDA can select the reliable â€œNot
ruleâ€ and ignore the unreliable â€œBut rule.â€ Second, Fig-

T9
hotel
room
day
staff
area
breakfast
pool
time
nâ€™t
night

T10
hotel
pool
day
area
staff
rooms
food
time
breakfast
good

T11
hotel
pool
day
food
good
bar
area
staff
beach
restaurant

T12
pool
hotel
food
good
beach
bar
day
nice
restaurant
staff

T13
beach
pool
food
good
resort
bar
great
day
hotel
nice

T14
beach
resort
great
pool
good
food
island
day
nice
ocean

T15
great
lovely
good
beautiful
excellent
beach
wonderful
nice
fantastic
amazing

ure 2(c) shows that sRLogicLDA outperforms sLogicLDA
in predictive R2 ,suggesting that automatically inferring the
robustness of knowledge achieves better performance.

5. Conclusions
We proposed Robust RegBayes, a framework to selectively
incorporate noisy FOL domain knowledge into Bayesian
models via posterior regularization. We applied our framework to unsupervised and supervised topic models, and
demonstrated that through incorporating domain knowledge robustly, we can improve both the predictive performance and topic interpretability. In the future, we plan
to extend Robust RegBayes to incorporate FOL domain
knowledge into Bayesian nonparametric models.

Acknowledgments
The work was supported by the National Basic Research
Program of China (Nos. 2013CB329403, 2012CB316301)
and National Natural Science Foundation of China (Nos.
61322308, 61332007) to JZ, and a Google Faculty Research Award to XZ.

Robust RegBayes: Selectively Incorporating First-Order Logic Knowledge into Bayesian Models

References
Andrzejewski, D., Zhu, X., Craven, M., and Recht, B. A
framework for incorporating general domain knowledge
into latent Dirichlet allocation using first-order logic. In
International Joint Conference on Artificial Intelligence
(IJCAI), 2011.
Asuncion, A., Welling, M., Smyth, P., and Teh, Y.W. On
smoothing and inference for topic models. In Uncertainty in Artificial Intelligence (UAI), 2009.
Blei, D.M., Ng, A.Y., and Jordan, M.I. Latent Dirichlet
allocation. Journal of Machine Learning Research, 3:
993â€“1022, 2003.
Bottou, L. and Bousquet, O. The tradeoffs of large-scale
learning. Optimization for Machine Learning, pp. 351,
2011.
Garthwaite, P., Kadane, J., and Oâ€™Hagan, A. Statistical
methods for eliciting probability distributions. Journal
of the American Statistical Association, 100(470):680â€“
700, 2005.
Mao, Y. and Lebanon, G. Domain knowledge uncertainty
and probabilistic parameter constraints. In Uncertainty
in Artificial Intelligence (UAI), 2009.
Raykar, V., Yu, S., Zhao, L., Valadez, G.H., Florin, C., Bogoni, L., and Moy, L. Learning from crowds. Journal of
Machine Learning Research, 11:1297â€“1322, 2010.
Richardson, M. and Domingos, P. Markov logic networks.
Machine Learning, 62(1-2):107â€“136, 2006.
Teh, Y.W., Newman, D., and Welling, M. A collapsed variational Bayesian inference algorithm for latent Dirichlet
allocation. Advances in Neural Information Processing
Systems (NIPS), 19:1353, 2007.
Wainwright, M.J. and Jordan, M.I. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1-2):1â€“305,
2008.
Wang, H., Lu, Y., and Zhai, C. Latent aspect rating analysis
on review text data: a rating regression approach. In
International Conference on Knowledge Discovery and
Data mining (SIGKDD), 2010.
Welinder, P., Branson, S., Belongie, S., and Perona, P. The
multidimensional wisdom of crowds. In Advances in
Neural Information Processing Systems (NIPS), 2010.
Zhu, J. Max-margin nonparametric latent feature models
for link prediction. In International Conference on Machine Learning (ICML), 2012.

Zhu, J. and Xing, E.P. Conditional topic random fields. In
International Conference on Machine Learning (ICML),
2010.
Zhu, J., Chen, N., and Xing, E.P. Infinite latent SVM for
classification and multi-task learning. Advances in Neural Information Processing Systems (NIPS), 25, 2011.
Zhu, J., Chen, N., Perkins, H., and Zhang, B. Gibbs maxmargin topic models with fast sampling algorithms. In
International Conference on Machine Learning (ICML),
2013a.
Zhu, J., Chen, N., and Xing, E.P. Bayesian inference with
posterior regularization and applications to infinite latent
SVMs. arXiv:1210.1766v2, 2013b.

