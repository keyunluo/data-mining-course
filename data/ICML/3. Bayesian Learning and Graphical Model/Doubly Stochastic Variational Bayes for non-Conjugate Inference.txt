Doubly Stochastic Variational Bayes for non-Conjugate Inference

Michalis K. Titsias
Department of Informatics, Athens University of Economics and Business, Greece
Miguel Lázaro-Gredilla
Dpt. Signal Processing & Communications, Universidad Carlos III de Madrid, Spain

Abstract
We propose a simple and effective variational
inference algorithm based on stochastic optimisation that can be widely applied for Bayesian
non-conjugate inference in continuous parameter
spaces. This algorithm is based on stochastic approximation and allows for efficient use of gradient information from the model joint density.
We demonstrate these properties using illustrative examples as well as in challenging and diverse Bayesian inference problems such as variable selection in logistic regression and fully
Bayesian inference over kernel hyperparameters
in Gaussian process regression.

1. Introduction
Modern machine learning and statistical applications require large scale inference in complex models. Bayesian
learning provides a probabilistic framework for inference
that combines prior knowledge with observed data in a
principled manner. However, apart from simple cases involving conjugate models, the Bayesian computations are
intractable and approximations based on either Markov
Chain Monte Carlo (MCMC) (Robert & Casella, 1999) or
variational Bayesian inference (Jordan et al., 1999; Neal
& Hinton, 1999; Wainwright & Jordan, 2008) are needed.
While MCMC can provide unbiased estimates of Bayesian
expectations, in practice designing MCMC algorithms that
reliably converge to the stationary posterior distribution can
be a notoriously difficult task especially in complex nonconjugate models. On the other hand, variational methods
formulate Bayesian inference as an optimization problem,
where the objective function is constructed to be a lower
bound on the marginal likelihood. This can allow for faster
algorithms having a simpler mechanism for monitoring
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

MTITSIAS @ AUEB . GR

MIGUEL @ TSC . UC 3 M . ES

convergence. Despite that, the variational approach cannot be applied as widely as MCMC and this is because the
variational objective function requires a high dimensional
expectation that becomes intractable for non-conjugate and
highly non-linear models.
In this paper, we expand the range of applicability of
variational inference algorithms by introducing a simple
stochastic optimization algorithm that can be widely applied in non-conjugate models where the joint probability densities are differentiable functions of the parameters.
This algorithm is based on stochastic approximation (Robbins & Monro, 1951) and differs from other work on nonconjugate stochastic variational inference (Paisley et al.,
2012; Ranganath et al., 2014; Mnih & Gregor, 2014) by
allowing for efficient use of gradient information from the
model joint density. We demonstrate these properties using illustrative examples as well as in challenging and diverge Bayesian estimation problems such as variable selection in logistic regression and fully Bayesian inference
over kernel hyperparameters in Gaussian process regression (Rasmussen & Williams, 2006). For the former application we also introduce a variational objective function, suitable for general-purpose sparse inference, which is
hyperparameter-free in the sense that the optimisation over
the initial sparsity-determining hyperparameters is dealt
with analytically. For the latter application our method provides a general variational inference technique for hyperparameters in Gaussian process regression that is widely applicable to differentiable kernel functions, demonstrating
also a very close agreement with ground-truth Monte Carlo
estimates obtained by much slower MCMC runs.
Furthermore, the proposed algorithm introduces stochasticity by sampling from the variational distribution. This
differs from the data sub-sampling stochasticity used in the
variational framework proposed by Hoffman et al. (2010;
2013). We show how to combine the two types of stochasticity, thus deriving a doubly stochastic variational inference algorithm, allowing for efficient non-conjugate inference for large scale problems. We demonstrate experimen-

Doubly Stochastic Variational Bayes for non-Conjugate Inference

tally this doubly stochastic scheme in large-scale Bayesian
logistic regression.
Independently from our work, Kingma & Welling (2013)
and Rezende et al. (2014) also derived doubly stochastic
variational inference algorithms by utilising gradients from
the joint probability density. Our work provides an additional perspective and it specialises also on different type
of applications such as variable selection and Gaussian process hyperparameter learning.

2. Theory
Consider a random vector z ∈ RD that follows a distribution with a continuous density function φ(z). We shall
assume φ(z) to exist in standard form so that any parameter mean vector is set to zero and scale parameters are set
to one. For instance, φ(z) could be the standard normal
distribution, the standard t distribution, a product of standard logistic distributions, etc. We often refer to φ(z) as
the standard distribution and for the time being, we shall
leave it unspecified and develop the theory in a general setting. A second assumption we make about φ(z) is that
it permits straightforward simulation of independent samples. We aim to utilise the standard distribution as a building block for constructing correlated variational distributions. While φ(z) has currently no structure, we can add
correlation by applying an invertible transformation,
θ = Cz + µ,
where the scale matrix C is taken to be a lower triangular positive definite matrix (i.e. its diagonal elements are
strictly positive) and µ is a real vector. Given that the Ja1
, the distribution
cobian of the inverse transformation is |C|
over θ takes the form
q(θ|µ, C) =


1
φ C −1 (θ − µ) ,
|C|

(1)

which is a multivariate and generally correlated distribution having as adjustable parameters the mean vector µ
and the scale matrix C. We wish to employ q(θ|µ, C)
as a variational distribution for approximating the exact
Bayesian posterior in the general setting where we have a
non-conjugate model. More precisely, we consider a probabilistic model with the joint density
g(θ) = p(y|θ)p(θ),

(2)

where y are data and θ ∈ RD are all unobserved random
variables which can include both latent variables and parameters. Following the standard variational Bayes inference method (Jordan et al., 1999; Neal & Hinton, 1999;
Wainwright & Jordan, 2008) we seek to minimise the KL
divergence KL[q(θ|µ, C)||p(θ|y)] between the variational

and the true posterior distribution. This can equivalently
formulated as the maximisation of the following lower
bound on the log marginal likelihood,
Z
g(θ)
F(µ, C) = q(θ|µ, C) log
dθ,
(3)
q(θ|µ, C)
where q(θ|µ, C) is given by (1). By changing variables
according to z = C −1 (θ − µ), the above is written as
Z
g(Cz + µ)|C|
dz
F(µ, C) = φ(z) log
φ(z)
= Eφ(z) [log g(Cz + µ)] + log |C| + Hφ , (4)
PD
where log |C| =
d=1 log Cdd and Hφ denotes the entropy of φ(z) which is constant with respect to the variational parameters (µ, C) and therefore it can be ignored
when maximising the bound. Also notice that the above requires integration over the distribution φ(z) which exists in
standard form and therefore it does not depend on the variational parameters (µ, C). These parameters somehow have
been transferred inside the logarithm of the joint density.
Further, it is worth noticing that when the logarithm of the
joint model density, i.e. log g(θ), is concave with respect
to θ, the lower bound in (4) is also concave with respect
to the variational parameters (µ, C) and this holds for any
standard distribution φ(z); see the supplementary material
for a formal statement and proof. This generalises the result
of Challis & Barber (2011; 2013), who proved it for the
variational Gaussian approximation, and it is similar to the
generalisation presented in (Staines & Barber, 2012).
To fit the variational distribution to the true posterior, we
need to maximise the bound (4) and therefore we consider
the gradients over µ and C,
∇µ F(µ, C) = Eφ(z) [∇µ log g(Cz + µ)] ,

(5)

∇C F(µ, C) = Eφ(z) [∇C log g(Cz + µ)] + ∆C ,

(6)

where ∆C denotes the diagonal matrix with elements
(1/C11 , . . . , 1/CDD ) in the diagonal. Also the term
∇C log g(Cz + µ) in eq. (6) should be understood as the
partial derivatives w.r.t. C stored in a lower triangular matrix so that there is one-to-one correspondence with the
elements in C. A first observation about the gradients
above is that they involve taking derivatives of the logarithm of the joint density by adding randomness through
z and then averaging out. To gain more intuition, we
can equivalently express them in the original space of θ
by changing variables in the reverse direction according
to θ = Cz + µ. Using the chain rule we have that
∇µ log g(Cz + µ) = ∇Cz+µ log g(Cz + µ) and similarly
∇C log g(Cz+µ) = ∇Cz+µ log g(Cz+µ)zT where again
∇Cz+µ log g(Cz + µ)zT should be understood as taking
the lower triangular part after performing the outer vector

Doubly Stochastic Variational Bayes for non-Conjugate Inference

Algorithm 1 Doubly stochastic variational inference
Input: φ, y, θ, ∇ log g.
Initialise µ(0) , C (0) , t = 0.
repeat
t = t + 1;
z ∼ φ(z);
θ (t−1) = C (t−1) z + µ(t−1) ;
(t−1)
µ(t) = µ(t−1) + ρt ∇
);
 θ log g(θ


C (t) = C (t−1) +ρt ∇θ log g(θ (t−1) ) × zT + ∆C (t−1) ;

until convergence criterion is met.

product. These observations allow to transform (5) and (6)
in the original space of θ as follows,
∇µ F(µ, C) = Eq(θ|µ,C) [∇θ log g(θ)] ,
(7)


T −T
∇C F(µ, C) = Eq(θ|µ,C) ∇θ log g(θ) × (θ − µ) C
+ ∆C ,

(8)

Eq. (7) is particularly intuitive as it says that the gradient
over µ is simply the gradient of the logarithm of the joint
density with respect to the parameters θ averaged over the
variational distribution.
We would like now to optimise the variational lower bound
over (µ, C) using a stochastic approximation procedure.
To this end, we need to provide stochastic gradients having
as expectations the exact quantities. Based on the expressions (5)-(6) or their equivalent counterparts (7)-(8) we can
proceed by firstly drawing θ (s) ∼ q(θ|µ, C), and then using ∇θ log g(θ (s) ) as the stochastic direction for updating
µ and ∇θ log g(θ (s) ) × (θ (s) − µ)T C −T as the direction
for updating C. To draw θ (s) , we need first to sample z
from φ(z) (which by assumption is possible) and then deterministically obtain θ (s) = Cz + µ. Based on the latter
(θ (s) − µ)T C −T is just zT , therefore the computationally
efficient way to implement the whole stochastic approximation scheme is as summarised in Algorithm 1.
Based on the theory of stochastic approximation (Robbins
& Monro,P
1951), using aP
schedule of the learning rates {ρt }
such that
ρt = ∞,
ρ2t < ∞, the iteration in Algorithm 1 will converge to a local maxima of the bound in (3)
or to the global maximum when this bound is concave. For
notational simplicity we have assumed common learning
rate sequences for µ and C, however, in practice we can
use different sequences and the algorithm remains valid.
We will refer to the above stochastic approximation algorithm as doubly stochastic variational inference (DSVI) because it introduces stochasticity in a different direction than
the standard stochastic variational inference proposed by
(Hoffman et al., 2010; 2013). The latter is based on subsampling the training data and performing online parameter updates by using each time a single data point or a small

“mini-batch” which is analogous to other online learning
algorithms (Bottou, 1998; Bottou & Bousquet, 2008). Instead, our algorithm introduces stochasticity by sampling
from the variational distribution. Notice that the latter
type of stochasticity was first introduced by (Paisley et al.,
2012) who proposed a different stochastic gradient for variational parameters that we compare against in Section 2.2.
For joint probability models with a factorised likelihood,
the two types of stochasticity can be combined so that in
each iteration the stochastic gradients are computed by both
sampling from the variational distribution and using a minibatch of n  N data points. It is straightforward to see that
such doubly stochastic gradients are unbiased estimates of
the true gradients and therefore the whole scheme is valid.
In the experiments, we demonstrate the double stochasticity for learning from very large data sets in Bayesian logistic regression. However, for simplicity in the remainder of
our presentation we will not analyse further the mini-batch
type of stochasticity.
Finally, for inference problems where the dimensionality
of θ is very large and therefore it is impractical to optimise over a full scale matrix C, we can consider a diagonal matrix in which case the scales can be stored in a
D-dimensional strictly positive vector c. Then, the update
over C in Algorithm 1 is replaced by
!
1
∂ log g(θ (t−1) )
(t)
(t−1)
zd + (t−1) , (9)
cd = cd
+ ρt
∂θd
c
d

where d = 1, . . . , D. Notice that when the initial standard distribution φ(z) is fully factorised the above leads
to a fully factorised variational approximation q(θ|µ, c) =
QD
d=1 qd (θd |µd , cd ). While such approach can have lower
accuracy than using the full scale matrix C, it has the great
advantage that it can scale up to thousands or millions of
parameters. In Section 3.2, we use this scheme for variable selection in logistic regression and we also introduce
a novel variational objective function for sparse inference
following the idea of automatic relevance determination.
In the following two sections we elaborate more on the
properties of DSVI by drawing connections with the Gaussian approximation (Section 2.1) and analysing convergence properties (Section 2.2).
2.1. Connection with the Gaussian approximation
The Gaussian approximation, see (Barber & Bishop, 1998;
Seeger, 1999) and more recently (Opper & Archambeau, 2009), assumes a multivariate Gaussian distribution
N (θ|µ, Σ) as a variational distribution to approximate the
exact model posterior which leads to the maximisation of
the lower bound
Z
g(θ)
dθ.
(10)
F(µ, Σ) = N (θ|µ, Σ) log
N (θ|µ, Σ)

Doubly Stochastic Variational Bayes for non-Conjugate Inference

The maximisation relies on analytical integration (or in the
worst case in
R one-dimensional numerical integration) for
computing N (θ|µ, Σ) log g(θ)dθ, which subsequently
can allow to tune the variational parameters (µ, Σ) using gradient optimization methods (Opper & Archambeau,
2009; Honkela et al., 2011). More recently, Challis & Barber (2011; 2013) use this framework with the parametrisation Σ = CC T and show that when log g(θ) is concave, the
bound is concave w.r.t. (µ, C). The limitation of these approaches is that theyR rely on log g(θ) having a simple form
so that the integral N (θ|µ, Σ) log g(θ)dθ is analytically
tractable. Unfortunately, this constraint excludes many interesting Bayesian inference problems, such as inference
over kernel hyperparameters in Gaussian process models,
inference over weights in neural networks and others.
In contrast, our stochastic variational framework only relies on log g(θ) being a differentiable function of θ. If
we specify the distribution φ(z) to be the standard normal N (z|0, I), the lower bound in (4) becomes the Gaussian approximation bound in (10) with the parametrisation
Σ = CC T . Subsequently, if we apply the DSVI iteration according to Algorithm 1 with the specialization that
z is drawn from N (z|0, I), the algorithm will stochastically maximise the Gaussian approximation bound. Therefore, DSVI allows to apply the Gaussian approximation to
a much wider range of models.
A different direction of flexibility in the DSVI framework
is concerned with the choice of the standard distribution
φ(z). Clearly, if we choose a non-Gaussian form we obtain
non-Gaussian variational approximations. For instance,
when this distribution is the standard t with ν degrees of
freedom, i.e. φ(z) = St(z, ν, 0, I), the variational distribution q(θ|µ, C) becomes the general t distribution with ν
degrees of freedom, i.e. q(θ|µ, C) = St(z, ν, µ, CC T ). A
flexible way to define a standardQdistribution is to assume
D
a fully factorised form φ(z) = d=1 φd (zd ) and then select the univariate marginals, φd (z) with d = 1, . . . , D,
from a family of univariate distributions for which exact
simulation is possible. While in such cases the resulting
q(θ|µ, C) can be of non-standard form, simulating exact
samples from this distribution is always straightforward
since θ (s) = Cz + µ, z ∼ φ(z) is by construction an
independent sample from q(θ|µ, C). In the current experimental study presented in Section 3 we only consider the
DSVI algorithm for stochastic maximisation of the Gaussian approximation bound. We defer the experimentation
with other forms of the φ(z) distribution for future work.
2.2. Illustrative convergence analysis
In this section, we informally analyse the convergence behaviour of DSVI, i.e., its ability to locate a local maximum
of the variational lower bound. We will use an illustra-

0

−2

−4

−6

−8

−10

−12

−14

−16

−18

−20
0

100

200

300

400

500

600

700

800

900

1000

Figure 1. The evolution of the lower bound (optimal value is zero)
obtained by the two stochastic approximation methods employing
two alternative stochastic gradients for fitting a 10-dimensional
Gaussian distribution N (θ|m, I) where m was set to the vector
of twos. The variational mean was initialised to the zero vector.
For each method two realisations are shown (one with small and
one with large learning rate). Blue solid lines correspond to DSVI
while green and red lines to the alternative algorithm.

tive example where g(θ) is proportional to a multivariate
Gaussian and we will compare our method with an alternative doubly stochastic approximation approach proposed in
(Paisley et al., 2012). For simplicity next we will be using
the notation f (θ) = log g(θ).
Recall eq. (7), which gives the gradient over the variational
mean µ, that we repeat here for convenience,
Z
N (θ|µ, Σ)∇θ f (θ)dθ,
(11)
where we have also specified the variational distribution
q(θ|µ, C) to be the Gaussian N (θ|µ, Σ) with Σ = CC T .
Based on the above, the implied single-sample stochastic approximation of the gradient is ∇θ(s) f (θ (s) ), where
θ (s) ∼ N (θ|µ, Σ), which is precisely what DSVI uses.
The question that arises now is whether exists an alternative way to write the exact gradient over µ that can give rise
to a different stochastic gradient and more importantly how
the different stochastic gradients compare with one another
in terms of convergence. In turns out that an alternative
expression for the gradient over µ is obtained by directly
differentiating the initial bound in (10) which gives
Z
N (θ|µ, Σ)f (θ)Σ−1 (θ − µ) dθ.
(12)
This form can be also obtained by the general
method in (Paisley et al., 2012) according to which
the gradient over some variational parameter ψ in
a variational
distribution q(θ|ψ) is computed based
R
on f (θ)q(θ|ψ)∇ψ [log q(θ|ψ)] dθ which in the case

Doubly Stochastic Variational Bayes for non-Conjugate Inference

where θ (s) ∼ N (θ|µ, Σ). While sample averages of any
size for both stochastic gradients are unbiased, the second
one suffers from undesirable random walk behaviour when
used for stochastic maximisation of the variational lower
bound. Intuitively, this is because it doesn’t utilise gradient
information from the log joint density f (θ) that could allow to locate quickly a mode of the posterior distribution.
Next we illustrate this using an example.
Suppose f (θ) = log (const × N (θ|m, Σ)), i.e. the joint
density is proportional to a multivariate Gaussian having the same covariance matrix with the variational distribution but different mean m. For further simplification let us set Σ = I. The stochastic gradient used in
DSVI becomes (m − θ (s) ) while the alternative gradient
is f (θ (s) )(θ (s) − µ). Given that we initialise µ far away
from m, the first gradient will allow updating µ essentially via a deterministic transient phase where µ rapidly
moves towards its optimal value m as shown in Figure 1
(blue solid lines) for two different values of the learning
rate (assumed constant during each run). Once the global
maximum area is reached, DSVI diffuses around the global
maximum with a variance that increases with the learning
rate. In contrast, the alternative gradient exhibits random
walk behaviour even in the transient phase (dashed green
and red lines). Intuitively, this can be explained by the
vector θ (s) − µ which determines the direction of movement. Clearly, this vector will point in any direction with
the same probability and what really saves the algorithm
from not diverging is that the random walk is drifted towards the global optimum area due to the penalty imposed
by the scale f (θ (s) ).
The random walk behaviour and high variance of the alternative stochastic gradient is well-acknowledged by Paisley et al. (2012) who devised sophisticated control variate
methods to improve convergence. Furthermore, the method
of Paisley et al. (2012) can be applied to a more general
class of inference problems than ours. However, for the
problems our method is applicable to, we believe it should
be preferred due to its efficiency and algorithmic simplicity.

3. Experiments
In this section, we apply the DSVI algorithm to different
types of non-conjugate models. In Section 3.1 we consider standard concave Bayesian logistic regression, while
in Section 3.2 and 3.3 we further elaborate on logistic regression by discussing how to deal with automatic variable
selection and very large datasets. In Section 3.4 we consider DSVI for Gaussian process hyperparameter inference.

−350
−400

F

−450
−500
−550
−600

Instantaneous value of the DSVI bound
Bound found by Challis&Barber
0

1000

2000

3000

4000

5000

6000

1

10

Sum of quadratic error of µ, C wrt Challis&Barber
Squared error

q(θ|ψ) = N (θ|µ, Σ) and ψ = µ reduces to the expression
in (12). This alternative expression suggests asone-sample

stochastic gradient the quantity f (θ (s) )Σ−1 θ (s) − µ ,

0

10

−1

10

−2

10

0

1000

2000

3000
Likelihood evaluations

4000

5000

6000

Figure 2. Top: Evolution of the instantaneous bound (see supplementary material for a definition) towards the reference value
provided by Challis & Barber (2013). Bottom: Evolution of the
squared error of the parameters, ||µ(t) − µ∗ ||2 + ||C (t) − C ∗ ||2 .

3.1. Bayesian logistic regression
We first consider DSVI for standard Bayesian logistic regression. Given a dataset D ≡ {x̃n , yn }N
n=1 , where
e
x̃n ∈ RD and yn ∈ {−1, +1}, we model the probability of theQoutputs conditional on some weights θ as
N
>
p(y|θ) =
n=1 s(yn xn θ), where s(a) is the logistic
>
function and xn = [1 x̃>
n ] is the input augmented with
an one to account for the bias. Using this likelihood and a
fixed Gaussian prior on the weights p(θ) = N (0, ID ) (with
e + 1), we have fully specified the model and we can
D=D
iterate Algorithm 1 for any given dataset. In this case, since
the likelihood is log-concave, the complete functional (4)
becomes concave so that convergence to the optimal solution is guaranteed. Results using this model are therefore
bound to be identical to those using the method in (Challis
& Barber, 2013), but obtained without the need of numerical quadrature and using instead simpler stochastic gradient
ascent (which of course will need a larger number of iterations to attain convergence).
For the above simple setting and using the well-known
Pima indians diabetes data set from the UCI repository,
we show on Figure 2 the convergence of our method, using the result of running the code from (Challis & Barber,
2013) as a reference. For both methods we assumed a full
scale matrix C so that the complexity per iteration is linear with the number of data points N and quadratic with
the dimensionality D. Only 16 L-BFGS likelihood evaluations are required for the convergence of the reference
method, whereas around 500 evaluations are needed for
DSVI (no stochasticity over the data set was used for this
experiment). However, the actual running time for DSVI
was only around 3 times longer due to its simplicity.

Doubly Stochastic Variational Bayes for non-Conjugate Inference

3.2. Variable selection for logistic regression

values back into the lower bound we obtain

In this section, we consider DSVI for variable selection in
large scale Bayesian logistic regression where the input dimensionality D can be of order of thousands or millions.
For such cases, it is impractical to learn a correlated variational distribution with a full scale matrix C and therefore we use a diagonal scale matrix so that the complexity becomes linear with D. As explained in Section 2, in
such cases the variational
QDapproximation takes a factorised
form, i.e. q(θ|µ, c) = d=1 qd (θd |µd , cd ). Next, based on
the former factorised approximation, we introduce a variational inference algorithm specialised to variable selection.
The starting point of our method is the automatic relevance determination (ARD) idea, as used for instance in
the relevance vector machine (Tipping, 2001). Specifically, the weights θ are assigned a zero-mean Gaussian
prior p(θ) = N (0, Λ) having a diagonal covariance matrix Λ, i.e. Λ = diag(`21 , . . . , `2D ) with each `2d representing the prior variance of θd . We would like to select the hyperparameters Λ by maximising an approximation to the marginal likelihood which, under the variational
framework, reduces to maximising the variational bound
F(µ, c, Λ) w.r.t. both the variational parameters (µ, c) and
the hyperparameters Λ. A standard way to perform this
maximisation is by using variational EM, where we alternate between updating (µ, c) given Λ and updating Λ
given (µ, c). However, this scheme can exhibit slow convergence due to the high dependence between the variational parameters and the hyperparameters. Fortunately, as
we will now show, the optimisation of F(µ, c, Λ) w.r.t.
Λ can be carried out analytically. This results in an elegant and simplified form for the final variational bound, the
maximisation of which can exhibit faster convergence.
Firstly note that while DSVI is generally applicable to any
non-conjugate model, more efficient algorithms could be
obtained for cases in which the expectation (under the variational distribution) for some part of the log joint density can be performed analytically. An example of this is
when the prior p(θ) is Gaussian, as in the above logistic
regression model, where the joint density takes the form
g(θ) = ge(θ)N (0, Λ) with ge(θ) = p(y|θ) denoting the
likelihood. Then, the variational lower bound is explicitly
written in the form
D

F(µ, c, Λ) = Eφ(z) [log ge(c ◦ z + µ)] +

1X
log c2d
2
d=1

−

D
1X

2

d=1

log `2d −

D
1 X c2 + µ2
d

2

d=1

d

`2d

+

D
. (13)
2

The maximum for each hyperparameter `2d can be found
analytically by setting the corresponding gradient to zero,
which yields (`2d )∗ = c2d +µ2d . By substituting these optimal

D

F(µ, c) = Eφ(z) [log ge(c ◦ z + µ)] +

1X
c2
log 2 d 2 .
2
cd + µd
d=1

(14)
This objective function has a rather simple form and it has
the elegant property that it depends solely on the variational parameters (µ, c). The second term in the sum can
be thought of as regularisation term where each individc2d
ual term log c2 +µ
2 encourages sparsity and, for instance,
d
d
it can allow to shrink a variational mean parameter µd to
zero whenever the corresponding input dimension is somehow redundant for solving the classification task. It is
straightforward to apply DSVI to maximise the above variational objective function. All update equations and complete pseudo-code is described by Algorithm 2 in the supplementary material. Next we refer to this algorithm as
DSVI-ARD.
We applied DSVI-ARD for binary classification in three
cancer-related data sets1 that are summarized in Table 1,
in which the input variables are different gene expression
measurements associated with patients and the output variable identify whether the patients have a certain type of
cancer or not; see e.g. (Shevade & Keerthi, 2003). Notice
that in all three datasets the number of training points is
much smaller than the number of input dimensions. Using
DSVI-ARD we solve these binary classification problems
and report predictions in Table 2. For comparison purposes
we also applied standard non-sparse Bayesian logistic regression with a fixed vague Gaussian prior over the parameters (denoted by CONCAV in Table 2). These results show
that the ARD model is more consistent in avoiding overfitting, whereas CONCAV is not so consistent since, for instance, it overfits the Leukemia data set.
To visualize the ability to perform variable selection, the
second row of Figure 3 displays the final values of the variational mean vector µ. Clearly, in all three datasets these
mean vectors are highly sparse which shows that the proposed method is effective in identifying the features (genes)
that are relevant for solving each classification task.
Finally, the learning rate sequences and annealing schedule when applying DSVI-ARD to all above problems was
chosen as follows. The learning rate ρt is initialised to
ρ0 = 0.05/#training examples and scaled every 5000 iterations by a factor of 0.95. This learning rate is used to
update µ, whereas 0.1ρt is used to update c. A total of
105 iterations was considered. The panels in the first row
of Figure 3 show the evolution of averaged values for the
lower bound over the iterations of the algorithm.
1
Available from http://www.csie.ntu.edu.tw/˜
cjlin/libsvmtools/datasets/binary.html.

Doubly Stochastic Variational Bayes for non-Conjugate Inference
Table 1. Size and number of features of each cancer data set.
Data set

#Train

#Test

D

42
38
38

20
34
4

2,000
7,129
7,129

Colon
Leukemia
Breast

Table 2. Train and test errors for the three cancer datasets and for
each method: CONCAV is the original DSVI algorithm with a
fixed prior, whereas ARD is the feature-selection version.
Problem

Train Error

Test Error

0/42
0/42
0/38
0/38
0/38
0/38

1/20
0/20
3/34
12/34
2/4
0/4

Colon (ARD)
Colon (CONCAV)
Leukemia (ARD)
Leukemia (CONCAV)
Breast (ARD)
Breast (CONCAV)

Table 3. Size and sparsity level of each large-scale data set.
#Train

#Test

D

#Nonzeros

32,561
20,242
400,000

16,281
677,399
100,000

123
47,236
2,000

451,592
49,556,258
800,000,000

Data set
a9a
rcv1
Epsilon

We use again the Bayesian logistic regression model with
variable selection and we applied the DSVI-ARD algorithm described previously. For all problems, mini-batches
of size 500 are used, so this process does not ever require the whole data set to be loaded in memory. We
contrast our results with standard `1 -logistic regression,
which exactly minimises the convex functional L(w) =
PN
||w||1 − λ n=1 log s(yn x>
n w). Both methods are run on
the exact same splits. The value of λ was selected using 5fold cross-validation. Results are reported on Table 4 and
show the compromises made between both approaches.
The proposed approach scales well to very large data sets
but it does not outperform `1 -logistic regression in these examples. This is expected, since the number of data points
is so high that there is little benefit from using a Bayesian
approach here. Note, however, the slight advantage obtained for rcv1, where there are a huge number of dimensions. Another benefit of DSVI-ARD is the low memory
requirements (we needed a 32GB RAM computer to run
the `1 -logistic regression, whereas a 4GB one was enough
for DSVI-ARD). In contrast, logistic regression was more
than 100 times faster in achieving convergence (using the
highly optimised LIBLINEAR software).
3.4. Gaussian process hyperparameters

Table 4. Test error rates for DSVI-ARD and `1 -logistic regression
on three large-scale data sets.
Data set

DSVI ARD

Log. Reg.

λ

0.1507
0.0414
0.1014

0.1500
0.0420
0.1011

2
4
0.5

a9a
rcv1
Epsilon

Table 5. Performance measures of GP regression where hyperparameters are selected by ML-II, DSVI or MCMC.
Data set
Boston
Bodyfat
Pendulum

(smse)
(nlpd)
(smse)
(nlpd)
(smse)
(nlpd)

ML-II

DSVI

MCMC

0.0743
0.1783
0.1992
-0.1284
0.2727
0.4537

0.0709
0.1425
0.0726
-2.0750
0.2807
0.4465

0.0699
0.1317
0.0726
-2.0746
0.2801
0.4462

3.3. Large-scale data sets
In order to demonstrate the scalability of the proposed
method, we run it on three well-known large-scale binary
classification datasets a9a, rcv1, and Epsilon, whose
details are listed on Table 3. Data set a9a is derived from
“Adult” in UCI repository, rcv1 is an archive of manually
categorised news stories from Reuters (we use the original
train/test split), and Epsilon is an artificial data set from
PASCAL’s large-scale learning challenge 2008.

Gaussian processes (GPs) are non-parametric Bayesian
models widely used to solve regression tasks. In a typical setting, a regression data set D ≡ {xn , yn }N
n=1 with
xn ∈ RD and yn ∈ R is modelled as yn = f (xn ) + εn ,
where εn ∼ N (0, σ 2 ) and f (x) ∼ GP(0, k(x, x0 ; θ)), for
some kernel hyperparameters θ and noise variance σ 2 .
Point estimates for the hyperparameters are typically obtained by optimising the marginal likelihood of the GP
using some gradient ascent procedure (Rasmussen &
Williams, 2006). Here, we suggest to replace this procedure with stochastic gradient ascent optimisation of the
lower bound that provides a posterior distribution over the
hyperparameters. While the stochastic nature of the proposed method will probably imply that more marginal likelihood evaluations are required for convergence, this additional computational cost will make the model more resistant to overfitting and provide a posterior over the hyperparameters at a fraction of the cost of full MCMC.
− 21

PD

(xd −x0d )2
2

`
d
,
Using a GP with kernel k(x, x0 ) = σf2 e
we place vague independent normal priors over the hyperparameters in log space and compute the posterior and predictive densities for three data sets: Boston, Bodyfat,
and Pendulum. Obviously, for this model, no stochasticity over the data set is used. Boston is a UCI data set related to housing values in Boston, Bodyfat requires predicting the percentage of body fat from several body measurements and in Pendulum the change in angular velocd=1

Doubly Stochastic Variational Bayes for non-Conjugate Inference
0

0

0

−5

−50
−50

−15
−20
−25

Lower bound

−100
Lower bound

Lower bound

−10
−100

−150

−150
−200
−250

−30
−200

−300

−35
−40
0

2

4
6
Iterations

8

−250
0

10
4
x 10

4
6
Iterations

8

−350
0

10
4
x 10

2

4
6
Iterations

8

10
4
x 10

5

6
4
2
0
−2
−4
−6
0

500

1000
Variable index

1500

−5

−10

−15
0

2000

Mean of the Var. Distr.

0
Mean of the Var. Distr.

Mean of the Var. Distr.

2

2000

4000
Variable index

0

−5

−10

6000

0

2000

4000
Variable index

6000

Figure 3. Top: Rolling-window average (see supplementary material) of the instantaneous lower bound values. Bottom: Final value of
the approximate mean vectors µ. First column corresponds to Colon, second to Leukemia and third to Breast dataset.
0.5

2.5

4
3.5

2

0.3

0.2

0.1

3
Density value

Density value

Density value

0.4

1.5

1

2.5
2
1.5
1

0.5

0.5
0
−2

0

2

log(ℓ21 )

4

6

8

0
−0.5

0

0.5
log(σf2 )

1

1.5

0
−4

−3.5

log(σ2 )

−3

−2.5

Figure 4. Marginal variational Gaussian distributions for some hyperparameters in Boston dataset (shown as dashed red lines). The
black solid lines show the ground-truth empirical estimates for these marginals obtained by MCMC.

ity of a simulated mechanical pendulum must be predicted.
Figure 4 displays variational posterior marginal distributions for three of the hyperparameters in the Boston
housing dataset together with the corresponding empirical marginals obtained by long MCMC runs. Clearly, the
variational marginals match very closely the MCMC estimates; see the supplementary material for a complete set of
such figures for all hyperparameters in all three regression
datasets. Furthermore, negative log-predictive densities
(nlpd) as well as standardised mean square errors (smse) in
test data are shown in Table 5 for maximum marginal likelihood model selection (ML-II, the standard for GPs), DSVI
and MCMC. As the table shows, ML-II, which is the most
widely used method for hyperparameter selection in GPs,
overfits the Bodyfat data set. DSVI and MCMC do not
show this problem, yielding much better test performance.
To provide an intuition of the computational effort associated to each of these methods, note that on these experiments, on average ML-II took 40 seconds, DSVI 30 minutes and MCMC 20 hours. Further details on all above GP

regression experiments, including the learning rates used,
are given in the supplementary material.

4. Discussion and future work
We have presented a stochastic variational inference algorithm that utilises gradients of the joint probability density and it is based on double stochasticity (by both subsampling training data and simulating from the variational density) to deal with non-conjugate models and big
datasets. We have shown that the method can be applied
to a number of diverge cases achieving competitive results. Further work should be concerned with speeding the
stochastic approximation algorithm as well as fitting more
complex variational distributions such as mixture models.
Acknowledgments
MKT greatly acknowledges support from “Research Funding at AUEB for Excellence and Extroversion, Action 1:
2012-2014”. MLG gratefully acknowledges support from
Spanish CICYT TIN2011-24533.

Doubly Stochastic Variational Bayes for non-Conjugate Inference

References
Barber, D. and Bishop, C. M. Ensemble learning in
Bayesian neural networks. In Jordan, M., Kearns, M.,
and Solla, S. (eds.), Neural networks and machine learning, pp. 215–237, Berlin, 1998.
Bottou, Léon. Online Algorithms and Stochastic Approximations. In Online Learning and Neural Networks.
Cambridge University Press, 1998.
Bottou, Léon and Bousquet, Olivier. The tradeoffs of large
scale learning. In NIPS, volume 20, pp. 161–168, 2008.
Challis, Edward and Barber, David. Concave gaussian
variational approximations for inference in large-scale
bayesian linear models. In AISTATS, pp. 199–207, 2011.
Challis, Edward and Barber, David. Gaussian kullbackleibler approximate inference. J. Mach. Learn. Res., 14
(1):2239–2286, January 2013.
Hoffman, Matthew D., Blei, David M., and Bach, Francis R. Online learning for latent dirichlet allocation. In
NIPS, pp. 856–864, 2010.
Hoffman, Matthew D., Blei, David M., Wang, Chong,
and Paisley, John William. Stochastic variational inference. Journal of Machine Learning Research, 14(1):
1303–1347, 2013.
Honkela, A., Raiko, T., Kuusela, M., Tornio, M., and
Karhunen, J. Approximate Riemannian conjugate gradient learning for fixed-form variational Bayes. Journal
of Machine Learning Research, 11:3235–3268, 2011.
Jordan, Michael I., Ghahramani, Zoubin, Jaakkola,
Tommi S., and Saul, Lawrence K. An introduction to
variational methods for graphical models. Mach. Learn.,
37(2):183–233, November 1999.
Kingma, Diederik P. and Welling, Max. Auto-encoding
variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Mnih, Andriy and Gregor, Karol. Neural variational inference and learning in belief networks. In The 31st
International Conference on Machine Learning (ICML
2014), 2014.
Neal, Radford M. and Hinton, Geoffrey E. A view of the
em algorithm that justifies incremental, sparse, and other
variants. In Jordan, Michael I. (ed.), Learning in Graphical Models, pp. 355–368. 1999.
Opper, M. and Archambeau, C. The variational Gaussian
approximation revisited. Neural Computation, 21(3):
786–792, 2009.

Paisley, John William, Blei, David M., and Jordan,
Michael I. Variational bayesian inference with stochastic
search. In ICML, 2012.
Ranganath, Rajesh, Gerrish, Sean, and Blei, David. Black
box variational inference. In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics (AISTATS), pp. 814822, 2014.
Rasmussen, C.E. and Williams, C.K.I. Gaussian Processes
for Machine Learning. Adaptive Computation and Machine Learning. MIT Press, 2006.
Rezende, Danilo Jimenez, Mohamed, Shakir, and Wierstra,
Daan. Stochastic backpropagation and approximate inference in deep generative models. In The 31st International Conference on Machine Learning (ICML 2014),
2014.
Robbins, Herbert and Monro, Sutton. A Stochastic Approximation Method. The Annals of Mathematical
Statistics, 22(3):400–407, 1951.
Robert, Christian P. and Casella, George. Monte Carlo
Statistical Methods. Springer-Verlag, 1 edition, August
1999.
Seeger, Matthias. Bayesian model selection for support
vector machines, gaussian processes and other kernel
classifiers. In NIPS 12, pp. 603–609, 1999.
Shevade, Shirish Krishnaj and Keerthi, S. Sathiya. A
simple and efficient algorithm for gene selection using
sparse logistic regression. Bioinformatics, 19(17):2246–
2253, 2003.
Staines, Joe and Barber, David. Variational optimization.
Technical report, 2012.
Tipping, Michael E. Sparse bayesian learning and the relevance vector machine. Journal of Machine Learning
Research, 1:211–244, 2001.
Wainwright, Martin J. and Jordan, Michael I. Graphical models, exponential families, and variational inference. Found. Trends Mach. Learn., 1(1-2):1–305, January 2008.

