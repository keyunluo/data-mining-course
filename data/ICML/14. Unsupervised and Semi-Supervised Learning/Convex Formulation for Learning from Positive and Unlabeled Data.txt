Convex Formulation for Learning from Positive and Unlabeled Data

Marthinus Christoffel du Plessis
The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan
Gang Niu
Baidu Inc., Beijing, 100085, China

NIUGANG @ BAIDU . CN

Masashi Sugiyama
The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, Japan

Abstract
We discuss binary classification from only positive and unlabeled data (PU classification),
which is conceivable in various real-world machine learning problems. Since unlabeled data
consists of both positive and negative data, simply separating positive and unlabeled data yields
a biased solution. Recently, it was shown that
the bias can be canceled by using a particular
non-convex loss such as the ramp loss. However,
classifier training with a non-convex loss is not
straightforward in practice. In this paper, we discuss a convex formulation for PU classification
that can still cancel the bias. The key idea is to
use different loss functions for positive and unlabeled samples. However, in this setup, the hinge
loss is not permissible. As an alternative, we propose the double hinge loss. Theoretically, we
prove that the estimators converge to the optimal
solutions at the optimal parametric rate. Experimentally, we demonstrate that PU classification
with the double hinge loss performs as accurate
as the non-convex method, with a much lower
computational cost.

1. Introduction
Let us consider the problem of learning a classifier only
from positive and unlabeled data. This problem, which refer to as PU classification, arises in various practical situations under different guises. For example:
â€¢ The goal of identification is to find samples in an unlabeled dataset that are similar to the samples provided
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

CHRISTO @ MS . K . U - TOKYO . AC . JP

SUGI @ K . U - TOKYO . AC . JP

by a user. Such a situation occurs, e.g., in automatic
face tagging: a user provides a set of images of himself, and the task is to automatically tag photos in the
userâ€™s photo album.
â€¢ Inlier-based outlier detection is aimed at identifying outliers in an unlabeled dataset based on another
dataset that consists only of inliers (Hido et al., 2008;
Smola et al., 2009). Thanks to the information brought
by the inlier dataset, this inlier-based approach is
more powerful than the conventional completely unsupervised approach. This problem is also known as
semi-supervised novelty detection (Scott & Blanchard,
2009; Blanchard et al., 2010).
â€¢ If the negative class is too diverse, it is difficult to
collect negative data in a representative way. Such a
situation is typically observable in â€œone-vs-restâ€ classification. For example, when classifying land cover
images into urban and non-urban regions (Li et al.,
2011), it is easy to obtain urban samples, but it is difficult to representatively collect diverse non-urban samples.
â€¢ The negative-class dataset shift changes the probability distributions of negative samples between the time
when the training data is collected and when the classifier is applied to the test data. Solving this problem with an ordinary classifier would require constant
generation of the negative dataset to keep up with the
changing distributions. On the other hand, PU classification only requires to update the unlabeled dataset,
which is much less costly. Negative-class dataset shift
may occur in spam detection, where adversarial spammers may change the tendency of negative samples
(â€˜spamâ€™) to defeat the existing classifier, while the
positive class (â€˜non-spamâ€™) is expected to remain stable over time.
Given its wide applicability as described above, PU classification is gathering a great deal of attention these days.
A naive approach to PU classification is to train a classi-

Convex Formulation for Learning from Positive and Unlabeled Data

fier to separate positive and unlabeled samples. However,
such a naive approach yields a poor solution since the unlabeled dataset consists of both positive and negative data.
Although using a loss function weighted according to the
class prior of the unlabeled dataset1 was shown to produce a
better solution (Blanchard et al., 2010; Scott & Blanchard,
2009), the PU classifier trained in this way still has a systematic estimation bias.
Recently, it was shown that using a loss function â„“(z) such
that â„“(z) + â„“(âˆ’z) = 1 can cancel the bias completely. For
example, the ramp loss, which is used in the robust support
vector machine (Collobert et al., 2006; Wu & Liu, 2007),
satisfies this condition2 . Classifier training with the ramp
loss can be performed, e.g,. via the convex-concave procedure (CCCP) (Yuille & Rangarajan, 2002). However, nonconvex optimization is computationally expensive and only
a sub-optimal local solution may be obtained. Another nonconvex formulation was proposed in Smola et al. (2009).
To overcome this weakness of the non-convex formulation,
we analyze a formulation of PU classification that is convex
but can still cancel the bias. The key idea is to use different loss functions for positive and unlabeled samples: an
ordinary convex loss function â„“(z) for unlabeled samples
and a composite loss function â„“(z) âˆ’ â„“(âˆ’z) for positive
samples3 . If â„“(z) âˆ’ â„“(âˆ’z) is a convex function, the entire objective function becomes convex and thus the global
solution can be obtained efficiently. The logistic loss and
the squared loss immediately yield convex composite loss
functions. On the other hand, the composite loss derived
from the hinge loss is not convex, but the modified hinge
loss with an extra kink (which we call the double hinge
loss) yields a convex composite loss.
Theoretically, we prove that the estimators converge to the
optimal solutions at the optimal parametric rate. Experimentally, the superior accuracy and computational advantage of the proposed double hinge loss is illustrated on
benchmark datasets.

Formulation of PU classification: Let x âˆˆ Rd be a ddimensional pattern and y âˆˆ {1, âˆ’1} be a class label. We
assume that we have a positive dataset X , and an unlabeled
dataset X â€² i.i.d. as
n

X := {xi }i=1 âˆ¼ p(x|y = 1),

 	nâ€²
X â€² := xâ€²j j=1 âˆ¼ p(x),

where p(x|y) is the class-conditional density of patterns
and p(x) is the marginal density of patterns. Since the unlabeled dataset X â€² consists of positive and negative samples, the marginal density is p(x) := Ï€p(x|y = 1) + (1 âˆ’
Ï€)p(x|y = âˆ’1). The goal is to learn a classifier g(x) that
assigns a label yb to a new pattern x as yb = sign (g(x)).

The optimal classifier g âˆ— is given by g âˆ—
=
arg mingâˆˆG J0-1 (g), where J0-1 (g) is the expected
misclassification rate when the classifier g(x) is applied to
unlabeled samples distributed according to p(x):
J0-1 (g) = Ï€E1 [â„“0-1 (g(X))]+(1âˆ’Ï€)Eâˆ’1 [â„“0-1 (âˆ’g(X))] ,
(1)

where the zero-one loss is â„“0-1 (z) =

1
2

sign(z) + 12 .

PU classification by non-convex loss minimization: In
the ordinary classification setting where positive and negative samples are available for classifier training, the expectations E1 and Eâˆ’1 in Eq. (1) can be estimated by corresponding sample averages. In the PU classification setting, however, no labeled samples from the negative class
is available and therefore Eâˆ’1 cannot be estimated directly.
This problem can be avoided by expressing J0-1 (g) as follows (du Plessis et al., 2014):
J0-1 (g) = 2Ï€E1 [â„“0-1 (g(X))] + EX [â„“0-1 (âˆ’g(X))] âˆ’ Ï€,
(2)

2. Non-convex PU classification

where EX denotes the expectation over p(x). This comes
from

In this section, we formulate the problem of PU classification and review the non-convex PU classification method
proposed in du Plessis et al. (2014).

EX [â„“0-1 (âˆ’g(X))]

1
Several methods have been introduced to estimate this class
prior (e.g., Scott & Blanchard, 2009; du Plessis & Sugiyama,
2014).
2
Loss function â„“(z) that satisfies â„“(z) + â„“(âˆ’z) = 1 is always
non-convex.
3
Note that this idea has been previously shown in the context
of learning from noisy labels (Natarajan et al., 2013). For correct
parameter choice, PU learning can be interpreted as a special case
of learning with noisy labels.

= Ï€E1 [â„“0-1 (âˆ’g(X))] + (1 âˆ’ Ï€)Eâˆ’1 [â„“0-1 (âˆ’g(X))]
= Ï€ (1 âˆ’ E1 [â„“0-1 (g(X))]) + (1 âˆ’ Ï€)Eâˆ’1 [â„“0-1 (âˆ’g(X))] ,
where the last line is due to â„“0-1 (âˆ’z) = 1 âˆ’ â„“0-1 (z). Note
that Eq. (2) corresponds to the cost-sensitive classification
(Elkan, 2001) with weights 2Ï€/Î· and 1/(1 âˆ’ Î·), where Î·
is the proportion of positive samples to unlabeled samples.
In practice, minimizing Eq. (2) is problematic since the
subgradient of the zero-one loss is zero everywhere except
when z = 0. For this reason, the zero-one loss is often

Convex Formulation for Learning from Positive and Unlabeled Data

substituted with a surrogate loss function4 â„“(z):

JPU (g) = 2Ï€E1 [â„“(g(X))] + Ï€E1 [â„“(âˆ’g(X))]

+ (1 âˆ’ Ï€)Eâˆ’1 [â„“(âˆ’g(X))] âˆ’ Ï€

â„“(z)

= Ï€E1 [â„“ (g(X))] + (1 âˆ’ Ï€)Eâˆ’1 [â„“(âˆ’g(X))]
{z
}
|
Ordinary error term

+ Ï€E1 [â„“(g(X)) + â„“(âˆ’g(X))] âˆ’Ï€.
|
{z
}
Superfluous penalty

The first and second terms correspond to the ordinary classification loss, while the third term is a superfluous term
that is specific to the PU classification setting. Due to the
superfluous term, a systematic estimation bias is incurred
by naive surrogate loss minimization.
However, as shown in du Plessis et al. (2014), the superfluous term can be canceled when the loss function satisfies
â„“(z) + â„“(âˆ’z) = 1. Note that this condition is met only by
non-convex loss functions such as the ramp loss5 .
Non-convex loss functions are, however, often problematic
in practice due to the difficulty of non-convex optimization
and the existence of local sub-optimal solutions. In the next
section, we explore an alternative way to remove the superfluous penalty.

z
Figure 1. Selected loss functions.

e is the difWhen â„“(z) is convex, the composite loss â„“(z)
ference between two convex functions. The key question
is whether the composite loss can be convex, which makes
Eq.(3) a convex function. The following simple theorem
(proven in Appendix A.1) positively answer the question.
e is convex, it is linear.
Theorem 1. If the composite loss â„“(z)
Various losses are illustrated in Fig. 1 (definitions are in
Table 1). A simple calculation shows that some losses, such
as the Hinge loss, do not result in a linear composite loss.

For simplicity, let us always normalize the losses so that the
e = âˆ’z. This results in an objective
composite loss is â„“(z)
function of
J(g) = Ï€E1 [âˆ’g(X)] + EX [â„“ (âˆ’g(X))] .

3. Convex PU classification
In this section, we give the formulation for convex PU classification.
Formulation: Let us consider another expression of
J0-1 (g) based on
(1 âˆ’ Ï€)Eâˆ’1 [â„“0-1 (âˆ’g(X))]

(4)

Note that the above is a special case of the previously proposed estimator in Natarajan et al. (2013) for learning from
label noise. For appropriate parameter choices, the learning
with label noise problem is reduced to PU learning.
Empirical version: In practice, we use a linear-inparameter model for function g(x):

= EX [â„“0-1 (âˆ’g(X))] âˆ’ Ï€E1 [â„“0-1 (âˆ’g(X))] .

g(x) = Î±âŠ¤ Ï•(x) + b,

(5)

Substituting this into Eq. (1), we obtain


âŠ¤
Ï•1 (x) . . . Ï•m (x)
where Ï•(x) =
is a set
J0-1 (g) = Ï€E1 [â„“0-1(g(X))âˆ’â„“0-1 (âˆ’g(X))]+EX [â„“0-1 (âˆ’g(X)] . of basis functions.
For basis functions, we may
use, e.g., the Gaussian functions
centered around

 samIf the zero-one loss is replaced with a surrogate loss â„“(z),
2
2
ple
points
Ï•
(x)
=
exp
âˆ’kx
âˆ’
c
k
/(2Ïƒ
)
, where
â„“
â„“
we have
â€²
â€²
i
h
{c1 , . . . , cm } = {x1 , . . . , xn , x1 , . . . , xnâ€² }, and m =
e
J(g) = Ï€E1 â„“(g(X))
+ EX [â„“(âˆ’g(X))] ,
(3)
n + nâ€² . Alternatively, linear or polynomial functions can
e is the composite loss: â„“(z)
e
where â„“(z)
= â„“(z) âˆ’ â„“(âˆ’z).
Eq.(3) corresponds to using an ordinary loss for unlabeled
samples and a composite loss for positive samples.
4

Examples of surrogate loss functions are illustrated in Fig. 1.
Many surrogate loss functions are convex, which results in convex
optimization problems.
5
The same condition was also proved in Ghosh et al. (2014)
for learning with label noise.

be used as basis functions. Using this model, Eq. (3) can
be empirically estimated as
b b) = âˆ’ Ï€
J(Î±,
n

n
X

Î±âŠ¤ Ï•(xi ) âˆ’ Ï€b

i=1

â€²

n
 Î»
1 X
+ â€²
â„“ âˆ’Î±âŠ¤ Ï•(xâ€²j ) âˆ’ b + Î±âŠ¤ Î±,
n j=1
2

Convex Formulation for Learning from Positive and Unlabeled Data

where the last term is for regularization. In Eq. (4), the first
two terms are always positive. However, it may happen
in degenerate cases, due to inadequate regularization, that
the first two terms in the above empirical criterion are not
bounded below by zero. To avoid numerical difficulties,
we may in practice constrain these two terms to be nonnegative.
The last remaining choice to obtain a practical algorithm is
the choice of the loss function â„“(z). We will discuss several
choices in the following section.

4. Convex loss functions for PU classification
In this section, various practical choices of convex loss
functions are explored.

Logistic loss: The logistic loss is defined as â„“LL (z) =
log(1 + exp(âˆ’z)). We therefore wish to minimize the objective function:
JLL (g) = âˆ’Ï€E1 [g(X)] + EX [log(1 + exp(g(X)))] .
(7)
The logistic loss is monotone decreasing when z > 1, so in
this sense it is preferable over the squared loss for classification.
The proposed method can be related to ordinary logistic
regression. The objective function for ordinary logistic regression is
EX [â„“LL (g(X))] = Ï€E1 [log (1 + exp(âˆ’g(X)))]
+ (1 âˆ’ Ï€)Eâˆ’1 [log (1 + exp(g(X)))] .

Squared loss: The squared loss, defined as â„“S (z) =
2
1
We use the identity log(1 + exp(âˆ’z)) = âˆ’z + log(1 +
4 (z âˆ’ 1) , results in the following objective function:
exp(z)) in the first term to get
i
h
1
2
JS (g) = âˆ’Ï€E1 [g(x)] + EX (g(X) + 1)
(6)
4Z
EX [â„“LL (g(X))] = âˆ’Ï€E1 [g(X)]
Z
1
1
2
+ Ï€E1 [log(1 + exp(g(X)))]
g(x) p(x)dx âˆ’
g(x)[2Ï€p1 (x) âˆ’ p(x)]dx + C,
=
4
2
+ (1 âˆ’ Ï€)Eâˆ’1 [log(1 + exp(g(X))] .
where C is an irrelevant constant. Let us assign a class label
y for x according to the difference of class-posteriors:
By collecting the last two terms into EX , we see that this
is equivalent to Eq. (7). This implies that ordinary logistic
r(x) = p(y = 1|x) âˆ’ p(y = âˆ’1|x)
regression can be exactly performed in the PU classification
= [p(x|y = 1)Ï€ âˆ’ p(x|y = âˆ’1)(1âˆ’Ï€)] /p(x)
setup.
= [2Ï€p(x|y = 1) âˆ’ p(x))] /p(x).
The regularized empirical approximation for the objective
Then our objective function corresponds to the leastfunction in Eq. (7) is
squares fitting of the difference of posteriors r(x) to a
model g(x) up to an irrelevant constant:
n
Ï€X âŠ¤
Î»
2
Z 
JbLL (Î±, b) = âˆ’
Î± Ï•(xi ) âˆ’ Ï€b + Î±âŠ¤ Î±
1
2Ï€p1 (x) âˆ’ p(x)
n i=1
2
p(x)dx.
g(x) âˆ’
4
p(x)
nâ€²

1 X
An advantage of this squared-loss formulation is that it can
â„“LL âˆ’Î±âŠ¤ Ï•(xjâ€² ) âˆ’ b . (8)
+ â€²
n j=1
be analytically solved. For example, when b is omitted
from the model Eq. (5), the objective function with the â„“2 This function is continuous and differentiable, therefore
regularizer becomes
optimization can be performed using a quasi-Newton
1 âŠ¤
1
1 Î¦U Î±
JbS (Î±) = â€² Î±âŠ¤ Î¦âŠ¤
method (see Appendix B for details).
U Î¦U Î± +
â€²
4n
2n
Î»
Ï€
âˆ’ 1âŠ¤ Î¦P Î± + Î±âŠ¤ Î±,
Hinge and double hinge losses: The hinge loss is den
2
fined
as â„“H (z) = 21 max(0, 1 âˆ’ z). From Table 1 we see
where [Î¦P ]iâ„“ = Ï•â„“ (xi ), and [Î¦U ]jâ„“ = Ï•â„“ (xâ€²j ). The minithat the composite loss â„“eH (z) is not a linear function. This
mizer of this objective function can be analytically obtained
non-convex composite loss would lead to an undesirable
as
non-convex optimization problem.

âˆ’1 

1
Ï€ âŠ¤
1 âŠ¤
1
.
Î¦U Î¦U + Î»I
Î¦P 1 âˆ’ â€² Î¦âŠ¤
Î±=
We can, however, obtain a convex objective func2n
n
2n U
tion if the loss is slightly
 modified as â„“DH (z) =
max âˆ’z, max 0, 21 âˆ’ 21 z . Since this loss function has
However, a drawback of the squared loss function is that
an extra kink at z = âˆ’1, we refer to it as the double hinge
the function increases as z > 1. This is undesirable, since
loss (see Fig. 1). For this loss function, the composite loss
a model that correctly classifies the sample when z > 1 is
penalized.
term is â„“eDH (z) = âˆ’z, which is a convex function.

Convex Formulation for Learning from Positive and Unlabeled Data

Table 1. A selected list of loss functions and their composite losses. Losses with a linear composite loss function was normalized so that
e = âˆ’z.
â„“(z)
e
Loss name
Notation â„“(z)
â„“(z)
Notes
2

1

1

Modified Huber loss

â„“MH (z)

Logistic loss

â„“LL (z)

(z âˆ’ 1) âˆ’ 4
4
(
1
max(0, 1 âˆ’ z)2
4
âˆ’z
log(1 + exp(âˆ’z))

Hinge loss

â„“H (z)

1
2

Double hinge loss
Perceptron loss
Boosting loss

â„“DH (z)
â„“P (z)
â„“EXP (z)

max(âˆ’z, max(0,
max(âˆ’z, 0)
exp(âˆ’z)

â„“S (z)

Square loss

max(0, 1 âˆ’ z)
1
2

The empirical optimization problem for the double hinge
loss is
n
Î»
Ï€X âŠ¤
b
Î± Ï•(xi ) âˆ’ Ï€b + Î±âŠ¤ Î±
JDH (Î±, b) = âˆ’
n i=1
2
â€²

n

1 X
â„“DH âˆ’Î±âŠ¤ Ï•(xâ€²j ) âˆ’ b .
+ â€²
n j=1

(9)

As in the standard support vector machines, we may rewrite
the minimization of the above criterion as a quadratic program by using slack variables Î¾ to bound the max operators:
min

âˆ’ nÏ€ 1âŠ¤ Î¦P Î± âˆ’ Ï€b +

s.t.

Î¾ â‰¥ 0,
Î¾ â‰¥ 21 1 + 21 Î¦U Î± + 12 b1,
Î¾ â‰¥ Î¦U Î± + b1,

Î±,b,Î¾

1 âŠ¤
nâ€² 1 Î¾

z â‰¥ âˆ’1
z < âˆ’1

+ Î»2 Î±âŠ¤ Î±

where â‰¥ is applied element-wise on vectors.

5. Discussion
In this section, we discuss the relation between PU classification and inlier-based outlier detection (Hido et al., 2008;
Smola et al., 2009).
The objective of inlier-based outlier detection is to find outliers in an unlabeled dataset based on an inlier dataset. Regarding inliers as samples from the positive class, we can
show that the class-posterior p(y = 1|x) is proportional to
the ratio of the densities between the positive samples and
unlabeled samples:

âˆ’ 21 z))

âˆ’z

Convex

âˆ’z

Convex

âˆ’z
ï£±
1
ï£´
z â‰¤ âˆ’1,
ï£² 2 (1 âˆ’ z)
âˆ’z
âˆ’1 â‰¤ z â‰¤ 1,
ï£´
ï£³ 1 (âˆ’1 âˆ’ z) z â‰¥ 1.
2
âˆ’z
âˆ’z
exp(âˆ’z) âˆ’ exp(z)

Convex
Non-convex
Convex
Convex
Non-convex

and unlabeled datasets separately and then computing the
ratio of estimated densities. However, this two-step procedure is undesirable since high-dimensional density estimation is often unreliable and taking their ratio can further
magnify the estimation error. To cope with this problem, in
Keziou (2003) and Nguyen et al. (2007), the following objective function for density ratio estimation was introduced:
Z
Z
sup g(x)p(x|y = 1)dxâˆ’ f âˆ— (g(x))p(x)dx, (10)
g

where f (t) is a convex function such that f (1) = 0, and
f âˆ— (z) = supt tz âˆ’ f (t) denotes its Fenchel dual. Eq.(10)
is actually a lower bound of the f -divergence from p(x|y =
1) to p(x) (Ali & Silvey, 1966):

Z 
p(x|y = 1)
p(x)dx.
f
p(x)
Eq.(10) is maximized at g = r if r(x) âˆˆ âˆ‚f âˆ— (g(x)) (i.e.,
the solution is a function of the density ratio). This estimator has been used for inlier-based outlier detection under the Kullback-Leibler divergence (Kullback & Leibler,
1951) in Smola et al. (2009) and under the Pearson divergence (Pearson, 1900) in Hido et al. (2008).
On the other hand, in PU classification, we are interested in
the sign of the difference of class-posterior probabilities:
p(y = 1|x) âˆ’ p(y = âˆ’1|x) âˆ

Ï€p(x|y = 1) 1
âˆ’ , (11)
p(x)
2

Since the density ratio r(x) will tend to take large values
for inliers and small values for outliers, it can be used for
outlier detection.

which also includes the density ratio r(x). Thus, inlierbased outlier detection and PU classification are highly related to each other. However, an important difference is
that inlier-based outlier detection requires an outlier score
for evaluating the outlyingness of samples, while PU classification requires the threshold between the positive and
negative classes. Because of this difference, Eq.(11) also
contains the class prior probability p(y = 1) = Ï€.

The density ratio r(x) can be naively estimated by first estimating the densities p(x|y = 1) and p(x) from the positive

Nevertheless, we can utilize the density-ratio framework
of f -divergence estimation in PU classification. Indeed,

p(y = 1|x) âˆ

p(x|y = 1)
= r(x).
p(x)

Convex Formulation for Learning from Positive and Unlabeled Data

Table 2. Conjugates and the corresponding loss function for PU
learning (cf. Table 1).
fÂ¯(t)
fÂ¯âˆ— (z)
Loss
(t âˆ’ 12 )2

1
(z + 1)2 âˆ’ 14
4
(
1
max(0, 1 + z)2 âˆ’ 41 z â‰¤ 1
4
(t âˆ’ 21 )2 , 0 â‰¤ t â‰¤ 1
z âˆ’ 14
z>1

|2tâˆ’1|, 0 â‰¤ t â‰¤ 1
max z, max 0,21 + 21 z âˆ’ 12
(1 âˆ’ t) ln(1 âˆ’ t)
ln(1 + exp(z))
+t ln(t)

â„“S (z)
â„“MH (z)
â„“DH (z)
â„“LL (z)

Our main idea is to regard three empirical objectives as
perturbed optimizations of three expected objectives, and
to establish Lipschitzian behavior of optimal solutions to
the perturbed optimizations. Without loss of generality, assume that 0 â‰¤ Ï•j (x) â‰¤ 1 for all j = 1, . . . , m and x âˆˆ R,
b 2 â‰¤ MÎ±
and that there exists a constant MÎ± such that kÎ±k
b to any optimization if Î±âŠ¤ Î± is
for the optimal solution Î±
regularized. To begin with, we have the following secondorder growth conditions.
Lemma 2. It holds that

Eq. (4) can be expressed as
Z
Z
sup Ï€ g(x)p(x|y = 1)dx âˆ’ fÂ¯âˆ— (g(x))p(x)dx,

JS (Î±) â‰¥ JS (Î±Sâˆ— ) + Î»kÎ± âˆ’ Î±âˆ—S k22 ,
JLL (Î±) â‰¥ JLL (Î±âˆ—LL ) + Î»kÎ± âˆ’ Î±âˆ—LL k22 ,
JDH (Î±) â‰¥ JLL (Î±âˆ—DH ) + Î»kÎ± âˆ’ Î±âˆ—LL k22 .

g

(12)

where fÂ¯âˆ— (t) corresponds to the loss function. Note that
Eq.(12) is an upper bound of

Z 
Î¸p(x|y = 1)
Â¯
p(x)dx.
f
p(x)
For different fÂ¯(t), we can recover the squared loss, modified Huber loss, double hinge loss and logistic loss, as
shown in Table 2.

6. Theoretical Analysis
In this section, we establish convergence results for the proposed methods. Assume that the number of basis functions m is a constant independent of n and nâ€² , i.e., g(x)
is parametric,
Pm and the bias b is ignored for simplicity:
g(x) = j=1 Î±j Ï•j (x) = Î±âŠ¤ Ï•(x). Assume that the ideal
estimates are given by
Î±âˆ—S = arg min JS (Î±),
Î±âˆ—LL = arg min JLL (Î±),
Î±âˆ—DH = arg min JDH (Î±),
respectively, where we plug g(x) into the original objectives JS (g), JLL (g) and JDH (g). We also assume that the
empirical estimates are given by
b S = arg min JbS (Î±),
Î±
b LL = arg min JbLL (Î±),
Î±

b DH = arg min JbDH (Î±).
Î±

We then derive convergence rates of the empirical estimates
and the empirical objectives based on a theory known as
perturbation analysis of optimization problems (see Bonnans & Shapiro, 1998; Bonnans & Cominetti, 1996, and
references therein).

First, consider the squared loss. Let u = {u1 , u2 , u3 |
m
u1 âˆˆ S+
, u2 âˆˆ Rm , u3 âˆˆ Rm } be a set of perturbation
m
âŠ‚ RmÃ—m is the cone of m-by-m
parameters, where S+
positive semi-definite matrices. Define our perturbed objective function by

Z
1 âŠ¤
âŠ¤
Ï•(x)Ï•(x) p(x)dx + u1 Î±
JS (Î±, u) = Î±
4
âŠ¤
Z
1
Î±
Ï•(x)p(x)dx + u2
+
2
âŠ¤
Z
Î»
âˆ’Ï€
Î± + Î±âŠ¤ Î±,
Ï•(x)p1 (x)dx + u3
2
Î±S (u) = arg minÎ± JS (Î±, u).

It is obvious that JS (Î±) = JS (Î±, 0), and JbS (Î±) =
JS (Î±, u), where
Z
n
1 X
â€²
â€² âŠ¤
Ï•(xi )Ï•(xi ) âˆ’ Ï•(x)Ï•(x)âŠ¤ p(x)dx,
u1 = â€²
n i=1
â€²

Z
n
1 X
â€²
u2 = â€²
Ï•(xi ) âˆ’ Ï•(x)p(x)dx,
n i=1
Z
n
1X
Ï•(xi ) âˆ’ Ï•(x)p1 (x)dx.
u3 =
n i=1
â€²

(13)

Lemma 3. The difference function JS (Â·, u) âˆ’ JS (Â·) is Lipschitz continuous modulus Ï‰(u) = O(ku1 kFro + ku2 k2 +
ku3 k2 ) on a sufficiently small neighborhood of Î±âˆ—S .
Theorem 4. As n, nâ€² â†’ âˆž, we have
b S âˆ’ Î±âˆ—S k2 = Op (nâˆ’1/2 + nâ€²âˆ’1/2 ),
kÎ±

b S ) âˆ’ JS (Î±âˆ—S )| = Op (nâˆ’1/2 + nâ€²âˆ’1/2 ).
|JbS (Î±

Second, consider the logistic loss. Let U be a Banach space
of Lipschitz continuous functions u : Rm 7â†’ R equipped

Convex Formulation for Learning from Positive and Unlabeled Data

with a sup-norm kukâˆž = supÎ± |u(Î±)|. Let u = {u3 , u4 |
u3 âˆˆ Rm , u4 âˆˆ U } be a set of perturbation parameters,
and define our perturbed objective functional by
âŠ¤
Z
Î±
JLL (Î±, u) = âˆ’Ï€
Ï•(x)p1 (x)dx + u3
Z
Î»
+ ln(1 + exp(Ï•(x)âŠ¤ Î±))p(x)dx + u4 (Î±) + Î±âŠ¤ Î±,
2
Î±LL (u) = arg minÎ± JLL (Î±, u).
It is not difficult to see that JLL (Î±) = JLL (Î±, 0) where
0 âˆˆ U , and JbLL (Î±) = JLL (Î±, u) where
Z
n
1X
u3 =
Ï•(xi ) âˆ’ Ï•(x)p1 (x)dx,
n i=1
â€²

n
1 X
ln(1 + exp(Ï•(xâ€²i )âŠ¤ Î±))
u4 (Î±) = â€²
n i=1
Z
âˆ’ ln(1 + exp(Ï•(x)âŠ¤ Î±))p(x)dx.

(14)

Lemma 5. The difference function JLL (Â·, u)âˆ’JLL (Â·) is Lipschitz continuous modulus Ï‰(u) = O(ku3 k2 + Lip(u4 ))
on a sufficiently small neighborhood of Î±âˆ—LL , where Lip(u4 )
is the best Lipschitz constant of u4 .
Theorem 6. As n, nâ€² â†’ âˆž, we have
b LL âˆ’ Î±âˆ—LL k2 = Op (nâˆ’1/2 + nâ€²âˆ’1/2 ),
kÎ±

b LL ) âˆ’ JLL (Î±âˆ—LL )| = Op (nâˆ’1/2 + nâ€²âˆ’1/2 ).
|JbLL (Î±

Finally, consider the double hinge loss. Here we use a similar set of perturbation parameters u = {u3 , u5 } as the
logistic loss, and define our perturbed objective functional
by
âŠ¤
Z
Î±
JDH (Î±, u) = âˆ’Ï€
Ï•(x)p1 (x)dx + u3


Z
1 + Ï•(x)âŠ¤ Î±
, Ï•(x)âŠ¤ Î± p(x)dx
+ max 0,
2
Î» âŠ¤
+ u5 (Î±) + Î± Î±,
2
Î±DH (u) = arg minÎ± JDH (Î±, u).
It is easy to see that JDH (Î±) = JDH (Î±, 0) where 0 âˆˆ U ,
and JbDH (Î±) = JDH (Î±, u) where
Z
n
1X
u3 =
Ï•(xi ) âˆ’ Ï•(x)p1 (x)dx,
(15)
n i=1


nâ€²
1 + Ï•(xâ€²i )âŠ¤ Î±
1 X
â€² âŠ¤
, Ï•(xi ) Î±
max 0,
u5 (Î±) = â€²
n i=1
2


Z
1 + Ï•(x)âŠ¤ Î±
âŠ¤
, Ï•(x) Î± p(x)dx.
âˆ’ max 0,
2

Lemma 7. The difference function JDH (Â·, u) âˆ’ JDH (Â·)
is Lipschitz continuous modulus Ï‰(u) = O(ku3 k2 +
Lip(u5 )) on a sufficiently small neighborhood of Î±âˆ—DH .
Theorem 8. As n, nâ€² â†’ âˆž, we have
b DH âˆ’ Î±âˆ—DH k2 = Op (nâˆ’1/2 + nâ€²âˆ’1/2 ),
kÎ±

b DH ) âˆ’ JDH (Î±âˆ—DH )| = Op (nâˆ’1/2 + nâ€²âˆ’1/2 ).
|JbDH (Î±

To sum up, the empirical estimates and the empirical objectives converge in Op (nâˆ’1/2 + nâ€²âˆ’1/2 ) to the corresponding
targets in all of three cases. This is the optimal convergence
rate, since it is of order Op (nâˆ’1/2 ) when approximating
an expectation by an empirical average based on n data.
Note that there is a generalization error bound in du Plessis
et al. (2014) that is also of order Op (nâˆ’1/2 + nâ€²âˆ’1/2 ) under the problem setting of PU classification. Nevertheless,
their proposed method is non-convex and has no convergence analysis. As a consequence, our proposed methods
are advantageous because they possess both bounds of the
convergence rate and generalization error.

7. Experiments
In this section we report experimental results.
Numerical illustrations: We numerically illustrate the
effect of multiple local minima for the ramp loss on a simple numerical problem. The two class-conditional distributions are


p(x|y = 1) = Nx 2, 12 and p(x|y = âˆ’1) = Nx âˆ’2, 12 ,
where N (Âµ, Ïƒ 2 ) denotes the univariate normal distribution
with mean Âµ and variance Ïƒ 2 . We generate 10 positive
samples and, using a class prior of Ï€ = 0.5, generate 20
unlabeled samples. Using a model g(x) = wx + b, and
choosing Î» = 10âˆ’3 we plot the value of the objective function w.r.t. to w and b in Fig. 2. Even in this simple problem,
we see that the ramp loss function has multiple minima. We
see in Fig. 3 that the bad local minimum leads to a worse
classification result.

Next, we illustrate the failure of applying ordinary classifiers in the PU learning problem due to the superfluous
penalty term. The positive and negative classes are distributed as U (0.1, 1) and U (âˆ’1.1, âˆ’0.1), where U (a, b) is
the uniform density between a and b. This dataset is trivially separable and the offset âˆ’b/w of a classifier should
always be in the range [âˆ’0.1, 0.1]. Drawing different
datasets and training classifiers on it gives the results in
Fig. 4. In this simple example, we see that directly using
the hinge loss and logistic loss result in a wrong classification boundary â€“ even in fully separable datasets. Our
proposed method and the ramp loss yield correct solutions.

Convex Formulation for Learning from Positive and Unlabeled Data

w

0.3
0.2
0.1

-b/w

J

Densities and decision boundaries

0.4

0

âˆ’0.1

LogReg
Câˆ’LL
Hinge
Câˆ’DH
Ramp

âˆ’0.2
âˆ’0.3
âˆ’0.4
0.2

0.3

0.4

b

Figure 3. Resulting discriminant boundary for the ramp loss minima P1 and P2
and the double hinge loss. P1 (with a
higher value) is an inferior classifier.

Average execution time [sec]

Figure 2. Objective value of the ramp loss
w.r.t. w and b, illustrating multiple local minima. The objective value for P1 is
higher than P2 .

0.5

0.6

0.7

0.8

True class-prior

Figure 4. Average offset âˆ’b/w for different classifiers trained on the fullyseparable problem. Correct classifiers
should be between -0.1 and 0.1.

Table 3. Classification accuracy (in percent) of the proposed
methods. Best and equivalent methods (under 5% t-test) are bold.
Dataset
0 vs 1
0 vs 2

Figure 5. Average execution time of different methods

Benchmark datasets: We performed experiments illustrating the method on the MNIST dataset. The following
methods were compared:
â€¢ LogReg, Hinge: Training a weighted classifier with
the logistic loss and the hinge loss. These methods are
convex, but subject to the superfluous penalty.
â€¢ C-LL, C-DH (proposed): The convex methods proposed in Sec. 4 using the logistic loss and double hinge
loss.
â€¢ Ramp: The method of du Plessis et al. (2014) using the non-convex ramp loss. The objective function
was minimized using the convex-concave procedure
(Yuille & Rangarajan, 2002; Collobert et al., 2006)
(see Appendix B.4 for a detailed discussion).

0 vs. 3
0 vs 4
0 vs 5
0 vs 6
0 vs 7
0 vs 8
0 vs 9

All methods used the same model. Hyperparameters were
selected via cross-validation on the zero-one loss objective
in Eq. (2). The â€œ0" digit was used for the positive class,
and another digit was used for the negative class (i.e., one
dataset for each digit â€œ1". . . â€œ9"). Dimensionality was reduced to 2 via principal component analysis and 200 positive samples and 400 unlabeled samples were drawn. The
class prior was varied across experiments, but it is assumed
that the class prior is known at training time6 .
The classification accuracy is given in Table 3. From this
we, see that the ramp-loss and the proposed double hinge
loss give accurate results. The comparison in average computational time (Fig. 5) shows however that our proposed
double hinge loss method is significantly faster.
6
In practice, it may be estimated with methods such as (Blanchard et al., 2010; du Plessis & Sugiyama, 2014).

Ï€
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7
0.1
0.4
0.7

LogReg
3.1%
8.9%
8.8%
4.2%
11.8%
11.2%
4.1%
11.9%
11.3%
3.7%
10.8%
10.2%
5.0%
14.4%
13.4%
4.1%
11.6%
11.6%
3.7%
10.4%
10.2%
4.0%
11.4%
10.8%
4.0%
11.1%
10.5%

C-LL
0.8%
1.3%
1.5%
3.0%
6.0%
6.9%
2.7%
5.8%
6.9%
1.8%
3.9%
4.4%
4.1%
9.4%
11.1%
3.1%
6.4%
7.1%
2.0%
4.0%
5.0%
2.8%
5.8%
6.4%
2.7%
4.8%
5.3%

Hinge
0.7%
1.6%
1.8%
3.1%
7.4%
7.6%
2.9%
7.4%
7.5%
2.1%
5.0%
5.3%
4.4%
11.5%
13.2%
3.1%
7.8%
7.8%
2.2%
4.9%
5.0%
2.8%
6.9%
7.9%
2.9%
5.7%
5.8%

C-DH
0.5%
0.9%
0.6%
2.8%
5.3%
5.1%
2.5%
5.1%
5.1%
1.6%
2.8%
2.7%
4.0%
9.4%
10.5%
2.9%
5.9%
6.0%
1.7%
3.0%
2.8%
2.6%
5.1%
5.3%
2.5%
4.1%
3.8%

Ramp
0.5%
0.8%
1.0%
2.7%
5.3%
5.4%
2.5%
5.1%
5.4%
1.4%
2.5%
2.8%
3.9%
9.3%
10.0%
2.8%
5.8%
6.1%
1.5%
2.8%
3.1%
2.6%
5.0%
5.3%
2.4%
4.0%
3.9%

8. Conclusion
We discussed a convex framework for learning from positive and unlabeled data. Theoretically, it was shown that the
proposed estimators converge to the optimal solutions at
the optimal parametric rate. Experimentally it was shown
that PU classification with the proposed double hinge loss
perform as accurate as the non-convex ramp-loss method,
but with a much lower computational burden. Furthermore,
we related the convex PU learning framework to several f divergence estimation based PU learning methods.
Acknowledgements
JST CREST.

MCdP and MS were supported by

Convex Formulation for Learning from Positive and Unlabeled Data

References
Ali, S. M. and Silvey, S. D. A general class of coefficients
of divergence of one distribution from another. Journal
of the Royal Statistical Society, Series B, 28:131â€“142,
1966.
Blanchard, G., Lee, G., and Scott, C. Semi-supervised novelty detection. Journal of Machine Learning Research,
11:2973â€“3009, 2010.
Bonnans, F. and Cominetti, R. Perturbed optimization in
banach spaces I: A general theory based on a weak directional constraint qualification; II: A theory based on
a strong directional qualification condition; III: Semiinfinite optimization. SIAM Journal on Control and Optimization, 34:1151â€“1171, 1172â€“1189, and 1555â€“1567,
1996.
Bonnans, F. and Shapiro, A. Optimization problems with
perturbations, a guided tour. SIAM Review, 40(2):228â€“
264, 1998.
Collobert, R., Sinz, F. H., Weston, J., and Bottou, L. Trading convexity for scalability. In Proceedings of 23rd International Conference on Machine Learning, pp. 201â€“
208, 2006.
du Plessis, M. C. and Sugiyama, M. Class prior estimation
from positive and unlabeled data. IEICE Transactions
on Information and Systems, E97-D, 2014.
du Plessis, M. C, Niu, G., and Sugiyama, M. Analysis of
learning from positive and unlabeled data. In Advances
in Neural Information Processing Systems 27, pp. 703â€“
711. 2014.
Elkan, C. The foundations of cost-sensitive learning. In In
Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, pp. 973â€“978, 2001.
Ghosh, A., Manwani, N., and Sastry, P. S. Making risk minimization tolerant to label noise. CoRR, abs/1403.3610,
2014.
Hido, S., Tsuboi, Y., Kashima, H., Sugiyama, M., and
Kanamori, T. Inlier-based outlier detection via direct
density ratio estimation. In Proceedings of IEEE International Conference on Data Mining, pp. 223â€“232,
2008.
Keziou, A. Dual representation of Ï†-divergences and applications. Comptes Rendus MathÃ©matique, 336(10):857â€“
862, 2003.
Kullback, S. and Leibler, R. A. On information and sufficiency. Annals of Mathematical Statistics, 22:79â€“86,
1951.

Li, W., Guo, Q., and Elkan, C. A positive and unlabeled
learning algorithm for one-class classification of remotesensing data. IEEE Transactions on Geoscience and Remote Sensing, 49(2):717â€“725, 2011.
Natarajan, N., Dhillon, I.S., Ravikumar, P.K., and Tewari,
A. Learning with noisy labels. In Advances in Neural
Information Processing Systems, pp. 1196â€“1204, 2013.
Nguyen, X.-L., Wainwright, M. J., and Jordan, M. I. Nonparametric estimation of the likelihood ratio and divergence functionals. In Proceedings of IEEE International
Symposium on Information Theory, pp. 2016â€“2020, june
2007.
Pearson, K. On the criterion that a given system of deviations from the probable in the case of a correlated system
of variables is such that it can be reasonably supposed to
have arisen from random sampling. Philosophical Magazine, 50:157â€“175, 1900.
Scott, C. and Blanchard, G. Novelty detection: Unlabeled
data definitely help. In Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics, pp. 464â€“471, 2009.
Smola, A. J., Song, L., and Teo, C. H. Relative novelty
detection. In Proceedings of the Twelfth International
Conference on Artificial Intelligence and Statistics, pp.
536â€“543, 2009.
Wu, Y. and Liu, Y. Robust truncated hinge loss support
vector machines. Journal of the American Statistical Association, 102(479):974â€“983, 2007.
Yuille, A. L. and Rangarajan, A. The concave-convex procedure (CCCP). In Advances in Neural Information Processing Systems 14, pp. 1033â€“1040. MIT Press, 2002.

