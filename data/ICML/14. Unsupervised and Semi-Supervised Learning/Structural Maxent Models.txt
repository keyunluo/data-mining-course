Structural Maxent Models
Corinna Cortes
Google Research, 111 8th Avenue, New York, NY 10011

CORINNA @ GOOGLE . COM

Vitaly Kuznetsov
Courant Institute of Mathematical Sciences, 251 Mercer Street, New York, NY 10012

VITALY @ CIMS . NYU . EDU

Mehryar Mohri
Courant Institute and Google Research, 251 Mercer Street, New York, NY 10012

MOHRI @ CIMS . NYU . EDU

Umar Syed
Google Research, 111 8th Avenue, New York, NY 10011

Abstract
We present a new class of density estimation
models, Structural Maxent models, with feature functions selected from a union of possibly very complex sub-families and yet benefiting from strong learning guarantees. The design of our models is based on a new principle
supported by uniform convergence bounds and
taking into consideration the complexity of the
different sub-families composing the full set of
features. We prove new data-dependent learning
bounds for our models, expressed in terms of the
Rademacher complexities of these sub-families.
We also prove a duality theorem, which we use
to derive our Structural Maxent algorithm. We
give a full description of our algorithm, including
the details of its derivation, and report the results
of several experiments demonstrating that its performance improves on that of existing L1 -norm
regularized Maxent algorithms. We further similarly define conditional Structural Maxent models for multi-class classification problems. These
are conditional probability models also making
use of a union of possibly complex feature subfamilies. We prove a duality theorem for these
models as well, which reveals their connection
with existing binary and multi-class deep boosting algorithms.

Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

USYED @ GOOGLE . COM

1. Introduction
Maximum entropy models, commonly referred to as Maxent models, are density estimation methods used in a
variety of tasks in natural language processing (Berger
et al., 1996; Rosenfeld, 1996; Pietra et al., 1997; Malouf,
2002; Manning & Klein, 2003; Ratnaparkhi, 2010) and in
many other applications, including species habitat modeling (Phillips et al., 2004; 2006; DudÄ±Ìk et al., 2007; Elith
et al., 2011).
Maxent models are based on the density estimation principle advocated by Jaynes (1957), which consists of selecting
the distribution that is the closest to the uniform distribution
or to some other prior, while ensuring that the average value
of each feature matches its empirical value. When closeness is measured in terms of the relative entropy, Maxent
models are known to coincide with Gibbs distributions, as
in the original Boltzmann models in statistical mechanics.
One key benefit of Maxent models is that they allow the
use of diverse features that can be selected and augmented
by the user, while in some other popular density estimation techniques such as n-gram modeling in language processing, the features are inherently limited. The richness
of the features used in many tasks as well as small sample
sizes have motivated the use of regularized Maxent models where the L1 -norm (Kazama & Tsujii, 2003) or the
L2 -norm (Chen & Rosenfeld, 2000; Lebanon & Lafferty,
2001) of the parameter vector defining the Gibbs distribution is controlled. This can be shown to be equivalent to
the introduction of a Laplacian or Gaussian prior over the
parameter vector in a Bayesian interpretation (Williams,
1994; Goodman, 2004). Group sparsity regularizations can
also be used with for example L1 - and L2 -norms: the parameter vector is partitioned into blocks with L2 -norm used

Structural Maxent Models

within blocks and L1 -norm for combining blocks (Huang
& Zhang, 2010).
An extensive theoretical study of these regularizations and
the introduction of other more general ones were presented
by DudÄ±Ìk et al. (2007). The generalization guarantees for
regularized Maxent models depends on the sample size and
the complexity of the family of features used. This dependency suggests using relatively simpler feature families,
such as threshold functions over the input variables. However, feature functions selected from simpler families could
excessively limit the expressiveness of the model.
This paper introduces and studies a new family of density
estimation models, Structural Maxent models, which offers
the flexibility of selecting features out of complex families, while benefiting from strong learning guarantees. Let
H1 , . . . , Hp be p families of feature functions with increasing complexity. Hk could be for example the family of
regression trees of depth k or that of monomials of degree
k based on the input variables. The main idea behind the
design of our model is to allow the use of features from the
family of very deep trees or other rich or complex families
(that is, Hk s with relatively large k), but to reserve less total model parameter weight for such features than for those
chosen from simpler families (Hk s with smaller k). We
call our Maxent models structural since they exploit the
structure of H as a union of Hk s. Note, however, that the
main idea behind the design of our models is distinct from
that of structural risk minimization (SRM) (Vapnik, 1998):
while SRM seeks a single Hk with an optimal trade-off between empirical error and complexity, structural Maxent allocates different model weights to features in different Hk s
to achieve an even better trade-off based on multiple Hk s.
In the following, we first define a new Structural Maxent principle for the general scenario where feature functions may be selected from multiple families (Section 2.1).
Our new principle takes into consideration the different
complexity of each of these families and is supported by
data-dependent uniform convergence bounds. This principle guides us to design our new Structural Maxent models, whose regularization depends on the data-dependent
complexity of each of the feature families. We study
the optimization problem for Structural Maxent models
and present a duality theorem showing the equivalence of
the primal and dual problems, which can be viewed as
a counterpart of the duality theorem for standard Maxent
(Pietra et al., 1997) (see also (DudÄ±Ìk et al., 2007)) (Section 2.2). Next, we present data-dependent learning guarantees for our Structural Maxent models in terms of the
Rademacher complexity of each of the feature families
used (Section 2.3). The amount of total parameter weight
apportioned to each family in our models is quantitatively
determined by our new Maxent principle and further jus-

tified by these learning guarantees. In Section 2.4, we
describe in detail our StructMaxent algorithm, including
the details of its derivation and its pseudocode. Our algorithm consists of applying coordinate descent to the dual
objective function proceeding in the same way as (DudÄ±Ìk
et al., 2007) for L1 -norm regularized Maxent. We derive
two versions of our algorithm differing only by the definition of the step, which is based on minimizing different
upper bounds. The first version of our algorithm uses the
same upper bounding technique as DudÄ±Ìk et al. (2007) for
L1 -norm regularized Maxent, and, as with the algorithm
of DudÄ±Ìk et al. (2007), is subject to several assumptions.
The second version of our algorithm does not require any
assumption and leads to a simpler analysis, at the cost of
only slightly slower convergence. We prove convergence
guarantees for both versions of our algorithm.
In Section 3, we further extend our ideas to the scenario
of multi-class classification. We present a new conditional
Maxent principle for the case where multiple feature families are used (Section 3.1), which leads to the definition of
our conditional Structural Maxent models. These are conditional probability models that admit as a special case existing conditional Maxent models, or, equivalently, multinomial logistic regression models. We prove a duality theorem showing the equivalence of the primal and dual optimization problems for our conditional Structural Maxent
models. This shows that these models precisely coincide
with the DeepBoost algorithms of Cortes et al. (2014) and
Kuznetsov et al. (2014) in the special case where the surrogate loss function used is the logistic function. Thus, our
algorithm benefits from the data-dependent learning guarantees and empirical validation already presented for deep
boosting. Conversely, our analysis and new conditional
structural Maxent principle provide an alternative justification in support of deep boosting. In Section 4, we report
the results of extensive experiments with data from various
domains including community crimes, traffic and species
habitat modeling. Our results show the advantage of our
structural Maxent models for density estimation when compared to existing regularized Maxent models.

2. Structural Maxent models
Let X denote the input space. We first consider the following problem of density estimation. Assume that a sample
S = (x1 , . . . , xm ) âˆˆ X m of m points drawn from an unknown distribution D is given and that we have at our disposal a feature vector Î¦(x) associated to each point x âˆˆ X .
Then, the standard density estimation problem consists of
using the sample S and the features to find a distribution p
that forms a good estimate of D.
We consider the general case of infinite families of feature
functions. Note that even standard families of threshold

Structural Maxent Models

functions over a finite set of variables have infinite size.
Let H1 , . . . , Hp be p â‰¥ 1 families of functions mapping X
to R with each feature function falling in one of these families. Assume that the Hk s have increasing Rademacher
complexities. For example, H1 may be composed of some
simple feature functions Ï†, H2 the set of all products Ï†Ïˆ
with Ï†, Ïˆ âˆˆ H1 , and, more generally, Hk may contain all
monomials of degree k over functions in H1 . In fact, it
is common in some applications where Maxent is used to
design new features precisely in this manner, starting with
some basic features, here H1 . Similarly, Hk may be the set
of regression trees of depth k with node questions based on
threshold functions of some set of variables or, more complex functions of these variables as in splines.
2.1. Principle
The key idea behind our new Maxent formulation is to take
into consideration the distinct complexity of each family of
feature functions Hk . Let Î¦ be the feature mapping from
X to the space F, with F = F1 Ã— Â· Â· Â· Ã— Fp . For any x âˆˆ X ,
Î¦(x) can be decomposed as Î¦(x) = (Î¦1 (x), . . . , Î¦p (x)),
with Î¦k a mapping from X to Fk such that kÎ¦k kâˆ â‰¤ Î›,
for all k âˆˆ [1, p], and with each of its components Î¦k,j
in Hk . By a standard Rademacher complexity bound
(Koltchinskii & Panchenko, 2002) and the union bound, for
any Î´ > 0, the following inequality holds with probability
at least 1 âˆ’ Î´ over the choice of a sample of size m:




 E [Î¦k (x)] âˆ’ E [Î¦k (x)] â‰¤
s
xâˆ¼D
xâˆ¼S
âˆ
log 2p
Î´
, (1)
2Rm (Hk ) + Î›
2m
for all k âˆˆ [1, p]. Here, we denote by Exâˆ¼S [Î¦k (x)] the
expected value of Î¦k with respect to the empirical distribution defined by the sample S. Let p0 be a distribution
over X with p0 [x] > 0 for all x âˆˆ X , typically chosen to
be the uniform distribution. In view of (1), our extension of
the maximum entropy principle (see Jaynes (1957; 1983))
consists of selecting p as the distribution that is the closest
to p0 and that verifies for all k âˆˆ [1, p]:




 E [Î¦k (x)] âˆ’ E [Î¦k (x)] â‰¤ 2Rm (Hk ) + Î²,
xâˆ¼p

xâˆ¼S

âˆ

where Î² > 0 is a parameter. Here, closeness is measured
using the relative entropy. Let âˆ† denote the simplex of
distributions over X , then, our structural Maxent principle
can be formulated as the following optimization problem:
min D(p k p0 ),
s.t. âˆ€k âˆˆ [1, p] :
(2)
pâˆˆâˆ†




 E [Î¦k (x)] âˆ’ E [Î¦k (x)] â‰¤ 2Rm (Hk ) + Î².
xâˆ¼p

xâˆ¼S

âˆ

Since the relative entropy, D, is convex with respect to
its arguments and since the constraints are affine, this defines a convex optimization problem. The solution is in fact

unique since the relative entropy is strictly convex. Since
the empirical distribution is a feasible point, problem (2) is
feasible. For any convex set K, let IK denote the function
defined by IK (x) = 0 if x âˆˆ K, IK (x) = +âˆ otherwise. Then, the problem can be equivalently expressed as
minp F (p) where
F (p) = D(p k p0 ) + Iâˆ† (p) + IC (E[Î¦]),
p

(3)

where âˆ† is the simplex and where C is the convex set defined by C = {u : kuk âˆ’ ES [Î¦k ]kâˆ â‰¤ Î²k , âˆ€k âˆˆ [1, p]},
with Î²k = 2Rm (Hk ) + Î².
2.2. Dual problem
As for the standard Maxent models with L1 constraints
(Kazama & Tsujii, 2003) (see also (DudÄ±Ìk et al., 2007)), we
can derive an equivalent dual problem for (2) or (3) formulated as a regularized maximum likelihood problem over
Gibbs distributions. Let G be the function defined for all w
in the dual of F by

 X
p
m
pw [xi ]
1 X
log
âˆ’
Î²k kwk k1 ,
(4)
G(w) =
m i=1
p0 [xi ]
k=1

wÂ·Î¦(x)

P
wÂ·Î¦(x)
with pw = p0 [x]eZw
and Zw =
.
xâˆˆX p0 [x]e
N
For simplicity, we assume that the dual of F is R . Then,
the following theorem gives a result similar to the duality
theorem of (Pietra et al., 1997).
Theorem 1. Problems (2) and (3) are equivalent to the
dual optimization problem supwâˆˆRN G(w):
sup G(w) = min F (p).
wâˆˆRN

(5)

p

Furthermore, let pâˆ— = argminp F (p), then, for any  > 0
and any w such that |G(w) âˆ’ supwâˆˆRN G(w)| < , the
following inequality holds: D(pâˆ— k pw ) â‰¤ .
The proof is given in Appendix A (Theorem 1). In view
of the theorem, if w is an -solution of the dual optimization problem, then D(pâˆ— k pâˆš
w ) â‰¤ , which, by Pinskerâ€™s
inequality implies that pw is 2-close in L1 -norm
âˆš to the
optimal solution of the primal: kpâˆ— âˆ’ pw k1 â‰¤ 2. Thus,
the solution of our structural Maxent problem can be determined by solving the dual problem, which can be written
equivalently as follows:
p
X

m

1 X
log pw [xi ].
N
m i=1
wâˆˆR
k=1
(6)
The difference in problem (6) with respect to the common
L1 -regularized Maxent problem is the remarkable new second term, which is defined by the Rademacher complexities
of the Hk s. This term penalizes more the norm of a weight
vector wk associated to a feature vector selected from a
complex hypothesis set Hk .
inf Î²kwk1 + 2

Rm (Hk )kwk k1 âˆ’

Structural Maxent Models

2.3. Generalization bound
Let LD (w) denote the log-loss of the distribution pw with
respect to a distribution D, LD (w) = Exâˆ¼D [âˆ’ log pw [x]],
and similarly LS (w) its log-loss with respect to the empirical distribution defined by a sample S.
b be a solution to the optiTheorem 2. Fix Î´ > 0.qLet w
log

2p
Î´

mization (6) with Î² = Î›
2m . Then, with probability at
b is bounded by
least 1 âˆ’ Î´ over the sample S, LD (w)
s


p
X
log 2p
Î´
inf LD (w) + 2
kwk k1 2Rm (Hk ) + Î›
.
w
2m
k=1

Proof. Using the definition of LD (w) and LS (w),
HoÌˆlderâ€™s inequality, and inequality (1), with probability at
least 1 âˆ’ Î´, the following holds:

=
â‰¤
â‰¤

k=1
p
X
k=1
p
X

b k Â· [E[Î¦k ] âˆ’ E[Î¦k ]]
w
D

S

b k k1 k E[Î¦k ] âˆ’ E[Î¦k ]kâˆ
kw
S

D

b k k1 (Î² + 2Rm (Hk )).
kw

k=1

b is a minimizer, we can write for any w
Thus, since w
b âˆ’ LD (w)
LD (w)
b âˆ’ LS (w)
b + LS (w)
b âˆ’ LD (w)
= LD (w)
â‰¤
â‰¤

p
X
k=1
p
X

b k k1 (Î² + 2Rm (Hk )) + LS (w)
b âˆ’ LD (w)
kw
kwk k1 (Î² + 2Rm (Hk )) + LS (w) âˆ’ LD (w)

k=1
p
X

â‰¤2

p
X

Î²k kwk k1 âˆ’wÂ·E[Î¦]+log

k=1

S

X


p0 [x]ewÂ·Î¦(x) ,

xâˆˆX

and Î²k = Î² + 2Rm (Hk ) for k âˆˆ [1, p]. Function F is not
differentiable but it is convex and admits a subdifferential
at any point. For notational simplicity, we will assume that
each Fk is finite.
2.4.1. D IRECTION
Let wtâˆ’1 denote the weight vector defined after (t âˆ’ 1)
iterations. At each iteration t âˆˆ [1, T ], the direction ek,j ,
(k, j) âˆˆ [1, p] Ã— [1, Nk ], with Nk being the size of Fk ,
considered by coordinate descent is Î´F (wtâˆ’1 , ek,j ).

F 0 (wtâˆ’1 , ek,j ) = Î²k sgn(wtâˆ’1,k,j ) + tâˆ’1,k,j .

D

S

F (w) =

If wtâˆ’1,k,j 6= 0, then F admits a directional derivative
along ek,j given by

b âˆ’ LS (w)
b
LD (w)
b Â· [E[Î¦] âˆ’ E[Î¦]]
=w
p
X

Pm
1
âˆ’m
i=1 log p0 [xi ], the optimization problem (6) can be
rewritten as inf w F (w) with

kwk k1 (Î² + 2Rm (Hk )),

k=1

where we used in the last step the left inequality counterpart
of inequality (1). This concludes the proof.

where tâˆ’1,k,j = Epwtâˆ’1[Î¦k,j ] âˆ’ ES [Î¦k,j ]. If wtâˆ’1,k,j = 0,
F admits right and left directional derivatives along ek,j :
F+0 (wtâˆ’1 , ek,j ) = Î²k + tâˆ’1,k,j and Fâˆ’0 (wtâˆ’1 , ek,j ) =
âˆ’Î²k + tâˆ’1,k,j . Thus, in summary, we can write,
Î´F (wtâˆ’1 , ek,j ) =
ï£±
ï£´
ï£²Î²k sgn(wtâˆ’1,k,j ) + tâˆ’1,k,j
0
ï£´
ï£³
âˆ’Î²k sgn(tâˆ’1,k,j ) + tâˆ’1,k,j

if (wtâˆ’1,k,j 6= 0)


else if tâˆ’1,k,j  â‰¤ Î²k
otherwise.

The coordinate descent algorithm selects the direction ek,j
with the largest numeric value of Î´F (wtâˆ’1 , ek,j ).
2.4.2. T WO ALTERNATIVE STEP SIZES
Given the direction ek,j , the optimal step value Î· is given
by argminÎ· F (wtâˆ’1 + Î· ek,j ). Î· can be found via a line
search or other numerical methods. We can also derive a
closed-form solution for the step by minimizing an upper
bound on F (wtâˆ’1 + Î· ek,j ). We present closed-form solutions based on two different but related upper bounds. The
full argument is given in Appendix C. In what follows, we
highlight the main steps of these derivations.
Observe that

This bound suggests that learning with feature functions
selected from highly complex families (relatively large
Rm (Hk )) can benefit from favorable learning guarantees
so long as the total weight assigned to these features by the
model is relatively small.

F (wtâˆ’1 + Î· ek,j ) âˆ’ F (wtâˆ’1 )

2.4. Algorithm

Since Î¦k,j âˆˆ [âˆ’Î›, +Î›], by the convexity of x 7â†’ eÎ·x , we
can write

Our algorithm consists of applying coordinate descent to
the objective function of (6). Ignoring the constant term

(7)

= Î²k (|wk,j + Î·| âˆ’ |wk,j |) âˆ’ Î· E[Î¦k,j ] + log
S

h

E [e

Î·Î¦k,j

pwtâˆ’1

S TEP SIZE â€“ S TRUCT M AXENT 1

eÎ·Î¦k,j â‰¤

Î›âˆ’Î¦k,j âˆ’Î·Î›
2Î› e

+

Î¦k,j +Î› Î·Î›
2Î› e .

i
] .

Structural Maxent Models

Taking the expectation and the log yields

for all (k, j) âˆˆ [1, p] Ã— [1, Nk ] and s âˆˆ {âˆ’1, +1}.

S TRUCT M AXENT 2(S = (x1 , . . . , xm ))
1 for t â† 1 to T do
2
for k â† 1 to p and j â† 1 to Nk do
3
if (wtâˆ’1,k,j 6= 0) then
4
dk,j â† Î²k sgn(wtâˆ’1,k,j ) + tâˆ’1,k,j
5
elseif |tâˆ’1,k,j | â‰¤ Î²k then
6
dk,j â† 0
7
else dk,j â† âˆ’Î²k sgn(tâˆ’1,k,j ) + tâˆ’1,k,j
8
(k, j) â†
argmax
|dk,j |

Plugging back this inequality in (7) and minimizing the
resulting upper bound on F (wtâˆ’1 + Î· ek,j ) âˆ’ F (wtâˆ’1 )
leads to the closed-form expression for the step size Î·. The
full pseudocode of the algorithm using this closed-form
solution for the step size, StructMaxent1, is given in Appendix B.

9
10
11
12
13
14

if (|wtâˆ’1,k,j Î›2 âˆ’ tâˆ’1,k,j | â‰¤ Î²k ) then
Î· â† âˆ’wtâˆ’1,k,j
elseif (wtâˆ’1,k,j Î›2 âˆ’ tâˆ’1,k,j > Î²k ) then
Î· â† Î›12 [âˆ’Î²k âˆ’ tâˆ’1,k,j ]
else Î· â† Î›12 [Î²k âˆ’ tâˆ’1,k,j ]
wt â† wtâˆ’1 + Î·ek,j

Note that the following condition on Î¦, Î› and Î²k must be
satisfied:

15

pwt â†

log E [eÎ·Î¦k,j ] â‰¤ log



+
Î¦tâˆ’1,k,j eÎ·Î›

pwtâˆ’1


âˆ’
Î¦tâˆ’1,k,j eâˆ’Î·Î›

âˆ’
2Î›

,

where we used the following notation:
s

Î¦tâˆ’1,k,j =

s

E [Î¦k,j ] + sÎ›

Î¦k,j = E[Î¦k,j ] + sÎ›,

pwtâˆ’1

S

(k,j)âˆˆ[1,p]Ã—[1,Nk ]

( E [Î¦k,j ] 6âˆˆ {âˆ’Î›, +Î›}) âˆ§ (| E[Î¦k,j ]| < Î› âˆ’ Î²k ). (8)

pwtâˆ’1

S

This first version of StructMaxent uses the same upper
bounding technique as the L1 -norm regularized Maxent algorithm of DudÄ±Ìk et al. (2007), which is subject to the same
type of conditions as (8).
S TEP SIZE â€“ S TRUCT M AXENT 2
An alternative method is based on a somewhat looser upper bound for log Epwtâˆ’1 [eÎ·Î¦k,j ] using Hoeffdingâ€™s lemma.
A key advantage is that the analysis is no more subject
to conditions such as (8). Additionally, the StructMaxent2 algorithm is much simpler. The price to pay is a
slightly slower convergence but, as pointed out in Section 4, both algorithms exhibit an exponential convergence
and lead to the same results. By Hoeffdingâ€™s lemma, since
Î¦k,j âˆˆ [âˆ’Î›, +Î›], we can write
log E [eÎ·Î¦k,j ] â‰¤ Î· E [Î¦k,j ] +
pwtâˆ’1

pwtâˆ’1

Î· 2 Î›2
.
2

Combining this inequality with (7) and minimizing the resulting upper bound leads to an alternative closed-form solution for the step size Î·. Figure 1 shows the pseudocode
of our algorithm using the closed-form solution for the step
size just presented.

P

p0 [x]ewt Â·Î¦(x)
p0 [x]ewt Â·Î¦(x)

xâˆˆX

16 return pwt
Figure 1. Pseudocode of the StructMaxent2 algorithm. For all
(k, j) âˆˆ [1, p] Ã— [1, Nk ], Î²k = 2Rm (Hk ) + Î² and tâˆ’1,k,j =
Epwtâˆ’1[Î¦k,j ] âˆ’ ES [Î¦k,j ]. Note that no technical assumption such
as those of (8) are required here for the closed-form expressions
of the step size.

The full proof of this result is given in Appendix D. We also
remark that if the step size is determined via a line search,
then our algorithms benefit from an exponential convergence rate (Luo & Tseng, 1992).

3. Conditional Structural Maxent Models
In this section, we extend the analysis presented in the previous section to that of conditional Maxent models, also
known as multinomial logistic regression.
We consider a multi-class classification problem with c â‰¥ 1
classes and denote by Y = {1, . . . , c} the output space
and by D the distribution over X Ã— Y from which pairs
(x, y) âˆˆ X Ã— Y are drawn i.i.d. As in standard supervised learning problems, the learner receives a labeled sample S = ((x1 , y1 ), . . . , (xm , ym )) âˆˆ (X Ã— Y)m and, as
in Section 2.1, we assume the learner has access to a feature function Î¦ : X Ã— Y â†’ F that can be decomposed as
Î¦ = (Î¦1 , . . . , Î¦p ), where for any k âˆˆ [1, p], Î¦k is a mapping from X Ã— Y to Fk with elements in Hk .

2.5. Convergence analysis

3.1. Principle

The following result gives convergence guarantees for both
versions of our StructMaxent algorithm.

Our conditional Structural Maxent, or structural logistic regression models can be defined in a way similar to that of
density estimation. Here, the problem consists of learning a
conditional probability p[Â·|x] for all x âˆˆ X . As in the density estimation case, we will denote by p0 [Â·|x] a conditional

Theorem 3. Let (wt )t be the sequence of parameter vectors generated by StructMaxent1 or StructMaxent2. Then,
(wt )t converges to the optimal solution wâˆ— of (6).

Structural Maxent Models

probability, often chosen to be the uniform distribution.
As in the density estimation case, the definition of our
algorithm is guided by a generalization bound expressed
in terms of the Rademacher complexity of the families
Hk . For any Î´ > 0, the following inequality holds with
probability at least 1 âˆ’ Î´ over the choice of a sample of
size m, for all k âˆˆ [1, p]:




 E [Î¦k (x, y)] âˆ’ E [Î¦k (x, y)] â‰¤ Î²k , (9)


xâˆ¼b
p
yâˆ¼D[Â·|x]

xâˆ¼b
p
yâˆ¼b
p[Â·|x]

âˆ

where we denote by ES the expectation over the empirical
distribution
defined by sample S and Î²k = 2Rm (Hk ) +
q
log 2 p
Î´
2m

. Let b
p denote the empirical distribution of the input points. Our structural conditional Maxent model is defined by searching the conditional probabilities p[Â·|x] that
are as close as possible to p0 [Â·|x], while ensuring an inequality similar to (9), where closeness is defined via the
conditional relative entropy based on b
p (Cover & Thomas,
2006). This leads to the following convex optimization
problem:
X

b
min
p[x] D p[Â·|x] k p0 [Â·|x]
(10)
p[Â·|x]âˆˆâˆ†

Furthermore, let pâˆ— = argminp Fe(p). Then, for any  > 0
e
e
and any w hsuch that |G(w)
âˆ’ sup
N G(w)| < , we
i wâˆˆR
âˆ—
have Exâˆ¼bp D p [Â·|x] k p0 [Â·|x] â‰¤ .
The proof of the theorem is given in Appendix A (Theorem 4). As in the non-conditional case, the theorem suggests that the solution of our structural conditional Maxent
problem can be determined by solving the dual problem,
which can be written equivalently as follows:
p
X

m


1 X
log pw [yi |xi ] .
inf Î²kwk1 +2
Rm (Hk )kwk k1 âˆ’
w
m i=1
k=1
(14)
We note that problem (14) coincides with the optimization
problem presented by Cortes et al. (2014) and Kuznetsov
et al. (2014) for the DeepBoost algorithms in the particular
case where the logistic function is used as a convex surrogate loss function. Our analysis and derivation starting
from the conditional Maxent principle provide an alternative justification for these algorithms. In return, our conditional StructMaxent algorithm benefits from the learning
guarantees already given by deep boosting.

xâˆˆX


h

s.t.  E
xâˆ¼b
p

E

i
[Î¦k (x, y)] âˆ’

yâˆ¼p[Â·|x]

â‰¤ 2Rm (Hk ) + Î²,

E
(x,y)âˆ¼S



[Î¦k (x, y)]

âˆ

âˆ€k âˆˆ [1, p],

where we again denote by âˆ† the simplex in Y. Let p denote the vector of conditional probabilities (p[Â·|xi ])iâˆˆ[1,m] .
Then, this problem can be equivalently expressed as
minp Fe(p) where






e
F (p) = E D p[Â·|x] k p0 [Â·|x] +Iâˆ† p[Â·|x] +IC E [Î¦] ,
xâˆ¼b
p

xâˆ¼b
p
yâˆ¼p[Â·|x]

(11)
where âˆ† is the simplex and C the convex set defined by
C = {u : kuk âˆ’ ES [Î¦k ]kâˆ â‰¤ Î²k , âˆ€k âˆˆ [1, p]}, with Î²k =
2Rm (Hk ) + Î².
3.2. Dual problem
e be the function defined for all w âˆˆ RN by
Let G

 X
p
m
pw [yi |xi ]
1 X
e
log
âˆ’
Î²k kwk k1 , (12)
G(w)
=
m i=1
p0 [yi |xi ]
k=1

wÂ·Î¦(x)

and Zw (x) =
with, for all x âˆˆ X , pw [y|x] = p0 [x]e
Zw (x)
P
wÂ·Î¦(x)
. Then, the following theorem gives a
xâˆˆX p0 [x]e
result similar to the duality theorem presented in the nonconditional case.
Theorem 4. Problem (10) is equivalent to dual optimizae
tion problem supwâˆˆRN G(w):
e
sup G(w)
= min Fe(p).
wâˆˆRN

p

(13)

4. Experiments
This section reports the results of our experiments with
the StructMaxent algorithm. We have fully implemented
both StructMaxent1 and StructMaxent2 with diverse feature families and will make the software used in our experiments available as open-source. We do not report empirical results for the conditional StructMaxent algorithm
since, as already pointed out, the conditional algorithm coincides with the deep boosting algorithms that have been
already extensively studied by Cortes et al. (2014).
Our StructMaxent algorithm can be applied with a variety
of different families of feature functions Hk mapping the
input space X to R. In our experiments, we used the union
of two broad classes of feature maps: monomial features
H mono and tree features H trees . Let H1mono = {Ïˆ1 , . . . , Ïˆd }
denote the set of raw features mapping X to R. We define Hkmono = {Ïˆj1 Â· Â· Â· Ïˆjk : jr âˆˆ [1, d]} as the set of all
monomials of degree k derived from H1mono and H mono as
mono
the union of all these families: H mono = âˆªâˆ
. Simk=1 Hk
trees
ilarly, we denote by Hk the set of all binary decision trees
with k internal nodes, where the node questions are threshold functions 1Ïˆj (x)â‰¤Î¸ with j âˆˆ [1, d] and Î¸ âˆˆ R, and
where the leaves are labeled with zero or one and define
trees
H trees as the union of these families: H trees = âˆªâˆ
k=1 Hk .
Note that our monomial and tree features are strict generalizations of the product features and threshold features used
by Phillips et al. (2004; 2006) and DudÄ±Ìk et al. (2007).
The hypothesis set H = H mono âˆª H trees is infinite and can
be very large even for a bounded monomial degree and for

Structural Maxent Models
Table 1. Experimental comparison of Maxent algorithms.
Dataset
b. variegatus

arson
rapes
burglary
larceny

traffic

Maxent
19.95
(0.54)

L1 -Maxent
15.67
(0.33)

StructMaxent
13.36
(0.28)

Dataset

5.93
(0.02)
6.42
(0.02)
6.04
(0.01)
5.83
(0.01)

5.75
(0.01)
6.22
(0.01)
5.85
(0.01)
5.65
(0.01)

5.68
(0.02)
6.16
(0.01)
5.78
(0.01)
5.58
(0.01)

murders

14.72
(1.11)

13.85
(0.24)

13.00
(1.01)

trees restricted to the finite training sample. Thus, exhaustively searching for the best monomial in H mono and the
best decision tree in H trees is not tractable. Instead, we
used the following greedy procedure: given the best monomial m(x) of degree k (starting with k = 0), we find the
best monomial of degree k + 1 that can be obtained from
m(x) by multiplying it with one of Ïˆ âˆˆ H1mono . Similarly,
given the best decision tree of size k, we find the best decision tree of size k + 1 that can be obtained by splitting
exactly one leaf of the given tree. Let Î¦1 , . . . , Î¦tâˆ’1 be features chosen by the algorithm after the first t âˆ’ 1 iterations.
Then, on the t-th iteration, the algorithm selects a feature
from {Î¦1 , . . . , Î¦tâˆ’1 , tâˆ— , mâˆ— }, where tâˆ— is the tree and mâˆ—
the monomial obtained by the procedure just described.
Note that StructMaxent requires the knowledge of the
Rademacher complexities Rm (Hk ), which in certain cases
can be estimated from the data. For simplicity, in our experiments, we used the following upper bounds
r
2k log d
mono
Rm (Hk ) â‰¤
m
(15)
r
(4k
+
2)
log
(d
+
2)
log(m
+
1)
2
,
Rm (Hktrees ) â‰¤
m
and we redefined Î²k as Î²k = Î»Bk + Î², where Bk is the
appropriate choice of an upper bound in (15) and where
the parameter Î» is introduced to control the balance between the magnitude of Bk and Î². The proof of these upper
bounds is given in Appendix E.
In our experiments, we determined both parameters Î» and Î²
through a validation procedure. Specifically, we optimized
over Î», Î² âˆˆ {0.0001, 0.001, 0.01, 0.1, 0.5, 1, 2}. Remarkably, in all of our experiments the best value of Î» was 0.1.
We compared StructMaxent with L1 -regularized Maxent
(Kazama & Tsujii, 2003; Phillips et al., 2004; 2006; DudÄ±Ìk
et al., 2007) which is the special case of StructMaxent with
Î» = 0. L1 -regularized Maxent is the only algorithm used
for experiments in (Phillips et al., 2004; 2006; DudÄ±Ìk et al.,
2007). The parameter Î² of L1 -Maxent was set in the same
way as for the StructMaxent algorithm. We compared the

m. minutus

robberies
assault
auto theft

Maxent
17.41
(0.87)

L1 -Maxent
12.20
(0.78)

StructMaxent
10.25
(0.30)

5.38
(0.02)
5.14
(0.01)
6.65
(0.02)
5.93
(0.02)

5.23
(0.02)
5.00
(0.01)
6.35
(0.01)
5.75
(0.01)

5.17
(0.02)
4.94
(0.01)
6.30
(0.01)
5.68
(0.02)

performance of StructMaxent to that of L1 -Maxent and to
standard Maxent (Î» = Î² = 0) which served as our baseline. Following Phillips et al. (2004), we ran each algorithm for 500 rounds, or until the change in the objective
on a single round fell below 10âˆ’5 .
For our experiments, we used a number of different datasets
related to species habitat modeling, traffic modeling, and to
communities and crimes, which we describe in the following subsections.
4.1. Species habitat modeling
Species habitat modeling is among the most prominent applications of Maxent models (Phillips et al., 2004; 2006;
DudÄ±Ìk et al., 2007; Elith et al., 2011). For our experiments,
we used two data sets from (Phillips et al., 2006) which
are accessible from http://www.cs.princeton.edu/
Ëœschapire/maxent. These datasets consist of a set of
648,658 geographical locations in South America which
constitute the input space X . For each of these locations,
we have a set of environmental variables such as temperature and precipitation, which constitute our raw features
Ïˆ1 , . . . , Ïˆd . For each location, we are also given the number of times a particular kind of species has been observed,
which defines the sample S used as an input to Maxent algorithms. The first dataset consists of 116 observations of
bradypus variegatus and the second dataset has 88 observations of microryzomys minutus. The task consists of estimating the geographical distribution of each species.
For each species, we first randomly split the sample S into
a training set S1 (70%) and a test set S2 (30%). We trained
all algorithms on S1 and used the error on S2 to find the optimal value of the parameters Î» and Î². Next we again split
the sample into a training set S10 (70%) and a test set S20
(30%). Using the best parameter values found on the previous step, each algorithm was trained on S10 and the log-loss
on S20 was recorded. We repeated the last step 10 times
and reported the average log-loss over these 10 runs. This
experimental setup matches that of (Phillips et al., 2004;

Structural Maxent Models

2006), with the exception of the validation step, which is
omitted in both of these references.
4.2. Minnesota traffic modeling
We also experimented with a Minnesota traffic dataset
(Kwon, 2004) which is accessible from http://www.d.
umn.edu/Ëœtkwon/TMCdata/TMCarchive.html. This
dataset contains traffic volume and velocity records collected by 769 road sensors over the period of 31 days with
an interval of 30 seconds between observations. The input
space X is the set of sensor locations and the task consists of estimating traffic density at each particular location
based on the historical data. More precisely, we chose 11
times t1 , . . . , t11 on the 31st day starting at midnight and
separated by one hour. For computational efficiency, instead of using the whole history, we defined the raw features Ïˆ1 , . . . , Ïˆd as the historical volume and velocity averages for each of the past 30 days, augmented with data
from the past hour collected every 10 minutes. For any
time tl , there are between 1,000 to 20,000 cars observed
by all of 769 sensors. For each time tl , we randomly selected 70% of observations for training and the remaining
observations were reserved for testing. Data from the first
time t1 was used to determine the best parameters Î» and Î².
The parameter values were then fixed and used for training
on the remaining ten times t2 , . . . , t11 . We report log-loss
on the test set averaged over these 10 time values.
4.3. Communities and crime
We used the UCI Communities and Crime dataset as another test case for StructMaxent algorithm. This dataset
contains demographic and crime statistics for 2,215 US
communities. Each community represents a point x in the
input space X and we define base features Ïˆj to be various demographic statistics. The goal is to model the likelihood of certain types of crimes based on the demographic
statistics available. The data set includes 8 different types
of crime: murder, rape, robbery, burglary, assault, larceny,
auto theft and arson. For each type of crime, there are between 17,000 to 5,000,000 records. To speed up our experiments, we randomly sub-sampled 11 training sets of size
5,000 for each type of crime (with the remaining data used
for testing). As before, the first training and test sets is
used to determine the best values for the parameters Î» and
Î², and we report the averaged log-loss on the test set when
training with Î» and Î² fixed at these values.

Table 2. Average AUC values.
Maxent
L1 -Maxent
StructMaxent

b. variegatus

m. minutus

0.810 Â± 0.020
0.817 Â± 0.027
0.873 Â± 0.027

0.879 Â± 0.141
0.972 Â± 0.026
0.984 Â± 0.006

sults are statistically significant using paired t-test at 1%
level. Furthermore, StructMaxent outperforms other algorithms on each of the individual runs. Our experiments indicate that the performances of StructMaxent1 and StructMaxent2 are comparable â€“ both better than that of L1 regularized and non-regularized Maxent in terms of logloss. Note that for the species habitat modeling experiments, Phillips et al. (2004; 2006) report only AUC (Area
Under the ROC curve) values, which measure ranking quality, instead of the log-loss optimized for density estimation.
They do so by treating the absence of any recorded observation at a particular location as a negative label. For
completeness, we also report AUC results for our experiments in Table 2. StructMaxent outperforms other methods
in terms of AUC as well.
The convergence of StructMaxent2 is somewhat slower
than that of StructMaxent1, but both exhibit exponential
convergence. Finally, note that the running time of our
StructMaxent algorithms is similar to that of L1 -Maxent.

5. Conclusion
We presented a new family of density estimation models, Structural Maxent models, which benefit from strong
data-dependent learning guarantees and can be used even
with complex feature families. Our experiments demonstrated the empirical advantage of these models. We also
introduced a new family of conditional probability models
for multi-class classification, structural conditional Maxent
models, and showed them to coincide with deep boosting
when using the logistic function as a surrogate loss. Our
conditional structural Maxent principle provide additional
support in favor of this family of algorithms.
As with standard Maxent models (Lafferty, 1999), our
structural Maxent models can be generalized by using an
arbitrary Bregman divergence (Bregman, 1967) in place of
the (unnormalized) relative entropy. Much of our analysis and theoretical guarantees straightforwardly extend to
cover this generalization, modulo some additional assumptions on the properties of the Bregman divergence used.
Acknowledgments

4.4. Results and discussion
The results of our experiments are presented in Table 1.
They show that StructMaxent provides an improvement
over L1 -Maxent that is comparable to the improvement of
L1 -Maxent over standard Maxent models. All of our re-

We thank Tian Jiang for several discussions about this work
and early experiments, and Slobodan Vucetic for facilitating our access to the Minnesota traffic dataset. This work
was partly funded by the NSF award IIS-1117591 and the
NSERC PGS D3 award.

Structural Maxent Models

References
Berger, Adam L., Pietra, Stephen Della, and Pietra, Vincent J. Della. A maximum entropy approach to natural
language processing. Comp. Linguistics, 22(1), 1996.
Boyd, Stephen P. and Vandenberghe, Lieven. Convex Optimization. Cambridge University Press, 2004.
Bregman, Lev M. The relaxation method of finding the
common point of convex sets and its application to the
solution of problems in convex programming. USSR
Computational Mathematics and Mathematical Physics,
7:200â€“217, 1967.
Chen, Stanley F. and Rosenfeld, Ronald. A survey of
smoothing techniques for ME models. IEEE Transactions on Speech and Audio Processing, 8(1), 2000.
Cortes, Corinna, Mohri, Mehryar, and Syed, Umar. Deep
boosting. In Proceedings of ICML, 2014.
Cover, Thomas M. and Thomas, Joy M. Elements of Information Theory. Wiley-Interscience, 2006.
DudÄ±Ìk, Miroslav, Phillips, Steven J., and Schapire,
Robert E. Maximum entropy density estimation with
generalized regularization and an application to species
distribution modeling. Journal of Machine Learning Research, 8, 2007.
Elith, Jane, Phillips, Steven J., Hastie, Trevor, DudÄ±Ìk,
Miroslav, Chee, Yung En, and Yates, Colin J. A statistical explanation of MaxEnt for ecologists. Diversity
and Distributions, 1, 2011.
Goodman, Joshua. Exponential priors for maximum entropy models. In Proceedings of HLT-NAACL, 2004.
Huang, Junzhou and Zhang, Tong. The benefit of group
sparsity. The Annals of Statistics, 38(4):1978â€“2004, 08
2010.

Kuznetsov, Vitaly, Mohri, Mehryar, and Syed, Umar.
Multi-class deep boosting. In Proceedings of NIPS,
2014.
Kwon, Taek M.
TMC traffic data automation for
Mn/DOTâ€™s traffic monitoring program. Univ. of Minnesota, Report no. Mn/DOT 2004-29, 2004.
Lafferty, John D. Additive models, boosting, and inference
for generalized divergences. In Proceedings of COLT,
pp. 125â€“133, 1999.
Lebanon, Guy and Lafferty, John D. Boosting and maximum likelihood for exponential models. In Proceedings
of NIPS, pp. 447â€“454, 2001.
Luo, Zhi-Quan and Tseng, Paul. On the convergence of coordinate descent method for convex differentiable minimization. Journal of Optimization Theory and Applications, 72(1):7 â€“ 35, 1992.
Malouf, Robert. A comparison of algorithms for maximum
entropy parameter estimation. In Proceedings of CoNLL2002, pp. 49â€“55, 2002.
Manning, Christopher D. and Klein, Dan. Optimization, maxent models, and conditional estimation without
magic. In Proceedings of HLT-NAACL, 2003.
Mansour, Yishay. Pessimistic decision tree pruning based
on tree size. In Proceedings of ICML, 1997.
Phillips, Steven J., DudÄ±Ìk, Miroslav, and Schapire,
Robert E. A maximum entropy approach to species distribution modeling. In Proceedings of ICML, 2004.
Phillips, Steven J., Anderson, Robet P., and Schapire,
Robert E. Maximum entropy modeling of species geographic distributions. Ecological Modelling, 190, 2006.
Pietra, Stephen Della, Pietra, Vincent J. Della, and Lafferty,
John D. Inducing features of random fields. IEEE Trans.
Pattern Anal. Mach. Intell., 19(4), 1997.

Jaynes, E. T. Information theory and statistical mechanics.
Physical Review, 106(4):620â€“630, 1957.

Ratnaparkhi, Adwait. Maximum entropy models for natural language processing. In Encyclopedia of Machine
Learning, pp. 647â€“651. Springer, 2010.

Jaynes, E. T. Papers on probability, statistics, and statistical physics. Synthese library. D. Reidel Pub. Co., 1983.

Rockafellar, R. Tyrrell. Convex analysis. Princeton University Press, 1997.

Kazama, Junâ€™ichi and Tsujii, Junâ€™ichi. Evaluation and
extension of maximum entropy models with inequality
constraints. In Proceedings of EMNLP, pp. 137â€“144,
2003.

Rosenfeld, Ronald. A maximum entropy approach to adaptive statistical language modelling. Computer Speech &
Language, 10(3):187â€“228, 1996.

Koltchinskii, Vladmir and Panchenko, Dmitry. Empirical margin distributions and bounding the generalization
error of combined classifiers. Annals of Statistics, 30,
2002.

Vapnik, Vladimir N. Statistical Learning Theory. WileyInterscience, 1998.
Williams, Peter M. Bayesian regularisation and pruning
using a Laplace prior. Neural Computation, 7:117â€“143,
1994.

