On Identifying Good Options under Combinatorially Structured Feedback
in Finite Noisy Environments

Yifan Wu
YWU 12@ UALBERTA . CA
András György
GYORGY @ UALBERTA . CA
Csaba Szepesvári
SZEPESVA @ UALBERTA . CA
Department of Computing Science, University of Alberta, Edmonton, AB T6G 2E8 CANADA

Abstract

1. Introduction
Consider the problem of identifying the most rewarding option(s) out of finitely many. At your disposal are a number
of probing devices, or just probes, that give you noisy measurements of the quality of a select set of options. More
precisely, each probe is associated with a known subset of
options whose quality the probe will measure. In a sequential process, the goal is to select the probes so that one can
stop early to return, with high probability, a sufficiently rewarding option (or a set of options). As a specific example,
consider the problem of identifying the segment on a road
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

0.25

SEWP
lilUCB
SE

Running time per probe (ms)

Number of probes used

We consider the problem of identifying a good
option out of finite set of options under combinatorially structured, noisy feedback about the
quality of the options in a sequential process:
In each round, a subset of the options, from an
available set of subsets, can be selected to receive noisy information about the quality of the
options in the chosen subset. The goal is to
identify the highest quality option, or a group
of options of the highest quality, with a small
error probability, while using the smallest number of measurements. The problem generalizes
best-arm identification problems. By extending previous work, we design new algorithms
that are shown to be able to exploit the combinatorial structure of the problem in a nontrivial fashion, while being unimprovable in special
cases. The algorithms call a set multi-covering
oracle, hence their performance and efficiency is
strongly tied to whether the associated set multicovering problem can be efficiently solved.

6

10

5

10

4

10

0.2

SEWP
lilUCB
SE

0.15

0.1

0.05

3

10

10

100
Number of options

1000

0

200

400
600
800
Number of options

1000

Figure 1. A specialized algorithm (SEWP) proposed in this paper
can take nontrivial advantage of the probe structure as compared
with simple adaptations of earlier algorithms, while being only
marginally more expensive. All algorithms maintain the same
error-rate. The plot on the left-hand-side uses a log-log-scale.
Due to the special structure of the problem, the expected √
stopping time of the specialized algorithm scale linearly with K,
while the others scale linearly with K, the number of options.

network that is in the worst shape after a long winter. Measurements can be obtained by sending trucks checking the
road for potholes along the paths they travel on. The trucks
must return to their garage every day. Here, the options
correspond to road segments, the probes correspond to a
closed walk in the road network that starts from the garage.
Somewhat ironically, a road segment is “rewarding” (from
the point of view of how beneficial it is to sending there the
repair team) if it has many potholes.1 Measurements are
noisy, as potholes are easy to miss.
Problems like the above one abound. Numerous quality
assurance and surveying tasks are such that measurements
give simultaneous information about multiple entities due
to physical constraints on the measurement process. Application areas include technical computing (e.g., networking), biology (ecology, microbiology, etc.), physics, etc.
Of course, even though individual measurements might be
1
In practice, one may want a whole “plan” at the end for the
repair team. As often, we took the liberty of simplifying the problem to be able to focus on how the structure of probes should be
used.

On Identifying Good Options under Combinatorially Structured Feedback

impossible, it is always possible to treat each probe as one
that gives individual measurements for the options associated with it, though this could be wasteful (cf. Fig. 1).
The main topic of the present paper is how to exploit, with
efficient algorithms, when probes give information about
multiple options.
The special case when each probe measures a single option,
is known as the best arm identification problem, whose history goes back more than half a century (Bechhofer, 1958;
Paulson, 1964), and with much activity in the last decade
(e.g., Even-Dar et al. 2002, Mannor & Tsitsiklis 2004, Audibert et al. 2010, Kalyanakrishnan & Stone 2010, Bubeck
et al. 2011, Kalyanakrishnan et al. 2012, Gabillon et al.
2012, Karnin et al. 2013, Kaufmann & Kalyanakrishnan
2013, Bubeck et al. 2013, Jamieson et al. 2014, Kaufmann
et al. 2015, Zhou et al. 2014, Chen et al. 2014).
In this paper we consider two basic settings: identifying the
best option with a prespecified error probability while using the smallest possible number of probes, and identifying
a group of options of a fixed size, again with a prespecified error probability with the smallest possible number of
probes. For the first setting, we propose two algorithms,
SEWP and EGEWP described in Section 3, extending the
works of Even-Dar et al. (2002) and Karnin et al. (2013).
They work by constructing coverings with the probes of
the sets of options not eliminated. The second algorithm
removes a logarithmic term from the upper bound and it
required a non-trivial extension of the median elimination
method of Even-Dar et al. (2002). For the second setting, in
Section 4, the quality of a group returned is assessed either
by the quality of the worst option in the group (following
Kalyanakrishnan & Stone (2010)), or by the average quality of options in the group (Zhou et al., 2014). We propose
a single algorithm (SARWP) that essentially covers both
cases. For the average quality, our distribution dependent
upper bound is novel even in the bandit case and also near
optimal in the worst case compared with the lower bound
proposed by Zhou et al. (2014). For simple probe structures
(singletons, or when a probe that covers all options is available), our algorithms are shown to be essentially unimprovable. We also give lower bounds for general probe structures. While both our lower and upper bounds express how
the structure of the probes interferes with the structure of
payoffs, they differ in subtle ways and it remains for future
work to see whether there is a gap between them.
Due to space constraints, proofs and some experimental results are relegated to the appendix.

2. Preliminaries
In this section, we formulate the problem studied, as well
as introducing the set covering problem, which will play an

important role in our algorithms and analysis. We start by
defining some notation.
2.1. Notation
The set of natural numbers will be denoted by N, which
includes zero. For a positive natural number n, [n] denotes
the set of integers between 1 and n: [n] = {1, . . . , n}.
The power set, i.e., the set of all subsets of a set S, will
be denoted by 2S . As usual, functions, mapping set X to
set Y will be viewed as elements of Y X . For v ∈ Y X ,
we will often write vx instead of v(x) to minimize clutter.
This also helps with the next convention: When U ⊂ X,
we will use vU to denote the restriction of v ∈ Y X to U :
vU (u) = v(u), u ∈ U . We identify Y [n] with Y n (the
set of n-tuples) in the natural way, which allows us to use
notation vU for v ∈ Y n ≡ Y [n] . The cardinality of a set
S is denoted by |S|. Certain symbols will be reserved to
denote elements of certain sets (i.e., p will always be an
element of set P). When
reserved symbols, we
P using such P
will abbreviate (e.g.) p∈P f (p) to p f (p). We will use
log(·) to denote the natural logarithm function.
2.2. Problem Formulation
A decision maker is given a pair ([K] , P), where elements
of [K] are called arms, or, interchangeably, actions, and
P ⊂ 2[K] such that the sets in P cover [K]: ∪P = [K].
Elements of P are called probes. A problem instance D,
or environment, is specified by K distributions over the reals, D = (D1 , . . . , DK ). The decision maker does not
have direct access to these distributions. For 1 ≤ i ≤ K,
we think of distribution Di as the distribution of “rewards”
associated
with arm i. We assume that the mean reward
R
µi = xDi (dx) of each arm is well defined. Further assumptions on Di will be given later.
The goal of the decision maker is to find arms with the
largest mean reward. For this, the decision maker can query
the rewards of the arms by using the probes in a sequential
manner. In particular, for each round t = 1, 2, . . . , first
a random reward Xt,i ∼ Di is generated for each arm i
from its associated distribution. It is assumed that Xt,i is
independent of the other rewards (Xs,j )s6=t or j6=i . We set
Xt = (Xt,1 , . . . , Xt,K ) ∈ RK . In round t = 1, 2, . . . , the
decision maker chooses a probe pt ∈ P based on her past
observations, to observe the values Xt,i for each arm i in
pt ; with our earlier introduced notation we can write that
.
the decision maker observes Xt,pt = (Xt )pt ∈ Rpt . At the
end of each round, the decision maker can decide between
continuing or stopping to return a list of guesses (or a single
guess) on the indices of the good arms. The goal is to stop
as soon as possible, while avoiding poor guesses.
The following specific problem settings will be considered:

On Identifying Good Options under Combinatorially Structured Feedback

(i) Fixed confidence, best-arm identification. The optimal arm is unique: If µ? = maxi∈[K] µi ,
maxi:µi 6=µ? µi < µ? . The goal of the decision maker
is to identify the index i? = argmaxi∈[K] µi of the
optimal arm. The decision maker is given a confidence parameter 0 ≤ δ < 1 and it is required that the
guess returned after τ probes must be correct on an
event E with probability at least 1 − δ. Decision makers are compared based on their probe complexity,
i.e., the number of probes they use when the “good
event” E happens.
(ii) PAC subset selection. There are two subproblems
that we consider. In both cases the decision maker
is given a confidence, 0 ≤ δ < 1, a suboptimality threshold ε > 0 and a subset cardinality 1 ≤
m ≤ K. The problems differ in how a quality
q(S, µ) measure is assigned to a subset S ⊂ [K] of
arms. In both problems, the goal is to find a subset of arms of cardinality m such that q(S, µ) ≥
maxP ⊂[K]:|P |=m q(P, µ) − ε and with probability
1 − δ, the decision maker must return a subset satisfying the above quality constraint. As before, decision makers are compared based on how many probes
they use before stopping. The two quality measures
considered are the reward of the worst arm in the set
and the average reward:
qmin (S, µ) = mini∈S µi and
P
1
µ
qavg (S, µ) = |S|
i∈S i , S ⊂ [K], |S| = m. We
call the corresponding problems the strong and the
average PAC subset selection problems.
An algorithm used by a decision maker to select probes,
stop and return a guess will be said to be admissible with
respect to a class of environments, if, for any environment
within the class and any 0 ≤ δ < 1, the guess computed is
correct (according to the previous requirements) with probability 1 − δ.
The above problems have been considered in the past in the
special case when P contains singletons only, by a number
of authors (see Section 1 for some references). We shall
call these the “bandit” problems. While one can readily
apply the algorithms developed for the bandit case to our
problem, the expectation is that the probe complexity of
reasonable algorithms should improve considerably as P
becomes “richer” (this was illustrated in Fig. 1). The question is how the structure of P together with the problem
instance influences the problem complexity. For example,
in the extreme case when P contains [K], we expect the
probe complexity of reasonable algorithms to scale sublinearly with K, whereas in the bandit case a linear scaling is
unavoidable. The case when P = {[K]} will be called the
full information case.
Note that since all probes “cost” the same amount (one unit

of time), a reasonable algorithm will avoid any probe p that
is entirely included in some other probe p0 ∈ P. Hence,
we may as well assume that the set of probes does not have
nontrivial chains in it.
We will present results for the class of environments Dsg
with the following restrictions: For each 1 ≤ i ≤ K, Di is
sub-Gaussian with common parameter σ 2 = 1/4:
Z
log e−λ(x−µi ) Di (dx) ≤ λ2 σ 2 /2 = λ2 /8
R

for all λ ∈ R. To simplify the presentation of our results,
without loss of generality, we assume that µ1 ≥ µ2 ≥
· · · ≥ µK . (note that, obviously, the algorithms do not
use this assumption). For further simplicity, we assume
that ∆i ∈ [0, 1] for all i ∈ [K] where ∆i = µ1 − µi ,
2 ≤ i ≤ K. Our assumptions on the reward distributions
Di are satisfied if, for example, Di has bounded support.
We will present algorithms, which will be shown to be admissible for Dsg and we will bound their probe complexities. The bounds on the probe complexities will be given in
terms of the (suboptimality) gaps ∆i , 2 ≤ i ≤ K, i.e., they
will be dependent on the distributions D = (D1 , . . . , DK ).
Hence, we call them distribution dependent bounds. We
will accompany our constructive results with lower bounds,
putting a lower limit on the probe complexity of all admissible algorithms. Again, these will be given in terms of the
gaps ∆i .
2.3. Set Multi-Cover Problems
Probes allow one to “explore” multiple arms simultaneously. Clever algorithms should use the probes in a smart
way to guarantee the necessary number of samples for each
of the arms while using the smallest number of probes. If,
for example, n ∈ N observations are enough from each of
the arms to distinguish their mean payoff from that of the
optimal arm, then an intelligent algorithm would try to create the smallest covering of [K] using the subsets in P to
meet this requirement. More generally, for J ⊂ [K], we
define
nP
o
P
P
CIP (J, n) = min
s
:
s
∈
N
,
s
≥
n,
i
∈
J
p
p
p
p:i∈p
to be the cost of the smallest n-fold multi-covering of elements of J. Any s ∈ NP achieving the minimum is called
an optimal (integral) n-cover of J, while a feasible vector s
is called an n-cover. Given an n-cover s ∈ NP , we will say
that probe p belongs to s (writing p ∈ s) if sp > 0. The optimization problem defining CIP is a linear integer program
(hence the IP in CIP ). Relaxing the integrality constraint
s ∈ NP to the nonnegativity constraint s ∈ [0, ∞)P , we
get a so-called fractional optimal n-cover of J by solving
the otherwise identical optimization problem. The resulting optimal value will be denoted by CLP (J, n). Note that

On Identifying Good Options under Combinatorially Structured Feedback

the relaxed problem is a linear program, explaining “LP”
in CLP . While this linear program has potentially exponentially many variables in K, it can still be efficiently
solved provided an efficiently computable membership oracle is available for its dual (Grötschel et al., 1993). Both
CIP (J, n) and CLP (J, n) can be extended to non-integer
values of n.
It follows immediately from the definitions that
CLP (J, n) ≤ CIP (J, n). Further, for any a > 0,
CLP (J, a n) = a CLP (J, n) = an CLP (J, 1). The integrality gap for a set multi-covering problem instance is given
by (P, J, n) is CIP (J, n)/CLP (J, n) (Vazirani, 2001).
Our algorithms will need “small” n-covers for various subsets J ⊂ [K]. Depending on the structure of P, calculating an optimal multi-cover of J may be easy or hard2
(e.g., Slavik, 1998; Schrijver, 2003; Korte & Vygen, 2006).
Thus, to keep the presentation general, our algorithms will
rely on a set multi-covering oracle COrcl, which given
J, n, P, returns an n-fold multi-cover of J using the sets
in P. Denote by CO (J, n) the cost of the multi-cover returned by the oracle on J, n (as with CIP and CLP the dependence on P is suppressed). The oracle’s integral (fractional) approximation gap, GIP (O, P) (GLP (O, P)), is the
worst-case multiplicative loss due to using COrcl in place
of an optimal integral (fractional) cover. In particular, with
? ∈ {IP, LP },
G? (O, P) =

sup
n∈N+ ,J⊂[K]

CO (J, n)
.
C? (J, n)

Let d = maxp∈P |p| be the maximum number of actions
that can be covered by a single probe. If the set-system
P has no special structure, one possibility is to use the
greedy algorithm G as the oracle. This algorithm works
by sequentially setting sp = n for the probe p ∈ P that
covers the maximum number of active arms in J and then
deactivates the arms that are covered by p, until all arms
are deactivated. Further, GLP (O, P) ≤ 1 + log(d) ≤
1 + log(K). Lovász (1975) showed that CG (J, 1) ≤
(1 + log d)CLP (J, 1). Then, CG (J, n) = n CG (J, 1) ≤
(1 + log d)n CLP (J, 1) = (1 + log d)CLP (J, n), showing
that the required inequality indeed holds. Raz & Safra
(1997) proved that the exists some constant c > 0 such
that, unless P = N P , no approximation ratio of c log(K)
can be achieved, so in a worst-case the greedy algorithm is
a near-optimal approximation algorithm.

3. Finding the Best Arm
In this section we present two algorithms and their analysis
for the fixed confidence, best-arm identification problem.
2

Computing the exact solution for the decision version of set
covering (i.e., when n = 1), when P can be any covering system,
is known to be NP-hard (Vazirani, 2001).

Recall that in this problem, given a set of probes P and
a confidence δ ∈ (0, 1], we need to design a sequential
procedure that identifies the best arm i? with probability at
least 1 − δ using as few probes as possible.
3.1. Successive Elimination with Probes
The first algorithm modifies the successive elimination algorithm of Even-Dar et al. (2002) to take into account the
richer observation structure of our problem. Recall that the
algorithm of Even-Dar et al. (2002) works in phases, in
each phase observing a certain number of rewards for each
remaining candidate actions. At the end of the phase the
provably suboptimal actions are eliminated. The number
of observations in each phase depends only on the phase
index. The process stops when the candidate set contains
a single element. The main difference to the algorithm
of Even-Dar et al. (2002) is that in each phase our algorithm, which we call Successive Elimination with Probes
(SEWP), computes a set multi-covering for the remaining
candidate actions given the probes, with a requirement adjusted to the phase index. The returned multi-cover is then
used to get the observations for the remaining actions.
Algorithm 1 SuccessiveEliminationWithProbes (SEWP)
1: Inputs: K, δ, P, observation scheduling function f :
N → N and confidence function g : N × (0, 1] →
[0, ∞).
2: Initialize candidate set: A1 = [K].
3: for t = 1, 2, . . . do
4:
C(t) ← COrcl(At , f (t), P).
5:
Use each p in C(t) for Cp (t)-times to get new observations.
6:
For each i ∈ At , let µ̂i (t) be the mean of all observations so far for arm i.
7:
At+1 ← {i ∈ At : µ̂i (t) + 2g(t, δ) > maxj∈At µ̂j (t)}.
8:
if |At+1 | = 1 then
9:
Return the arm in At+1 .
10:
end if
11: end for
Our first result shows that Algorithm 1 is admissible and
gives an upper bound on its probe complexity. To state it,
define the scheduling and confidence functions
r
log(4Kt2 /δ)
t
f (t) = 2 ,
g(t, δ) =
.
(1)
2t+1
For simplicity, assume that the arms are ordered in decreasing order of their mean rewards and ∆2 > 0, i.e., the optimal arm is unique. For 2 ≤ i ≤ K define


∆i
,
(2)
Tbi (δ) = 1 + max s : g(s, δ) ≥
4


128
54K
4
N̂i (δ) = 2 log
log
(3)
∆i
δ
∆i

On Identifying Good Options under Combinatorially Structured Feedback

and let TbK+1 (δ) = 0 and N̂K+1 (δ) = 0. Note that
b
2Ti (δ)+1 ≤ N̂i (δ), and both are decreasing with i ≥ 2
increasing.
Theorem 1. Pick any 0 ≤ δ < 1 and let SEWP run with inputs (K, δ, P, f, g) with f, g given by (1). Then, with probability at least 1 − δ, SEWP returns the optimal arm i? = 1
within N probes, where N satisfies
N ≤ GIP (O, P)

K
X

Tbi (δ)

X

CIP ([i] , 2t ) .

(4)

i=2 t=Tbi+1 (δ)+1

.
Furthermore, with M̂i (δ) = N̂i (δ) − N̂i+1 (δ),
N ≤ GLP (O, P)

K
X

M̂i (δ) CLP ([i] , 1) .

(5)

i=2

The bound (4) may be tighter than that shown in (5), but
perhaps the second is a bit easier to understand.3 For simplicity, let us explain (5). Once (5) is explained, the meaning of (4) follows. The term GLP (O, P) is the price of
using an oracle combined with some upper bounding that
allowed us to arrive at this simpler result by resorting to
the linearity properties of CLP . The rest is what we call
a sequential fractional multi-cover with the requirements
that arm i be covered N̂i (δ) times: In a sequential multicover, the covering is not done in a single-shot, but is done
in phases. In the first phase, all the arms must be covered M̂K (δ) times. In the next phase, all the arms but
the last must be covered M̂K−1 (δ) times, etc., up to the
last phase when arms one and two must be covered M̂2 (δ)
times. Note that the total requirements for an arm i are
M̂K (δ)+ M̂K−1 (δ)+· · ·+ M̂i (δ) = N̂K (δ)− N̂K+1 (δ)+
N̂K−1 (δ) − N̂K (δ) + · · · + N̂i (δ) − N̂i+1 (δ) = N̂i (δ).
Roughly N̂i (δ) ≈ O(1/∆2i ) is the number of observations
needed from arm i (and one) in order to be able to tell which
of the two arms has a bigger mean reward. Now, compared
to (5), (4) uses a more precise expression for the number
of probes, by relying on the the phase structure of the algorithm.
An alternative choice
q of f (t) and g(t, δ) is that f (t) = 1
log(4Kt2 /δ)
, which leads to N̂i (δ) =
and g(t, δ) =
t


1
K
O ∆2 log δ∆i instead.

bound, one shows that arm i will be eliminated after phase
T̂i (δ). This happens because in each phase the confidence
sets of all arms decrease at a uniform rate.
Now, we argue that this bound is tight up to a log K factor,
at least in some cases. In particular, in the bandit case, the
covering problem is trivial and we can use an optimal covering oracle.Then, CO ([i] ,2t ) = i2t , 
and hence the bound
PK 1
K
1
. Up to a log facbecomes O
i=1 ∆2i log
δ log ∆i
tor, this matches the lowerbound of Kaufmann et
 al. (2015)
PK
−2
which takes the form Ω
i=1 ∆i log(1/δ) . Furthermore, as noted by Jamieson et al. (2014) (based on a result
of Farrell (1964)) the log log ∆−1 term is necessary.
To examine the tightness of the upper bound, we derive a
distribution dependent lower bound on the probe complexity of algorithms admissible for Dsg . Call an environment
D a Gaussian environment with common variance σ 2 if for
any 1 ≤ i ≤ K, Di is a Gaussian with variance σ 2 .
Theorem 2 (Distribution-dependent lower bound). For any
algorithm admissible for Dsg , any confidence 0 < δ < 1/2,
any probe set P, any sequence 0 = ∆1 < ∆2 ≤ . . . ∆K , if
D is a Gaussian environment with common variance σ 2 =
1/4 and means µ1 = µ2 + ∆2 = · · · = µK + ∆K , if N is
the number of probes used by the algorithm on D then
X
X
1
1
E[N ] ≥ min
sp s.t.
sp ≥
2 log 6δ ,
P
4∆
s∈[0,∞)
2
p:1∈p
p∈P

and

X
p:i∈p

sp ≥

1
1
log
,
4∆2i
6δ

2≤i≤K.

The proof can be found in Appendix A.2.
Note that the lower bound clearly reflects the structure of
P. However, even disregarding the constants and logarithmic factors, there is still a gap between our upper and lower
bounds: In the upper bound, as explained before, the size of
a sequential cover that appears, while in the lower bound,
the size of a “one-shot” cover is seen. Note that in either
the bandit or the full information case, there is no gap between these quantities. We were able to establish a gap of
log(K) when considering sequential and one-shot integral
covers. However, it remains a very interesting open question whether the gap can be closed in the fractional case.

i

The proof, which borrows ideas from Even-Dar et al.
(2002), is in Appendix A.1. To prove that SEWP is admissible, one only needs to show that when none of the confidence intervals based on g used in the elimination step fail,
the optimal arm will not be eliminated. This essentially
relied on Hoeffding’s inequality, union bounds and calculations. To calculate the bound on the probe complexity
3
In fact, if CO (·, n) is monotone increasing, (4) will hold with
CO replacing GIP · CIP , further tightening the bound.

3.2. An Alternative Algorithm to Find the Best Arm
The second algorithm is a generalization of the exponential
gap elimination algorithm of Karnin et al. (2013), which
improves the logarithmic term in the sample complexity
1
1
1
from log( K
δ log ∆ ) to log( δ log ∆ ) for the bandit problem.
So we expect that generalizing that algorithm to our setting
will have a similar improvement regarding the log K term.
The exponential gap elimination algorithm of Karnin et al.

On Identifying Good Options under Combinatorially Structured Feedback

(2013) calls the median elimination algorithm of Even-Dar
et al. (2002) as a subroutine, which finds an ε-optimal arm
using O(Kε−2 log(1/δ)) samples with probability at least
1 − δ (an arm is ε-optimal iff its expected reward is at least
µ1 − ε). So before generalizing the exponential gap elimination algorithm, we need to first design a counterpart for
the median elimination algorithm.
3.2.1. M EDIAN E LIMINATION W ITH P ROBES
Simply replacing the uniform sampling in each phase
in the median elimination algorithm of Even-Dar et al.
(2002) with a set multi-cover does not work (shown in Appendix B.1), so a more careful design is needed. Our proposed algorithm, called Median Elimination With Probes
(MEWP) is shown in Algorithm 2. It essentially runs the
original median elimination algorithm for bandits over a
one-cover of all arms (that is, each probe in the cover is
treated as an arm in the bandit setting), and in each phase
we eliminate half of the probes that do not seem to cover
a good arm. We stop running median elimination when a
single probe covers all the remaining arms. Then the algorithm enters its second stage where we use this probe
until we identify an almost optimal arm from the remaining ones. In the next theorem we prove that the algorithm
is admissible, and give an upper bound on the number of
probes required to find an ε-optimal arm.
Algorithm 2 MedianEliminationWithProbes
1: Inputs: K, δ ∈ (0, 1], ε > 0, P.
δ
2: Set εt = 6ε ( 34 )t , δt = 2t+1
.
3: C ← COrcl([K] , 1, P), and define a partition of the
arms as A1 = {πp ⊂ p : p ∈ C, ∪p∈C πp = [K]}.
4: for t = 1, 2, . . . do
5:
for all π ∈ At do
6:
Use ε42 log 3|π|
δt -times p ∈ C that covers π to get
t
observations for each arm in p.
7:
Let µ̂π (t) = maxi∈π µ̂i (t), where µ̂i (t) is the empirical mean reward of arm i based on the observations in the actual phase t.
8:
end for
9:
Find the median m(t) of {µ̂π (t) : π ∈ At }.
10:
Let At+1 = {π ∈ At : µ̂π (t) ≥ m(t)}.
11:
if |At+1 | = 1 then
12:
terminate the loop and let π
b∗ be the single element
of At+1
13:
end if
14: end for
15: If |b
π ∗ | > 1, use the probe that covers π
b∗ for
2|b
π∗ |
8
ε2 log δ -times.
16: Return the arm î∗ ∈ π
b∗ with the highest empirical
mean based on these observations.
Theorem 3. With probability at least 1 − δ, MEWP returns

an ε-optimal arm î∗ , and N , the total number of probes
used by the algorithm is


|πmax |
CO ([K] , 1)
log
N =O
.
(6)
ε2
δ
where |πmax | = maxπ∈A1 |π|.
Note that we have |πmax | inside the log term instead of the
expected 1. It can be shown that the argument of the log
term cannot be 1 in our problem setting, at least in the full
information case (where it has to be K). Detailed discussion about this can be found in Appendix B.2.
3.2.2. E XPONENTIAL G AP E LIMINATION A LGORITHM
Algorithm 3 ExpGapEliminationWithProbes
1: Inputs: K, δ, P.
1
2: Initialize candidate set: A1 = [K]. Set εt = 4·2
t,
δ
δt = 50t3 .
3: for t = 1, 2, . . . do
4:
C(t) ← COrcl(At , 1, P).
5:
Create
a partition Πt of At such 	that Πt =

πp ⊂ p : p ∈ C(t), ∪p∈C(t) πp = At .
6:
for πp ∈ Πt do
2|π |
7:
Use probe p for ε22 log δtp -times to get observat
tions for each arm in p.
8:
end for
9:
For each i ∈ At , let µ̂i (t) be the mean of all observations in phase t for arm i.
10:
it ← MedianEliminationWithProbes(At , ε2t , δt ).
11:
Let At+1 = {i ∈ At : µ̂i (t) ≥ µ̂it (t) − εt }.
12:
if |At+1 | = 1 then
13:
Return the arm in At+1 .
14:
end if
15: end for
Given the MEWP algorithm, we continue with generalizing the exponential gap elimination algorithm. The new algorithm, called Exponential Gap Elimination with Probes
(EGEWP), is shown in Algorithm 3. The new idea here
is to use the partition-based exploration technique (as in
the MEWP algorithm) and replace the bandit-case median
elimination subroutine with MEWP. The analysis follows a
combination of the techniques of Karnin et al. (2013) and
the proof of Theorem 3. However, due to the more complicated observation structure, we are only able to prove a ∆2
dependent upper bound on the number of probes:
Theorem 4. If the oracle COrcl always returns the optimal solution for integer programming, EGEWP finds the
optimal arm with probability at least 1 − δ after using



|pmax |
1
CO ([K] , 1)
log
log
(7)
O
∆22
δ
∆2
probes where |pmax | = maxp∈P |p|.

On Identifying Good Options under Combinatorially Structured Feedback

If COrcl is not guaranteed to return the optimal integer cover, the above theorem still holds by making the following modification to the algorithm to ensure that Πt+1 is not worse than Πt for every t: if
| {π ∈ Πt : π ∩ At+1 6= ∅} | < CO (At+1 , 1), then use the
same partition pattern from Πt for Πt+1 .

and let N̂(K+1) (ε, δ) = 0.

Compared to the bound for SEWP, the log K term
is replaced with log |pmax |.
More specifically, in
the full information
case,
the
upper
bound becomes


K
1
1
O ∆2 log δ log ∆2 , which is the same as the upper
2
bound for SEWP. In the bandit case, the algorithm is exactly the same as the exponential gap elimination algorithm
et al. (2013),
 which enjoys an optimal
Pof Karnin 
K
1
1
1
upper bound on the number
O
i=1 ∆2i log δ log ∆i
of probes, and is better than the upper bound for SEWP in
bandit case. Therefore, although not formally proved, we
expect that EGEWP enjoys an improved probe complexity
compared with SEWP.

4.1. Strong PAC Subset Selection

4. PAC Subset Selection
In this section, we consider the two PAC subset selection
problems introduced in Section 2. The first, named strong
PAC subset selection, is the same as the E XPLORE-m problem introduced by Kalyanakrishnan & Stone (2010) where
the goal is to find m (ε, m)-optimal arms. The second
problem, named average PAC subset selection, is to select
a subset of m arms with ε-optimal average reward, introduced by Zhou et al. (2014).
The basic idea of our approach is to generalize our SEWP
algorithm with two modifications: (i) First, besides rejecting the arms that cannot be in the best m arms after each
phase, we also accept arms that have enough confidence
to be one of the best m arms, which shares a similar idea
with the Racing algorithm in Kaufmann & Kalyanakrishnan (2013). (ii) Specific stopping conditions are designed
to meet the ε-relaxation in the problem definition.
To make it easier to express the probe complexity, we intro(ε,m)
(ε,m)
duce a new symbol ∆i
defined by ∆i
= max{µi −
(ε,m)
µm+1 , ε} if i ≤ m and ∆i
= max{µm − µi , ε} if
(ε,m)
i > m. We then sort ∆i
for all i ∈ [K] in ascending
(ε,m)
order and let S(i) be the first i arms in the list, while ∆(i)
denotes the i-th smallest entry.
Analogously
to Theorem 1, let f (t) = 2t , g(t, δ) =
q
2
log(4Kt /δ)
, and define
2t+1

N̂(i) (ε, δ) = 

128
(ε,m)
∆(i)





2 log 

54K
4
log (ε,m) 
δ
∆(i)

(8)

(ε,m)

Note that N̂(1) (ε, δ) = N̂(2) (ε, δ) since ∆(1)
(ε,m)
∆(2)

= max{µm

=
.
− µm+1 , ε}. Also let M̂(i) (ε, δ) =

N̂(i) (ε, δ) − N̂(i+1) (ε, δ).

First we propose an algorithm that returns a subset Ŝ ∗ containing m (ε, m)-optimal arms with high probability. An
arm i is defined to be (ε, m)-optimal iff µi ≥ µm − ε. This
requirement is the same as qmin (Ŝ ∗ , µ) ≥ qmin ([m] , µ)−ε
where qmin (S, µ) = mini∈S µi .
The algorithm, called Successive Accept Reject with
Probes (SARWP) is shown in Algorithm 4. The following theorem shows that Algorithm 4 is admissible and the
probe complexity is bounded.
Algorithm 4 SuccessiveAcceptRejectWithProbes
1: Inputs: K, m, ε, δ, P, observation scheduling function
f : N → N and confidence function g : N × (0, 1] →
[0, ∞).
2: Initialize candidate set A1 = [K], accepted arms Aa1 =
∅, rejected arms Ar1 = ∅.
3: for t = 1, 2, . . . do
4:
C(t) ← COrcl(At , f (t), P).
5:
Use each p ∈ C(t) for Cp (t)-times to get new observations.
6:
For each i ∈ At , let µ̂i (t) be the mean of all observations so far for arm i. Sort the arms in At in descending order of µ̂i (t). Let Ht be the first m − |Aat |
arms and Lt = At \ Ht .
7:
if mini∈Ht µ̂i (t) ≥ maxi∈Lt µ̂i (t) + 2g(t, δ) − ε
then
8:
Return Ŝ ∗ = Aat ∪ Ht as selected subset.
9:
end if
10:
Let
Aat+1 = Aat ∪ {i ∈ Ht : µ̂i (t) > maxj∈Lt µ̂j (t) +
2g(t, δ)},
Art+1 = Art ∪ {i ∈ Lt : µ̂i (t) < minj∈Ht µ̂j (t) −
2g(t, δ)},
and At+1 = [K] − Aat+1 − Art+1
11: end for
Theorem 5. With probability at least 1 − δ, SARWP returns a subset Ŝ ∗ of size m within N probes, where
qmin (Ŝ ∗ , µ) ≥ qmin ([m] , µ) − ε and N satisfies N ≤

PK
GLP (O, P) i=2 M̂(i) (ε, δ)CLP S(i) , 1 .
The upper bound on the probe complexity is in a similar
form to the one for SEWP in Theorem 1, while here the
number of samples required for arm i is determined by
(ε,m)
∆i
instead of ∆i . This complexity measure matches
existing work for the bandit case (Kalyanakrishnan et al.,

On Identifying Good Options under Combinatorially Structured Feedback

2012; Kaufmann & Kalyanakrishnan, 2013). In the bandit
case, the upper bound matches the worst case lower bound
in Kalyanakrishnan et al. (2012): Ω(Kε−2 log(m/δ)), up
to logarithmic factors. We do not have a distribution dependent lower bound like Theorem 2 and even in the bandit
case a distribution dependent lower bound for ε > 0 is still
an open question (Kaufmann & Kalyanakrishnan, 2013).
4.2. Average PAC Subset Selection
Next we consider the problem that aims to find a subset whose aggregate regret is ε-optimal. Given a subset
S ⊂ [K] and |S|
regret
of S is defined
P= m, the aggregate

P
1
µ
−
µ
=
q
as RS = m
avg ([m] , µ) −
i∈[m] i
i∈S i
P
1
qavg (S, µ) where qavg (S, µ) = |S| i∈S µi . The aggregate
regret of S is said to be ε-optimal iff RS ≤ ε.
To address the problem of finding an average ε-optimal
subset, Algorithm 4 can still be employed by only modifying the stopping condition according to the different objective. The new stopping condition is described as follows:
Stopping condition for average PAC subset selection: First
for each i ∈ At , we construct an adversarial estimation
µ̂0i (t) by setting µ̂0i (t) = µ̂i (t) − g(t, δ) if i ∈ Ht and
µ̂0i (t) = µ̂i (t) + g(t, δ) if i ∈ Lt . Then we sort the arms in
descending order according to µ̂0i (t) and let Ht0 be the first
m − |Aat | arms while L0t be the remaining. The algorithm
stops and returns Ŝ ∗ = Aat ∪ Ht if
X
X
(µ̂i (t) + g(t, δ))−mε .
(µ̂i (t) − g(t, δ)) ≥
i∈Ht \Ht0

i∈Ht0 \Ht

This way of constructing “adversarial estimation” is similar
to the one in the CLUCB algorithm of Chen et al. (2014),
where the goal is to identify a subset with the highest reward sum without ε relaxation.
The next theorem shows that with the modified stopping
condition, Algorithm 4 is admissible and bounds its probe
complexity. Define
n
mε o
b(m, ε) = max a ∈ N+ : µm−a+1 − µm+a ≤
,
a
(9)
or b(m, ε) = 1 if µm − µm+1 > mε. Then we have the
following result:
Theorem 6. With probability at least 1 − δ,
SARWP with modified stopping condition returns
a subset Ŝ ∗ of size m within N probes, where
qavg (Ŝ ∗ , µ) ≥ qavg ([m] , µ) − ε and N satisfies

PK
N
≤
GLP (O, P) i=2 M̂(i) (mε/b, δ)CLP S(i) , 1 ,
where b = b(m, ε).
Compared with Theorem 5, the complexity here is mea(mε/b,m)
sured by ∆i
instead. This distribution depen-

dent complexity measure is novel even in the bandit case
since the algorithm in Zhou et al. (2014) comes with
distribution independent guarantee only. Regarding the
worst case performance, since b(m, ε) ≤ min{m, K −
m}, in bandit case our upper
 bound can be further
K
1
K
log
log
≤ K/2 and
relaxed
to
O
2
ε
δ
ε  if m


K(K−m)2
K
K−m
if m > K/2. ComO
log δ log mε
m2 ε2
pared with 
the worst
case
lower

 bound in Zhou et al.
log(1/δ)
K
(2014): Ω ε2 1 + m
for m ≤ K/2 and



log(1/δ)
K
K−m
Ω K−m
for m > K/2, alm · ε2
m +
m
though our upper bound does not exactly match this worse
case lower bound, our distribution dependent quantity
2
b(m, ε) shows how the different εK2 and K(K−m)
terms
m2 ε2
appear for small m and large m compared with K/2.

5. Conclusions
We introduced a generalized version of the best arm identification problem, where a decision maker can query multiple arms at a time. This generalization describes several
real world problems that are not adequately modeled by the
standard best-arm identification problem. We generalized
several existing algorithms and provided distribution dependent upper and lower bounds on the probe complexity,
and showed that our algorithms achieve essentially the best
possible performance in special cases. In the PAC subset
selection problems our complexity measure either matches
existing works for the bandit case or provides some new
insights. One very interesting question that remains for future work is whether there is a real gap between our lower
and upper bounds. However, much work remains to be
done: We view our paper as opening a whole new practical and exciting research area of investigating richer feedback structures in “winner selection” problems. Interesting
questions include how to change the algorithms when the
subsets to be returned are restricted, or when probes are
associated with costs.

Acknowledgement
This work was supported by the Alberta Innovates Technology Futures through the Alberta Ingenuity Centre for
Machine Learning (AICML) and NSERC.

On Identifying Good Options under Combinatorially Structured Feedback

References
Audibert, J.-Y., Bubeck, S., and Munos, R. Best arm identification in multi-armed bandits. In Proceedings of the
Annual Conference on Learning Theory (COLT), 2010.
Bechhofer, R. E. A sequential multiple-decision procedure
for selecting the best one of several normal populations
with a common unknown variance, and its use with various experimental designs. Biometrics, 14(3):408–429,
1958.
Bubeck, S., Munos, R., and Stoltz, G. Pure exploration in
finitely-armed and continuous-armed bandits. Theoretical Computer Science, 412(19):1832–1852, 2011.
Bubeck, S., Wang, T., and Viswanathan, N. Multiple identifications in multi-armed bandits. In Proceedings of International Conference on Machine Learning (ICML),
2013.

Kalyanakrishnan, S., Tewari, A., Auer, P., and Stone, P.
PAC subset selection in stochastic multi-armed bandits.
In Proceedings of International Conference on Machine
Learning (ICML), 2012.
Karnin, Z., Koren, T., and Somekh, O. Almost optimal
exploration in multi-armed bandits. In Proceedings of
International Conference on Machine Learning (ICML),
2013.
Kaufmann, E. and Kalyanakrishnan, S. Information complexity in bandit subset selection. In Proceedings of the
Annual Conference on Learning Theory (COLT), 2013.
Kaufmann, E., Cappé, O., and Garivier, A. On the complexity of best arm identification in multi-armed bandit
models. The Journal of Machine Learning Research,
2015. (to appear).
Korte, B. H. and Vygen, J. Combinatorial optimization:
theory and algorithms. Springer, 3 edition, 2006.

Cesa-Bianchi, N. and Lugosi, G. Prediction, Learning, and
Games. Cambridge University Press, Cambridge, 2006.

Lovász, L. On the ratio of optimal integral and fractional
covers. Discrete mathematics, 13(4):383–390, 1975.

Chen, S., Lin, T., King, I., Lyu, M. R., and Chen, W.
Combinatorial pure exploration of multi-armed bandits.
In Advances in Neural Information Processing Systems
(NIPS), 2014.

Mannor, S. and Tsitsiklis, J. N. The sample complexity of exploration in the multi-armed bandit problem.
The Journal of Machine Learning Research, 5:623–648,
2004.

Even-Dar, E., Mannor, S., and Mansour, Y. PAC bounds
for multi-armed bandit and Markov decision processes.
In Proceedings of the Annual Conference on Learning
Theory (COLT), pp. 255–270, 2002.

Paulson, E. A sequential procedure for selecting the population with the largest mean from k normal populations.
The Annals of Mathematical Statistics, 35(1):174–180,
1964.

Farrell, R. H. Asymptotic behavior of expected sample size
in certain one sided tests. The Annals of Mathematical
Statistics, 35(1):36–72, 1964.
Gabillon, V., Ghavamzadeh, M., and Lazaric, A. Best arm
identification: A unified approach to fixed budget and
fixed confidence. In Advances in Neural Information
Processing Systems (NIPS), 2012.
Grötschel, M., Lovász, L., and Schrijver, A. Geometric
Algorithms and Combinatorial Optimization. Springer,
2 edition, 1993.
Jamieson, K., Malloy, M., Nowak, R., and Bubeck, S. lil’
ucb : An optimal exploration algorithm for multi-armed
bandits. In Proceedings of the Annual Conference on
Learning Theory (COLT), 2014.
Kalyanakrishnan, S. and Stone, P. Efficient selection of
multiple bandit arms: Theory and practice. In Proceedings of International Conference on Machine Learning
(ICML), 2010.

Raz, R. and Safra, S. A sub-constant error-probability lowdegree test, and a sub-constant error-probability PCP
characterization of NP. In STOC, pp. 475–484, 1997.
Schrijver, Alexander. Combinatorial Optimization: Polyhedra and Efficiency. Springer, 2003.
Slavik, Petr. Approximation Algorithms for Set Cover and
Related Problems. PhD thesis, State University of New
York at Buffalo, 1998. AAI9833643.
Vazirani, V.V. Approximation algorithms. Springer, 2001.
Zhou, Y., Chen, X., and Li, J. Optimal pac multiple
arm identification with applications to crowdsourcing.
In Proceedings of International Conference on Machine
Learning (ICML), 2014.

