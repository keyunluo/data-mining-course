A Consistent Histogram Estimator for Exchangeable Graph Models

Stanley H. Chan
SCHAN @ SEAS . HARVARD . EDU
School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USA
Edoardo M. Airoldi
Department of Statistics, Harvard University, Cambridge, MA 02138, USA

Abstract
Exchangeable graph models (ExGM) subsume a
number of popular network models. The mathematical object that characterizes an ExGM is
termed a graphon. Finding scalable estimators of
graphons, provably consistent, remains an open
issue. In this paper, we propose a histogram estimator of a graphon that is provably consistent
and numerically efficient. The proposed estimator is based on a sorting-and-smoothing (SAS)
algorithm, which first sorts the empirical degree
of a graph, then smooths the sorted graph using
total variation minimization. The consistency of
the SAS algorithm is proved by leveraging sparsity concepts from compressed sensing.

1. Introduction
Developing statistical models for network data has been a
growing research area in statistics and machine learning
over the past decade (Goldenberg et al., 2009; Kolaczyk,
2009; Airoldi et al., 2011). Among many models, the
parametric families have been the major focus in the literature because of their simplicity and analytic tractability. Popular examples of these parametric models include the exponential random graph model (Wasserman,
2005; Hunter & Handcock, 2006), the stochastic blockmodel (Nowicki & Snijders, 2001), the mixed membership model (Airoldi et al., 2008), the latent space
model (Hoff et al., 2002), the graphlet (Azari & Airoldi,
2012) and many others. However, as the complexities of
the networks increase, it becomes increasingly more challenging to fit the data using a particular parametric model.
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

AIROLDI @ FAS . HARVARD . EDU

1.1. Non-parametric representation of a graph
In this paper, we consider a non-parametric perspective
of modeling network data using the exchangeable graph
models (ExGM). The notion of exchangeability is due to
de Finetti, later generalized by Aldous (1981), Hoover
(1979) and Kallenberg (2005). A connection between popular parametric models and exchangeable graph models has
been recently made (Hoff, 2008; Bickel & Chen, 2009).
The non-parametric (limit) object that characterizes an
ExGM is often termed a graphon. As we will define formally in Section 2, a graphon is a 2-dimensional continuous
function on [0, 1]2 → [0, 1] that generates random graphs.
Since a graphon is a model for network data, any model
based inference, prediction and hypothesis testing can be
performed using a graphon (Lloyd et al., 2012). For instance, when comparing networks that span different sample sizes, graphons provide a natural solution: If two samples of a network are generated from the same ExGM, they
should have the same graphon, and hence, comparing two
networks can be done by comparing two graphons.
In this paper, we propose an efficient graphon estimator
based on 2D histograms. The challenge of the problem is
two-fold. First, since graphons are unique up to measurepreserving transformations, it is important to identify the
conditions under which graphons can be uniquely recovered (e.g., see Yang et al., 2014). Second, it is desirable for
a graphon estimator to be provably consistent.
1.2. Related work
Previous methods of graphon estimation algorithms can be
classified into two categories as follows.
The first category is to perform graphon estimation conditioned on the node arrangement. When the node arrangement is conditioned on, we can bypass the difficult problem of identifying a canonical representation
of the graphon. For example, the universal singular
value thresholding (Chatterjee) and the matrix completion (Keshavan et al., 2010) seek low-rank structures of the

A Consistent Histogram Estimator for Exchangeable Graph Models

adjacency matrix, whereas the stochastic blockmodel approximation (Airoldi et al., 2013; Chan et al., 2013) groups
similar nodes to form community structures. However,
since the estimations are conditioned on the node arrangement, the resulting graphons are not canonical.

2. Graphons and identifiability

Different from the first category, the second category of
methods estimate canonical graphons. In (Bickel et al.,
2011), the authors proposed a method of moments which
is theoretically consistent for that purpose. However,
the method requires knowledge of all wheels of the network, and hence is computationally infeasible. Choi et
al. (Choi et al., 2012; Choi & Wolfe) attempted the problem by a clustering approach, but they stopped at the clustering step without actually estimating the graphon. In
(Lloyd et al., 2012), Lloyd et al. considered a Bayesian approach to estimate a graphon. However, the MCMC sampling process of the algorithm is computationally intensive.
Moreover, there is no consistency guarantee of the estimator. More recently, other groups have begun exploring
alternative approaches (Wolfe & Olhede; Tang et al., 2013;
Latouche & Robin, 2013; Olhede & Wolfe). Yet, none of
these methods are both consistent and computationally efficient.

2.1. Definition of a graphon

1.3. Contributions
In this paper, we propose a histogram approach to estimate
graphons. Our method, called the Sorting-And-Smoothing
(SAS) algorithm, consists of two steps. In the first step,
we sort the empirical degrees and rearrange the nodes of
the graph for a canonical ordering. In the second step, we
compute the histogram of the sorted graph and smooth the
histogram by a total variation minimization. Details of the
SAS algorithm are presented in Section 3.
The estimator returned by the SAS algorithm is consistent.
The consistency proof leverages the sparsity concepts from
compressed sensing. In particular, we show, in Theorem
3, that if the true graphon satisfies some Lipschitz conditions and has sparse gradients, then the mean squared error
(MSE) of the estimator is O((log n)/n), where n is the size
of the network. Discussion of the consistency is presented
in Section 4.
We test the SAS algorithm on both simulation data and real
data (Section 5). The experiment of using the simulation
data indicates that the SAS algorithm is superior to, both
in terms of estimation quality and speed, several existing
methods. Applying the SAS algorithm to real data, we estimate graphons of two large-scale social networks and reveal some structures. These results provide an alternative
way of analyzing large-scale network data.
For clarity of the presentation, details of the proofs can be
found in a follow up report (Chan & Airoldi, 2014).

The purpose of this section is to introduce the concepts of a
graphon and discuss the conditions under which a graphon
can be uniquely identified.

We let G be the adjacency matrix of a graph with the
(i, j)th entry denoted by Gij ∈ {0, 1}. For an infinitely
sized graph G, we say that G is exchangeable if it satisfies
the following definition.
Definition 1. An infinite random array G = (Gij )i,j∈N is
exchangeable if
d

(Gij ) = (Gσ(i)σ(j) ),

(1)

for any permutation σ.
Definition 1 is also known as the joint exchangeability, because the permutation is applied to both rows and columns
simultaneously (Orbanz & Roy).
We refer to all random graph models that satisfy exchangeability as exchangeable graph models (ExGM). A useful characterization of an ExGM is given by the AldousHoover theorem.
Theorem 1 (Aldous-Hoover). An infinite random array
(Gij )i,j∈N is exchangeable if and only if there is a random
measurable function F : [0, 1]3 → {0, 1} such that
d

(Gij ) = (F (Ui , Uj , Uij )),

(2)

where (Ui )i∈N and (Uij )i,j∈N are sequences of i.i.d.
Uniform[0, 1] random variables.
The function F in Theorem 1 defines a graphon:
Definition 2 (Graphon). A graphon w is a symmetric measurable function w : [0, 1]2 → [0, 1] such that
F (Ui , Uj , Uij ) =

(

1,
0,

if Uij < w(Ui , Uj )
otherwise,

(3)

where (Ui )i∈N and (Uij )i,j∈N are sequences of i.i.d.
Uniform[0, 1] random variables.
Equivalently, (3) can be expressed as the following twostage sampling scheme:
Ui
Gij | Ui , Uj

iid

∼ Uniform[0, 1],
∼ Bernoulli(w(Ui , Uj )).

(4)

Therefore, a finite sized network generated from a graphon
can be regarded as a finite sample drawn according to (4).

A Consistent Histogram Estimator for Exchangeable Graph Models

2.2. Identifiability of a graphon
To understand the identifiability issue of a graphon, it is
important to discuss measure preserving transformations.
Definition 3 (Measure Preserving Transformation). A
transformation ϕ : [0, 1] → [0, 1] is measure-preserving
w.r.t. a measure µ if it is measurable, and for all A ∈ [0, 1],
µ(ϕ−1 (A)) = µ(A).

def

w′ (u, v) = w(ϕ(u), ϕ(v))
defines the same ExGM as w because there exists a transformation such that w and w′ are identical.
The identifiability issue of a graphon arises because the
converse of Definition 3 is not true in general: If w and
w′ define the same ExGM, there may not exist a measure preserving transformation ϕ′ such that w(u, v) =
w′ (ϕ′ (u), ϕ′ (v)) (Diaconis & Janson, 2008). For example, the functions w(u, v) = uv and w′ (u, v) = (2u
mod 1)(2v mod 1) define the same ExGM, but there is
no ϕ′ such that w(u, v) = w′ (ϕ′ (u), ϕ′ (v)).
A formal statement of the above observation is given by the
following theorem, which says that we need to find a pair
of measure-preserving transformations ϕ and ϕ′ in order to
show that w is unique.
Theorem 2 ((Diaconis & Janson, 2008), Thm. 7.1). Let w
and w′ be two graphons. Then δ (w, w′ ) = 0 if and only if
there exist measure-preserving transformations ϕ and ϕ′ :
[0, 1] → [0, 1] such that
(6)

where the distance δ (w, w′ ) is the cut-norm defined by
(Lovász & Szegedy, 2006).
A consequence of Theorem 2 is the notion of twin-free:
Definition 4 (Twin-free (Borgs et al., 2010)). A graphon w
is called twin-free if for any u1 and u2 ∈ [0, 1], w(u1 , v) 6=
w(u2 , v) for almost all v ∈ [0, 1].
Essentially, the twin-free condition excludes the cases
where two graphons can be made identical by row and column permutations. For example, the pair shown in Figure 1
are twin, and hence they are not identifiable.
The twin-free condition is necessary but not sufficient
for identifying a unique graphon when we marginalize a
graphon (Orbanz & Roy):
Z 1
def
g(u) =
w(u, v)dv.
0

1

1

0

1

0

0

1

(5)

For example, if ϕ is a measure preserving transformation
and U ∼ Uniform[0, 1], then ϕ(U ) is also distributed uniformly on [0, 1]. Similarly, if ϕ is a measure preserving
transformation, then the graphon

w(ϕ(u), ϕ(v)) = w′ (ϕ′ (u), ϕ′ (v)),

0

w′

w

Figure 1. Example of a pair of twin graphons: w and w′ are not
identifiable if we randomly permute their columns and rows.

For example, if we consider w and w′ in Figure 1, and a
graphon w′′ (u, v) = 1/2, then w′′ is twin-free but g(u) =
g ′ (u) = g ′′ (u), where g, g ′ and g ′′ are marginalizations of
w, w′ and w′′ , respectively.
The necessary and sufficient condition for a graphon to
be identifiable is to require strict monotonicity of degrees
(Bickel & Chen, 2009; Yang et al., 2014).
Condition 1 (Strict Monotonicity of Degree). A graphon
w has a unique representation if and only if there exists
wcan such that
Z 1
def
g can (u) =
wcan (u, v)dv
0

is strictly increasing (or decreasing). The graphon wcan is
called the canonical representation of w.
It is evident that the strict monotonicity condition implies twin-free, but not vice versa. In addition, if we let
U ∼ Uniform[0, 1], then strict monotonicity implies that
g can (U ) is absolutely continuous.
In the rest of the paper we assume that all graphons of interests satisfy the strict monotonicity condition. For notational simplicity, we drop the superscript (·)can , and denote
w as the canonical representation.

3. The sorting-and-smoothing algorithm
3.1. Overview
The intuition of the proposed SAS algorithm is based on the
following idea: As the size of a graph grows, the (sorted)
empirical degree should converge to the ideal (canonical)
degree distribution. Therefore, if we can sort the empirical
degree of a given graph, then by applying suitable smoothing algorithms we can find an estimate of the canonical
graphon.
Following this intuition, we propose a two-stage algorithm.
In the first stage, we sort the rows and columns of G to
b according to the empirical degree.
obtain a sorted graph A

A Consistent Histogram Estimator for Exchangeable Graph Models
50

50

100

100

150

10

10

20

20

30

30

40

40

150

200

200

250

250

300

300

50

50

350

350

60

60

400

400

70

70

450

450
80

500

80

500
100

200

300

400

500

Observed graph
G ∈ {0, 1}n×n

100

200

300

400

Sorted graph
b ∈ {0, 1}n×n
A

500

10

20

30

40

50

60

70

80

10

Histogram
b ∈ [0, 1]k×k
H

20

30

40

50

60

70

80

Estimated graphon
w
btv ∈ [0, 1]k×k

b Then, a
Figure 2. Illustration of the SAS algorithm. Given an observed graph G, we first sort G using the empirical degrees to get A.
b is computed and a total variation minimization is used to determine an estimate w
local histogram H
btv .

b of A,
b and
In the second stage, we compute a histogram H
apply a total variation minimization to find an estimate w
btv .
An illustration of the SAS algorithm is shown in Figure 2.
3.2. Stage 1: Sorting
The purpose of the sorting step is to rearrange the observed
graph G so that the rearranged empirical degrees are monotonically increasing. To this end, we compute the empirical
degree
n
X
def
di =
Gij ,
(7)
j=1

and define a permutation σ
b such that dσb(1) < . . . < dσb(n) .
Then, we define a rearranged graph
bij = Gσb(i)bσ (j) ,
A

(8)

where an example is shown in Figure 2.
It is important to note that since the permutation σ
b is defined by the empirical degrees, it could be different from
the true permutation that defines the canonical graphon according to the node arrangement. To differentiate the empirical permutation σ
b and the true permutation, we define
σ as the oracle permutation that sorts the node labels (Ui )
such that Uσ(1) < . . . < Uσ(n) . Correspondingly, we define the oracle ordered graph as
Aij = Gσ(i)σ(j) .

(9)

3.3. Stage 2: Smoothing
Network Histogram Estimation
Once the graph is rearranged to have monotonically increasing degrees, the graphon estimation problem becomes
bij ). To this end,
finding a smooth surface that best fits (A
we consider a simplified version of the stochastic blockmodel approximation (Airoldi et al., 2013) which approximates the continuous graphon using a piecewise constant
function. More precisely, the stochastic blockmodel ap-

proximation defines
h X
h
X
b ij = 1
bih+i1 ,jh+j1 ,
H
A
h2 i =1 j =1
1

(10)

1

and correspondingly
Hij =

h
h
1 X X
Aih+i1 ,jh+j1 ,
h2 i =1 j =1
1

(11)

1

for some parameter h > 0 denoting the size of each block.
Equations (10) and (11) indicate that the stochastic blockb ij ) and (Hij ) are the histograms
model approximations (H
b
of (Aij ) and (Aij ), respectively. Since all function values in the same block are identical, the effective degrees of
b ij ) and (Hij ) are k × k instead of n × n,
freedom in (H
where k = ⌊n/h⌋ is the number of blocks.
Total Variation Minimization
While the network histogram estimation step is consistent,
the decay rate of the error can be further improved by introducing a total variation minimization step.

The total variation minimization step is based on a sparsity
assumption of the true graphon w. Analogous to natural
images, we assume that graphons are sparse in the gradients. Discretizing the continuous graphon w into a k × k
grid, the assumption suggests that w needs to have a small
total variation
s
2

2
k X
k
X
∂w
∂w
kwkT V =
+
,
(12)
∂x ij
∂y ij
i=1 j=1
∂w
where ∂w
∂x and ∂y denote the horizontal and vertical finite
difference of w, respectively.

Using the total variation concept, the refinement step can
be posed as the following minimization problem:
w
btv = argmin kb
r kT V ,
r
b

b 2 ≤ ε, (13)
subject to kb
r − Hk

A Consistent Histogram Estimator for Exchangeable Graph Models

where k·k2 is the matrix Frobenius norm, and ε > 0 is a parameter that controls the fidelity between the total variation
b To solve the minimization
solution rb and the histogram H.
problem (13), we use the alternating direction method of
multipliers (ADMM) (Chan et al., 2011).
We remark that the size of w
btv is k × k. To ensure that the
final estimate have the same size as the true graphon, we
define the final estimate as
w
b

est

tv

=w
b

⊗ 1h×h ,

(14)

where 1h×h denotes an all 1 matrix of size h×h, and ⊗ denotes the Kronecker product operator. Therefore, the final
estimate w
best has a size n × n.
3.4. Complexity

The complexity of the SAS algorithm can be analyzed by
considering each step individually. In computing the empirical degree distribution, O(n) additions are used. The
sorting procedure, in general, requires O(n log n) comparisons. Therefore, the complexity for sorting is about
O(n log n) multiplications plus O(n) additions. Next, for
the histogram computation, computing each value of the
bin requires O(h2 ) additions, and there are k 2 = (n/h)2
bins. Thus a total of O(n2 ) additions are needed. Finally,
the total variation minimization is solved on a k × k array.
Thus, the complexity of the ADMM step is O(k 2 log k 2 ).
(See (Chan et al., 2011) for discussions.) Combing these
results we can show that the overall complexity of the SAS
algorithm is O(n log n + k 2 log k 2 ) multiplications plus
O(n2 ) additions.

Lemma 1 (Piecewise Constant Function Approximation).
Let w ∈ [0, 1]n×n be the true graphon and let H w ∈
[0, 1]k×k be the histogram approximation defined in (16).
Then,
C′
kH w ⊗ 1h×h − wk22 ≤ 2 ,
(17)
k
where C ′ is a constant independent of n.
Therefore, it remains to find an upper bound of kw
btv −
H w k22 . (The last expectation in (15) can be bounded using
Cauchy’s inequality.) In the following subsections, we discuss how each step of the SAS algorithm contributes to this
upper bound.
4.1. Consistency of empirical degree sorting
To establish the consistency of the empirical degree sorting,
we must first establish the relationship between the oracle
permutation (σ(i)) and the oracle degree (dσ(i) ).
Lemma 2. Let σ(i) be the oracle permutation such that
R1
Uσ(1) < Uσ(2) < . . . < Uσ(n) . Let g(u) = 0 w(u, v)dv,
and assume that there exists constants L1 > 0 and L2 > 0
such that
L2 |x − y| ≤ |g(x) − g(y)| ≤ L1 |x − y|,

for any 0 ≤ x ≤ 1 and 0 ≤ y ≤ 1. Then, the following
result holds.
q



σ(j) 
log n
1
If  σ(i)
−
<

n
n
6L1
n , then


dσ(i) − dσ(j)  <

4. Consistency
In this section we discuss the statistical consistency of the
proposed SAS algorithm.
Analyzing the consistency of the SAS algorithm is equivalent to determining an upper bound of the error
 est

def 1
MSE = 2 E kw
b − wk22
n



1   2 tv
= 2 E h kw
b − H w k22 + E kH w ⊗ 1h×h − wk22
n
 tv

+ 2E (w
b − H w )T (H w ⊗ 1h×h − w) ,
(15)
where H w is the histogram approximation of w:
w
Hij
=

h
h
1 X X
wih+i1 ,jh+j1 .
h2 i =1 j =1
1

(16)

1

Before we proceed, we note that the second expectation
in (15) is a classical result of approximating a continuous
function by step functions. The bound is given in the following Lemma.

(18)

with probability at least 1 − 8e

−

r

1
18L2
1

log n
,
n
log n

(19)

.

Conversely, if (19) holds with probability at least 1 −
8e

−

1
18L2
1

log n

, then

 r


 σ(i) σ(j) 
log n 1
1
1


+
+
,
 n − n <
n
3L1
3L1 L2
L2
(20)

with probability at least 1 − 40e

−

1
18L2
1

log n

.

The interpretation of Lemma 2 is as follows. First, (18)
is the two-sided Lipschitz condition, with Lipschitz constants L1 and L2 . The Lipschitz condition enforces the degree distribution g(u) to be well-behaved so that there is
no abrupt transition for both g and g −1 . Second, the forward statement suggests that if the oracle ordered indices
have bounded differences, then correspondingly the empirical degrees should also have bounded differences. Conversely, (20) suggests that if we can bound the difference
in empirical degrees, then the difference in the true positions should also be bounded.

A Consistent Histogram Estimator for Exchangeable Graph Models

As an immediate consequence of Lemma 2, we observe
that for any fixed i, if we choose j such that σ(j) = σ
b(i),
then the converse of Lemma 2 implies the following.

 q
Corollary 1. If dσ(i) − dσb(i)  < logn n holds with prob−

1

2

log n

, then
ability at least 1 − 8e 18L1
r


 σ(i) σ
log n
b(i) 

 n − n <C
n
−

1
2

log n

holds with probability at least 1 − 40e 18L1
, where
C = 3L1 1 + 3L11 L2 + L12 is a constant independent of n.



Therefore, if the error dσ(i) − dσb(i)  is small, then the error between σ(i) and σ
b(i) will also be small.
4.2. Consistency of the histogram estimator

During the histogram estimation step, the error associated
with the empirical degree sorting is translated to the error
b and the ideal histogram
between the empirical histogram H
H. This is reflected in the following lemma.
b − Hk2 ). Let w be the ground
Lemma 3 (Bounds on kH
truth graphon and assume that w is Lipschitz with constant
b are defined according to (11) and (10),
L > 0. If H and H
respectively, then


k4
2
2 2 log n
b
E[kH − Hk2 ] ≤ 2 2 + 4C L
n
n


2
2 2 log n
+ k 4C L
,
(21)
n
where C is a constant independent of n.
We also establish the relationship between H and the step
approximation H w .
w

k4
.
n2

(22)

4.3. Consistency of total variation smoothing
To analyze the total variation minimization step, we first
observe that
b = Hw + H
b − H + H − Hw.
H
| {z
} | {z }
η

To characterize the solution of the total variation minimization problem, we first define the s-sparsity of the gradient
of a function H w .
Definition 5. A function H w ∈ [0, 1]k×k is s-sparse in
gradient if its gradient ∇H w has at most s non-zero entries.
With this definition, we apply the following result in compressed sensing.
b = Hw +
Lemma 5 ((Needell & Ward) Theorem A). If H
2
2
η + ρ with ε = E[kη + ρk2 ], then the solution w
btv of
w
btv = argmin kb
r kT V

subject to

r
b

satisfies the condition

kw
btv − H w k2 ≤

b 2 ≤ ε,
kb
r − Hk

k∇H w − (∇H w )s k1
√
+ ε,
s

where (·)s denotes the function reconstructed from the s
most significant non-zero entries of the argument.
Lemma 5 indicates that the error kw
btv −H w k2 is controlled
by the perturbation ε and the sparse approximation error
k∇H w − (∇H w )s k1 . Since ε2 = E[kη + ρk22 ], and η
and ρ are defined according to (23), ε is upper bounded by
(21) and (22). For the sparse approximation error term, in
general k∇H w − (∇H w )s k1 6= 0 because H w is not necessarily s-sparse in gradient. However, in practice, many
real world networks are sparse (i.e. number of edges are
much fewer than number of nodes). Therefore, for practical consideration it is often reasonable to assume that H w
is s-sparse in gradient and so k∇H w − (∇H w )s k1 = 0.
4.4. Overall consistency

w

Lemma 4 (Bounds on kH − H k2 ). Let H be the step
function approximation of the graphon w and let H be the
histogram defined as (11). Then,
E[kH − H w k22 ] ≤

(23), we find a solution w
btv that best fits (23) and has the
minimum total variation.

(23)

ρ

Therefore, if we consider H w as the desired function to be
estimated, and consider η and ρ as perturbations added to
b can be regarded as a noisy observation of H w .
H w , then H
Consequently, by applying total variation minimization to

In summary, the overall consistency is given by the following theorem.
Theorem 3 (Consistency of SAS algorithm). Let w be the
true graphon with the following properties: (i) w is LipR1
schitz with constant L > 0; (ii) g(u) = 0 w(u, v)dv is
Lipschitz as defined in Lemma 2; (iii) H w is s-sparse in
gradient. Then, the MSE of the SAS estimator satisfies


log n
MSE ≤ O
,
(24)
n
and hence MSE → 0 as n → ∞ and k/n → 0, where k is
the number of blocks defined in (11).

5. Experimental results
After establishing the theoretical results, we now present
simulation results of the proposed SAS algorithm.

A Consistent Histogram Estimator for Exchangeable Graph Models

5.1. Simulations

SAS (Proposed)

USVT

SBA

The first experiment considers a number of graphons listed
in Table 1. The choices of these graphons are made to include both low rank and high rank graphons, where the rank
is measured numerically using a 1000×1000 discretization
of the continuous graphons. Among the 10 graphons listed
in Table 1, we note that graphon no. 1 w(u, v) = uv is a
special case of the eigenmodel (Hoff, 2008), graphon no. 5
w(u, v) = 1/(1 + exp{−10(u2 + v 2 )}) is a variation of the
logistic model presented in (Chatterjee), and graphon no. 6
w(u, v) = |u − v| is the latent distance model (Hoff et al.,
2002). Other graphons are chosen to demonstrate the robustness of the SAS algorithm.

(a) 1.09 × 10−5

(b) 8.69 × 10−5

(c) 1.60 × 10−3

(d) 1.37 × 10−4

(e) 1.24 × 10−3

(f) 7.38 × 10−4

ID
1
2
3
4
5
6
7
8
9
10

w(u, v)
uv
0.7
exp{−(u
+ v 0.7 )} 
 2
1
2
1/2
+ v 1/2
4 u +v +u
1
(u
+
v)
2
1
1+exp{−10(u2 +v 2 )}

|u − v|

1
1+exp{−(max(u,v)2 +min(u,v)4 )}
3/4

exp{− max(u, v) }

exp{− 21 min(u, v) + u1/2 + v 1/2 }
log(1 + 0.5 max(u, v))

rank(w)
1
1
2
2
10
1000
1000
1000
1000
1000

Table 1. List of graphons for testing. The rank of w is estimated
from a 1000 × 1000 discretization of the graphon.

We compare the SAS algorithm with the universal singular value thresholding (USVT) algorithm (Chatterjee)
and the stochastic blockmodel approximation algorithm
(Airoldi et al., 2013). These two algorithms are the existing methods that have provable consistency and are numerically efficient. However, since both of these two methods
do not have a sorting step, we apply the sorting step of the
SAS algorithm prior to running the two algorithms. For the
choice of binwidth h, we set h = log n for the SAS algorithm, and an oracle h that minimizes the MSE for the SBA
algorithm (i.e., using the ground truth).
The results of the experiment are shown in Table 2, where
we report the mean squared error (MSE) of the estimated
graphons using the SAS algorithm, the USVT algorithm
and the SBA algorithm. To reduce the random fluctuations
caused by independent realizations of the random graphs,
we average the MSE over 50 independent trials. Two cases
of graph sizes are considered: n = 200 and n = 1000.
The results show that the SAS algorithm in general outperforms the USVT algorithm and the SBA algorithm. Averaged over the 10 testing graphons, we see that the SAS
algorithm achieves the lowest MSE among all three methods.

Figure 3. Comparisons between the SAS algorithm, the USVT
algorithm (Chatterjee), and the SBA algorithm (Airoldi et al.,
2013). Numbers indicate the mean squared error. (a)-(c):
Graphon 5; (d)-(f): Graphon 10. SAS algorithm uses h = log n.
SBA algorithm uses an oracle h that minimizes the MSE. In this
example, we set n = 1000.

Figure 3 displays two examples of the estimated graphons.
As shown in the figure, we see that while the USVT algorithm returns a reasonable estimate for graphon no.5 (which
has a low rank), it returns a relatively worse estimate for
graphon no. 10 (which has a high rank). Looking at the
SBA algorithm, it is evident that using the oracle binwidth
h, the average MSE is lower than that of USVT. However,
the SBA algorithm tends to return a graphon with few communities. This is not favorable if the network has non-block
structures. In contrast, the SAS algorithm returns results
with lower MSE, and retains important features of the true
graphons.
In Figure 4 we show the runtime comparison between the
SAS algorithm and the USVT algorithm. Both algorithms
are implemented on an Intel 3.5GHz machine with 16GB
RAM, Windows 7 / MATLAB R7.12.0 platform. The runtime plot indicates that the SAS algorithm has a significantly lower complexity than the USVT algorithm.
5.2. Real data analysis
As an application of the proposed SAS algorithm, we
consider the problem of estimating graphons from realworld networks. For this purpose, we consider the collaboration network of arXiv astro physics (ca-AstroPh)
and the who-trusts-whom network of Epinions.com (socEpinions1) from Stanford Large Network Dataset Collection1 . The ca-AstroPh network is a symmetric binary graph
consisting of 1.8 × 104 nodes and 3.9 × 105 edges, whereas
the soc-Epinions-1 network is an unsymmetrical binary
1

http://www.cise.ufl.edu/research/sparse/matrices/SNAP/

A Consistent Histogram Estimator for Exchangeable Graph Models

ID

SAS (Proposed)

n = 200
USVT (Chatterjee)

SBA (Airoldi et al., 2013)

SAS (Proposed)

n = 1000
USVT (Chatterjee)

SBA (Airoldi et al., 2013)

1
2
3
4
5
6
7
8
9
10

6.59e-04 ± 5.18e-05
4.92e-04 ± 6.81e-05
6.95e-04 ± 7.52e-05
6.48e-04 ± 5.30e-05
9.74e-05 ± 2.76e-05
4.29e-02 ± 9.27e-05
4.81e-04 ± 7.50e-05
9.38e-04 ± 1.21e-04
6.50e-04 ± 7.73e-05
7.67e-04 ± 1.01e-04

1.90e-03 ± 1.88e-04
2.18e-03 ± 1.95e-04
3.12e-03 ± 2.32e-04
3.51e-03 ± 1.93e-04
3.15e-03 ± 8.76e-19
8.91e-02 ± 1.23e-03
2.40e-03 ± 1.77e-04
6.27e-03 ± 1.58e-03
2.87e-03 ± 2.32e-04
4.74e-03 ± 6.25e-04

2.77e-03 ± 1.60e-04
2.36e-03 ± 1.97e-04
5.08e-03 ± 2.26e-04
2.77e-03 ± 1.49e-04
3.13e-03 ± 3.31e-04
4.37e-02 ± 1.20e-04
2.71e-03 ± 2.09e-04
1.52e-03 ± 1.52e-04
3.96e-03 ± 3.25e-04
1.13e-03 ± 1.23e-04

8.56e-05 ± 3.42e-06
7.12e-05 ± 5.92e-06
9.60e-05 ± 5.78e-06
7.82e-05 ± 5.17e-06
1.09e-05 ± 1.66e-06
4.19e-02 ± 9.58e-06
8.48e-05 ± 7.47e-06
1.73e-04 ± 1.30e-05
1.02e-04 ± 5.15e-06
1.37e-04 ± 1.02e-05

3.86e-04±1.70e-05
4.46e-04±1.84e-05
9.69e-04±2.67e-05
8.83e-04±2.47e-05
8.69e-05±7.03e-06
8.42e-02±1.70e-04
6.76e-04±1.81e-05
1.66e-03±4.56e-05
1.26e-03±3.01e-05
1.24e-03±3.30e-05

9.00e-04 ± 1.70e-05
1.39e-03 ± 3.99e-05
8.66e-04 ± 1.90e-05
1.43e-03 ± 2.63e-05
1.60e-03 ± 3.45e-05
4.22e-02 ± 1.42e-05
1.21e-03 ± 3.65e-05
6.81e-04 ± 2.14e-05
1.15e-03 ± 3.44e-05
7.38e-04 ± 1.67e-05

Average

4.83e-03 ± 7.43e-05

1.19e-02 ± 4.65e-04

6.91e-03 ± 1.99e-04

4.27e-03 ± 6.74e-06

9.18e-03±3.91e-05

5.22e-03±2.06e-05

Table 2. Mean squared error (average ± std. dev.) comparisons between the SAS algorithm, the USVT algorithm (Chatterjee), and the
SBA algorithm (Airoldi et al., 2013). MSE is averaged over 50 independent trials.

ca-AstroPh network, the graphon shows close collaborations among a group of people concentrated around the
top left corner of the graphon. It also shows a number
of small communities along the diagonal. For the socEpinions1 network, the graphon indicates that there are
some influential nodes which consistently interact among
themselves. These can be seen from the repeated patterns
of the graphon.

5
USVT
SAS (proposed)

4.5

Run Time (Seconds)

4
3.5
3
2.5
2
1.5
1
0.5
0

0

500

1000
n

1500

2000

Figure 4. Run time comparison between USVT (Chatterjee) and
the SAS algorithm (averaged over 10 graphons listed in Table 1).

Figure 5. Estimated graphons for real networks. Left: Collaboration network of arXiv astro physics (ca-AstroPh) n = 1.8 ×
104 . Right: who-trusts-whom network of Epinions.com (socEpinions1) n = 7.5 × 104 .

graph consisting of 7.5×104 nodes and 5.1×105 edges. For
both networks, we randomly permute the rows and columns
to simulate the raw data scenario where nodes are initially
unordered.
Figure 5 shows the results of the SAS algorithm. For the

We remark that or the ca-AstroPh network (n = 1.8 × 104)
and the soc-Epinions-1 network (n = 7.5 × 104 ), the estimations are completed in 20 seconds and 170 seconds, respectively, on a PC using an unoptimized MATLAB code.
This provides a strong indication of the scalability of the
SAS algorithm to larger networks.

6. Concluding remarks
The Sorting-And-Smoothing (SAS) algorithm is a consistent and efficient graphon estimation algorithm. The SAS
algorithm consists of two steps. In the first step, the observed graph is rearranged so that the degrees are monotonically increasing. In the second step, a histogram estimation and a total variation minimization is applied to
estimate a smooth surface that best fits the observed data.
The SAS algorithm is evaluated on both simulation data
and real network data. Our simulation results indicate that
the SAS algorithm outperforms the universal singular value
thresholding algorithm and the stochastic blockmodel approximation algorithm. On large-scale real networks, the
SAS algorithm returns consistent graphon estimates.
Code. Available at: https://github.com/airoldilab/SAS
Acknowledgments. The authors thank J. J. Yang and C. Q.
Han for useful discussions. SHC is partially supported by
a Croucher Foundation Postdoctoral Research Fellowship.
EMA is partially supported by NSF CAREER award IIS1149662, AROMURI award W911NF-11-1-0036, and an
Alfred P. Sloan Research Fellowship.

A Consistent Histogram Estimator for Exchangeable Graph Models

References
Airoldi, E. M., Blei, D. M., Fienberg, S. E., and Xing, E. P.
Mixed-membership stochastic blockmodels. Journal of Machine Learning Research, 9:1981–2014, 2008.
Airoldi, E. M., Bai, X., and Carley, K. M. Network sampling and
classification: An investigation of network model representations. Decision Support Systems, 51:506–518, Jun. 2011.
Airoldi, E. M., Costa, T. B., and Chan, S. H. Stochastic blockmodel approximation of a graphon: Theory and consistent estimation. In Advances in Neural Information Processing Systems
(NIPS), volume 26, pp. 692–700, 2013. ArXiv:1311.1731.
Aldous, D. J. Representations for partially exchangeable arrays
of random variables. Journal of Multivariate Analysis, 11(4):
581–598, Dec. 1981.
Azari, H. and Airoldi, E. M. Graphlet decomposition of a
weighted network. Journal of Machine Learning Research,
W&CP, 22:54–63, 2012.
Bickel, P. J. and Chen, A. A nonparametric view of network models and Newman-Girvan and other modularities. Proc. Natl.
Acad. Sci. USA, 106(50):21068–21073, Dec. 2009.
Bickel, P. J., Chen, A., and Levina, E. The method of moments
and degree distributions for network models. The Annals of
Statistics, 39(5):2280–2301, 2011.
Borgs, C., Chayes, J., and Lovász, L. Moments of two-variable
functions and the uniqueness of graph limits. Geom. Funct.
Anal., 19:1597–1619, Mar. 2010.
Chan, S. H. and Airoldi, E. M. A consistent histogram estimator
for exchangeable graph models. arXiv:1402.1888, Feb. 2014.
Chan, S. H., Khoshabeh, R., Gibson, K. B., Gill, P. E., and
Nguyen, T. Q. An augmented Lagrangian method for total
variation video restoration. IEEE Trans. Image Process., 20
(11):3097–3111, Nov. 2011.
Chan, S. H., Costa, T. B., and Airoldi, E. M. Estimation of exchangeable random graph models by stochastic blockmodel
approximation. In Proc. IEEE Global Conference on Signal
and Information Processing (GlobalSIP), pp. 293–296, 2013.
Chatterjee, S. Matrix estimation by universal singular value
thresholding. ArXiv:1212.1247. 2012.
Choi, D. S., Wolfe, P. J., and Airoldi, E. M. Stochastic blockmodels with a growing number of classes. Biometrika, 99(2):
273–284, Jun. 2012.
Choi, D.S. and Wolfe, P.J. Co-clustering separately exchangeable
network data. ArXiv:1212.4093. 2012.

Hoff, P. D. Modeling homophily and stochastic equivalence in
symmetric relational data. In Advances in Neural Information
Processing Systems (NIPS), volume 20, pp. 657–664, 2008.
Hoff, P. D., Raftery, A. E., and Handcock, M. S. Latent space
approaches to social network analysis. Journal of the American
Statistical Association, 97(460):1090–1098, Dec. 2002.
Hoover, D. Relations on probability spaces and arrays of random
variables. Institute for Advanced Study, Princeton, NJ, 1979.
Hunter, D. R. and Handcock, M. S. Inference in curved exponential family models for networks. Journal of Computational and
Graphical Statistics, 15(3):565–583, 2006.
Kallenberg, O. Probabilistic Symmetries and Invariance Principles. Springer, 2005.
Keshavan, R. H., Montanari, A., and Oh, S. Matrix completion
from a few entries. IEEE Trans. Information Theory, 56:2980–
2998, Jun. 2010.
Kolaczyk, E. Statistical Analysis of Network Data: Methods and
Models. Springer, 2009.
Latouche, P. and Robin, S. Bayesian model averaging of stochastic block models to estimate the graphon function and motif
frequencies in a w-graph model. ArXiv:1310.6150, Oct. 2013.
Unpublished manuscript.
Lloyd, J. R., Orbanz, P., Ghahramani, Z., and Roy, D. M. Random function priors for exchangeable arrays with applications
to graphs and relational data. In Advances in Neural Information Processing Systems (NIPS), volume 25, pp. 1007–1015,
2012.
Lovász, L. and Szegedy, B. Limits of dense graph sequences.
Journal of Combinatorial Theory, Series B, 96:933–957, 2006.
Needell, D. and Ward, R. Stable image reconstruction using total
variation minimization. ArXiv:1202.6429. 2013.
Nowicki, K. and Snijders, T. Estimation and prediction of
stochastic block structures. Journal of American Statistical Association, 96:1077–1087, 2001.
Olhede, S. C. and Wolfe, P. J. Network histograms and universality of blockmodel approximation. ArXiv:1312.5306. 2013.
Orbanz, P. and Roy, D. M. Bayesian models of graphs, arrays and other exchangeable random structures. Unpublished
manuscript. 2013.
Tang, M., Sussman, D. L., and Priebe, C. E. Universally consistent vertex classification for latent positions graphs. The Annals
of Statistics, 41:1406–1430, 2013.
Wasserman, L. All of Nonparametric Statistics. Springer, 2005.

Diaconis, P. and Janson, S. Graph limits and exchangeable random graphs. Rendiconti di Matematica e delle sue Applicazioni, Series VII, pp. 33–61, 2008.

Wolfe, P. J. and Olhede, S. C. Nonparametric graphon estimation.
ArXiv:1309.5936. 2013.

Goldenberg, A., Zheng, A. X., Fienberg, S. E., and Airoldi,
E. M. A survey of statistical network models. Foundations
and Trends in Machine Learning, 2(2):129–233, Feb. 2009.

Yang, J. J., Han, C. Q., and Airoldi, E. M. Nonparametric estimation and testing of exchangeable graph models. In Journal
of Machine Learning Research, W & CP (AISTATS), 2014. In
press.

