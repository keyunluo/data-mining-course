Correlation Clustering in Data Streams

Kook Jin Ahn1
University of Pennsylvania, Philadelphia, PA 19104, USA.

KOOKJIN @ CIS . UPENN . EDU

Graham Cormode
University of Warwick, Coventry CV4 7AL, UK.

G . CORMODE @ WARWICK . AC . UK

Sudipto Guha
University of Pennsylvania, Philadelphia, PA 19104, USA.

SUDIPTO @ CIS . UPENN . EDU

Andrew McGregor
University of Massachusetts, Amherst, MA 01003, USA.

MCGREGOR @ CS . UMASS . EDU

Anthony Wirth
AWIRTH @ UNIMELB . EDU . AU
Department of Computing and Information Systems, The University of Melbourne, Vic 3010, Australia.

Abstract

1

1. Introduction

In this paper, we address the problem of correlation clustering in the dynamic data stream
model. The stream consists of updates to the edge
weights of a graph on n nodes and the goal is to
find a node-partition such that the end-points of
negative-weight edges are typically in different
clusters whereas the end-points of positive-weight
edges are typically in the same cluster. We present
polynomial-time, O(n ¬∑ polylog n)-space approximation algorithms for natural problems that arise.

The correlation clustering problem was first formulated as
an optimization problem by Bansal et al. (2004). The input
is a complete weighted graph G on n nodes, where each pair
of nodes uv has weight wuv ‚àà R. A positive-weight edge
indicates that u and v should be in the same cluster, whereas
a negative-weight edge indicates that u and v should be in
different clusters. Given a node-partition C = {C1 , C2 , . . .},
we say edge uv agrees with C, denoted by uv ‚àº C, if the
relevant soft constraint is observed. Summing over all edges,

We first develop data structures based on linear
sketches that allow the ‚Äúquality‚Äù of a given nodepartition to be measured. We then combine these
data structures with convex programming and
sampling techniques to solve the relevant approximation problem. However the standard LP and
SDP formulations are not obviously solvable in
O(n ¬∑ polylog n)-space. Our work presents spaceefficient algorithms for the convex programming
required, as well as approaches to reduce the adaptivity of the sampling. Note that the improved
space and running-time bounds achieved from
streaming algorithms are also useful for offline
settings such as MapReduce models.

agree(G, C) :=

Currently at Google, Inc. Email:kookjin@google.com

Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

X
uv‚àºC

|wuv | =

X

|wuv | ‚àí disagree(G, C) .

uv

The goal is to find the partition C that maximizes
agree(G, C) or, equivalently for optimization, minimizes
disagree(G, C). Solving this problem exactly is known
to be NP-hard. A large body of work has been devoted
to approximating max-agree(G) = maxC agree(G, C) and
min-disagree(G) = minC disagree(G, C), along with variants min-disagreek (G) and max-agreek (G), where we consider partitions with at most k clusters. In this paper, we
focus on multiplicative approximation results exclusively.
If all weights are ¬±1, there is a polynomial time approximation scheme PTAS for max-agree (Bansal et al., 2004;
Giotis & Guruswami, 2006) and a 2.06-approximation for
min-disagree (Chawla et al., 2015). When there is an upper
bound k on the number of clusters in C, and all weights
are ¬±1, Giotis & Guruswami (2006) introduced a PTAS for
both problems. Even k = 2 is interesting and an efficient
local-search approximation was introduced by Coleman
et al. (2008).

Correlation Clustering in Data Streams

If the weights are arbitrary, there is a 0.7666-approximation
for max-agree (Charikar et al., 2005; Swamy, 2004) and an
O(log n) approximation for min-disagree (Charikar et al.,
2005; Demaine et al., 2006). These methods use convex
programming: as described, this cannot be implemented
in O(n polylog n) memory even when the input graph is
sparse. This annoying feature is well known in practice:
Bagon & Galun (2011); Bonchi et al. (2014); Elsner &
Schudy (2009) discuss the difficulty of scaling the convex
programming approach.
Clustering and Graph Analysis in Data Streams. Given
the importance of clustering as a basic tool for analyzing
massive data sets, it is unsurprising that a considerable effort
has gone into designing clustering algorithms in the relevant computational models. In particular, in the data-stream
model we are permitted a limited number of passes (ideally
just one) over the data while using only limited memory.
This model abstracts the challenges in traditional applications of stream processing such as network monitoring, and
also leads to I/O-efficient external-memory algorithms. Naturally, in either context, an algorithm should also be fast,
both in terms of the time to process each stream element
and in returning the final answer.
Classical clustering problems including k-median (Charikar
et al., 2003; Guha et al., 2000), k-means (Ailon et al.,
2009), and k-center (Charikar et al., 2004; Guha, 2009;
McCutchen & Khuller, 2008) have all been studied in the
stream model, as surveyed by Silva et al. (2013). Nonadaptive sampling algorithms for correlation clustering can
be implemented in the data stream model and such algorithms were used by Ailon & Karnin (2012) to construct additive approximations. However, the first multiplicative result for correlation clustering was only recently established;
Chierichetti et al. (2014) presented a polynomial-time
(3 + )-approximation for min-disagree on ¬±1-weighted
graphs using O(‚àí1 log2 n) passes. Their basic approach
yields both a MapReduce and semi-streaming algorithm ‚Äî
that is, a streaming algorithm using Œò(n polylog n) memory (Feigenbaum et al., 2005). Using space proportional to
the number of nodes can be shown to be necessary for solving many natural graph problems in the streaming model including, we show, correlation clustering. McGregor (2014)
surveys semi-streaming algorithms and graph sketching.
Computational Model. In the basic graph stream model
the input stream consists of a sequence edges and their
weights. The available space to process the stream and perform any necessary post-processing is O(n polylog n) bits.
Our results also extend to the dynamic graph stream model
where the stream consists of both insertions and deletions
of edges; the weight of an edge is specified when the edge
is inserted and deleted (if it is subsequently deleted).
For simplicity, we assume that all weights are integral.

We will consider three types of weighted graphs: (a) unit
weights, where all wuv ‚àà {‚àí1, 1}; (b) bounded weights,
where all weights are non-zero, with absolute value bounded
above by a constant. and (c) arbitrary weights where we
only require that all weights are O(poly n).
1.1. Our Results
For max-agree we provide the following single-pass streaming algorithms, each needing OÃÉ(n‚àí2 ) space: (i) a
polynomial-time (1‚àí)-approximation for bounded weights
(Theorem 7), and (ii) a 0.766(1 ‚àí ) approximation for arbitrary weights in OÃÉ(n‚àí10 ) time (Theorem 16).
We can show that any algorithm that can test whether
min-disagree(G) = 0 in a single pass, for arbitrary
 weights,
must store ‚Ñ¶(n + |E ‚àí |) bits for any |E ‚àí | ‚â§ n2 . For unit
weights, the lower bound is ‚Ñ¶(n). We provide a single-pass
algorithm that uses OÃÉ(n‚àí2 + |E ‚àí |) space and OÃÉ((|E ‚àí | +
n‚àí2 )2 ) time and provides an O(log |E ‚àí |) approximation
(Theorem 13). Since Demaine et al. (2006) and Charikar
et al. (2005) provide approximation-preserving reductions
from the ‚Äòminimum multicut‚Äô problem to min-disagree with
arbitrary weights, it is expected to be difficult to approximate the latter to better than a log |E ‚àí | factor in polynomial
time. For unit weights when min-disagree(G) ‚â§ t, we provide a single-pass polytime algorithm that uses OÃÉ(n + t‚àí2 )
space (Theorem 4). We provide a OÃÉ(n‚àí2 )-space PTAS for
min-disagree2 for bounded weights (Theorem 10).
We also considering multipass streaming algorithms. For
unit weights, we present a O(log log n)-pass algorithm that
mimics the algorithm by Ailon et al. (2008), and with
high probability provides a 3 approximation (Theorem 20).
This improves the result of Chierichetti et al. (2014). For
min-disagreek (G), on unit-weight graphs with k ‚â• 3, we
give a min(k ‚àí 1, O(log log n))-pass polynomial-time algorithm using OÃÉ(n‚àí2 ) space (Theorem 21).
1.2. Techniques and Roadmap
In Section 2, we present three basic data structures for the
agree and disagree query problems where a partition C is
specified at the end of the stream, and the goal is to return an approximation of agree(G, C) or disagree(G, C).
They are based on linear sketches and incorporate ideas
from recent work on constructing graph sparsifiers via linear sketches (Ahn et al., 2012b). These data structures
can be constructed in the semi-streaming model and can
be queried in OÃÉ(n) time. As algorithms rely on relatively
simple matrix-vector operations, they can be implemented
fairly easily in MapReduce.
In Section 3, we introduce several new ideas in solving the
LP and SDP for min-disagree and max-agree. In each case,
the convex formulation has to be chosen carefully to allow

Correlation Clustering in Data Streams

intermediate solutions to be represented, verified, and updated in small space. We expect space efficiency of solving
convex optimizations to be increasingly important and of
independent interest. We discuss multipass algorithms in
Section 4. Proofs are deferred to the full version.

2. Basic Data Structures and Applications
We introduce three basic data structures that can be constructed with a single-pass over the input stream that defines
the weighted graph G. Given a query partition C, these data
structures return estimates of agree(G, C) or disagree(G, C).
Solving the correlation clustering optimization problem with
these structures directly would require exponential time or
œâ(n polylog n) space. Instead, we will exploit them carefully to design more efficient solutions. In this section, we
present a short application of each data structure.
2.1. First Data Structure: Bilinear Sketch
Consider a graph G with unit weights (wij ‚àà {‚àí1, 1}) and
a clustering C. Define the matrices M G and M C where
G
Mij
= max(0, wij ) and
(
0 if i and j are separated in C
C
Mij
=
1 if i and j are not separated in C .
Observe that the (squared) matrix distance induced by the
FrobeniusP
norm gives exactly disagree(G, C) = kM G ‚àí
C 2
C 2
G
M kF = ij (mG
ij ‚àímij ) . To efficiently estimate kM ‚àí
M C k2F when C is not known a priori, we can repurpose the
bilinear sketch approach of Indyk & McGregor (2008):
1. Let Œ± ‚àà {‚àí1, 1}n and Œ≤ ‚àà {‚àí1, 1}n be independent random vectors whose entries are 4-wise independent,
P and in a single pass over the input compute
Y = ij‚ààE + Œ±i Œ≤j .
2. Given query partition C = {C1 , C2 , . . .}, return X =
 P

2
P P
.
`
i‚ààC` Œ±i
i‚ààC` Œ≤i ‚àí Y
Following the results of Indyk & McGregor (2008) and
Braverman et al. (2010), we have:
hP
i
Lemma 1. For each {fij }i,j‚àà[n] , E ( i,j Œ±i Œ≤j fij )2 =
hP
i
P
P
2
2
2 2
f
and
V
(
Œ±
Œ≤
f
)
‚â§ 9( i,j fij
) .
i
j
ij
i,j ij
i,j

Theorem 2. For unit weights, there exists a
O(‚àí2 log Œ¥ ‚àí1 log n)-space algorithm for the disagree
query problem. Each positive edge is processed in OÃÉ(‚àí2 )
time, while the query time is OÃÉ(‚àí2 n).
We note that by setting Œ¥ = 1/nn in the above theorem, it
follows that we may estimate disagree(G, C) for all partitions C using OÃÉ(‚àí2 n) space. Hence, we can also (1+) approximate min-disagree(G) given exponential time. While
this is near-optimal in terms of the space use, in this paper
we focus on polynomial time algorithms.
Application to Cluster Repair. Consider the Cluster
Repair problem (Gramm et al., 2005), in which we are
promised min-disagree(G) ‚â§ t for some constant t. As
we can narrow down the number of possible clusterings
to poly(n), there is a simple polynomial-time application
of the above data structure.
First construct a spanning forest F of G+ using the OÃÉ(n)space dynamic graph algorithm (Ahn et al., 2012a). Let CF
be the node-partition corresponding to the connected components of F . Then, let F1 , F2 , . . . be all the forests formed
by deleting at most t edges from F . Let CFi be the nodepartition corresponding to the connected components of Fi .
Lemma 3. The optimal partition of G is a refinement
of CF and a coarsening
of some CFi and there are at most

O (n(t + 1))t+1 such partitions.

Therefore, setting Œ¥ = O (n(t + 1))‚àí(t+1) in Theorem 2
yields the following theorem.
Theorem 4. For a unit-weight graph G with
min-disagree(G) ‚â§ t, there exists a polynomial-time
data-stream algorithm using OÃÉ(n + t‚àí2 ) space that with
high probability (1 + ) approximates min-disagree(G).
2.2. Second Data Structure: Sparsification
A sparsification of graph G is a weighted graph H such that
the weight of every cut in H is within a 1 +  factor of the
weight of the corresponding cut in G. A celebrated result
of BenczuÃÅr & Karger (1996) shows that the size of H is
at most OÃÉ(n‚àí2 ). A recent result shows that this can be
constructed in the dynamic graph stream model.
Theorem 5. Ahn et al. (2012b). There is a single-pass
semi-streaming algorithm that returns a sparsification using
space OÃÉ(n‚àí2 ) and time OÃÉ(m).

C
Applying the above lemma to fij = mG
ij ‚àí mij establishes that E [X] = disagree(G, C) and V [X] ‚â§
9(disagree(G, C))2 . Hence, running O(‚àí2 log Œ¥ ‚àí1 ) parallel repetitions of the scheme and averaging the results appropriately2 yields a (1 ¬± )-approximation for disagree(G, C)
with probability at least 1 ‚àí Œ¥.

The algorithm can also be implemented in MapReduce (Ahn
& Guha, 2015). The next lemma is straightforward.
Lemma 6. Let H + and H ‚àí be sparsifications of G+ =
(V, E + ) and G‚àí = (V, E ‚àí ) such that all cuts are preserved
within factor (1 ¬± /3), and let H = H + ‚à™ H ‚àí . For every

2
Specifically, take the standard approach of partitioning the
estimates into O(log Œ¥ ‚àí1 ) groups, each of size O(‚àí2 ). With

constant probability, the mean of each group is within a 1¬± factor;
we finally return the median of the resulting group estimates.

Correlation Clustering in Data Streams

clustering C, agree(G, C) = (1 ¬± )agree(H, C) ¬± w(E + )
and disagree(G, C) = (1 ¬± )disagree(H, C) ¬± w(E ‚àí ).
Note that disagree(G, C) = (1 ¬± )disagree(H + ‚à™ E ‚àí , C).
Application to max-agree with Unit Weights. It would
be unfortunate if, by approximating the unit-weight graph
by a weighted sparsification, we lost the ability to return
a 1 ¬±  approximation in polynomial time. We resolve
this as follows. We emulate part of an algorithm by Giotis & Guruswami (2006) for max-agreek using a single pass over the stream3 . In their algorithm, the nodes
are partitioned into m = O(1/) groups V1 , V2 , . . . , Vm ,
each of size O(n), and for each Vi we draw a sample of
r = poly(1/, k, log 1/Œ¥) nodes Si from V \ Vi . Using
the weights on edges between each Si and Vi , we consider
all possible partitions of Si . The required sampling can be
performed simultaneously with the construction of the sparsifier. Then, at the end of the stream, the possible partitions
are generated and we use the graph sparsifier to find the best
of these partitions.
Theorem 7. For bounded-weight inputs, there exists a polytime semi-streaming algorithm that with high probability
(1 + )-approximates max-agree(G).
2.3. Third Data Structure: Node-Based Sketch
In this section we develop a data structure that supports
queries to disagree(G, C) for arbitrarily weighted graphs
when C is restricted to be a 2-partition. For each node i,

n
define the vector, ai ‚àà R( 2 ) , indexed over the [n]
2 edges,
where the only non-zero entries are:
Ô£±
Ô£¥
if ij ‚àà E ‚àí
Ô£≤wij /2
i
aij = wij /2
if ij ‚àà E + , i < j
Ô£¥
Ô£≥
‚àíwij /2 if ij ‚àà E + , i > j
Lemma 8. For P
a two-partition
P C =
disagree(G, C) = k `‚ààC1 a` ‚àí `‚ààC2 a` k1 .

{C1 , C2 },

Hence, we use the `1 -sketching result of Kane et al. (2010)
to compute a random linear sketch of each ai .
Theorem 9. For arbitrary weights, and for query partitions
that contain two clusters, to solve the disagree query problem, there exists an O(‚àí2 n log Œ¥ ‚àí1 log n)-space algorithm.
The query time is O(‚àí2 n log Œ¥ ‚àí1 log n).
Unfortunately, for queries C where |C| > 2, ‚Ñ¶(n2 ) space is
necessary.
Application to min-disagree2 (G) with Bounded Weights.
We apply the above node-based sketch in conjunction with
another algorithm by Giotis & Guruswami (2006), this time
for min-disagree2 . It samples r = poly(1/)¬∑log n nodes S
3

Note max-agreek (G) ‚â• (1 ‚àí )max-agree(G) for k =
O(1/) (Bansal et al., 2004).

and, using the weights of the edges incident on S, generates
2m‚àí1 possible partitions; we generalize this to the bounded
weights case. The sampling of S and its incident edges
can be performed using one pass and O(nr log n) space.
We then find the best of these possible partitions in postprocessing using the above node-based sketches.
Theorem 10. For bounded-weight inputs, there exists a
polynomial-time semi-streaming algorithm that with high
probability (1 + )-approximates min-disagree2 (G).

3. Convex Programming in Small Space
In this section we discuss an SDP-based algorithm for
max-agree and an LP-based algorithm for min-disagree. At
a high level, progress arises from new ideas and modifications needed to implement convex programs in small space.
While the time to solve convex programs has always been
an issue, additionally restricting to small space is relatively
recent (Ahn & Guha, 2013). In this paper, we follow the
Multiplicative Weight Update method and its derivatives.
This method has a rich history across many different communities (Arora et al., 2012), and has been extended to SDPs
(Arora & Kale, 2007).
In all these approaches, the optimization problem is first
reduced to a decision variant, involving a ‚Äúguess‚Äù Œ± of the
objective value; we show later how to instantiate this guess.
For LPs, we seek to solve the system:

cT y ‚â• Œ±
MWM LP:
s.t Ay ‚â§ b, y ‚â• 0
n
where A ‚àà Rn√óm
, c, y ‚àà Rm
+ , and b ‚àà R+ . For SDPs,
+
consider the following definition:

Definition
1. For matrices X, Z, let X ‚ó¶ Z denote
P
X
Z
ij ij , let X  0 denote that X is positive semidefii,j
nite, and let X  Z denote X ‚àí Z  0.
A semidefinite decision problem in canonical form is:

C‚ó¶X‚â•Œ±
MWM SDP:
s.t Fj ‚ó¶ X ‚â§ gj , ‚àÄ1 ‚â§ j ‚â§ q, X  0
where C, X ‚àà Rn√ón and g ‚àà Rq+ . Denote the set of the
feasible solutions by X . Typically we are interested in the
Cholesky decomposition of X, a set of n vectors {xi } such
that Xij = xTi xj .
To solve the LP or the SDP, the multiplicative-weight update algorithm proceeds iteratively. In each iteration, given
the current solution y, X the meta-algorithm either decides
that the current candidate is (approximately) feasible or
computes a new current solution.
Equivalently, we can describe the process as maintaining
a set of multipliers (one for each constraint) and computing a new candidate solution y0 , X0 which (approximately)

Correlation Clustering in Data Streams

satisfies the linear combination of the inequalities. The
new current solution is a linear combination of the previous
solution and the new candidate.
These two views are consistent: typically, the multiplier
of a constraint is a exponential of the violation (suitably
scaled) induced by the current solution, and the current
solution is typically the running average (suitably scaled) of
the candidates produced by the different iterations. Consider
the following two theorems.
Theorem 11 (Steurer (2010)). Let D be a fixed diagonal
matrix with positive entries and assume X be nonempty.
Suppose there is an Oracle that for each positive semidefinite X either (a) tests and declares X to be approximately
feasible ‚Äî for all 1 ‚â§ i ‚â§ q, we have Fi ‚ó¶X ‚â§ gi +Œ¥, or (b)
provides a real symmetric matrix A and a scalar b satisfying
(i) A ‚ó¶ X ‚â§ b ‚àí Œ¥ and for all X0 ‚àà X , A ‚ó¶ X0 ‚â• b and (ii)
œÅD  A ‚àí bD  ‚àíœÅD, then a multiplicative-weight-style
algorithm produces an approximately feasible X, in fact its
Cholesky decomposition, in T = O(œÅ2 Œ¥ ‚àí2 ln n) iterations.
Theorem 12 (Arora et al. (2012)). Suppose that, given
a set of non-negative multipliers u(t) in iteration t, an
T
Oracle provides a y(t) satisfying:
P (i) c y(t) ‚â• Œ±, (ii)
T
T
u(t) Ay(t) ‚àí u(t) b ‚â§ Œ¥ i ui (t), and (iii) ‚àíœÅ ‚â§
‚àí` ‚â§ Ai y(t) ‚àí bi ‚â§ œÅ for all 1 ‚â§ i ‚â§ n. After
T = O(œÅ`Œ¥ ‚àí2 ln n) iterations of the multiplicative-weight
P
update algorithm, the average vector, y = T1 t y(t), satisfies Ai y ‚àí bi ‚â§ 4Œ¥ for all i.
The above two theorems are expressed differently, each corresponding to a different view of the multiplicative-weight
update method. The first view corresponds to the ‚Äústate‚Äù
that needs to be maintained in each iteration; the second
corresponds to a more operational view, where multiple constraints are reduced to a single linear constraint which is
(hopefully) easier to solve. From the perspective of space
efficiency, both views must be followed. In both contexts,
the parameter œÅ is called the ‚Äúwidth‚Äù, and controls the speed
of convergence. As is explicitly stated in the two cited
papers, and as is widely recognized, the construction of a
small-width Oracle is the key component of an effective
solution. However, the width parameter is inherently tied to
the specific formulation chosen.
Consider the standard LP relaxation for min-disagree, where
xij corresponds to edge ij being cut.
X
X
min
wij xij +
|wij |(1 ‚àí xij )
ij‚ààE +

ij‚ààE ‚àí

xij + xj` ‚â• xi`
xij ‚â• 0

‚àÄi, j, `
‚àÄi, j

The constraints simply enforce that if we cut one side of a
triangle, we must also cut at least one of the other two sides.
Note that the size of formulation is Œò(n3 ) irrespective of

the number of nonzero entries in E + , E ‚àí . We will use the
sparsification of E + , but that does not in any way change the
Àú space, we
size of the above linear program. To achieve O(n)
need new formulations and new algorithms to solve them.
Let H + be the sparsification of E + with m0 = |H + |. For
h
edge sq ‚àà H + let wsq
denote the weight after the sparsification. For ij ‚àà E ‚àí , let Pij (E 0 ) denote the set of all paths
using the edges of edge set E 0 . Consider the following LP
for min-disagree, similar to that by Wirth (2004), but in this
sparsified setting:
X
X
h
min
|wij |zij +
wsq
xsq
ij‚ààE ‚àí

zij +

X

sq‚ààH +

xsq ‚â• 1 ‚àÄp ‚àà Pij (H + ), ij ‚àà E ‚àí

sq‚ààp

zij , xsq ‚â• 0

‚àÄij ‚àà E ‚àí , sq ‚àà H +

(LP1)

The intuition of an integral 0/1 solution is that zij = 1 for all
edges ij ‚àà E ‚àí that are not cut, and xsq = 1 for all sq ‚àà H +
that are cut, by the intended clustering. Although LP1
now has exponential size, we will apply the multiplicative weights framework (Theorem 12) to the dual of LP1.
The oracle we provide has the twist that if it fails to find
y(t) with the necessary properties, then it provides a feasible f -approximation of the primal (in this case LP1). This
idea, of applying the multiplicative-weight update method
to a formulation with exponentially many variables (the
dual), and modifying the Oracle to provide a solution to
the primal (with exponentially many constraints) in a single step, has also benefited solving maximum matching in
small space (Ahn & Guha, 2015). The existence of multiple
such examples demonstrates that starting from the dual, a
‚Äúdual-primal method‚Äù, helps solve convex programs in small
space. One key insight is that the dual, with exponentially
many variables and few constraints, is easier to solve in a
few iterations because there are many degrees of freedom.
This reduces the adaptive nature of the solution, and therefore we can make a lot of progress in satisfying many of the
primal constraints in parallel. In contrast, the classic application of primal-dual techniques in approximation algorithms
tries to construct a solution of the dual efficiently: in that
context, in polynomial time. It is often thought, as is explicitly mentioned by Arora & Kale (2007), that the primal-dual
approximation algorithms use a different set of techniques
from the primal-dual approach of multiplicative-weight update methods. By switching the dual and the primal, we
align both sets of techniques and use them interchangeably.
Interestingly, the algorithm of Steurer (2010) can be viewed
as a dual-primal algorithm. This algorithm collects separating hyperplanes to solve the dual of the SDP: on failure to
provide such a hyperplane, the algorithm provides a primal
feasible X. It is therefore unsurprising that the candidate X
generated by Steurer‚Äôs algorithm is an exponential of the

Correlation Clustering in Data Streams

(suitably scaled) averages of the hyperplanes (A, b): this
would be the case if we were applying the multiplicativeweight update paradigm to the dual of the SDP in canonical
form. Of course, to prove that such paradigms (Ahn &
Guha, 2015; Steurer, 2010) work requires some careful effort, and even after that the construction of the Oracle is
never obvious. But the key point, reiterated here, is that
the formulation plays an outsized role in terms of space
efficiency, both from the perspective of the state required
to compute and the operational perspective of efficiently
updating that state. In future, we expect the space efficiency
of solving convex optimization to be increasingly important.

Algorithm 1 Oracle for LP2
t
1: Given multipliers utsq for sq ‚àà H + (Œ±) and vij
for
P
‚àí
h t
ij ‚àà E (Œ±), define Qu =
sq‚ààH + (Œ±) wsq usq and
P
t
Qv = ij‚ààE ‚àí (Œ±) |wij |vij
.
t
2: Let xsq = Œ±utsq /(Qu + Qv ), zij = Œ±vij
/(Qu + Qv ).
3: Treating the xsq as edge lengths, let dx (¬∑, ¬∑) be the shortest path metric. Define the ball of radius r centered at Œ∂:
B(Œ∂, r) = {Œ∂ 0 | dx (Œ∂, Œ∂ 0 ) ‚â§ r}
and the weight of the edges of cut by the ball:
X
cut(B(Œ∂, r)) =
wŒ∂h0 Œ∂ 00

3.1. min-disagree with Arbitrary Weights

Œ∂ 0 Œ∂ 00 ‚ààH + (Œ±)
dx (Œ∂,Œ∂ 0 )‚â§r<dx (Œ∂,Œ∂ 00 )

In this section, we sketch the following theorem:
Theorem 13. There is a 3(1 + ) log |E ‚àí |-approximation
algorithm for min-disagree that requires OÃÉ((n‚àí2 +
|E ‚àí |)2 ‚àí3 ) time, OÃÉ(n‚àí2 + |E ‚àí |) space, and a single pass.
We apply Theorem 12 (the multiplicative-weight update
framework) to the dual of LP1, but omit the constraints in
the dual corresponding to small-weight edges. For each
Œ± ‚â• 0, let H + (Œ±), E ‚àí (Œ±) be the set of edges in H + , E ‚àí ,
respectively, with weight at least Œ¥Œ±/(m0 +|E ‚àí |). Note that
ignoring
edges not in E ‚àí (Œ±), H + (Œ±) will only decrease
P
p yp by at most 2Œ¥Œ±. Consider:
X

yp ‚â• (1 ‚àí 2Œ¥)Œ±

4: Find a collection of balls B(Œ∂1 , r1 ), B(Œ∂2 , r2 ), . . . such

5:
6:

7:
8:

that (i) each radius at most 1/3, (ii) every endpoint
‚àí
of
(iii)
P an edge in E (Œ±) belongs to some ball, and
‚àí
cut(B(Œ∂
,
r
))
‚â§
3Œ±Q
/(Q
+Q
)¬∑ln(|E
|+1).
g
g
u
u
v
g
The existence of such balls follows from Lemma 14.
if there exists ij ‚àà E ‚àí (Œ±) with i, j in the same ball and
zij < 1/3. then
Find the corresponding path p between i and j. Since
the length of this path is at most 2/3 and zij < 1/3,
the corresponding constraint is violated. Return yp =
Œ± and yp0 = 0 for all other paths for edges in E ‚àí .
else
Return the union of cuts defined by the balls.

p

1
|wij |
1
h
wsq

X

yp ‚â§ 1

‚àÄij ‚àà E ‚àí (Œ±)

Lemma 14. Let Œ∫ = |E ‚àí |, Z =

‚àÄsq ‚àà H + (Œ±)

vol(B(u, r)) =

P

uv‚ààH + (Œ±)

h
xuv wuv
. Let

p‚ààPij (H + (Œ±))

X

yp ‚â§ 1

Z
+
Œ∫

p‚ààP:sq‚ààp

yp ‚â• 0
where P(Œ±) =

‚àÄp ‚àà P(Œ±)
S

ij‚ààE ‚àí (Œ±)

(LP2)

Pij (H + (Œ±)).

We attempt to find an approximate feasible solution to LP2
for a large value of Œ±. If the Oracle fails to make progress
then it provides a solution to LP1 of value f ¬∑ Œ±. In that
case we set Œ± ‚Üê Œ±/(1 + Œ¥) and try the Oracle again. Note
that if we lower Œ± then the Oracle invocations for larger
values of Œ± continue to remain valid; if Œ±1 ‚â§ Œ±2 , then
Pij (H + (Œ±1 )) ‚äá Pij (H + (Œ±2 )). Eventually we lower Œ±
sufficiently that we have a feasible solution to LP2. But then
we have a solution to LP1 returned by the Oracle of value
f Œ±(1 + Œ¥), corresponding to the previous value of Œ±. The
feasibility of LP2 shows that Œ±(1 ‚àí 2Œ¥) is a lower bound for
the optimum solution of LP1.
The Oracle is provided in Algorithm 1 and relies on the
following lemma:

X

h
xvv0 wvv
0

vv 0 ‚ààH + (Œ±)
v,v 0 ‚ààB(u,r)

X

+
0

h
(r ‚àí dx (u, v))wvv
0 .

+

vv ‚ààH (Œ±)
dx (u,v)‚â§r<dx (u,v 0 )

Suppose that, for a node Œ∂, the radius r of its ball is
increased until cut(B(Œ∂, r)) ‚â§ Cvol(B(Œ∂, r)). If C =
3 ln(Œ∫ + 1), the ball stops growing before the radius becomes 1/3. We start this process setting Œ∂1 to be an arbitrary endpoint of an edge in E ‚àí , and let the stopping
radius be r1 . We remove B(Œ∂1 , r1 ) and continue the process on the remainder of the graph. The collection of
B(Œ∂1 , r1 ), B(Œ∂2 , r2 ), . . .P
satisfy the condition that each radius is at most 1/3 and g cut(B(Œ∂g , rg )) ‚â§ CZ.
The above lemma is essentially applying the result of Garg
et al. (1993) to H + (Œ±) with the terminal pairs defined
by E ‚àí . The proof follows from the fact that cut(B(Œ∂, r))
is the derivative of vol(B(Œ∂, r)) w.r.t. r, and the volume

Correlation Clustering in Data Streams

cannot increase by more than a factor of Œ∫ + 1. For nonnegative xsq , standard shortest-path algorithms lead to a running
time of OÃÉ(m0 ).
Since we removed all small edge weights, we may bound
the width of the above oracle as follows :
Lemma 15. œÅ = (m0 + |E ‚àí |)/Œ¥, ` = 1 for Algorithm 1.
In fact, we prove a general oracle construction that provides
small width for every problem targeted by Theorem 12. The
total weight of positive edges cut by the solution returned in
line 8 of Algorithm 1 is at most 3Œ±Qu /(Qu +Qv )¬∑ln(|E ‚àí |+
1). Each negative edge that is not cut corresponds to setting
zij = 1 but zij ‚â• 1/3; hence the cost of these edges is
3Œ±Qv
‚àí
Qu +Qv . Finally, the cost of the edges in neither E (Œ±)
nor H + (Œ±) is at most 2Œ¥Œ±. The overall solution has cost
(3 ln(|E ‚àí | + 1) + 2Œ¥)Œ±.
Finally, we show how to initialize Œ±. Divide the edges
of H + according to weight, in intervals (2z‚àí1 , 2z ], as we
decrease z. For each group z, we find the largest weight
edge ij ‚àà E ‚àí , call this weight g(z), such that i and j are
connected by H + -edges of group z or higher. Observe
that g(z) is an increasing function of z. Let the smallest z
such that g(z) ‚â• 2z be z0 . Then it follows that the optimum
solution is at least 2z0 ‚àí1 . Again, 2z0 n2 serves as an initial
value of Œ±, which is a O(n2 ) approximation to the optimum
solution.
3.2. max-agree with Arbitrary Weights
In this section, we sketch the following theorem:
Theorem 16. There is a 0.7666(1 ‚àí )-approximation
algorithm for max-agree(G) that uses OÃÉ(n‚àí2 ) space,
OÃÉ(m + n‚àí10 ) time and a single pass.
h
We use Lemma 6 and edge set H = H + ‚à™ H ‚àí . Let wij
correspond to the weight of an edge ij ‚àà H. Our SDP for
max-agree is:
h
X
X |wij
|(Xii + Xij ‚àí 2Xij )
h
wij
Xij +
‚â•Œ±
2
+
‚àí
ij‚ààH

Xii
‚àíXii
‚àíXij
X

ij‚ààH

‚â§1
‚â§ ‚àí1
‚â§0
0

‚àÄi ‚àà V
‚àÄi ‚àà V
‚àÄi, j ‚àà V

(SDP)

If two vertices, i and j, are in the same cluster, their corresponding vectors xi and xj will coincide, so Xij = 1; on
the other hand, if they are in different clusters, their vectors
should be orthogonal, so Xij = 0. Observe that under the
restriction Xii = Xjj = 1, the contribution of an ij ‚àà H ‚àí
is Xii + Xij ‚àí 2Xij = (1 ‚àí Xij ), as intended. However,
this formulation helps prove that the width is small.
P
P
h
Definition 2. Define di =
j:ij‚ààH |wij | and
i di =
2W . Let D be the diagonal matrix with Dii = di /2W .

A random partition of the graph provides a trivial 1/2approximation for maximizing agreements. Letting W be
the total weight of edges in H, the sparsified graph, we
perform binary search for Œ± ‚àà [W/2, W ], and stop when
the interval is of size Œ¥W . This increases the running time
by a O(log Œ¥ ‚àí1 ) factor.
The diagonal matrix D specified in Definition 2 sets up the
update algorithm of Steurer (2010). The choice of D will
be critical to our algorithm: typically, this D determines the
‚Äúpath‚Äù taken by the SDP solver, since D alters the projection
to density matrices. Summarizing, Theorem 16 follows from
the Oracle provided in Algorithm 2. The final solution only
guarantees xi ¬∑xj ‚â• ‚àíŒ¥. Even though the standard rounding
algorithm assumes Xij ‚â• 0, the fractional solution with
Xij ‚â• ‚àíŒ¥ can be rounded efficiently. Ensuring xi ¬∑ xj ‚â• 0
appears to be difficult (or to require a substantially different
oracle).
Algorithm 2 Oracle for SDP.
1: For the separating hyperplane, we only describe nonzero entries in A. Recall that we have a candidate X
where Xij = xi ¬∑ xj .
P
2: Let S1 = {i : kxi k2 ‚â• 1 + Œ¥}, ‚àÜ1 = i‚ààS1 di .
P
3: Let S2 = {i : kxi k2 ‚â§ 1 ‚àí Œ¥}, ‚àÜ2 = P i‚ààS2 di .
4: Let S3 = {ij : xi ¬∑ xj < ‚àíŒ¥}, ‚àÜ3 = ij‚ààS3 |wij |.
5: if ‚àÜ1 ‚â• Œ¥Œ± then
6:
Let Aii = ‚àídi /‚àÜ1 for i ‚àà S1 and b = ‚àí1.
7:
Return (A, b).
8: else if ‚àÜ2 ‚â• Œ¥Œ± then
9:
Let Aii = di /‚àÜ2 for i ‚àà S2 and b = 1.
10:
Return (A, b).
11: else if ‚àÜ3 ‚â• Œ¥Œ± then
h
/‚àÜ3 for ij ‚àà S3 and b = 0.
12:
Let Aij = wij
13:
Return (A, b).
14: else
15:
Ignore all nodes in S1 and S2 and all edges in S3 .
Let C0 be the matrix that corresponds to the objective
function of the modified graph G0 .
16:
if C0 ‚ó¶ X < (1 ‚àí 4Œ¥)Œ± then
17:
Let A = C0 /Œ± and b = 1 ‚àí 3Œ¥. Return (A, b).
18:
else
19:
Round X, and return the rounded solution.
Lemma 17. Algorithm 2 is Œ¥-separating: for all returned
(A, b), A ‚ó¶ X ‚â§ b ‚àí Œ¥ and ‚àÄX0 ‚àà X , A ‚ó¶ X0 ‚â• b where X
is the feasible space of SDP.
Lemma 18. For œÅ = O(1/Œ¥), Algorithm 2 is œÅ-bounded:
œÅD  A ‚àí bD  ‚àíœÅD
The update procedure (Steurer, 2010) maintains (and defines) the candidate vector X implicitly. In particular it
uses matrices of dimension n √ó d, in which every entry is a
(scaled) Gaussian random variable. The algorithm also uses

Correlation Clustering in Data Streams

a precision parameter (degree of the polynomial approximation to represent matrix exponentials) r. Assuming that TM
is the time for a multiplication between a returned A and
some vector, the update process computes the tth X in time
O(t ¬∑ r ¬∑ d ¬∑ TM ), a quadratic dependence on t in total. We
will ensure that any returned A has at most m0 nonzero
entries, and therefore TM = O(m0 ). The algorithm requires
space that is sufficient to represent a linear combination of
the matrices A which are returned in the different iterations.
We can bound œÅ = O(1/Œ¥), and therefore the total number
of iterations is OÃÉ(Œ¥ ‚àí4 ). For our purposes, in max-agree
we will have d = O(Œ¥ ‚àí2 log n), r = O(log(Œ¥ ‚àí1 ), and
TM = O(m0 ), giving us a OÃÉ(nŒ¥ ‚àí10 ) time and OÃÉ(nŒ¥ ‚àí2 )
space algorithm. However, unlike the general X used in
Steurer‚Äôs approach, in our oracle the X is used in a very
specific way. This leaves open the question of determining
the exact space-versus-running-time tradeoff.

4. Multipass Algorithms
Consider the 3-approximation algorithm for min-disagree
on unit-weight graphs due to Ailon et al. (2008).
1: Let v1 , . . . , vn be a uniformly random ordering of V .

Let U ‚Üê V be the set of ‚Äúuncovered‚Äù nodes.
2: for i = 1 to n do
3:
if vi ‚àà U then
4:
Define Ci ‚Üê {vi } ‚à™ {vj ‚àà U : vi vj ‚àà E + } and

let U ‚Üê U \ Ci . We say vi is ‚Äúchosen‚Äù.
5:
else
6:
Ci ‚Üê ‚àÖ.
7: Return the collection of non-empty sets Ci .

It may appear that emulating the above algorithm in the
data stream model requires ‚Ñ¶(n) passes, since determining
whether vi should be chosen may depend on whether vj
is chosen for each j < i. However, we will show that
O(log log n)-passes suffice. This improves upon a result
by Chierichetti et al. (2014), who developed a modification of the algorithm that used O(‚àí1 log2 n) streaming
passes and returned a (3 + )-approximation, rather than a
3-approximation. Our improvement is based on:
Lemma 19. Let Ut be the set of uncovered nodes after
iteration t of the above algorithm, and let
+
+
0
Ft,t
0 = {vi vj ‚àà E , i, j ‚àà Ut , t < i, j ‚â§ t } .

With high probability,

Theorem 20. On a unit-weight graph, there exists a
O(log log n)-pass semi-streaming algorithm that returns
with high probability a 3-approximation to min-disagree.
4.2. min-disagreek with Unit Weights
Our result in this section is based the following algorithm
of Giotis & Guruswami (2006) that returns a (1 + )approximation for min-disagreek on unit-weight graphs.
The algorithm samples m = poly(1/, k) ¬∑ log n nodes S
and for every possible k-partition {Si }i‚àà[k] of S computes
the cost of the clustering where v ‚àà V \ S is assigned to
the ith cluster if
Ô£´
Ô£∂
X
X
i = argmax Ô£≠
wsv +
|wsv |Ô£∏ .
j

4.1. min-disagree with Unit Weights

+
|Ft,t
0|

(2j)-th pass we have simulated the first tj iterations of Ailon
et al.‚Äôs algorithm. Since tj ‚â• n for j = 1 + log log n, our
algorithm terminates after O(log log n) passes.

02

‚â§ 5 ¬∑ ln n ¬∑ t /t.

Semi-Streaming Algorithm. Our semi-streaming algoj
rithm proceeds as follows. For j ‚â• 1, let tj = (2n)1‚àí1/2 :
+
during the (2j ‚àí 1)-th pass, we store all edges in Ftj‚àí1 ,tj ,
and during the (2j)-th pass we determine Utj . After the

s‚ààSj :sv‚ààE +

s6‚ààSj :sv‚ààE ‚àí

Let C 0 be the best clustering found. If all clusters in C 0
have at least n/(2k) nodes, return C 0 . Otherwise, fix all
the clusters of size at least n/(2k) and recurse on the set
of nodes in ‚Äúsmall‚Äù clusters. To emulate each recursive
step in one pass, we simply choose S at the start of the
stream and then collect all incident edges on S. We then
use the disagree oracle developed in Section 2.1 to find the
best possible partitions during post-processing. To design
an O(log log n)-pass algorithm, we proceed as follows. In
the i-th pass, suppose we have k 0 clusters still to determine
and let Vi‚àí1 be the set of nodes that have not yet been
included in some (large) cluster. We pick k 0 random sets
of samples S1 , . . . , Sk0 in parallel from Vi‚àí1 each of size
i‚àí1
Ni = mn2 /p , for p = log n. Since Ni ‚â• n for i ‚â•
1 + log log n, the algorithm must terminate in O(log log n)
passes. We prove that in pass i the number of clusters drops
i‚àí1
by n2 /p from the start of the last pass, and inductively,
i
that |Vi | = n/n(2 ‚àí1)/p . The space needed by our algorithm
for round i is therefore O(k 0 Ni |Vi |) = O(kmn1+1/p ) =
OÃÉ(kmn).
Theorem 21. There exists a min(k ‚àí 1, log log n)-pass
semi-streaming algorithm that (1 + )-approximates
min-disagreek with high probability.

Acknowledgements
Graham Cormode is supported by a Royal Society Wolfson
Research Merit Award and the Yahoo Faculty Research
Engagement Program. Sudipto Guha is supported by NSF
award CCF-1117216. Andrew McGregor is supported by
NSF awards CCF-0953754. CCF-1320719, IIS-1251110
and a Google Faculty Research Award. Anthony Wirth is
supported by ARC Future Fellowship FT120100307.

Correlation Clustering in Data Streams

References
Ahn, Kook Jin and Guha, Sudipto. Linear programming in
the semi-streaming model with application to the maximum matching problem. Information and Computation
(ICALP 2011 Special Issue), 222:59‚Äì79, 2013.
Ahn, Kook Jin and Guha, Sudipto. Access to data and
number of iterations: Dual primal algorithms for maximum matching under resource constraints. In Symposium
on Parallelism in Algorithms and Architectures (SPAA).
Also in CORR, arXiv 1307.4359, 2015. URL http:
//dx.doi.org/10.1145/2755573.2755586.
Ahn, Kook Jin, Guha, Sudipto, and McGregor, Andrew.
Analyzing graph structure via linear measurements.
In Symposium on Discrete Algorithms: SODA, pp.
459‚Äì467, 2012a.
URL http://portal.acm.
org/citation.cfm?id=2095156&CFID=
63838676&CFTOKEN=79617016.
Ahn, Kook Jin, Guha, Sudipto, and McGregor, Andrew.
Graph sketches: sparsification, spanners, and subgraphs.
In Principles of Database Systems: PODS, pp. 5‚Äì14,
2012b. URL http://doi.acm.org/10.1145/
2213556.2213560.
Ailon, Nir and Karnin, Zohar Shay. A note on: No need
to choose: How to get both a PTAS and sublinear query
complexity. CoRR, abs/1204.6588, 2012.
Ailon, Nir, Charikar, Moses, and Newman, Alantha. Aggregating inconsistent information: Ranking and clustering.
J. ACM, 55(5), 2008. URL http://doi.acm.org/
10.1145/1411509.1411513.
Ailon, Nir, Jaiswal, Ragesh, and Monteleoni, Claire. Streaming k-means approximation. In Conference on Neural
Information Processing Systems: NIPS, pp. 10‚Äì18, 2009.
URL http://books.nips.cc/papers/files/
nips22/NIPS2009_1085.pdf.
Arora, Sanjeev and Kale, Satyen. A combinatorial,
primal-dual approach to semidefinite programs. In
ACM Symposium on Theory of Computing: STOC, pp.
227‚Äì236, 2007. URL http://doi.acm.org/10.
1145/1250790.1250823.
Arora, Sanjeev, Hazan, Elad, and Kale, Satyen. The multiplicative weights update method: a meta algorithm
and applications. Theory of Computing, 8(6):121‚Äì164,
2012. URL http://www.theoryofcomputing.
org/articles/v008a006.
Bagon, S. and Galun, M. Large scale correlation clustering
optimization. arXiv:1112.2903v1, 2011.

Bansal, Nikhil, Blum, Avrim, and Chawla, Shuchi. Correlation clustering. Machine Learning, 56(1‚Äì3):89‚Äì113,
2004. URL http://dx.doi.org/10.1023/B:
MACH.0000033116.57574.95.
BenczuÃÅr, AndraÃÅs A. and Karger, David R. Approximating
s ‚àí t minimum cuts in OÃÉ(n2 ) time. In Symposium on
Theory of Computing: STOC, pp. 47‚Äì55, 1996.
Bonchi, Francesco, Garcia-Soriano, David, and Liberty, Edo.
Correlation clustering: From theory to practice. In International Conference on Knowledge Discovery and Data
Mining: KDD, pp. 1972‚Äì1972, New York, NY, USA,
2014. ACM. ISBN 978-1-4503-2956-9. URL http:
//doi.acm.org/10.1145/2623330.2630808.
Braverman, Vladimir, Chung, Kai-Min, Liu, Zhenming, Mitzenmacher, Michael, and Ostrovsky, Rafail.
AMS without 4-wise independence on product domains.
In International Symposium on Theoretical Aspects of Computer Science: STACS, pp. 119‚Äì
130, 2010. URL http://dx.doi.org/10.4230/
LIPIcs.STACS.2010.2449.
Charikar, Moses, O‚ÄôCallaghan, Liadan, and Panigrahy, Rina.
Better streaming algorithms for clustering problems. In
Symposium on Theory of Computing: STOC, pp. 30‚Äì
39, 2003. URL http://doi.acm.org/10.1145/
780542.780548.
Charikar, Moses, Chekuri, Chandra, Feder, TomaÃÅs, and
Motwani, Rajeev. Incremental clustering and dynamic
information retrieval. SIAM J. Comput., 33(6):1417‚Äì
1440, 2004. URL http://dx.doi.org/10.1137/
S0097539702418498.
Charikar, Moses, Guruswami, Venkatesan, and Wirth, Anthony. Clustering with qualitative information. J. Comput. Syst. Sci., 71(3):360‚Äì383, 2005. URL http://dx.
doi.org/10.1016/j.jcss.2004.10.012.
Chawla, Shuchi, Makarychev, Konstantin, Schramm, Tselil,
and Yaroslavtsev, Grigory. Near optimal LP rounding
algorithm for correlation clustering on complete and complete k-partite graphs. In Symposium on Theory of Computing: STOC, 2015.
Chierichetti, Flavio, Dalvi, Nilesh N., and Kumar, Ravi.
Correlation clustering in mapreduce. In International
Conference on Knowledge Discovery and Data Mining:
KDD, pp. 641‚Äì650, 2014. URL http://doi.acm.
org/10.1145/2623330.2623743.
Coleman, Tom, Saunderson, James, and Wirth, Anthony. A
local-search 2-approximation for 2-correlation-clustering.
In European Symposium on Algorithms: ESA, pp. 308‚Äì
319, 2008. URL http://dx.doi.org/10.1007/
978-3-540-87744-8_26.

Correlation Clustering in Data Streams

Demaine, Erik D., Emanuel, Dotan, Fiat, Amos, and Immorlica, Nicole. Correlation clustering in general weighted
graphs. Theoretical Computer Science, 361(2‚Äì3):172‚Äì
187, 2006. URL http://dx.doi.org/10.1016/
j.tcs.2006.05.008.
Elsner, Micha and Schudy, Warren. Bounding and comparing methods for correlation clustering beyond ilp. In
Workshop on Integer Linear Programming for Natural
Langauge Processing: ILP, pp. 19‚Äì27, Stroudsburg, PA,
USA, 2009. Association for Computational Linguistics.
ISBN 978-1-932432-35-0. URL http://dl.acm.
org/citation.cfm?id=1611638.1611641.
Feigenbaum, Joan, Kannan, Sampath, McGregor, Andrew,
Suri, Siddharth, and Zhang, Jian. On graph problems
in a semi-streaming model. Theoretical Computer Science, 348(2‚Äì3):207‚Äì216, 2005. URL http://dx.
doi.org/10.1016/j.tcs.2005.09.013.
Garg, Naveen, Vazirani, Vijay V., and Yannakakis, Mihalis. Approximate max-flow min-(multi)cut theorems
and their applications. In ACM Symposium on Theory
of Computing: STOC, pp. 698‚Äì707, 1993. URL http:
//doi.acm.org/10.1145/167088.167266.
Giotis, Ioannis and Guruswami, Venkatesan. Correlation
clustering with a fixed number of clusters. Theory of
Computing, 2(1):249‚Äì266, 2006. URL http://dx.
doi.org/10.4086/toc.2006.v002a013.
Gramm, Jens, Guo, Jiong, HuÃàffner, Falk, and Niedermeier,
Rolf. Graph-modeled data clustering: Exact algorithms
for clique generation. Theory Comput. Syst., 38(4):373‚Äì
392, 2005. URL http://dx.doi.org/10.1007/
s00224-004-1178-y.
Guha, Sudipto. Tight results for clustering and summarizing
data streams. In International Conference on Database
Theory: ICDT, pp. 268‚Äì275, 2009. URL http://doi.
acm.org/10.1145/1514894.1514926.
Guha, Sudipto, Mishra, Nina, Motwani, Rajeev,
and O‚ÄôCallaghan, Liadan.
Clustering data
streams.
In IEEE Foundations of Computer
Science:
FOCS, pp. 359‚Äì366, 2000.
URL

http://doi.ieeecomputersociety.org/
10.1109/SFCS.2000.892124.
Indyk, Piotr and McGregor, Andrew. Declaring independence via the sketching of sketches. In Symposium on Discrete Algorithms: SODA, pp. 737‚Äì
745, 2008. URL http://dl.acm.org/citation.
cfm?id=1347082.1347163.
Kane, Daniel M., Nelson, Jelani, and Woodruff, David P. On
the exact space complexity of sketching and streaming
small norms. In ACM-SIAM Symposium on Discrete Algorithms: SODA, pp. 1161‚Äì1178, 2010. URL http://
dx.doi.org/10.1137/1.9781611973075.93.
McCutchen, Richard Matthew and Khuller, Samir. Streaming algorithms for k-center clustering with outliers
and with anonymity. International Workshop on Approximation Algorithms for Combinatorial Optimization: APPROX, pp. 165‚Äì178, 2008. doi: 10.1007/
978-3-540-85363-3 14.
McGregor, Andrew. Graph stream algorithms: a survey.
SIGMOD Record, 43(1):9‚Äì20, 2014. URL http://
doi.acm.org/10.1145/2627692.2627694.
Silva, Jonathan A., Faria, Elaine R., Barros, Rodrigo C.,
Hruschka, Eduardo R., Carvalho, AndreÃÅ C. P. L. F. de,
and Gama, JoaÃÉo. Data stream clustering: A survey. ACM Comput. Surv., 46(1):13:1‚Äì13:31, July 2013.
ISSN 0360-0300. URL http://doi.acm.org/10.
1145/2522968.2522981.
Steurer, David. Fast sdp algorithms for constraint satisfaction problems. In Symposium on Discrete Algorithms:
SODA, pp. 684‚Äì697, 2010.
Swamy, Chaitanya. Correlation clustering: maximizing
agreements via semidefinite programming. In Symposium on Discrete Algorithms: SODA, pp. 526‚Äì527, 2004.
URL http://doi.acm.org/10.1145/982792.
982866.
Wirth, Anthony Ian. Approximation Algorithms for Clustering. PhD thesis, Princeton University, 2004.

