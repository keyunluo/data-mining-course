Influence Function Learning in Information Diffusion Networks

Nan Du, Yingyu Liang
{DUNAN , YLIANG 39}@ GATECH . EDU
Maria-Florina Balcan
NINAMF @ CC . GATECH . EDU
Le Song
LSONG @ CC . GATECH . EDU
College of Computing, Georgia Institute of Technology, 266 Ferst Drive, Atlanta, 30332 USA

Abstract
Can we learn the influence of a set of people
in a social network from cascades of information diffusion? This question is often addressed
by a two-stage approach: first learn a diffusion
model, and then calculate the influence based on
the learned model. Thus, the success of this approach relies heavily on the correctness of the
diffusion model which is hard to verify for real
world data. In this paper, we exploit the insight that the influence functions in many diffusion models are coverage functions, and propose
a novel parameterization of such functions using a convex combination of random basis functions. Moreover, we propose an efficient maximum likelihood based algorithm to learn such
functions directly from cascade data, and hence
bypass the need to specify a particular diffusion
model in advance. We provide both theoretical
and empirical analysis for our approach, showing
that the proposed approach can provably learn
the influence function with low sample complexity, be robust to the unknown diffusion models,
and significantly outperform existing approaches
in both synthetic and real world data.

1. Introduction
Social networks are important in information diffusion,
which has motivated the influence maximization problem:
find a set of nodes whose initial adoptions of an idea can
trigger the largest number of follow-ups. This problem has
been studied extensively in literature from both modeling
and algorithmic point of view (Kempe et al., 2003; Chen
et al., 2010; Borgs et al., 2012; Rodriguez & SchoÃàlkopf,
2012; Du et al., 2013b). Essential to the influence maximization problem is the influence function of a set of nodes,
which is an estimate of the expected number of triggered
follow-ups from these nodes.
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

In practice, the influence function is not given to us, and we
only observe the information diffusion traces, or cascades,
originating from these nodes. In order to model the cascade data, many information diffusion models have been
proposed in the literature, such as the discrete-time independent cascade model and linear threshold model (Kempe
et al., 2003), and more recently the continuous-time independent cascade model (Gomez Rodriguez et al., 2011; Du
et al., 2013b). To estimate the influence, we can employ
a two-stage method: a particular diffusion model is first
learned from cascade data, and then the influence function
is evaluated or approximated from such learned model.
However, there still remain many challenges in these traditional two-stage approaches. First, real world information
diffusion is complicated, and it is not easy to determine the
most suitable diffusion model in practice. A chosen diffusion model may be misspecified compared to real world
data and lead to large model bias. Second, the diffusion
network structure can be also hidden from us, so we need
to learn not only the parameters in the diffusion model,
but also the diffusion network structure. This often leads
to under-determined high dimensional estimation problem
where specialized methods need to be designed (Du et al.,
2012; 2013a). Third, calculating the influence based on
learned diffusion models often leads to difficult graphical
model inference problem where extra approximation algorithms need to be carefully designed (Du et al., 2013b).
If the sole purpose is to estimate the influence, can we
avoid the challenging diffusion model learning and influence computation problem? In this paper, we provide a
positive answer to the question and propose an approach
which estimates the influence function directly from cascade data. Our approach will exploit the observation that
the influence functions in many diffusion models are coverage functions. Instead of learning a particular diffusion
model, we will aim to learn a coverage function instead,
which will then naturally subsume many diffusion models
as special cases. Furthermore, in the information diffusion
context, we show that the coverage function can be represented as a sum of simpler functions, each of which is
an expectation over random binary functions. Based on
these structures of the problem, we propose a maximum-

Direct Learning of Influence Function

likelihood based approach to learn the influence function
directly from cascade data. More precisely,
Direct and robust approach. Our algorithm does not rely
on the assumption of a particular diffusion model, and can
be more robust to model misspecification than two-stage
approaches. Furthermore, directly learning the coverage
function also allows us to avoid the difficulty involved in
diffusion model estimation and influence computation.
Novel Parameterization. We propose a parametrization
of the coverage function using a convex combination of
random basis function. Similar parameterization has been
used in classification and kernel methods setting (Rahimi
& Recht, 2008), but its usage in the information diffusion
and coverage function estimation context is novel.
Approximation guarantee. We show that our parameterization using K random basis functions generates a rich
enough family of functions which can approximate the true
influence function within an error of O( ‚àö1K ). This allows
us to work with a small number of parameters without creating too much bias at the same time.
Efficient algorithm. We propose a maximum likelihood based convex formulation to estimate the parameters,
which allows us to leverage existing convex optimization
techniques (Kivinen & Warmuth, 1997) to solve the problem efficiently. The time required to evaluate each gradient
is O(dmK), linear in the number of nodes d, the number
of cascades m, and the number of basis functions K.
Sample complexity. We prove that to learn the influence
3
function to an  error, we only need O( d3 ) cascades where
d is the number of nodes in the diffusion networks. This is
no obvious since the number possible source configurations
can be exponential in the number of nodes in the network.
Our approach is able to make use of the structure of the
coverage function and be able to generalize only after seeing a polynomial number of cascades.
Superior performance. We evaluate our algorithms using
large-scale datasets, and show that it achieves significantly
better performance in both the synthetic cases where there
is known model misspecification, and in real world data
where the true model is completely unknown in advance.

2. Diffusion Models and Influence Function
Several commonly used models exist for information diffusion over networks. Interestingly, although these models
are very different in nature, the derived influence functions
belong to the same type of combinatorial functions ‚Äî coverage functions. Such commonality allows us later to approach the problem of learning influence functions directly
without assuming a particular diffusion model.
More specifically, a diffusion model is often associated

with a directed graph G = (V, E), and a cascade from a
model is just a set of influenced nodes according to the
model given a set of source nodes S ‚äÜ V. In general, we
have the following typical types of diffusion models :
Discrete-time independent cascade model (Kempe et al.,
2003). Each edge is associated with a weight in [0, 1].
When a cascade is being generated from the source nodes
S, independently for each edge according to the edge
weight, a binary random variable is sampled, indicating
whether the edge is included in a ‚Äúlive edge graph‚Äù or not.
The influenced nodes are those reachable from at least one
of the source nodes in the resulting ‚Äúlive edge graph‚Äù.
Discrete-time linear threshold model (Kempe et al.,
2003). Each edge is again associated with a weight in [0, 1],
but the sum of the incoming edge weights for each node
is smaller or equal to 1. When a cascade is being generated from the source nodes S, each node first independently
sample one of its incoming edges with probability proportional to the edge weight. The chosen edges are then used
to form the ‚Äúlive edge graph‚Äù. The influenced nodes are
those reachable from at least one of the source nodes.
Continuous-time independent cascade model (Du et al.,
2013b). Being different from the discrete-time models, this
model associates each edge (j, i) with a transmission function, fji (œÑji ), a density over time. The source nodes are
assumed to be initially influenced at time zero. Then a diffusion time is sampled independently for each edge according to the transmission function and is viewed as the length
of the edge. The influenced nodes are those within shortest
distance T from at least one of the source nodes.
Being common to these diffusion models, the influence
function, œÉ(S) : 2V 7‚Üí R+ , of a set of nodes S, is defined
as the expected number of influenced nodes with respect to
the generative process of each model. This influence function is a combinatorial function which maps a subset S of
V to a nonnegative number.
Although these diffusion models are very different in nature, their corresponding influence functions belong to the
same type of functions ‚Äî coverage functions, and share
very interesting combinatorial structures (Kempe et al.,
2003; Rodriguez & SchoÃàlkopf, 2012). This means that the
influence function can be written as
X
œÉ(S) =
au ,
(1)
S
u‚àà

s‚ààS

As

with three sets of objects :
(i) a ground set U which may be different from the set V
of nodes in the diffusion network,
(ii) a set of nonnegative weights {au }u‚ààU , each associated with an item in the ground set U,
(iii) and a collection of subsets {As : As ‚äÜ U}s‚ààV , one
for each source node in diffusion network.

Direct Learning of Influence Function

Essentially, each source node s ‚àà S covers a set As of
items from U, and the function value œÉ(S) is the weighted
sum over the union of items covered by all nodes in S.
The combinatorial structures of coverage functions allow
them to be potentially learned directly from cascades.
However, the problem of learning coverage functions is
very challenging for several reasons. First, there are an exponential number of different S from the power set of V,
while one typically only observes a small number of cascades polynomial in the number of nodes, d = |V|, in the
network. Second, both the ground set U, the weights {au }
and the subsets {As } are unknown, and one has to estimate a very large set of parameters if one wants to use the
definition in (1) directly.
In fact, learning such combinatorial functions in general
settings has attracted many recent research efforts (Balcan
& Harvey, 2011; Badanidiyuru et al., 2012; Feldman &
Kothari, 2013; Feldman & Vondrak, 2013), many of which
show that coverage functions can be learned from just polynomial number of samples. However, existing algorithms
are mostly of theoretical interest and impractical for real
world problem yet. To tackle this challenge, we will exploit additional structure of the coverage function in the information diffusion context which allows us to derive compact parameterization of the function, and design a simple
and efficient algorithm with provable guarantees.

3. Structure of the Influence Function
Besides being coverage functions, the influence functions,
œÉ(S), in the diffusion models discussed in Section 2 share
additional structures. In all models, a random graph G is
first sampled from the distribution induced by a particular
diffusion model; and then a function is defined for computing node reachability in the sampled graph; finally the
influence is the expectation of this function with respect to
the distribution of the random graphs.

d

{0, 1} , with its i-th entry
(
1, s ‚àà S,
œáS (s) :=
0, otherwise.

(3)

Then the inner product œá>
S R:j ‚àà Z+ will give us an indication whether a target node j is reachable from any of the
sources in S. More specifically, œá>
S R:j ‚â• 1 if the target
node j is reachable, and 0 otherwise. Finally, using a concave function œÜ(u) = min {u, 1} : Z+ 7‚Üí {0, 1}, we can
transform œá>
S R:j into a binary function of œáS

œÜ œá>
: 2V 7‚Üí {0, 1} .
(4)
S R:j

We note that œÜ œá>
S R:j itself is a coverage function where
(i) the ground set U contains a single item uj , (ii) the weight
on uj is 1, (iii) and the collection of subset is either As =
{uj } if Rsj = 1 and otherwise As = ‚àÖ if Rsj = 0.
Then the influence of S in graph G is the number of target
nodes reachable from the source set S
Xd

#(S|R) :=
œÜ œá>
(5)
S R:j .
j=1

#(S|R) is also a coverage function where (i) the ground
set U contains d items u1 , . . . , ud , (ii) the weight on each
uj is 1, (iii) and As = {uj | Rsj = 1}. Since the graph G
and the associated R are random quantities, the Œ¶ function
is a random function.
3.2. Expectation of random functions
Each diffusion model will induce a distribution over random graph G and hence a distribution pR over the random binary matrix R. Then the overall influence of a
source set S in a diffusion model is the expected value of
#(S|R), i.e.,
œÉ(S) := ER‚àºpR [#(S|R)] ,

(6)

which is also a coverage function, since non-negative combinations of coverage functions are still coverage functions
(See Appendix A).

3.1. Random reachability function
We represent each sampled random graph G as a binary
d√ód
reachability matrix R ‚àà {0, 1}
with (s, j)-th entry
(
1, j is reachable from source s,
Rsj =
(2)
0, otherwise.

Next we will manipulate expression (6) to expose its structure as a sum over a set of conditional probabilities

Essentially, the s-th row of R, denoted as Rs: , records the
information that if s is the source, which node is reachable
given sampled graph G . Furthermore, the j-th column of
R, denoted as R:j , records the information that whether j
is reachable from each of the other nodes. Then given a
set S of sources, we can calculate whether a node j will
be influenced or not in graph G through a simple nonlinear
function œÜ defined below.

=

First, we represent the set S as an indicator vector œáS ‚àà

ER‚àºpR [#(S|R)]
X


d
>
= ER‚àºpR
œÜ œáS R:j
j=1

=

Xd
j=1
Xd



ER‚àºpR œÜ œá>
S R:j



	
Pr œÜ œá>
S R:j = 1|œáS
j=1 |
{z
}

(7)
(by definition (5))
(sum ‚áî expectation)
(œÜ(¬∑) is binary),

:=fj (œáS )

where fj (œáS ) is the conditional probability of œÜ œá>
S R:j
being 1 given the set indicator œáS .



Strategy for learning: The form of the influence function
as a sum over conditional probabilities suggests a simple
strategy for learning the influence function:

Direct Learning of Influence Function

5. Efficient Learning Algorithm

1. we learn each fj (œáS ) separately,
2. and then sum them together,
which we will elaborate in subsequent sections.

4. Random Basis Function Approximation
In this section, we will provide a novel parameterization of
function fj (œáS ) using random basis functions. Recall from
the derivation in (7) that


fj (œáS ) = Er‚àºpj (r) œÜ(œá>
(8)
S r)
where r := R:j and pj (r) is the marginal distribution of
column j of R induced by pR . Since fj (œáS ) is an expectation w.r.t. a distribution pj (r) over the binary vecd
tors {0, 1} , we will use a convex combination of random
basis functions to parameterize fj (œáS ). A similar idea,
called random kitchen sinks (Rahimi & Recht, 2008), has
appeared in the classification and kernel methods context.
Our use of such parameterization is novel in the information diffusion and coverage function learning context, and
our analysis is also different.
Specifically, consider drawing a set of K random binary
vectors (random features) {r1 , r2 , . . . , rK } from some disn
tribution q(r) on {0, 1} , and build functions of the form
XK
>
f w (œáS ) =
wk œÜ(œá>
(9)
S rk ) = w œÜ(œáS ),
k=1
XK
subject to
wk = 1, wk ‚â• 0
(10)
k=1

where w := (w1 , . . . , wK )> are parameters to be
learned, rk is the sampled random feature, and œÜ(œáS ) :=
>
>
(œÜ(œá>
Since each random basis
S r1 ), . . . , œÜ(œáS rK )) .
>
function œÜ(œáS rk ) takes value either 0 or 1, the above combination of such functions will qualify as a probability in
[0, 1]. We will denote the class of functions defined by
equations (9) and (10) as Fbw .
How well can the random basis function f w (œáS ) approximate the original function fj (œáS )? We can show that there
exists some w such that f w (œáS ) approximates fj (œáS ) well
when K is sufficiently large. More specifically, let C be
the minimum value such that
n

pj (r) ‚â§ Cqj (r), ‚àÄj ‚àà [d], ‚àÄr ‚àà {0, 1} .
Intuitively, C measures how far away the sampling distribution qj (r) is from the true distribution pj (r).
Lemma 1. Let pœá (œáS ) be a distribution of œáS . If K =
2
C
) and r1 , . . . , rK are drawn i.i.d. from qj (r),
O( C2 log Œ¥
then with probability at least 1‚àíŒ¥, there exists an f w ‚àà Fbw
such that EœáS ‚àºpœá [(fj (œáS ) ‚àí f w (œáS ))2 ] ‚â§ 2 .
Alternatively, the lemma can also be interpreted as the approximation error  scales as O( ‚àöCK ). Note that we require
PK
that w lie in a simplex, i.e., wk ‚â• 0 and k=1 wk = 1, and
it is slightly different from that in Rahimi & Recht (2008).

After generating the random features, we can learn the
weights w = (w1 , . . . , wK ) by fitting f w (œáS ) to training
data. Since the target function fj (œáS ) is a conditional probability, l2 or l1 error metric may not be suitable loss functions to optimize. A natural approach is maximum conditional likelihood estimation. We use an efficient exponentiated gradient algorithm for performing the estimation
for the weights in f w . Here, we describe the algorithm, and
then present the sample complexity analysis in the next section.
Suppose we observe a dataset of m i.i.d. cascades
Dm := {(S1 , I1 ), . . . , (Sm , Im )} ,

(11)

where each cascade is a pair of observation of the source set
Si and the corresponding set Ii of influenced nodes. Each
cascade (Si , Ii ) in the dataset is obtained by first sampling
a source set Si from a distribution pœá (œáS ) (e.g., power
law), then sampling a random reachability
matrix R from

	
pR , and finally calculating Ii := j : œÜ œá>
S R:j = 1 .
We note that R is an intermediate quantity which is not observed in the dataset. In our setting, we let Si ‚äÜ Ii which
means the nodes in the source set are also considered as
influenced nodes.
For a particular cascade (Si , Ii ) and a particular target
node j, we can define a binary variable indicating whether
the target node j is influenced in this cascade, yij :=
I {j ‚àà Ii }. Then the conditional likelihood of the status of
node j (influenced or not) can be expressed using fj (œáS )
fj (œáSi )yij (1 ‚àí fj (œáSi ))

1‚àíyij

.

(12)

So in the following, we will focus on learning individual
function f w which is an approximation of fj (œáS ).
5.1. Maximum conditional likelihood estimation
In a way very similar to logistic regression and conditional
random fields by Lafferty et al. (2001), we will maximize
the conditional log-likelihood the yij given the œáSi . In contrast to logistic regression and conditional random fields
where the models usually take the exponential family form,
we will use a form of a convex combination of random basis function (f w ). The additional challenge for this parameterization is that the conditional probability may be zero
for some S. To address this challenge, we will use a truncated or Winsorized version of the function f w
f w,Œª (œáS ) = (1 ‚àí 2Œª)f w (œáS ) + Œª

(13)

which squashes the function output to the range of [Œª, 1 ‚àí
Œª]. We will denote this new class of functions as Fbw,Œª . Although this transformation introduces additional bias to the
function class, we show in later analysis that it is fine if we
choose Œª to be about the same level as the approximation
error. In practice, Œª is selected via cross-validation.

Direct Learning of Influence Function

Then the log-likelihood of the data Dm can be written as
Xm
`j (w) :=
yij log f w,Œª (œáSi )
(14)
i=1

+ (1 ‚àí yij ) log(1 ‚àí f w,Œª (œáSi )),
and we can find w by maximizing the log-likelihood
w
b := argmax

`j (w)

(15)

w

subject to

XK
k=1

wk = 1, wk ‚â• 0.

One can easily show that the optimization problem in (15)
is a convex optimization problem over a probability
simplex. Hence we can leverage existing techniques
from convex optimization by Kivinen & Warmuth (1997)
and Schmidt et al. (2009) to find w
b efficiently.
5.2. Exponentiated gradient algorithm
We describe a simple exponentiated gradient (EG) algorithm, originally introduced by Kivinen & Warmuth (1997)
in the online learning context. The EG updates involve the
following simple multiplicative modification

1
(16)
wkt+1 = t wkt exp ‚àíŒ∑ ‚àák (wt )
Z
P
K
where Z t = k=1 wkt exp (‚àíŒ∑ ‚àák (wt )) is the normalization constant, the parameter Œ∑ > 0 is the learning rate, and
the gradient ‚àá(wt ) is given by
m 
X
1 ‚àí yij
‚àá(w) =(1 ‚àí 2Œª)
‚àí
1 ‚àí Œª ‚àí (1 ‚àí 2Œª)w> œÜ(œáSi )
i=1

yij
œÜ(œáSi )
(17)
Œª + (1 ‚àí 2Œª)w> œÜ(œáSi )
Algorithm 1 summarizes algorithm for learning the influence function. We first generate K random features {r1 , . . . , rK } from the given distribution qj (r).
Then, we precompute m feature vectors œÜ(œáSi ) =
>
>
(œÜ(œá>
œáSi is usually very
Si r1 ), . . . , œÜ(œáSi rK )) . Because P
m
sparse, this preprocessing costs O(K i=1 |Si |), where
|Si | is the cardinality of the set Si . Then we use the exponentiated gradient algorithm to find the weight w that
maximizes the log-likelihood of the training data. According to Kivinen & Warmuth (1997), to get within  of the
1
) iterations, where the main work
optimum, we need O( Œ∑
of each iteration is evaluating the gradient with complexity O(dmK). The final estimate œÉ
b(S) is the sum of all the
functions learned for each node. The learning task for each
node is independent of those for the other nodes (except
that we use the same set of training data), so the algorithm
can be easily parallelized. We refer to our algorithm as I N FLU L EARNER .
5.3. How to choose random basis function
By our analysis in Lemma 1, the number of random features needed for node j depends on the sampling distribu-

Algorithm 1 I NFLU L EARNER
1
input training data {(Si , Ii )}m
i=1 , Œª ‚àà (0, 4 )
for each node j ‚àà [d] do
sample K random features {r1 , . . . , rK } from qj (r);
>
compute œÜ(œáSi ) = (œÜ(œá>
Si r1 ), . . . , œÜ(œáSi rK )), ‚àÄi;
1
initialize w to a interior point of a K-simplex;
for t = 1, . . . , T do
calculate ‚àá(wt ) using (17)
update wt+1 ‚àù wt exp(‚àíŒ∑ ‚àá(wt )) using (16)
end for
fbjw,Œª (œáS ) = Œª + (1 ‚àí 2Œª)(wT )> œÜ(œáS )
end for
Pd
output œÉ
b(S) = j=1 fbjw,Œª (œáS ).
tion qj (r). More precisely, it has quadratic dependence on
C where pj (r) ‚â§ Cqj (r) for all r. If we know pj (r), then
by sampling random features from pj (r), we have C = 1
so that much fewer features are needed. However, in practice, pj (r) is often unknown, so we consider estimating
pj (r) by qj (r) using the following simple approach.
Inspired by the empirical success of Naƒ±Ãàve Bayes algorithm
in classification by Bishop (2006) and the mean field approximation in graphical model inference (Wainwright &
Jordan, 2003), we assume that qj (r) is fully factorized, i.e.,
Yd
qj (r) =
qj (r(s)).
s=1

where qj (r(s)) means the marginal distribution of the i-th
dimension of r. Given a training dataset Dm as in equation (11), we estimate each qj (r(s)) using the frequency of
node P
j being influenced by source node i, i.e., qj (r(s)) =
1
m
i‚ààDsm yij where Ds := {i : s ‚àà Si }. Although
|Dsm |
this qj (r) may be quite different from pj (r), by the additional steps of drawing random features and adjusting the
corresponding weights, it leads to very good results, as illustrated in our experiments.
A more intelligent approach for choosing qj (r) may be first
learning a diffusion model outlined in Section 2 and then
using samples from the diffusion model to generate the random basis functions. This approach requires more computation and is left for future study.

6. Sample Complexity of MLE
Here we analyze Algorithm 1 and provide sample complexity bounds for the number of random basis functions and
the size of the training data needed to get a solution close
to the truth. We describe our results here and provide the
proof in the appendix.
We note that existing analysis for random kitchen
sink (Rahimi & Recht, 2008) does not apply to the maximum likelihood estimation. Therefore, we use a general
framework by BirgeÃÅ & Massart (1998) for maximum like-

Direct Learning of Influence Function

lihood estimation. Loosely speaking, the error of the maximum likelihood estimator fbjw,Œª (œáS ) ‚àà Fbw,Œª is bounded
by the best possible in the hypothesis class plus a term
scale roughly as OÃÉ(D/m), where D is the dimension of
the set of candidate models based on a covering approach.
Hence, to get sample complexity bounds for our problem,
we need to bound the dimension of Fbw,Œª . We consider the
mapping from the weight w to the corresponding hypothesis f ‚àà Fbw,Œª , and show that the distance between two
functions f and f 0 are approximately the distance between
their corresponding weights w and w0 . Then a covering on
the space of w induces a covering on the function space
Fbw,Œª , and thus the dimensions of the two spaces are approximately the same, which is O(K). Combined the dimension bound with Lemma 1, we arrive at the following:

7.1. Competitors
Two-stage methods. Two-stage learning methods depend
on the diffusion model assumptions, families of pairwise
temporal dynamics, and whether network structures are
given or not. We design the following four representative
competitors :

Lemma 2. Assume the statement in Lemma 1 is true.
If m = OÃÉ( K ), then the maximum likelihood estimator
fbjw,Œª ‚àà Fbw,Œª satisfies
 2

h
i
 + Œª2
EDm Epœá (fbjw,Œª (œáS ) ‚àí fj (œáS ))2 ‚â§ OÃÉ
.
Œª

For the methods CIC and CIC-S, we use NETRATE
(Gomez Rodriguez et al., 2011) to learn the structure and
parameters of the pairwise transmission functions. For
DIC and DIC-S, we learn the pairwise infection probability
based on the method of (Netrapalli & Sanghavi, 2012).

This means to get  accuracy, it suffices to choose Œª = 
and choose K large enough to make sure that the l2 error
between the true function and the set of candidate functions
in Fbw,Œª is at most 2 . The bound then follows by applying
the above argument on each node with accuracy O(/d).

Theorem 3. Suppose in Algorithm
 2 3 1, we set Œª = OÃÉ( d ),
2 2
K = OÃÉ( C2d ), and m = OÃÉ C3d . Then with probability at least 1 ‚àí Œ¥ over the drawing of the random features,
the output of Algorithm 1 satisfies
"
2 #
Xd
w,Œª
EDm Epœá
fbj (œáS ) ‚àí œÉ(S)
‚â§ .
j=1

Pd
Intuitively, the l2 error of the function j=1 fbjw,Œª learned
is small if the number K of random features and the size
m of the training data are sufficiently large. Both quantities have a quadratic dependence on C, since if C is large,
then the difference between pj and qj could be large, and
thus we need more random features to approximate fj and
also more training data to learn the weights. K and m also
depend on the number d of nodes in the network, for the
reason that we need to estimate each fj up to accuracy /d
so that their sum is estimated to accuracy . This is far
too pessimistic, as we observe in our experiment that much
smaller K or m is needed.

1. Continuous-time Independent Cascade model with
exponential pairwise transmission function (CIC).
2. Continuous-time Independent Cascade model with
exponential pairwise transmission function and given
network Structure (CIC-S).
3. Discrete-time Independent Cascade model (DIC).
4. Discrete-time Independent Cascade model with given
network Structure (DIC-S).

Approach based on logistic regression. Instead of using
random features, we represent fj (œáS ) using a modified logistic regression
fj (œáS ) =

2 exp (w> œáS )
‚àí 1, where w ‚â• 0.
1 + exp (w> œáS )

(18)

Since the sigmoid function is concave in R+ and w> œáS is
a linear function of œáS , the representation in (18) is also a
submodular function of the set S. We learn w by maximizing the log-likelihood subject to the nonnegative constraint.
We also experimented with the original logistic regression
model which does not lead to a submodular function, and
thus does not perform as well as the representation in (18)
(and hence not reported).
Approach based on linear regression. We use the linear
regression model, w> œáS + b, to directly regress from œáS to
the cascade size |I|. This approach does use the knowledge
that the influence function is a coverage function.

7. Experiments

7.2. Synthetic Data
We generate Kronecker type of synthetic networks with the
parameter matrix [0.9 0.5; 0.5 0.3], which mimics the information diffusion traces in real world networks (Leskovec
et al., 2010). The generated networks consist of 1,024
nodes and 2,048 edges. Given a generated network structure, we apply the continuous-time independent cascade,
the discrete-time independent cascades and the linearthreshold model to generate the cascades, respectively.

We evaluate I NFLU L EARNER in synthetic and real world
data. We compare it to the state-of-the-art two-stage approaches, as well as methods based on linear regression and
logistic regression, and show that I NFLU L EARNER is more
robust to model misspecification than these alternatives.

For the continuous-time diffusion model, we used both
Weibull distribution (Wbl) and exponential distribution
(Exp) for the pairwise transmission function, and set their
parameters at random to capture the heterogeneous temporal dynamics. For the Weibull distribution, f (t; Œ±, Œ≤) =

Direct Learning of Influence Function

Logistic

4

InfluLearner

2
0
1

Logistic

10

CIC‚àíS

2

4
8
#cascades per source

5
16

(a) Weibull Family (CIC)

32

4

15

0
1

InfluLearner

2

CIC

2

CIC‚àíS

1

4
8
#cascades per source

Linear

3

CIC

MAE

MAE

20
CIC

CIC

6

DIC‚àíS

Linear

MAE

Linear

6

DIC‚àíS

5

25

8

8
DIC

DIC

10
MAE

6

DIC

30

DIC‚àíS

12

Logistic

Linear

2

16

(b) Exponential (CIC)

32

Logistic

DIC

4
CIC‚àíS

InfluLearner

DIC‚àíS

CIC‚àíS

0
1

InfluLearner

2

4
8
#cascades per source

(c) DIC

16

32

0
1

2

4
8
#cascades per source

16

32

(d) LT

Figure 1. Over the generated synthetic networks with 1,024 nodes and 2,048 edges, we present the mean absolute error of the estimated
influence on the testing data by increasing the number of training data when the true diffusion model is (a) continuous-time independent
cascade with pairwise Weibull transmission functions, (b) continuous-time independent cascade with pairwise exponential transmission
functions, (c) discrete-time independent cascade model and (d) linear-threshold cascade model.
Œ≤
Œ±


t Œ≤‚àí1 ‚àí(t/Œ±)Œ≤
e
,t
Œ±

> 0, where Œ± > 0 is a scale parameter and Œ≤ > 0 is a shape parameter. We choose Œ± and Œ≤
from 1 to 10 uniformly at random for each edge in order
to have heterogeneous temporal dynamics. The true influence value range is from 1 to 235, and the average value is
15.78 with the time window T = 10. For the exponential
distribution, the average influence is 37.81.

diffusion models or transmission functions but only learns
the influence function directly from the data. Thus, it is
much more robust and better than the two-stage methods.
Since I NFLU L EARNER has better representational power
than the logistic regression based approach, it is able to
better approximate the true influence function and thus can
achieve the best performance overall.

For the discrete-time independent cascade model, the pairwise infection probability is chosen uniformly from 0 to
1. For the discrete-time linear-threshold model, we followed Kempe et al. (2003) where the edge weight wuv between u and v is 1/dv , and dv is the degree of node v. We
run these generative models for 10 time steps. The average
influence values are 9.2 and 8.9 respectively.

The cascades used in Figure 1(b) are generated from the
continuous-time independent cascade model with pairwise
exponential transmission functions. Note that in this case
we expect CIC-S and CIC to do well, since they have the
correct assumptions about both the diffusion model and
the family of transmission functions. Particularly, with the
prior knowledge of the true network structure, CIC-S simply fits the model parameters for each edge, and thus the
estimates converge to the true influence function quickly.
Still, we see that the performance of I NFLU L EARNER is
close to that of CIC-S and CIC. Figure 1(b) again show
that I NFLU L EARNER is robust to diffusion model changes.

The source locations are sampled uniformly without replacement from V, and the source set sizes conform to a
power law distribution with parameter 2.5. For the training set, we independently sample 1,024 source sets, and
independently generate 8 to 128 cascades for each source
set. The test set contains 128 independently sampled source
sets with the ground truth influence estimated from 10,000
simulated cascades.
7.3. Robustness to model misspecification
The cascades used in Figure 1(a) are generated from the
continuous-time independent cascade model with pairwise
Weibull transmission functions. We expect that the four
two-stage methods are not doing well due to model misspecification of one form or the other. Figure 1(a) shows
the MAE (Mean Absolute Error) between the estimated
value and the true value. Both CIC-S and CIC used the correct continuous-time diffusion model but the wrong family
of pairwise transmission functions, so their performance
lies in the middle. However, CIC-S has the prior knowledge about the true network structure, so it is reduced to
a much simpler learning problem and is thus better than
CIC. DIC-S and DIC used the wrong diffusion model with
unit time step (which is hard to determine in practice), so
they have the lowest performance overall. In contrast, I N FLU L EARNER does not explicitly make assumptions about

In Figure 1(c, d), we generate cascades according to
discrete-time independent cascade model and linear threshold model respectively. In Figure 1(c), DIC-S and DIC assumes the correct model, so their performance improves a
lot. However, in Figure 1(d), because CIC-S, CIC, DIC-S,
and DIC all assume the wrong diffusion model, we observe
a similar trend as as in Figure 1(a): I NFLU L EARNER is robust and obtain the best results. Note that in this case, the
gap between different methods is not as big since the average influence value is small.
7.4. Scalability
Figure 2(a) reports the parallel runtime of I NFLU L EARNER
as we increase the number of training cascades per source
set. We arbitrarily divide the 1,024 independent learning
problems into 32 individual jobs running on a cluster of
32 cores (AMD Opteron(tm) Processor, 2.5GHz). It shows
that the runtime grows almost linearly as the number of
cascades increases.

Direct Learning of Influence Function
30

4

10

InfluLearner

Logistic

Linear

CIC

400

6

DIC

5

300

15
10

2

8

16

32
64
#cascades per source

(a) Runtime

128

0

4
3

250
200
150

2

5
10

influence

10

MAE

MAE

time(s)

20
3

DIC
CIC
Linear
Logistic
InfluLearner

350

25

1

2

3
4
5
Groups of memes

6

7

(b) MAE on real data

1
4

100
8

16
32
64 128
#random features

256

512

(c) Effect of random features

50
16

32

64
#source

128

(d) Influence maximization

Figure 2. (a) Runtime in log-log scale; (b) MAE on seven sets of real cascade data; (c) The performance gain of using different number
of random features; (d) Maximized expected influence of different selected sources on the real hold-out testing data.

7.5. Influence estimation on real data
We further evaluate the performance of our proposed
method on the MemeTracker dataset which includes 300
million blog posts and articles collected from 5,000
active media sites between March 2011 and February
2012 (Leskovec et al., 2009). The flow of information was
traced using quotes which are short textual phrases spreading through the websites. Because all published documents
containing a particular quote are time-stamped, a cascade
induced by the same quote like ‚Äòapple and jobs‚Äô is a collection of times when the media site first mentioned it.
We have selected seven groups of cascades with the typical keywords like ‚Äòapple and jobs‚Äô, ‚Äòtsunami earthquake‚Äô,
‚Äòwilliam kate marriage‚Äô, ‚Äòoccupy wall-street‚Äô, ‚Äòairstrikes‚Äô,
‚Äòegypt‚Äô and ‚Äòelections‚Äô. We split each set of cascades into
60%-train and 40%-test. Because we do not have any prior
knowledge about either the diffusion structure or the underlying diffusion mechanism on the real cascades data, we
only compare I NFLU L EARNER with the Logistic regression, Linear regression, CIC and DIC.
We evaluate the performance on the held-out testing cascades as follows : we randomly select 10 sources from the
testing cascades, which represents one particular source set
S. For each node u ‚àà S, let C(u) denote the set of cascades
generated from u on the testing data. For each u ‚àà S,
we uniformly sample one cascade from C(u). Thus, the
union of all sampled cascades is the set of nodes infected
by source set S. We repeat the process for 1,000 times
and take the average of the number of infected nodes as
the true influence of source set S. Finally, we have generated 100 source sets and report the MAE of each method
in Figure 2(b). We can see that the performance of I N FLU L EARNER is robust and consistent across all groups of
testing cascades, and is significantly better than the other
competitors.
Moreover, Figure 2(c) demonstrates the effect of the
number of random features on the performance of I N FLU L EARNER by showing the average MAE over the seven
sets of cascade data as the number of random features increases. As the number of random features grows, I N FLU L EARNER approximates the true influence better, and

thus the MAE decreases. It seems that 128 to 256 random
features are sufficient to achieve good performance overall.
7.6. Influence maximization on real data
Finally, we use the learned influence function (from I N FLU L EARNER , Logistic, Linear, CIC and DIC) for solving
the influence maximization problem Kempe et al. (2003);
Du et al. (2013b). Here we want to find a set S ‚àó of C
source nodes which maximizes the influence, i.e., S ‚àó =
argmax|S|‚â§C œÉ(S). We will use a greedy algorithm framework of Nemhauser et al. (1978) to solve the problem.
We use the held-out test cascade to estimate the influence
achieved by selected source nodes. The observation time
window used is T = 14.
Figure 2(d) shows the influence achieved in Meme group
1 (the rest of the testing groups has similar results as in
the Appendix). I NFLU L EARNER, Logistic and CIC perform consistently better than DIC and linear regression.
The source nodes selected by I NFLU L EARNER, Logistic
and CIC are very similar, though the estimated influence
value can be different. As a result, the influence value of
I NFLU L EARNER, Logistic and CIC are very close.

8. Conclusion
Based on the observation that the influence function in
many diffusion models are coverage functions, we propose
to directly learn the influence from cascade data. In this
paper, we provide a novel parameterization of the influence function as a convex combination of random basis
functions, and an efficient maximum likelihood based algorithm for learning the weighting of the random basis functions. Theoretically, we show that the algorithm can learn
the influence with low sample complexity, and our empirical study also shows our method outperforms traditional
two-stage approaches.

Acknowledgement
The research was supported in part by NSF/NIH BIGDATA
1R01GM108341, NSF IIS-1116886, NSF CAREER IIS-1350983
to L.S.; NSF CCF-1101283, NSF CAREER CCF-0953192,
AFOSR FA9550-09-1-0538, ONR N00014-09-1-0751, and a Microsoft Research Faculty Fellowship to M.B; a Raytheon Faculty
Fellowship to M.B. and L.S.; and a Facebook Fellowship to N .D.

256

Direct Learning of Influence Function

References
Badanidiyuru, A., Dobzinski, S., Fu, H., Kleinberg, R. D.,
Nisan, N., and Roughgarden, T. Sketching valuation
functions. In Proceedings of the Annual ACM-SIAM
Symposium on Discrete Algorithms, 2012.
Balcan, Maria-Florina and Harvey, Nicholas JA. Learning
submodular functions. In Proceedings of the 43rd annual
ACM symposium on Theory of computing, pp. 793‚Äì802.
ACM, 2011.
BirgeÃÅ, L. and Massart, P. Minimum Contrast Estimators on
Sieves: Exponential Bounds and Rates of Convergence.
Bernoulli, 4(3), 1998.
Bishop, Christopher. Pattern Recognition and Machine
Learning. Springer, 2006.
Borgs, Christian, Brautbar, Michael, Chayes, Jennifer, and
Lucier, Brendan. Influence maximization in social networks: Towards an optimal algorithmic solution. arXiv
preprint arXiv:1212.0884, 2012.
Chen, Wei, Wang, Chi, and Wang, Yajun. Scalable influence maximization for prevalent viral marketing in
large-scale social networks. In Proceedings of the 16th
ACM SIGKDD international conference on Knowledge
discovery and data mining, pp. 1029‚Äì1038. ACM, 2010.
Du, N., Song, L., Smola, A., and Yuan, M. Learning networks of heterogeneous influence. In Advances in Neural Information Processing Systems 25, pp. 2789‚Äì2797,
2012.
Du, N., Song, L., Woo, H., and Zha, H. Uncover topicsensitive information diffusion networks. In Artificial
Intelligence and Statistics (AISTATS), 2013a.
Du, Nan, Song, Le, Rodriguez, Manuel Gomez, and Zha,
Hongyuan. Scalable influence estimation in continuoustime diffusion networks. In Advances in Neural Information Processing Systems 26, 2013b.
Feldman, Vitaly and Kothari, Pravesh. Learning coverage
functions. arXiv preprint arXiv:1304.2079, 2013.
Feldman, Vitaly and Vondrak, Jan. Optimal bounds on approximation of submodular and xos functions by juntas.
In FOCS, 2013.
Gomez Rodriguez, Manuel, Balduzzi, David, and
SchoÃàlkopf, Bernhard.
Uncovering the temporal
dynamics of diffusion networks.
arXiv preprint
arXiv:1105.0697, 2011.
Kempe, David, Kleinberg, Jon, and Tardos, EÃÅva. Maximizing the spread of influence through a social network.
In Proceedings of the ninth ACM SIGKDD international

conference on Knowledge discovery and data mining,
pp. 137‚Äì146. ACM, 2003.
Kivinen, J. and Warmuth, M. K. Exponentiated gradient
versus gradient descent for linear predictors. Information
and Computation, 132(1):1‚Äì64, January 1997.
Lafferty, J. D., McCallum, A., and Pereira, F. Conditional
random fields: Probabilistic modeling for segmenting
and labeling sequence data. In Proceedings of International Conference on Machine Learning, volume 18, pp.
282‚Äì289, San Francisco, CA, 2001. Morgan Kaufmann.
Leskovec, Jure, Backstrom, Lars, and Kleinberg, Jon.
Meme-tracking and the dynamics of the news cycle. In
Proceedings of the 15th ACM SIGKDD international
conference on Knowledge discovery and data mining,
pp. 497‚Äì506. ACM, 2009.
Leskovec, Jure, Chakrabarti, Deepayan, Kleinberg, Jon,
Faloutsos, Christos, and Ghahramani, Zoubin. Kronecker graphs: An approach to modeling networks.
Journal of Machine Learning Research, 11(Feb):985‚Äì
1042, 2010.
Nemhauser, G., Wolsey, L., and Fisher, M. An analysis of
the approximations for maximizing submodular set functions. Mathematical Programming, 14:265‚Äì294, 1978.
Netrapalli, Praneeth and Sanghavi, Sujay.
Learning the graph of epidemic cascades. In SIGMETRICS/PERFORMANCE, pp. 211‚Äì222. ACM, 2012.
ISBN 978-1-4503-1097-0.
Rahimi, Ali and Recht, Benjamin. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. In Advances in neural information processing systems, pp. 1313‚Äì1320, 2008.
Rodriguez, M.G. and SchoÃàlkopf, B. Influence maximization in continuous time diffusion networks. In Proceedings of the International Conference on Machine Learning, 2012.
Schmidt, M., van den Berg, E., Friedlander, M. P., and
Murphy, K. Optimizing costly functions with simple
constraints: A limited-memory projected quasi-newton
algorithm. In van Dyk, D. and Welling, M. (eds.), Proceedings of The Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS) 2009, volume 5, pp. 456‚Äì463, Clearwater Beach, Florida, April
2009.
Wainwright, M. J. and Jordan, M. I. Graphical models,
exponential families, and variational inference. Technical Report 649, UC Berkeley, Department of Statistics,
September 2003.

