Asymptotically consistent estimation
of the number of change points in highly dependent time series

Azadeh Khaleghi
CBIO Mines ParisTech, INSERM U900, Institut Curie, FRANCE
Daniil Ryabko
SequeL-INRIA Lille - Nord Europe, FRANCE

Abstract
The problem of change point estimation is considered in a general framework where the data
are generated by arbitrary unknown stationary
ergodic process distributions. This means that
the data may have long-range dependencies of
an arbitrary form. In this context the consistent estimation of the number of change points
is provably impossible. A formulation is proposed which overcomes this obstacle: it is possible to find the correct number of change points
at the expense of introducing the additional constraint that the correct number of process distributions that generate the data is provided. This
additional parameter has a natural interpretation
in many real-world applications. It turns out
that in this formulation change point estimation
can be reduced to time series clustering. Based
on this reduction, an algorithm is proposed that
finds the number of change points and locates the
changes. This algorithm is shown to be asymptotically consistent. The theoretical results are
complemented with empirical evaluations.

1. Introduction
Change point estimation is a classical problem in statistics and machine learning (Brodsky & Darkhovsky,
1993; Basseville & Nikiforov, 1993) and has applications in a broad range of such domains as market analysis, bioinformatics, audio and video segmentation, fraud
detection, only to name a few.
The problem can
be introduced as follows. A given sequence x :=
X1 , . . . , Xbnθ1 c , . . . , Xbnθκ c+1 , . . . , Xn is formed as the
Proceedings of the 31 st International Conference on Machine
Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).

AZADEH . KHALEGHI @ CURIE . FR

DANIIL . RYABKO @ INRIA . FR

concatenation of an (unknown) number κ + 1 of nonoverlapping segments where θk ∈ (0, 1), k = 1..κ. Each
segment is generated by one of r ≤ κ unknown stochastic
process distributions. The process distributions that generate every pair of consecutive segments are different. The
index bnθk c where one segment ends and another starts is
called a change point. The parameters θk , k = 1..κ that
specify the change points bnθk c are unknown and to be estimated.
We consider highly dependent time series, making as little
assumptions as possible on how the data are generated. In
particular, the distributions that generate the data are unknown and can be arbitrary; the only assumption is that
they are stationary ergodic. This means that we make no
such assumptions as independence, finite memory or mixing. Moreover, the change refers to the change in time series distribution and can have an arbitrary form. In particular, it is not restricted to the change in the mean, moment,
etc., and is not confined to the finite-dimensional marginals
of any fixed size. For example, the change may concern
only the form of the long-range dependence.
With no further assumptions or additional information, this
general formulation of the problem does not allow for the
correct estimation of the number of change points, even
in the weakest asymptotic sense. Indeed, as shown by
(Ryabko, 2010b) in the general setting of highly dependent
time series, it is even impossible to distinguish between the
case of 0 and 1 change point; this impossibility result holds
even for discrete-valued time series.
Stricter statistical frameworks are usually considered in the
literature, making it possible to find κ at the cost of making
stronger assumptions on the time series and on the form of
the change. These stronger assumptions typically result in
that the speed of convergence of a certain empirical statistic is known, e.g. from concentration inequalities, which
can then be used to identify the changes via thresholding.
However, our objective in this paper is to seek a natural for-

Estimation of the number of change points in highly dependent time series

mulation under which it is possible to consistently solve the
change point problem without the need to impose stronger
assumptions on the process distributions.
To this end, we propose a novel formulation of the problem, which, at the expense of a single additional parameter
allows us to overcome the impossibility result described.
Namely, we assume that the total number r of process distributions that generate the data is provided to the algorithm. This formulation and the additional parameter is motivated by applications. Indeed, first of all, the assumption
that the data are highly dependent complies well with most
real-world scenarios. Assumptions on the rates of convergence of certain statistics (such as mixing), and even more
general assumptions made to that effect, are usually impossible to verify in practice. On the other hand, in many applications the number r of distributions is a natural parameter of the problem. The simple example where a pair of
distributions alternate in generating a sequence with many
change points, may, in many cases, correspond to a system whose behaviour over time alternates between normal
and abnormal (r = 2). To a varying extent, this may be a
suitable model for system performance management, video
surveillance and fraud detection. The identification of coding versus non-coding regions in genomic data is another
potential application for this formulation with r = 2. Another application concerns the problem of authorship attribution in a given text written collaboratively by a known
number r of authors. Finally, in speech segmentation r may
be the total number of speakers.
Main Results. We propose a natural formulation of the
change point problem, as well as a nonparametric algorithm to find the number of change points and to estimate
the changes in stationary ergodic time series. We demonstrate both theoretically and experimentally that our algorithm is asymptotically consistent in the general framework
described. The asymptotic regime means that the error is
arbitrarily small if the sequence is sufficiently long. In particular, the problem is “offline” and the sequence does not
grow with time.
The novelty of our work lies not only in the algorithm proposed, but also in the problem formulation. We demonstrate that, despite theoretical impossibility results, if the
total number r of process distributions that generate the
data is provided, the problem of obtaining the correct number of change points admits a solution, without requiring the knowledge of any probabilistic characteristics of
the distributions generating the data or of the form of the
changes.
Moreover, we show that a consistent algorithm can be obtained by a reduction to the problem of time series clustering. Thus, our results establish a novel formal link between
two classical unsupervised learning problems, namely clus-

tering and change point analysis, potentially bringing a new
insight to both communities.
The theoretical results are illustrated with experiments on
synthetic data. To generate the data we have used a wellknown family of distributions that, while being stationary
ergodic, do not belong to any “simpler” class of processes,
and in particular cannot be modeled by finite- or countablestate models (such as finite-state HMMs).
Methodology. Our approach is composed of two main
steps. First, we use a so-called list-estimator (Khaleghi
& Ryabko, 2012) to produce an exhaustive list of at least
κ candidate estimates, whose first κ elements are guaranteed to be asymptotically consistent. Once sorted in increasing order, the resulting list induces a partitioning of
the sequence into consecutive segments. At this point we
group the resulting segments into r clusters. A candidate
estimate is identified as redundant if it joins a pair of consecutive segments in the same cluster. Finally, we remove
the redundant estimates from the list and provide the remaining estimates as output. The clustering procedure uses
farthest-point initialization to designate r cluster centres,
and then assigns each remaining point to the nearest centre. To measure the distance between the segments, empirical estimates (Ryabko & Ryabko, 2010) of the so-called
distributional distance (Gray, 1988) are used. The consistency of the proposed method can be established using any
list-estimator that is consistent under the considered framework; we take a list-estimator from (Khaleghi & Ryabko,
2012) as an example. Different clustering procedures can
be used as well, although their consistency for stationary
ergodic time series cannot be exploited directly. The main
challenge is in that the clustering procedure is used on
segments that are obtained as concatenations of sequences
generated by different process distributions, rather than by
a single distribution. This means that the consistency analysis has to be performed anew.
Related Work. In a typical formulation of the problem, the
sequence is assumed to have a single change point and the
samples within each segment are assumed to be generated
i.i.d, the distributions have known forms and the change
is in the mean; see e.g. (Csörgö & Horváth, 1998) for a
comprehensive review. In the literature on non-parametric
methods for dependent data, the nature of dependence is
typically restricted. For example, strong mixing conditions
is a constraint that is commonly imposed, see e.g. (Brodsky & Darkhovsky, 1993). More general settings have also
been considered, e.g. (Giraitis et al., 1995; Carlstein &
Lele, 1993), with the latter work considering stationary ergodic time series. However, all these works assume that the
single-dimensional marginals are different before and after
the change point; this assumption is in fact prevalent in the
literature.

Estimation of the number of change points in highly dependent time series

The multiple change point estimation problem is considerably more difficult than the analysis of a single change,
even if the number of change points is known. Thus, it
is not as widely explored as that concerning single change
point analysis. For known κ and dependent observations
satisfying mixing conditions, the problem has been addressed from a global optimization perspective (Lavielle,
1999; Lavielle & Teyssiere, 2007). For the general framework considered in this paper, the case where κ is known
has been considered by (Ryabko & Ryabko, 2010) (κ = 1)
and (Khaleghi & Ryabko, 2013) (κ > 1). However, if κ
provided to these algorithms is incorrect, their behavior can
be arbitrarily bad. The case of unknown κ in this general
setting is considered by (Khaleghi & Ryabko, 2012), where
a list of possibly more than κ candidate estimates is produced, but no attempt is made to estimate κ; the produced
list is sorted such that its first κ elements converge to the
true change points.
The problem of estimating the number of change points is
nontrivial, even under these more restrictive assumptions.
In such settings, this problem is usually addressed with penalized criteria; see, e.g. (Lebarbier, 2005; Lavielle, 2005).
Such criteria necessarily rely on additional parameters on
which the resulting number of change points depends. Note
that the algorithm proposed in this work also requires an
input parameter: the number r of distributions. However,
as argued above, parameter has a natural interpretation in
many real-world applications. The problem of clustering
stationary ergodic time series is considered by (Ryabko,
2010a), where the goal is to group together those and only
those sequences that are generated by the same process distribution. Here we reduce the change point problem to
clustering in this formulation. The important difference,
which makes the consistency result of (Ryabko, 2010a) not
directly applicable, is that we have to deal with concatenations of sequences generated by different distributions,
rather than with individual sequences each generated by a
single distribution.
Organization. The remainder of this paper is organized as
follows. In Section 2 we introduce some preliminary notation and definitions. In Section 3 we formalize the problem.
In Section 4 we present our algorithm, state the main consistency result, and intuitively explaining why it holds; we
also provide a brief discussion on its computational complexity. The proofs of the main consistency results are
given in Section 7. Section 5 is dedicated to our experimental results, and some concluding remarks are provided
in Section 6.

2. Preliminaries
Let X be a measurable space (the domain); in this work
we let X = R but extensions to more general spaces are

straightforward. For a sequence X1 , . . . , Xn we use the
abbreviation X1..n . Consider the Borel σ-algebra B on X ∞
generated by the cylinders {B × X ∞ : B ∈ B m,l , m, l ∈
N}, where the sets B m,l , m, l ∈ N are obtained via the
partitioning of X m into cubes of dimension m and volume
2−ml (starting at the origin). Let also B m := ∪l∈N B m,l .
Process distributions are probability measures on the space
(X ∞ , B). For x = X1..n ∈ X n and B ∈ B m let ν(x, B)
denote the frequency with which x falls in B, i.e.
n−m+1
I{n ≥ m} X
I{Xi..i+m−1 ∈ B}. (1)
ν(x, B) :=
n − m + 1 i=1

A process ρ is stationary if for any i, j ∈ 1..n and B ∈
B m , m ∈ N, we have ρ(X1..j ∈ B) = ρ(Xi..i+j−1 ∈
B). A stationary process ρ is stationary ergodic if for all
B ∈ B with probability 1 we have limn→∞ ν(X1..n , B) =
ρ(B). By virtue of the ergodic theorem, this definition can
be shown to be equivalent to the standard definition, see,
e.g. (Csiszar & Shields, 2004).
Definition 1 (Distributional Distance). The distributional
distance between a pair of process distributions ρ1 , ρ2 is
defined as follows (Gray, 1988)
d(ρ1 , ρ2 ) :=

∞
X

wm wl

X

|ρ1 (B) − ρ2 (B)|,

B∈B m,l

m,l=1

where wm and wl , m, l ∈ N are sequences of positive
summable real weights; we let wj := 1/j 2 .
In words, we partition the sets X m , m ∈ N into cubes of
decreasing volume (indexed by l) and take a weighted sum
over the differences in probabilities of all the cubes in these
partitions, where smaller weights are given to larger m and
finer partitions.
Definition 2 (Empirical estimates of d(·, ·)). Consider sequences xi ∈ X ni ni ∈ N, i = 1, 2, x ∈ X n , n ∈ N
and process distribution ρ. The empirical estimates of d
are defined as follows.
ˆ ρ) :=
d(x,

mn X
ln
X

wm wl

m=1 l=1

ˆ 1 , x2 ) :=
d(x

mn X
ln
X
m=1 l=1

X

|ν(x, B) − ρ(B)|

(2)

B∈B m,l

wm wl

X

|ν(x1 , B) − ν(x2 , B)|

B∈B m,l

(3)
where mn and ln are any sequences of integers that go to
infinity with n.
Remark 1. Despite the infinite summations, dˆ can be
calculated efficiently, (Ryabko, 2010a); its computational
complexity is O(n polylog n) for mn := log n, and ln :=
− log s, where s := minXi 6=Xj , i,j∈1..n |Xi − Xj |. This
choice of parameter is justified by (Khaleghi et al., 2012),
and (Ryabko, 2010a); see also (Khaleghi & Ryabko, 2012).

Estimation of the number of change points in highly dependent time series

ˆ ·) is asymptotically consistent (Ryabko
Proposition 1 (d(·,
& Ryabko, 2010)). Let a pair of sequences xi ∈ X ni , i =
1, 2 be generated by a distribution ρ whose marginals
ρi , i = 1, 2 are stationary and ergodic. Then

Define the minimum separation of the change point parameters θk , k = 1..κ as

ˆ i , ρj ) = d(ρi , ρj ), i, j ∈ 1, 2, ρ − a.s.,
lim d(x

(4)

ˆ 1 , x2 ) = d(ρ1 , ρ2 ), ρ − a.s.
d(x

(5)

Since the consistency properties we are after are asymptotic
in n, we require that λmin > 0. Note that this condition is
standard in the change point literature, although it may be
unnecessary when simpler formulations of the problem are
considered, for example when the samples are i.i.d. However, conditions of this kind are inevitable in the general
setting that we consider, where the segments as well as the
samples within each segment are allowed to be arbitrarily
dependent: if the length of one of the sequences is constant
or sub-linear in n, obtaining asymptotic consistency is not
possible in this setting.

ni →∞

lim

n1 ,n2 →∞

3. Problem formulation
We formalize the problem as follows. The sequence
x := X1 , . . . , Xn ∈ X n , n ∈ N, generated by an unknown arbitrary process distribution, is
formed as the concatenation of κ + 1 of sequences
X1..bnθ1 c , Xbnθ1 c+1..bnθ2 c , . . . , Xbnθκ c+1..n where θk ∈
(0, 1), k = 1..κ, and κ are unknown. Each of the sequences xk := Xπk−1 +1..πk , k = 1..κ + 1, π0 :=
0, πκ+1 := n is generated by one of r ≤ κ + 1 unknown
stationary ergodic process distributions ρ1 , . . . , ρr . It is
important to note that the number of change points κ is unknown and has to be estimated, but the number of different
process distributions r is known and is provided to the algorithm.
To define the setting more formally, consider a matrix
X ∈ (X ∞ )κ+1 of random variables generated by some
(unknown) stochastic process distribution ρ such that 1. the
marginal distribution over every one of its rows is an unknown stationary ergodic process distribution, and 2. the
marginal distributions over the consecutive rows are different, so that every two consecutive rows are generated
by different process distributions in {ρ1 , . . . , ρr }. The sequence x ∈ X n , n ∈ N with κ change points is obtained as follows. First, the length n ∈ N is fixed, then
for each k = 1..κ + 1 a segment xk ∈ X bn(θk −θk−1 )c
is obtained as the first bn(θk − θk−1 )c elements of the
k th row of X with θ0 := 0, θκ+1 := 1. The individual
segments xk , k = 1..κ + 1 are concatenated to produce
x := x1 , . . . , xκ+1 . Thus, there exists a ground-truth partitioning
G := {G1 , . . . , Gr }
(6)
of the set {1..κ + 1} into r disjoint subsets where for every
k = 1..κ + 1 and r0 = 1..r we have k ∈ Gr0 if and only
if xk is generated by ρr0 . The parameters θk , k = 1..κ
specify the change points bnθk c which separate consecutive segments xk , xk+1 generated by different process
distributions. The change points are unknown and to be
estimated. The process distributions ρ1 , . . . , ρr are completely unknown and may be dependent. Moreover, the
means, variances, or more generally, the finite-dimensional
marginal distributions of any fixed size before and after the
change points are not required to be different. We consider
the most general scenario where the process distributions
are different.

λmin :=

min

k=1..κ+1

θk − θk−1 .

(7)

As discussed in the introduction, it is provably impossible (Ryabko, 2010b) to distinguish between the case of one
and zero change points in the general framework. Hence,
the number κ of change points cannot be estimated with no
further information. This is the reason why we assume that
the total number r of process distributions that generate the
data is provided (while the number κ of change points remains unknown).
Thus, the problem formulation we consider can be described as follows. Given a sequence x, a lower-bound on
the minimum distance λ between the change points, and the
total number r of process distributions, we seek a method
that outputs the estimated number κ̂ of change points and
the estimated change point parameters θ̂1 , . . . , θ̂κ̂ . We require the algorithm to be asymptotically consistent so that
with probability 1 from some n on κ̂ = κ, and the estimates
θ̂k satisfy
lim sup |θ̂k (n) − θk | = 0 a.s.

n→∞ k=1..κ

(8)

Note that in the particular case of r = κ+1 where all of the
process distributions are different we have κ change points
and thus we arrive to the formulation of the problem with
known κ. More generally, r can be very different from
κ + 1, and as discussed in the introduction, has a natural
interpretation in many real-world applications.

4. Main theoretical results
In this section we present our algorithm and informally explain how it works. Theorem 1 establishes its consistency.
The proposed algorithm relies on a so-called list estimator: a procedure that, given x and λ, outputs a (long, exhaustive) list of change point estimates, without attempting
to estimate the number of change points in the sequence.
More precisely, a list-estimator is defined as follows.
Definition 3 (List-estimator). A list-estimator Υ is a function that, given a sequence x ∈ X n of length n ∈ N

Estimation of the number of change points in highly dependent time series

Algorithm 1 A change point estimator for known r
input: x ∈ X n , λ ∈ (0, λmin ], Number r of process
distributions
Initialize: ψ0 ← 0, ψ|Υ|+1 ← n
1. Obtain a list of candidate estimates via a consistent
list-estimator:
Υ ← Υ(x, λ)
2. Sort the list in increasing order:
{ψi : i = 1..|Υ|} ← sort({nθ̂ : θ̂ ∈ ψ})
(so that i < j ⇔ ψi < ψj , i, j ∈ 1..|Υ|.)
Generate a set S of consecutive segments:
S ← {e
xi := Xψi−1 +1..ψi : i = 1..|Υ| + 1}

(9)

3. Partition S into r clusters:
i. Initialize r farthest segments as cluster centres
c1 ← 1
j−1

ˆ xi , x
e ci0 ), j = 2..r
cj ← argmax min
d(e
0
i=1..|Υ| i =1

(10)

ii. Assign every segment to the closest cluster
ˆ xi , x
e cj ), i = 1..|Υ|
T (e
xi ) ← argminj=1..r d(e
4. Eliminate redundant estimates:
C ← {1..|Υ|}
for i = 1..|Υ| do
if T (e
xi ) = T (e
xi+1 ) then
C ← C \ {i}
end if
end for
5. Obtain κ and the estimates for θk , k = 1..κ
κ̂ ← |C|, θ̂i :=

1
ψi , i ∈ C
n

return: κ̂, θ̂i , i ∈ C

and a parameter λ ∈ (0, 1), produces a list Υ(x, λ) :=
(θ̂1 (n), . . . , θ̂|Υ| (n)) ∈ (0, 1)|Υ| of some |Υ| ≥ κ estimates. Let (θ̂µ1 , θ̂µ2 , . . . , θ̂µκ ) := sort(θ̂1 , . . . , θ̂κ ) be
the first κ elements of Υ(x, λ), sorted in increasing order of value. We call Υ asymptotically consistent if
for every λ ∈ (0, λmin ] with probability 1 we have
limn→∞ supk=1..κ |θ̂µk (n) − θk | = 0.
An example of a consistent list-estimator is provided in
(Khaleghi & Ryabko, 2012).

The key idea of the proposed algorithm is to have a consistent list-estimator, such as that presented in (Khaleghi &
Ryabko, 2012), produce a list of at least κ change point estimates, and then cluster the segments induced by the candidate estimates to identify the redundant estimates in the
list.
More specifically, Algorithm 1 works as follows. First,
a consistent list-estimator is used to obtain an initial set
of change-point candidates. The estimates are sorted in
increasing order to produce a set S of consecutive nonoverlapping segments of x. The set S is then partitioned
into r clusters. We use the following clustering procedure.
First, a total of r cluster centres are obtained as follows.
The first segment x1 is chosen as the first cluster centre.
Iterating over j = 2..r a segment is chosen as a cluster
centre if it has the highest minimum distance from the previously chosen cluster centres. Once the r cluster centres
are specified, the remaining segments are assigned to the
closest cluster. In each cluster, the change point candidate
that joins a pair of consecutive segments of x is identified
as redundant and is removed from the list. Once all of the
redundant candidates are removed, the algorithm outputs
the remaining candidate estimates.
Theorem 1. [Algorithm 1 is asymptotically consistent.]
With probability 1, from some n on we have κ̂ = κ, and the
estimates θ̂k satisfy limn→∞ supk=1..κ |θ̂k (n) − θk | = 0,
provided that λ ∈ (0, λmin ], and the correct number r of
process distributions are given.
The proof is provided in Section 7. A sketch of the proof
follows.
Since a consistent list-estimator Υ is used in the first step,
for large enough n, an initial set of possibly more than κ
estimated parameters is generated, that contains κ elements
which are arbitrarily close to the true change point parameters. (Note that since κ is unknown, the fact that the correct
estimates appear first in the list is irrelevant. Indeed, all we
can use here is that the correct estimates are somewhere in
the list.) Therefore, if x is long enough, the largest portion
of each segment in S is generated by a single process distribution. Since the initial change point candidates are at
least nλ apart, the lengths of the segments in S are linear
functions of n. Thus, we can show that for large enough
n, the empirical estimate of the distributional distance between a pair of segments in S converges to 0 if and only
if the same process distribution generates most of the two
segments. Given the total number r of process distributions, for long enough x the clustering algorithm groups
together those and only those segments in S that are generated by the same process distribution. This lets the algorithm identify and remove the redundant candidates. By
the consistency of Υ, the remaining estimates converge to
the true change point parameters.

Estimation of the number of change points in highly dependent time series

5. Experimental results

1
Al gori th m 1
l i st -e st i mat or Υ

0.9
0.8

Estimation Error Rate

Computational Complexity. It is easy to see that the algorithm can be implemented efficiently. The initial |Υ| ≤
1/λ change point candidates are obtained via the algorithm
of (Khaleghi & Ryabko, 2012) which is in turn shown to
have computational complexity O(n2 polylog n), where n
corresponds to the length of the sequence. The clustering procedure only requires r|Υ| pairwise distance calculations; apart from that, the remaining calculations are of
order O(r(|Υ| + 1)). Thus, by Remark 1, the resource
complexity of Algorithm 1 is O(n2 polylog n).

0.7
0.6
0.5
0.4
0.3
0.2

We evaluate our method using synthetically generated data.
The data are generated using stationary ergodic process distributions that do not belong to any “simpler” general class
of time series, and cannot be approximated by finite state
models. Also, the single-dimensional marginals of all distributions are the same throughout the generated sequence.
n

To generate a sequence x ∈ R , n ∈ N with κ change
points we proceed as follows. For every k ∈ 1..κ + 1
we use the so-called ergodic rotation to generate the segment xk := Xbnθk−1 c+1 , . . . , Xbnθk c ∈ Rnk with nk :=
bnθk c − bnθk−1 c, where θ0 := 0 and θκ+1 := 1. More
specifically, to generate the segment xk , k ∈ 1..κ + 1 we
proceed as follows.
1. Fix a parameter αk ∈ (0, 1) and two uniform distributions U1 and U2 .

0.1
0

0

1

2

3

4. Set Xi+bnθk−1 c as
(1)

Xi+bnθk−1 c = I{ri ≤ 0.5}xi

5

6

and using uniform distributions U1 and U2 over [0, 0.7] and
[0.3, 1] respectively. We used the algorithm proposed by
(Khaleghi & Ryabko, 2012) as the list-estimator Υ(·, ·).
As shown in Figure 5 the estimation error rate of
Alg1(x, λ, r) with λ := 0.6λmin converges to 0 as n ranges
over 1000..60000. In each run, the error is calculated as
I{|C| 6= κ} + I{|C| = κ}

κ
X

|θ̂k − θk |.

k=1

For illustration, we also plot the performance of the list estimator of (Khaleghi & Ryabko, 2012). Since the reference
method does not attempt to estimate κ, we calculate its error on the first κ elements of its output list.

(2)

+ I{ri > 0.5}xi .

6. Conclusion
If αk is irrational this procedure produces a real-valued stationary ergodic time series xk . These processes are commonly used as examples of stationary ergodic processes
that are not B-processes, see e.g. (Shields, 1996). We simulate αk , k = 1..κ + 1 by a longdouble with a long
mantissa. For the purpose of our experiment, we fixed three
parameters α1 := 0.12.., α2 := 0.14.., α3 := 0.16.. (with
long mantissae) to correspond to r := 3 different process
distributions. To produce x ∈ Rn we generated κ := 3
change point parameters θk , k = 1..κ with minimum separation λmin := 0.1. Every segment xk of length was generated with αk where k := k 0 mod r, k 0 = 0..κ + 1 (so
that the first and the last segments, namely x1 and x4 , were
deliberately generated by the same process distribution),

4

x 10

Figure 1. Average (over 40 runs) error rates of Alg 1(x, r, λ) and
the list-estimator Υ(x, λ) of (Khaleghi & Ryabko, 2012) as a
function of the sequence length n for x ∈ Rn ; for Υ, the error is
calculated on its first κ elements.

2. Let a0 be drawn uniformly at random from [0, 1].
3. For each i = 1..nk , shift ai−1 to the right by αk and
remove the integer part, i.e. ai = ai−1 + αk mod 1.
(j)
Also draw xi from Uj , j = 1, 2.

4

Sequence Length

We have presented an asymptotically consistent algorithm
to find the number of change points, and locate the changes
in highly dependent time series. While in the general
framework considered, it is provably impossible to obtain
the number of change points, we have managed to tackle
the problem under a natural formulation, namely, under the
assumption that the correct number of process distributions
that generate the data is provided.
As discussed in the paper, in this framework rates of convergence are provably impossible to obtain. Therefore, the
algorithms developed for this framework are forced not to
rely on rates of convergence. While the downside is that
the asymptotic results obtained for these methods cannot

Estimation of the number of change points in highly dependent time series

be strengthened, the advantage is that the rate-free methods designed for this framework are applicable to a much
broader range of real-world situations. At the same time, it
may be interesting to derive the rates of convergence of the
proposed algorithm under stronger assumptions (e.g. i.i.d.,
mixing, etc.). We conjecture that our algorithm is close to
optimal in such settings as well (although it clearly cannot be optimal in parametric settings). Another interesting
question concerns the time series distance used in the algorithms. We establish our consistency results using some
properties specific to the (empirical estimates of the) distributional distance. It is possible that other distances, for
example the telescope distance of (Ryabko & Mary, 2012),
can replace the distributional distance used in our method.
These questions may be addressed in future work.

7. Proofs
The proof of Theorem 1 relies on Lemma 1 which is borrowed from (Khaleghi & Ryabko, 2013), and on Lemma 2
which is stated and proven below.
Lemma 1 (Khaleghi & Ryabko, 2013). Let x = X1..n be
generated by a stationary ergodic process ρ. For α ∈ (0, 1)
the following statements hold with ρ-probability 1:
(i) For every T ∈ N we have
lim

sup

n→∞ |b −b |≥αn
2
1

(ii) lim

sup

n→∞ |b −b |≥αn
2
1

X

|ν(Xb1 ..b2 , B) − ρ(B)| = 0.

B∈B m,l ,
m,l∈1..T

produced by a consistent list-estimator Υ(x, λ), (see Definition 3), there exists an index-set I := {µ1 , . . . , µκ } ∈
{1..|Υ|}κ and some N0 such that for all n ≥ N0 we have
1
|ψµk − πk | ≤ ε.
n
k=1..κ
sup

Moreover, the initial candidates are at least nλ apart so that
inf
i∈1..|Υ|+1

K := argmax |{ψi−1 +1, . . . , ψi }∩{nθk−1 +1, . . . , nθk }|,
k∈Gr0

where Gj , j = 1..r are given by (6).
Lemma 2. Let x ∈ X n , n ∈ N be a sequence with
κ change points with minimum separation λmin for some
λmin ∈ (0, 1). Assume that the distributions that generate
x are stationary and ergodic. Let S be the set of segments
specified by (9) in Algorithm 1. For all λ ∈ (0, λmin ) with
ˆ xi , ρei ) = 0.
probability 1 we have limn→∞ supxi ∈S d(e

(12)

S1 := {e
xi := Xψi−1 +1..ψi ∈ S : {i, i − 1} ∩ I = ∅}
the subset of the segments in S whose elements are formed
by joining pairs of consecutive elements of I 0 and let
S2 := S \ S1 be its complement. Let the true change points
that appear immediately to the left and to the right of an
index j ∈ 1..n − 1 be given by L(j) := maxk∈0..κ+1 πk ≤
j and R(j) := mink∈0..κ+1 πk > j respectively, with
π0 := 0, πκ+1 := n where equality occurs when j is
itself a change point. We have two cases. 1. Consider
x
ei := Xψi−1 +1..ψi ∈ S1 . By definition, x
ei cannot contain a true change point for n ≥ N0 since otherwise, either
i − 1 or i would belong to I contradicting the assumption that x
ei ∈ S1 . Therefore, for all n ≥ N0 we have
ρei = ρ where ρ ∈ {ρ1 , . . . , ρr } is the process that generates XL(ψi−1 )..R(ψi−1 ) . By (12) and hence part (ii) of
Lemma 1, there exists some Ni ≥ N0 such that for all
ˆ xi , ρei ) := d(X
ˆ ψ ..ψ , ρ) ≤ ε. Let
n ≥ Ni we have d(e
i−1
i
0
N := maxi s.t. xe i ∈S1 Ni . For all n ≥ N 0 we have
ˆ xi , ρei ) ≤ ε.
sup d(e

(13)

x
ei ∈S1

2. Take x
ei := Xψi−1 ..ψi ∈ S2 . Observe that, by definition
I ∩ {i, i − 1} =
6 ∅ so that either i − 1 or i belong to
I. We prove the statement for the case where i − 1 ∈ I.
The case where i ∈ I is analogous. We start by showing
that [ψi−1 , ψi ] ⊆ [π − εn, π 0 + εn] for all n ≥ N0 where
π := argminπk ,k=1..κ n1 |πk −ψi−1 | and π 0 := R(π). Since
i−1 ∈ I, by (11) for all n ≥ N0 we have n1 |π −ψi−1 | ≤ ε.
We have two cases. Either i ∈ I so that by (11) for all
n ≥ N0 we have n1 |ψi − π 0 | ≤ ε, or i ∈ I 0 in which case
ψi < π 0 . To see the latter statement assume by way of
contradiction that ψi > π 0 where π 0 6= n; (the statement
trivially holds for π 0 = n). By the consistency of Υ(x, λ)
there exists some j > i − 1 ∈ I such that n1 |ψj − π 0 | ≤ ε
for all n ≥ N0 . Moreover, by (11) and (12) for all n ≥ N0
the candidates indexed by I 0 have linear distances from the
true change points, that is,
inf

k∈1..κ, i∈I 0

Proof. Fix an ε ∈ (0, λ/2). Define πk := bnθk c, k =
1..κ. Since the initial list Υ of change point candidates are

ψi − ψi−1 ≥ nλ

where ψ0 := 0 and ψ|Υ|+1 := n. Let I 0 := {1..|Υ|} \ I.
Denote by

ˆ b ..b , ρ) = 0.
d(X
1
2

We introduce the following additional notation. Consider
the set S of segments specified by Line (9) in Algorithm 1.
e i := Xψi−1 ..ψi ∈ S, i = 1..|Υ| + 1 define ρei as
For every x
the process distribution that generates the largest portion of
x
ei . That is, let ρei := ρj where j is such that K ∈ Gj with

(11)

≥

|πk − ψi |

inf

k∈1..κ, i∈I 0 ,j∈I

(14)

|ψi − ψj | − |πk − ψj | ≥ n(λ − ε).

Estimation of the number of change points in highly dependent time series

Thus, from (11) and (14) we obtain that ψi −ψj ≥ λ−2ε >
0. Since the initial estimates are sorted in increasing order,
this implies j ≤ i leading to a contradiction. Thus we
have [ψi−1 , ψi ] ⊆ [π − εn, π 0 + εn]. Therefore, ρei = ρ
where ρ is the process distribution ρ ∈ {ρ1 , . . . , ρr } that
ˆ xi , ρ) ≤ ε we proceed as
generates Xπ..π0 . To show that d(e
P∞
follows. There exists some T such that m,l=T wm wl ≤
ε. It is easy to see that by (14), and the assumption that
λ ∈ (0, λmin ], (where λmin is given by (7)), the segment
Xπ.. min{ψi ,π0 } has length at least nλ, i.e.
min{ψi , π 0 } − π ≥ nλ.
Therefore, by part (i) of Lemma 1, there exists some Ni ≥
N0 such that for all n ≥ Ni we have
T
X

X

wm wl

m,l=1

|ν(Xπ.. min{ψi ,π0 } , B) − ρ(B)| ≤ ε.

B∈B m,l

(15)
Using the definition of ν(·, ·) given by (1), for every B ∈
B m,l , m, l ∈ 1..T we have

point parameters. Here, the only important message is that,
for all n ≥ N1 the consistent estimates are somewhere
within the list Υ. That is for all n ≥ N1 there exists a
set of indices {µk : k = 1..κ} ⊆ 1..|Υ| such that
sup |θ̂µk − θk | ≤ ε.

(19)

k∈1..κ

Since there are a finite number of segments in the set
S (specified by (9) in Algorithm 1), by Lemma 2, there
exists some N2 such that for all n ≥ N2 we have
ˆ xi , ρei ) ≤ ε. Hence, applying the triangle insupxe i ∈S d(e
ˆ for all n ≥ N2 we have
equality on d,
sup
e i ,e
x
xj ∈S, ρ
ei =e
ρj

inf

e i ,e
x
xj ∈S, ρ
ei 6=ρ
ej

ˆ xi , x
e j ) ≤ 2ε.
d(e

(20)

ˆ xi , x
e j ) ≥ δ − 2ε.
d(e

(21)

By (20) and (21), for all n ≥ N2 , the segments x
ei , x
ei+1 ∈
S with ρei = ρei+1 are closer to each other (in the empirical
estimate of the distributional distance) than to the rest of
the segments. By (21) for all n ≥ N2 and every j ∈ 2..r
ˆ xi , x
e cj ) ≥ δ − 2ε where,
we have max minj 0 ∈2..j−1 d(e

m−1
)|ν(e
xi , B) − ρ(B)|
ψi − ψi−1
min{ψi , π 0 } − π − m + 1
i∈1..|S|
≤
|ν(Xπ.. min{ψi ,π0 } , B) − ρ(B)| as specified by Algorithm 1, c := 1 and c , j = 2..r are
1
j
ψi − ψi−1
given
by
(10).
Hence,
for
all
n
≥
N
,
the
cluster centres
0
0
2
I{ψi ≥ π }(ψi − π )
|ψi − π|
+
+
(16)
x
ecj , j = 1..r are each generated by a different process disψi − ψi−1
ψi − ψi−1
tribution. That is, ρecj 6= ρecj0 for j 6= j 0 ∈ 1..r. On the
other hand, the rest of the segments are each assigned to
Increase Ni if necessary
Pn to have T /(λNi ) ≤ ε, and let
the closest cluster, so that by (20) for all n ≥ N we have
n ≥ Ni . Recall that m,l=1 wm wl ≤ 1, and observe that
|ν(·, ·) − ρ(·)| ≤ 1. By (11), (12), (15) and (16) we have
T (e
xi ) = T (e
xi0 ) ⇔ ρei = ρei0 .
(22)
ˆ xi , ρei )
d(e

(1 −

≤

T
X
m,l=1

+

wm wl

X
B∈B m,l

(1 −

m−1
)|ν(e
xi , B) − ρ(B)|
ψi − ψi−1

m−1
+ ε ≤ 3ε(1 + 1/λ)
ψi − ψi−1

(17)

Let N 00 := maxi s.t. xe i ∈S2 . By (17) for all n ≥ N 00 we
have
ˆ xi , ρei ) ≤ 3ε(1 + 1/λ).
sup d(e
(18)
e i ∈S2
x

Finally, by (13) and (18) for all n ≥ max{N 0 , N 00 } we
ˆ xi , ρei ) ≤ 3ε(1 + 1/λ). Since the choice
have supxe i ∈S d(e
of ε is arbitrary, this proves the statement.
Proof of Theorem 1. Let δ := mini6=j∈1..r d(ρi , ρj ) denote the minimum distance between the distinct distributions that generate x. Fix an ε ∈ (0, δ/4). Recall that the
list-estimator Υ(x, λ) is consistent for all λ ∈ (0, λmin ]
(see Definition 3). Therefore, there exists some N1 such
that for all n ≥ N1 the first κ elements of the list of candidate estimates that it produces, converge to the true change

Let N := max Ni , i = 1, 2. It remains to show that for
all n ≥ N , all of the redundant estimates namely, θ̂i , i 6=
µk , k = 1..κ are removed in the last step of the algorithm,
so that for all n ≥ N there exists an index i ∈ 1..|Υ| in C, if
and only if it corresponds to a consistent estimate in Υ. To
this end, we note that by (19) and (22) for all n ≥ N and all
i ∈ C we have ρei 6= ρei+1 so that C = {µk : k = 1..κ} for
all n ≥ N . By (19) and noting that κ̂ := |C| the statement
follows.
Acknowledgments
This work is supported by the French Ministry of Higher
Education and Research, by FP7/2007-2013 under grant
agreements 270327 (CompLACS) and 216886 (PASCAL2), by the French National Research Agency (project Lampada ANR-09-EMER-007), by the Nord-Pas-de-Calais Regional Council and FEDER through CPER 2007-2013, and
by an INRIA Ph.D. grant to Azadeh Khaleghi. Most of the
work has been done while Azadeh Khaleghi was a PhD student at INRIA Lille - Nord Europe.

Estimation of the number of change points in highly dependent time series

References
Basseville, M. and Nikiforov, I.V. Detection of abrupt
changes: theory and application. Prentice Hall information and system sciences series. Prentice Hall, 1993.
Brodsky, B.E. and Darkhovsky, B.S. Nonparametric methods in change point problems. Mathematics and its applications. Kluwer Academic Publishers, 1993.
Carlstein, E. and Lele, S. Nonparametric change point estimation for data from an ergodic sequence. Teor. Veroyatnost. i Primenen., 38:910–917, 1993.
Csiszar, I. and Shields, P.C. Notes on information theory
and statistics. In Foundations and Trends in Communications and Information Theory, 2004.
Csörgö, Miklós and Horváth, Lajos. Limit Theorems in
Change-Point Analysis (Wiley Series in Probability &
Statistics). Wiley, January 1998.
Giraitis, L, Leipus, R, and Surgailis, D. The change point
problem for dependent observations. JStat Plan and Infer, pp. 1–15, 1995.
Gray, R. Probability, Random Processes, and Ergodic
Properties. Springer Verlag, 1988.
Khaleghi, A. and Ryabko, D. Locating changes in highlydependent data with unknown number of change points.
In Neural Information Processing Systems (NIPS), Lake
Tahoe, Nevada, United States, 2012.
Khaleghi, A. and Ryabko, D. Nonparametric multiple
change point estimation in highly dependent time series.
In ALT’13, Singapore, 2013. Springer.
Khaleghi, A., Ryabko, D., Mary, J., and Preux, P. Online
clustering of processes. In AI & Stats, pp. 601–609, La
Palma, Canary Islands, 2012.
Lavielle, M. Using penalized contrasts for the change point
problem. Signal Processing, 85(8):1501 – 1510, 2005.
Lavielle, Marc. Detection of multiple changes in a sequence of dependent variables. Stochastic Processes and
their Applications, 83(1):79–102, 1999.
Lavielle, Marc and Teyssiere, Gilles. Adaptive detection of
multiple change points in asset price volatility. In Long
memory in economics, pp. 129–156. Springer, 2007.
Lebarbier, E. Detecting multiple change points in the mean
of gaussian process by model selection. Signal Processing, 85(4):717 – 736, 2005.
Ryabko, D. Clustering processes. In ICML 2010, pp. 919–
926, Haifa, Israel, 2010a.

Ryabko, D. Discrimination between B-processes is impossible. Journal of Theoretical Probability, 23(2):565–
575, 2010b.
Ryabko, D and Mary, J. Reducing statistical time series
problems to binary classification. In NIPS, pp. 2069–
2077, United States, 2012.
Ryabko, D. and Ryabko, B. Nonparametric statistical inference for ergodic processes. IEEE Trans. on Info. Theory,
56(3):1430–1435, 2010.
Shields, P. The Ergodic Theory of Discrete Sample Paths.
AMS Bookstore, 1996.

