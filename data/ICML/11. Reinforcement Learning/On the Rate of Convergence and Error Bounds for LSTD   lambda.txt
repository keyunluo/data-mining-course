On the Rate of Convergence and Error Bounds for LSTD(λ)

Manel Tagorti
Bruno Scherrer
Inria, Villers-lès-Nancy, F-54600, France
Université de Lorraine, LORIA, UMR 7503, Vandœuvre-lès-Nancy, F-54506, France

Abstract
We consider LSTD(λ), the least-squares
temporal-difference algorithm with eligibility
traces algorithm proposed by Boyan (2002). It
computes a linear approximation of the value
function of a fixed policy in a large Markov
Decision Process. Under a β-mixing assumption, we derive, for any value of λ ∈ (0, 1), a
high-probability bound on the rate of convergence of this algorithm to its limit. We deduce
a high-probability bound on the error of this
algorithm, that extends (and slightly improves)
that derived by Lazaric et al. (2012) in the
specific case where λ = 0. In the context
of temporal-difference algorithms with value
function approximation, this analysis is to our
knowledge the first to provide insight on the
choice of the eligibility-trace parameter λ with
respect to the approximation quality of the space
and the number of samples.

1. Introduction
In a large Markov Decision Process context, we consider
LSTD(λ), the least-squares temporal-difference algorithm
with eligibility traces proposed by Boyan (2002). It is a
popular algorithm for performing a projection onto a linear space of the value function of a fixed policy. Such a
value estimation procedure can for instance be useful in a
policy iteration context to eventually estimate an approximately optimal controller (Bertsekas & Tsitsiklis, 1996;
Szepesvári, 2010).
The asymptotic almost sure convergence of LSTD(λ) was
proved by Nedic & Bertsekas (2002). Under a β-mixing assumption, and given a finite number of samples n, Lazaric
et al. (2012) derived a high-probability error bound with a
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

MANEL . TAGORTI @ INRIA . FR
BRUNO . SCHERRER @ INRIA . FR

Õ( √1n ) rate1 in the restricted situation where λ = 0. Pires
& Szepesvári (2012) also sketch an analysis of variations
of LSTD(0) with several sorts of regularizations. To our
knowledge, however, similar finite-sample error bounds are
not known in the literature for λ > 0. The main goal of
this paper is to fill this gap. This is all the more important that it is known that the parameter λ allows to control the quality of the asymptotic solution of the value: by
moving λ from 0 to 1, one can continuously move from
an oblique projection of the value (Scherrer, 2010) to its
orthogonal projection and consequently improve the corresponding guarantee (Tsitsiklis & Roy, 1997) (restated in
Theorem 2, Section 3).
The paper is organized as follows. Section 2 starts by describing the necessary background. Section 3 then contains our main results. Theorem 1 shows that unpenalized
LSTD(λ) converges to its limit at the rate Õ( √1n ). We then
deduce a global error (Corollary 1) that sheds some light on
the role of the parameter λ, and discuss some of its practical consequences. Theorem 3 then extends this result to
the case of penalized LSTD(λ). Section 4 will go on by
providing a detailed proof of our claims. Finally, Section 5
concludes by describing related and potential future work.

2. LSTD(λ) and Related Background
We consider a Markov chain taking its values on a finite or
countable state space X , with transition kernel P , and that
is ergodic2 ; consequently, it admits a unique stationary distribution µ. For any K ∈ R+ , we denote B(X , K) the set
of functions defined on X and bounded by K. We consider
a reward function r ∈ B(X , Rmax ) for some Rmax ∈ R, that
provides the quality of being in some state. The value function v related to the Markov chain is defined, for any state
i, as the average discounted sum of rewards along infinitely
1

Throughout the paper, we shall write f (n) = Õ(g(n)) as a
shorthand for f (n) = O(g(n) logk g(n)) for some k ≥ 0.
2
We focus on finite/countable state spaces essentially because
it eases the presentation. We believe that extensions to more general state spaces is straight-forward.

On the Rate of Convergence and Error Bounds for LSTD(λ)

long trajectories starting from i:


∞
X

∀i ∈ X , v(i) = E 
γ j r(Xj )X0 = i ,

seen that θ is a solution of the equation Aθ = b (Tsitsiklis
& Roy, 1997; Nedic & Bertsekas, 2002) where for any i,

j=0

where γ ∈ (0, 1) is a discount factor. It is well-known
that the value function v is the unique fixed point of
the linear Bellman operator T : ∀i ∈ X , T v(i) =
r(i) + γE [v(X1 )|X0 = i] . It can easily be seen that v ∈
max
B(X , Vmax ) with Vmax = R
1−γ .
When the size |X | of the state space is very large, one may
consider approximating v by using a linear architecture.
Given some d (typically d  |X |), we consider a feature
matrix Φ = (φ(x))x∈X = (φ1 . . . φd ) of dimension |X | ×
d. For any x ∈ X , φ(x) = (φ1 (x), ..., φd (x))T is the
feature vector in state x. For any j ∈ {1, ..., d}, we assume
that the feature function φj : X 7→ R belongs to B(X , L)
for some finite L. Throughout the paper, we will make the
following assumption.
Assumption 1. The feature vectors (φj )j∈{1,...,d} are linearly independent.
Let S be the subspace generated by the vectors (φj )1≤j≤d .
We consider the orthogonal projection Π onto S with
respect
to the µ-weighed quadratic norm kf kµ =
p
P
2
x∈X f (x) µ(x). It is well known that this projection
has the following closed form
Π = Φ(ΦT Dµ Φ)−1 ΦT Dµ ,

A = ΦT Dµ (I − γP )(I − λγP )−1 Φ
(3)
" i
#
X
=E
(γλ)i−k φ(Xk )(φ(Xi ) − γφ(Xi+1 ))T
k=−∞

(4)
and b = ΦT Dµ (I − γλP )−1 r
" i
#
X
i−k
=E
(γλ) φ(Xk )r(Xi ) ,

where the sum starts from −∞ to ensure that the process
(Xk ) is in stationary regime. Since for all x, φ(x) is of
dimension d, we see that A is a d × d matrix and b is a
vector of size d. Under Assumption 1, it can be shown
(Nedic & Bertsekas, 2002) that the matrix A is invertible,
and thus vLST D(λ) = ΦA−1 b is well defined.
The LSTD(λ) algorithm that is the focus of this article is
now precisely described. Given one trajectory X1 , ...., Xn
generated by the Markov chain, the expectation-based expressions of A and b in Equations (4)-(5) suggest to compute the following estimates:
Â =

(1)

and b̂ =

where Dµ is the diagonal matrix with elements of µ on the
diagonal, and for all u, uT denotes the transpose of u.

where zi =

The goal of LSTD(λ) is to estimate a solution of the equation v = ΠT λ v, where the operator T λ is defined as a
geometric average of the applications of the powers T i of
the Bellman operator T for all i > 1:
∀λ ∈ (0, 1), ∀v, T λ v = (1 − λ)

∞
X

λi T i+1 v.

(2)

i=0

Note in particular that when λ = 0, one has T λ = T .
By using the facts that T i is affine and kP kµ = 1 (Tsitsiklis & Roy, 1997), it has been shown that the operator T λ is a contraction mapping of modulus (1−λ)γ
1−λγ ≤ γ
(Nedic & Bertsekas, 2002). Since the orthogonal projector Π is non-expansive with respect to µ (Tsitsiklis & Roy,
1997), the operator ΠT λ is contracting and thus the equation v = ΠT λ v has one and only one solution, which
we shall denote vLST D(λ) since it is what the LSTD(λ)
algorithm converges to (Nedic & Bertsekas, 2002). As
vLST D(λ) belongs to the subspace S, there exists a θ ∈ Rd
such that vLST D(λ) = Φθ = ΠT λ Φθ. If we replace Π and
T λ with their expressions (Equations 1 and 2), it can be

(5)

k=−∞

n−1
1 X
zi (φ(Xi ) − γφ(Xi+1 ))T
n − 1 i=1
n−1
1 X
zi r(Xi )
n − 1 i=1
i
X

(λγ)i−k φ(Xk )

(6)

k=1

is the so-called eligibility trace. The algorithm then returns
v̂LST D(λ) = Φθ̂ with3 θ̂ = Â−1 b̂, which is a (finite sample)
approximation of vLST D(λ) . Using a variation of the law
of large numbers, Nedic & Bertsekas (2002) showed that
both Â and b̂ converge almost surely respectively to A and
b, which implies that v̂LST D(λ) tends to vLST D(λ) . The
main goal of this paper is to deepen this analysis: we shall
estimate a bound on the rate of convergence of v̂LST D(λ)
to vLST D(λ) , and bound the error kv̂LST D(λ) − vkµ of the
overall algorithm.

3. Main result
This section contains our main results. Our key assumption for the analysis is that the Markov chain process that
generates the states has some mixing property4 .
3
We will see in Theorem 1 that Â is invertible with high probability for a sufficiently big n.
4
A Markov chain that is ergodic and stationary is always βmixing (Bradley, 2005).

On the Rate of Convergence and Error Bounds for LSTD(λ)

Assumption 2. The process (Xn )n≥1 is βth
mixing, in
h the sense that its i coefficienti βi =
t
supt≥1 E supB∈σ(Xt+i
∞ ) |P (B|σ(X1 )) − P (B)| tends to
0 when i tends to infinity, where Xlj = {Xl , ..., Xj } for
j ≥ l and σ(Xlj ) is the sigma algebra generated by Xlj .
Furthermore, (Xn )n≥1 mixes at an exponential decay rate
with parameters β > 0, b > 0, and κ > 0 in the sense that
κ
βi ≤ βe−bi .
Intuitively the βi coefficients measure the degree of dependence of samples separated by i time steps (the smaller the
coefficient the more independence). We are now ready to
state the main results of the paper, which provides a rate of
convergence of LSTD(λ).
Theorem 1. Let Assumptions 1 and 2 hold and let
X1 ∼ µ, where µ is the stationary distribution of
the chain. For any n ≥ 1 and δ ∈ (0, 1), define
o κ1
n
,
1
, where Λ(n, δ) =
I(n, δ) = 32Λ(n, δ) max Λ(n,δ)
b
 2
log 8nδ + log(max{4e2 , nβ}). Also define the positive
l
m
integer mλn = log(n−1)
. Let n0 (δ) be the smallest inte1
log
λγ

ger such that for all n ≥ n0 (δ),
2dL2
(1 − γ)ν



2 p λ
√
(mn + 1)I(n − 1, δ)+
n−1

2
1
+
mλn < 1
(n − 1)(1 − λγ)
(n − 1)

(7)

where ν is the smallest eigenvalue of the Gram matrix ΦT Dµ Φ. Then, for all δ, with probability at least
1 − δ, for all n ≥ n0 (δ), Â is invertible and the distance
kvLST D(λ) − v̂LST D(λ) kµ is upper bounded by
√

4Vmax dL2
n − 1(1 − γ)ν

q

(mλn + 1) I(n − 1, δ) + h(n, δ)

with h(n, δ) = Õ( n1 log 1δ ).
The constant ν is positive under Assumption 1. For all δ, it
is clear that the finite constant n0 (δ) exists since the l.h.s.
of Equation (7) tends to 0 when n tends to infinity. As
mλn and I(n − 1, δ) are of order Õ(1), we
 see that
 can
LSTD(λ) estimates vLST D(λ) at a rate Õ

√1
n

. Finally,

mλn

we can observe that since λ 7→
is increasing, the rate of
convergence deteriorates when λ increases. This negative
effect can be balanced by the fact that, as shown by the
following result from the literature, the quality of vLST D(λ)
improves when λ increases.
Theorem 2 (Tsitsiklis & Roy (1997)). The approximation
error satisfies
kv − vLST D(λ) kµ ≤

1 − λγ
kv − Πvkµ .
1−γ

Since the constant equals 1 when λ = 1, one recovers
the well-known fact that LSTD(1) computes the orthogonal projection Πv of v. By using the triangle inequality,
one deduces from Theorems 1 and 2 the following global
error bound.
Corollary 1. Let the assumptions and notations of Theorem 1 hold. For all δ, with probability at least 1 − δ, for all
n ≥ n0 (δ), the global error of LSTD(λ) satisfies:
kv − v̂LST D(λ) kµ ≤
+√

4Vmax dL2
n − 1(1 − γ)ν

1 − λγ
kv − Πvkµ
1−γ
q
(mλn + 1) I(n − 1, δ) + h(n, δ).

The bound requires a sufficiently large number of samples n (n ≥ n0 (δ)). For a fixed δ, this number increases
when λ increases. The existence of such a condition is not
surprising since we focus on an unregularized version of
LSTD(λ), and thus the estimated matrix Â may not be invertible when n is too small.
As we have already mentioned, λ = 1 minimizes the bound
on the approximation error kv − vLST D(λ) kµ (the first term
in the r.h.s. in Corollary 1) while λ = 0 minimizes the
bound on the estimation error kvLST D(λ) − v̂LST D(λ) kµ
(the second term). For any δ and n ≥ n0 (δ), there exists a value λ∗ that minimizes the global error bound by
making an optimal compromise between the approximation
and estimation errors upper-bounds. When the number of
samples n tend to infinity, the optimal value λ∗ tends to
1. Previous studies on the role of the parameter λ were to
our knowledge empirical (Sutton & Barto, 1998; Downey
& Sanner, 2010) or dedicated to an exact representation of
the value function (Kearns & Singh, 2000). This is the first
time a bound on a temporal-difference learning algorithm
with value function approximation shows this trade-off explicitely.
The form of the result stated in Corollary 1 is slightly
stronger than the one of Lazaric et al. (2012). It has the
advantage to make clear the connection with the previous
analysis of Nedic & Bertsekas (2002) since our formulation implies the almost sure convergence of v̂LST D(λ) to
vLST D(λ) : for some property P (n), our result is of the
form “∀δ, ∃n0 (δ), such that with probability at least 1 −
δ, ∀n ≥ n0 (δ), P (n) holds” while the result
stated by (Lazaric et al., 2012) is of the form
“∀n, ∃δ(n), such that with probability at least 1 −
δ(n), P (n) holds.” In other words, we can fix a real δ such
that the property is true for all n ≥ n0 (δ) with probability
at least 1 − δ, while in (Lazaric et al., 2012), δ depends on
the number of samples.
Pires & Szepesvári (2012) studied penalized versions of
linear systems estimated with noise, and explained how

On the Rate of Convergence and Error Bounds for LSTD(λ)

to apply their approach to LSTD(0). Such a penalization
allows to control the magnitude of θ̂ in situations where
the matrix Â is (close to) singular. This has the advantage of removing the need for a condition on the number
of samples to ensure the invertibility of Â, and as a side
effect this allows to derive bounds that are valid for any
value of the probability threshold δ and number of samples n (while in the above mentionned result without penalization, the minimum number of samples n0 (δ) grows
to infinity when δ approaches 0). The most natural penalization that one would like to consider for LSTD(λ) is the
one where we add a term ρI to the estimate Â (Nedic &
Bertsekas, 2002). This amounts tonsolve the following peo
nalized problem: θ̂ρ = arg minθ kÂθ − b̂k22 + ρkθk22 .
Unfortunately, this very form of regularization—squared
error with squared penalty—is not considered by Pires &
Szepesvári (2012). It turns out that it is rather straightforward to bound the residual kAθ̂ρ −bk2 in this case by following an approach very similar to that described in Pires &
Szepesvári (2012). Combined with the analyisis performed
for Theorem 1, we can derive the following result.
Theorem 3. Under Assumptions 1 and 2, for any δ ∈ (0, 1)
ρn,δ
and n consider the estimate v̂LST
D(λ) = Φθ̂ρ obtained
with penalization parameter ρn,δ = 2Ξ2 (n, δ) s.t.
4dL2
√
Ξ(n, δ) =
(1 − λγ) n − 1

s

2



(mn
λ + 1)I
2

n − 1,


2n2 δ
+
3

mλn

2dL
4dL
.
+
(n − 1)(1 − λγ)2
(n − 1)(1 − λγ)
ρn,δ
Then, with probability at least 1−δ, for all n, kv̂LST
D(λ) −

vLST D(λ) kµ is bounded by
√
√
q
4Vmax dL(3 + dL)
√
(mλn + 1) I(n − 1, δ) + g(n, δ),
√
n − 1(1 − γ) ν
where g(n, δ) and I(n, δ) and mλn are defined as in Theorem 1.
We defer the proof to Appendix B of the supplementary
material.

4. Proof of Theorem 1
This section provides a detailed proof of Theorem 1. The
proof is organized in four steps. In the first step, we study
the sensitivity of the solution vLST D(λ) to a potential deterministic deviation of the estimates Â and b̂ from their
limits A and b. In the second step, we shall derive a general concentration analysis to control with high probability
the deviations of processes defined through infinitely-long
eligibility traces. Then, in the third step, we will apply this
concentration analysis to Â and b̂. Finally, we will gather
all elements to deduce the high-probability bound on the
distance between v̂LST D(λ) and vLST D(λ) .

4.1. Deterministic sensivity of LSTD(λ)
We begin by showing the following lemma on the sensitivity of LSTD(λ).
Lemma 1. Write A = Â−A, b = b̂−b and ν the smallest
eigenvalue of the matrix ΦT Dµ Φ. For all λ ∈ (0, 1), the
error kvLST D(λ) − v̂LST D(λ) kµ is upper bounded by5 :
1 − λγ
√ k(I + A A−1 )−1 k2 kA θ − b k2 ,
(1 − γ) ν
where θ = A−1 b. Furthermore, if for some  and C,
1
kA k2 ≤  < C ≤ kA−1
k2 , then Â is invertible and
k(I + A A−1 )−1 k2 ≤

1
.
1 − C

Proof. The definitions of vLST D(λ) and v̂LST D(λ) lead to
v̂LST D(λ) − vLST D(λ) = ΦA−1 (Aθ̂ − b).

(8)

On the one hand, with the expression of A in Equation (3),
writing M = (1 − λ)γP (I − λγP )−1 and Mµ = ΦT Dµ Φ,
we can see that

−1
ΦA−1 = Φ ΦT Dµ (I − γP )(I − λγP )−1 Φ

−1
= Φ ΦT Dµ (I − λγP − (1 − λ)γP )(I − λγP )−1 Φ
= Φ(Mµ − ΦT Dµ M Φ)−1 .
Since the matrices A and Mµ are invertible, the matrix (I −
Mµ−1 ΦT Dµ M Φ) is also invertible and
ΦA−1 = Φ(I − Mµ−1 ΦT Dµ M Φ)−1 Mµ−1 .
By definition, the projection matrix Π defined in Equation (1) satisfies kΠkµ = 1 and we know from Tsitsiklis &
Roy (1997) that the stochastic matrix P of the process also
satisfies kP kµ = 1. Hence, we have kΠM kµ = (1−λ)γ
1−λγ <
1 and the matrix (I − ΠM ) is invertible. We can use the
identity X(I − Y X)−1 = (I − XY )−1 X with X = Φ and
Y = Mµ−1 ΦT Dµ M , and obtain
ΦA−1 = (I − ΠM )−1 ΦMµ−1 .

(9)

On the other hand, using the facts that Aθ = b and Âθ̂ = b̂,
we can see that
Aθ̂ − b = Aθ̂ − b − (Âθ̂ − b̂)
= b̂ − b − (Â − A)(θ̂ − θ) − (Â − A)θ
= b̂ − Âθ − (b − Aθ) + A A−1 (Aθ − Aθ̂)
= b̂ − Âθ − A A−1 (Aθ̂ − b)
= (I + A A−1 )−1 (b̂ − Âθ)
= (I + A A−1 )−1 (b − A θ).

(10)

5
When Â is not invertible, we have v̂LST D(λ) = ∞ and the
inequality is always satisfied since, as we will see shortly, the
invertiblity of Â is equivalent to that of (I + A A−1 ).

On the Rate of Convergence and Error Bounds for LSTD(λ)

Using Equations (9) and (10), Equation (8) can be rewritten
as follows:
v̂LST D(λ) − vLST D(λ)
= (I − ΠM )−1 ΦMµ−1 (I + A A−1 )−1 (b − A θ). (11)
We shall now bound kΦMµ−1 (I + A A−1 )−1 (b − A θ)kµ .
Notice that for all x,
q
kΦMµ−1 xkµ = xT Mµ−1 ΦT Dµ ΦMµ−1 x
q
1
(12)
= xT Mµ−1 x ≤ √ kxk2
ν
where ν is the smallest (real) eigenvalue of the Gram matrix
Mµ . By taking the norm in Equation (11) and using the
above relation, we get

4.2. Concentration inequality for infinitely-long
trace-based estimates
As both terms Â and b̂ have the same structure, we will
consider here a matrix that has the following general form:
Ĝ =

n−1
1 X
Gi with Gi = zi (τ (Xi , Xi+1 ))T
n − 1 i=1

where zi is the trace defined in Equation (6) and τ : X 2 →
Rk . Let k.kF denote the Frobenius norm satisfying: for
Pd Pk
2
M ∈ Rd×k , kM k2F =
l=1
j=1 (Ml,j ) . The second important element of our analysis is the following concentration inequality for the infinitely-long-trace β-mixing
process Ĝ.
Lemma 2. Let Assumptions 1 and 2 hold and let X1 ∼ µ.
Define the d × k matrix Gi such that

kv̂LST D(λ) − vLST D(λ) kµ
≤ k(I − ΠM )

−1

kµ kΦMµ−1 (I

+ A A

−1 −1

)

(b − A θ)kµ

1
≤ k(I − ΠM )−1 kµ √ k(I + A A−1 )−1 k2 kA θ − b k2 .
ν
The first part of the lemma is obtained by using the fact that
kΠM kµ = (1−λ)γ
1−λγ < 1, which implies that
−1

k(I − ΠM )


∞
∞

X
X

i
kΠM kiµ
(ΠM )  ≤
kµ = 


i=0

≤

1−

i=0

µ

1
(1−λ)γ
1−λγ

1 − λγ
=
.
1−γ

(13)

We are going now to prove the second part of the lemma.
Since A is invertible, the matrix Â is invertible if and only
if the matrix ÂA−1 = (A + A )A−1 = I + A A−1 is invertible. Let us denote ρ(A A−1 ) the spectral radius of
the matrix A A−1 . A sufficient condition for ÂA−1 to
be invertible is that ρ(A A−1 ) < 1. From the inequality
ρ(M ) ≤ kM k2 for any square matrix M , we can see that
1
for any C and  that satisfy kA k2 ≤  < C < kA−1
k2 ,
ρ(A A−1 ) ≤ kA A−1 k2 ≤ kA k2 kA−1 k2 ≤


< 1.
C

It follows that the matrix Â is invertible and


∞
∞  i
X

X


−1 −1
−1 i 
k(I + A A ) k2 =  (A A )  ≤


C
i=0

2

Gi =

i
X

(λγ)i−l φ(Xl )(τ (Xi , Xi+1 ))T .

(14)

l=1

Recall that φ = (φ1 , . . . , φd ) is such that for all j, φj ∈
B(X , L). Assume that for all 1 ≤ j ≤ d, τj ∈ B(X 2 , L0 ).
Let mλn and I(n, δ) be defined as in Theorem 1. Let
J(n, δ) = I(n, 4n2 δ). Then, for all δ in (0, 1), with probability at least 1 − δ,


n−1

 1 n−1
X
1 X


Gi −
E[Gi ]


n − 1
n
−
1
i=1
i=1
2
√
q
2 d × kLL0
√
≤
(mλn + 1) J(n − 1, δ) + (n),
(1 − λγ) n − 1
√

0

d×kLL
where (n) = 2mλn (n−1)(1−λγ)
.

Proof. The proof of this result is tedious, so we only give
a sketch and defer the details to Appendix A in the Supplementary material. There are two main difficulties regarding the estimates Gi used to compute Ĝ: 1) Gi is a
σ(X i+1 ) measurable function of the non-stationary vector
(X1 , . . . , Xi+1 ), and is consequently not stationary; 2) For
all i, Gi are computed from one single trajectory of the
Markov chain and are consequently mutually dependent.
To deal with the first issue (non-stationarity), we shall consider the m-truncated trace,
zim =

i=0

i
X

(λγ)i−k φ(Xk ),

k=max(i−m+1,1)

This concludes the proof of Lemma 1.
and approximate Ĝ with the process Ĝm defined as:
Lemma 1 suggests that we control both terms kA k2 =
kÂ − Ak2 and kb k2 = kb̂ − bk2 . The next subsection
shows how to do so with high probability.

Ĝm =

n−1
1 X m
m
T
G , with Gm
i = zi (τ (Xi , Xi+1 )) .
n − 1 i=1 i

On the Rate of Convergence and Error Bounds for LSTD(λ)
m+1
) measurable function of the
Indeed, Gm
i is now a σ(X
stationary vector Zi = (Xi−m+1 , Xi−m+2 , . . . , Xi+1 ),
the vector Zi being stationary since we assumed X1 ∼ µ.

To deal with the second issue (dependence of samples), for
any possible value of the truncation depth m, we shall use
the β-mixing assumption (Assumption 2) to transform the
dependent samples Gm
i into blocks of independent samples, by using the “blocking technique” of Yu (1994) in a
way somewhat similar to—but technically slightly more involved than—what Lazaric et al. (2012) did for LSTD(0).
This being done, we will be able to use a concentration inequality for i.i.d. processes from the literature (Lemma 7
in Appendix A in the Supplementary material). In addition to the use of a truncation depth m, a specific ingredient of the analysis of LSTD(λ) with respect to that
of LSTD(0) is that we need to prove that the stationary
process (Zi )i≥1 = (Xi−m+1 , Xi−m+2 , . . . , Xi+1 )i≥1 on
which the m-truncated process Gm
i is defined, inherits the
β-mixing property of the original process (Xi )i≥1 . This is
the purpose of the following technical lemma.
Lemma 3. Let (Xn )n≥1 be a β-mixing process, then
(Zn )n≥m = (Xn−m+1 , Xn−m+2 , . . . , Xn+1 )n≥m is a βmixing process such that its ith β mixing coefficient βiZ
X
satisfies βiZ ≤ βi−m
.

4.3. Bounding the deviations of Â and b̂
We shall now apply the concentration inequality of
Lemma 2 on the quantities of interest of Lemma 1, i.e. on
kA k2 and kA θ − b k2 .
Bounding kA k2 . By the triangle inequality, we have
kA k2 ≤ kE[A ]k2 + kA − E[A ]k2 .

(15)

Write Ân,k = φ(Xk )(φ(Xn ) − γφ(Xn+1 ))T . For all n
and k, we have: kÂn,k k2 ≤ 2dL2 . We can bound the first
term of the r.h.s. of Equation (15) by replacing A with its
expression in Equation (4):

"
#
n−1 i


1 XX


i−k
(λγ) Âi,k 
kE[A ]k2 = A − E


n − 1 i=1
k=1
2
 "
!#
n−1
i
i


X
X
X
1


i−k
i−k
= E
(λγ) Âi,k −
(λγ) Âi,k 


n − 1 i=1
k=−∞
k=1
2
 "
#
n−1
0


X
X
1


(λγ)−k Âi,k 
(λγ)i
= E


n−1
i=1

≤

1
n−1

n−1
X

(λγ)i

i=1

k=−∞

2

2

2

2dL
1
2dL
def
≤
= 0 (n).
1 − λγ
n − 1 (1 − λγ)2
(16)

Finally, setting m to mλn will ensure that the distance
between Ĝ and Ĝm is bounded by (n) (as defined in
Lemma 2), and is therefore neglibible with respect to the
result of the deviation analysis obtained by the “blocking
techinque” of (Yu, 1994).

Let (δn )n≥1 be a sequence in (0, 1) that we will set later.
4dL2
With (n) = (n−1)(1−λγ)
mλn (defined in Lemma 2) and
0 (n) defined in Equation (16), define:

Using a very similar proof, we may derive a (simpler and)
general-purpose concentration inequality for β-mixing processes:
Lemma 4. Let Y = (Y1 , . . . , Yn ) be random variables
taking their values in the space Rd , generated from a stationary exponentially β-mixing process with parameters β,
b and κ, and such that for all i, kYi − E[Yi ]k2 ≤ B2 almost
surely. Then for all δ > 0, with probability at least 1 − δ,


n
n
1 X

1X
B2 p


Yi −
E[Yi ] ≤ √
J(n, δ)

n

n i=1
n
i=1

(17)

2

where J(n, δ) is defined as in Lemma 2.
If the variables Yi were independent, we would have βi = 0
for all i, that is we could choose β = 0 and b = ∞, so that
2
J(n, δ) reduces to 32 log 8eδ = O(1) and we recover standard concentration results for i.i.d. processes (such as the
one we describe in Lemma 7 in Appendix A in the Supplementary material). The price to pay for making a β-mixing
assumption (instead of simple independence) lies in the extra coefficient J(n, δ) which is Õ(1); in other words, it is
rather mild.

1 (n, δn ) =

4dL2
√
(1 − λγ) n − 1
+ (n) + 0 (n).

q

(mλn + 1) J(n − 1, δn )

By using Equation (15), the bound of Equation (16) and
Lemma 2 applied to A , we get
P {kA k2 ≥ 1 (n, δn )}
≤ P{kA − E[A ]k2 ≥ 1 (n, δn ) − 0 (n)}
≤ δn .

(18)

Bounding kA θ−b k2 . By using the fact that Aθ = b, the
definitions of Â and b̂, and the fact that φ(x)T θ = [φθ](x),
we have
A θ − b = Âθ − b̂
=

n−1
n−1
1 X
1 X
zi (φ(Xi ) − γφ(Xi+1 )T )θ −
zi r(Xi )
n − 1 i=1
n − 1 i=1

=

n−1
1 X
zi ([φθ](Xi ) − γ[φθ](Xi+1 ) − r(Xi ))
n − 1 i=1

=

n−1
1 X
zi ∆ i
n − 1 i=1

On the Rate of Convergence and Error Bounds for LSTD(λ)

where, since vLST D(λ) = Φθ, ∆i is the following number:
∆i = vLST D(λ) (Xi ) − γvLST D(λ) (Xi+1 ) − r(Xi ).
Let L0 be a bound on max1≤i≤n−1 |∆i | (we shall compute
L0 below). We can control kA θ − b k2 by following the
same proof steps as above. In fact we can see that
kA θ − b k2 ≤ kA θ − b − E[A θ − b ]k2
+ kE[A θ − b ]k2 ,

(19)

Since ΦT Dµ Φ is a symmetric matrix, we have ν ≤
kΦT Dµ Φk2 .
We can see that kΦT Dµ Φk2
≤
1

and therefore we can take L0 = 2

with kE[A θ − b ]k2 ≤ kE[A ]k2 kθk2 + kE[b ]k2 .
From what has been developed before we can see that
1
2dL2
kE[A ]k2 ≤ 0 (n) = n−1
(1−λγ)2 . Similarly we can show
that kE[b ]k2 ≤

√
dLRmax
1
n−1 (1−λγ)2 .

We can hence conclude that

kE[A θ − b ]k2

√
dLRmax def 0
2dL2
1
1
kθk2 +
= 0 (n).
≤
2
n − 1 (1 − λγ)
n − 1 (1 − λγ)2
(20)

By using Equation (19), Equation (21) and Lemma 2 applied to a θ − b, we get
P(kA θ − b k2 ≥ 2 (n, δn ))
≤ P(kA θ − b − E[A θ − b ]k2 ≥ 2 (n, δn ) − 00 (n))
≤ δn .

(22)

To finish this third part of the proof, it remains to compute
the bound L0 on max1≤i≤n−1 |∆i |. To do so, it suffices to
bound vLST D(λ) (x) for all x. For all x ∈ X , we have
√
|vLST D(λ) (x)| = |φT (x)θ| ≤ kφT (x)k2 kθk2 ≤ dLkθk2 ,
where the first inequality is obtained from the CauchySchwarz inequality. It remains to bound kθk2p
. On the one
hand,
we
have:
kv
k
=
kΦθk
=
θ T Mµ θ ≥
µ
µ
LST
D(λ)
√
νkθk2 , and on the other hand, we have: kvLST D(λ) kµ =
max
k(I − ΠM )−1 Π(I − λγP )−1 rkµ ≤ R
1−γ = Vmax . Therefore kθk2 ≤ V√max
, and we can deduce that: ∀x ∈
ν
√

X , |vLST D(λ) (x)| ≤

dLV
√ max .
ν

Then, for all i we have

|∆i | = |vLST D(λ) (Xi ) − γvLST D(λ) (Xi+1 ) − r(Xi )|
√
√
dLVmax
dLVmax
√
≤
+γ √
+ (1 − γ)Vmax .
ν
ν

√
√dL Vmax .
ν

4.4. Conclusion of the proof
Now that we know how to control both terms kA k2 and
kA θ − b k2 , we are ready to conclude the proof. Consider
the event

E = ∃n ≥ 1, {kA k2 ≥ 1 (n, δn )}
	
∪ {kA θ − b )k2 ≥ 2 (n, δn )} .
Using the analysis of Section 4.3 and in particular Equations (18) and 22, we deduce that

2

4dL
mλn (defined in Lemma 2) and
With (n) = (n−1)(1−λγ)
0
0 (n) defined in Equation (20), define:
√
q
2 dLL0
√
2 (n, δn ) =
(mλn + 1) J(n − 1, δn )
(1 − λγ) n − 1
+ (n) + 00 (n).
(21)

1

d maxj,k |φTk Dµ φj | = d maxj,k |φTk Dµ2 Dµ2 φj | ≤
d maxj,k kφTk kµ kφj kµ ≤ dL2 , so that ν ≤ dL2 . It follows that, for all i
√
√
√
dLVmax
dLVmax
dL
√
+γ √
+ √ (1 − γ)Vmax ,
|∆i | ≤
ν
ν
ν

P(E) ≤

∞
X

P {kA k2 ≥ 1 (n, δn )}

n=1

+ P {kA θ − b )k2 ≥ 2 (n, δn )}
∞
1 π2
1X 1
δ=
δ<δ
≤2
δn =
2
2 n=1 n
2 6
n=1
∞
X

if on the last line we set δn = 4n1 2 δ. By the second part
of Lemma 1, for all δ, with probability at least 1 − δ, for
all n such that 1 (n, δn ) < C, where C is chosen such that
1
C ≤ kA−1
k2 , then Â is invertible and
2 (n, δn )
1 − λγ
√
(1 − γ) ν 1 − 1 (n,δn )
C


1 − λγ
1 (n, δn ) 2 (n, δn )
√ 2 (n, δn ) +
=
.
C − 1 (n, δn )
(1 − γ) ν

kvLST D(λ) − v̂LST D(λ) kµ ≤

The bound of the Theorem 1 is obtained by replacing
1 (n, δn ) and 2 (n, δn ) with their definitions in Equations (17) and (21), in particularly noticing that (n), 0 (n)
and 00 (n) are Õ( n1 ).
To fully complete the proof of Theorem 1, we finally need
1
to show how to pick C ≤ kA−1
k2 . We have ∀v ∈
p
√
d
−1
R , kΦA vkµ = (A−1 v)T Mµ A−1 v ≥ νkA−1 vk2 .
−1
−1
We know that kΦA vkµ = k(I − ΠM ) ΦMµ−1 vkµ ≤
1−λγ
√ kvk2 where the inequalities are respectively ob(1−γ) ν
tained from Equations (12) and (13). Therefore kA−1 k2 ≤
(1−γ)ν
1−λγ
(1−γ)ν , and consequently we can take C = 1−λγ . Note
that the condition 1 (n, δn ) < C for this choice of C is
equivalent to the one that characterizes the index n0 (δ) in
the theorem. This concludes the proof of Theorem 1.

On the Rate of Convergence and Error Bounds for LSTD(λ)

5. Summary, Related and Future Work
This paper provides high-probability bound on the convergence rate for the standard LSTD(λ) and a penalized variation, in terms of the number of samples n and the parameter λ. Theorems 1 and 3 show that this convergence is
at the rate of Õ( √1n ), in the case where the samples are
generated from a stationary β-mixing process. Our result
is based on two original technical contributions: a) a deterministic sensitivity analysis of LSTD(λ) (Lemma 1) and
b) an original vector concentration inequality (Lemma 2)
for estimates that are based on eligibility traces. A simplified version of the latter (Lemma 4) is a general-purpose
concentration inequality that may apply to general stationary beta-mixing processes, which may be useful in many
other contexts where we want to relax the i.i.d. hypothesis
on the samples. Corollary 1, which is an immediate consequence of Theorem 1, is to our knowledge the very first
analytical result that provides insight on the choice of the
eligibility-trace parameter λ of temporal-difference learning algorithm with respect to the approximation quality of
the space and the number of samples. Validating empirically the lessons that we can take from this result constitutes immediate interesting future work.
Under the same assumptions, the global error bound obtained by Lazaric et al. (2012) in the restricted case where
λ = 0 has the following form:
!
r
√
d log d
4 2
kv − Πvkµ + O
,
kṽLST D(0) − vkµ ≤
1−γ
νn
where ṽLST D(0) is the truncation with thresholds
{−Vmax , Vmax } of the estimate v̂LST D(0) . In our analysis,
we get for λ = 0:


d
1
√
kv − Πvkµ + Õ
kv̂LST D(0) − vkµ ≤
.
1−γ
ν n
On the one hand, the term √
corresponding to the approximation error is a factor 4 2 better with our analysis;
our bound is thus asymptotically better. Note that, contrary to our approach, the analysis of Lazaric et al. (2012)
does not imply a rate of convergence for LSTD(0) (a
bound on kvLST D(0) − v̂LST D(0) kµ ); their arguments,
based on a model of regression with Markov design, consists in directly bounding the global error. On the other
hand, our bound on the estimation error depends linearly
on the features space dimension d and on ν1 while the
one obtained by Lazaric
et al. (2012) takes the form of

p
O
d log d/(nν) . Thus our bound seems suboptimal
on d and ν. A technical element for explaining such a difference is the fact, mentionned above, that Lazaric et al.
(2012) consider the truncated version of vLST D(0) . Inp
deed, a close examination shows that the extra term d/ν
in our bound results from a bound (uniform on x) on
vLST D(λ) (x).

A critical condition in the analysis of LSTD(0) previously
done by Lazaric et al. (2012) is that the noise term in
the Markov Regression model is a Martingale difference
sequence with respect to the filtration generated by the
Markov chain. As soon as λ > 0, this property stops to
hold and it has not been clear how one may fix this issue.
We believe that the techniques we used for the proof of our
concentration inequality (Lemma 2)—the truncation of the
trace at some depth m and the focus on the “block” chain
(Zn ) = (Xi−m+1 , Xi−m , . . . , Xi+1 )—constitutes a potential track for addressing these issues. If successful, note
however that an extension to λ > 0 of the work of√Lazaric
et al. (2012) would still contain a suboptimal 4 2 extra
factor in the final bound.
Regarding the dependence with respect to the parameters
d and ν, it is worth mentionning that the bound obtained
by Pires & Szepesvári (2012) for a regularized version
of LSTD(0) depends also linearly √
on d and kθk2 (which
in turn can be bounded by Vmax / ν). In (Antos et al.,
2006) the bound does
 not
depend on ν but the convergence
1
4
rate is of order Õ 1/n
which is a slower rate than the
one we get. In the deterministic design and pure regression setting—pure regression corresponds to value function
learning with γ = 0—, the corresponding bound does not
also involve the parameter ν (Györfi et al., 2002). We do
not know whether one could have the√best of all worlds: the
best asymptotic bound without the 4 2 coefficient, and the
best rate with respect to n, d and ν. This constitutes interesting future work.
More generally, in the future, we plan to instantiate our new
bound in a Policy Iteration context like Lazaric et al. (2012)
did for LSTD(0). An interesting follow-up work would
also be to extend our analysis of LSTD(λ) to the situation
where one considers non-stationary policies, as Scherrer &
Lesner (2012) showed that it allows to improve the overall performance of the Policy Iteration Scheme. Finally, a
challenging problem would be to consider convergence rate
LSTD(λ) in the off-policy case, for which the convergence
has recently been proved by Yu (2010).
Acknowledgments. We thank the anonymous reviewers,
whose comments helped to improve the paper. This work
was supported by the French National Research Agency
(ANR) through the project BARQ.

References
Antos, András, Szepesvári, Csaba, and Munos, Rémi.
Learning near-optimal policies with bellman-residual
minimization based fitted policy iteration and a single
sample path. In In COLT-19, pp. 574–588. SpringerVerlag, 2006.
Bertsekas, Dimitri P. and Tsitsiklis, John N.

Neuro-

On the Rate of Convergence and Error Bounds for LSTD(λ)

Dynamic Programming. Athena Scientific, 1996.
Boyan, Justin A. Technical update: Least-squares temporal difference learning. Machine Learning, 49(2–3):233–
246, 2002. ISSN 0885-6125.
Bradley, Richard. Basic properties of strong mixing conditions. a survey and some open questions. Probability
Survey, 2:107–144, 2005.
Downey, Carlton and Sanner, Scott. Temporal difference
bayesian model averaging: A bayesian perspective on
adapting lambda. In Fürnkranz, Johannes and Joachims,
Thorsten (eds.), ICML, pp. 311–318. Omnipress, 2010.
Györfi, László, Kholer, Michael, Krzyzak, Adam, and
Walk, Harro. A Distribution-Free Theory of Nonparametric Regression. Springer-Verlag, New York, 2002.
Hayes, Thomas P. A large-deviation inequality for vectorvalued martingales, 2005. Technical report.
Kearns, M.J. and Singh, S.P. Bias-variance error bounds
for temporal difference updates. In Cesa-Bianchi, Nicolò
and Goldman, Sally A. (eds.), COLT, pp. 142–147. Morgan Kaufmann, 2000.
Lazaric, Alessandro, Ghavamzadeh, Mohammad, and
Munos, Rémi. Finite-sample analysis of least-squares
policy iteration. Journal of Machine Learning Research,
13:3041–3074, October 2012.
Nedic, Angelia and Bertsekas, Dimitri P. Least squares policy evaluation algorithms with linear function approximation. Theory and Applications, 13:79–110, 2002.
Pires, Bernardo A. and Szepesvári, Csaba. Statistical linear
estimation with penalized estimators: an application to
reinforcement learning. In ICML, pp. 1535–1542, 2012.
Scherrer, Bruno. Should one compute the temporal difference fix point or minimize the Bellman residual? the
unified oblique projection view. In ICML, pp. 959–966,
2010.
Scherrer, Bruno and Lesner, Boris. On the use of nonstationary policies for stationary infinite-horizon Markov
decision processes. In NIPS 2012 Adv.in Neural Information Processing, December 2012.
Sutton, Richard S. and Barto, Andrew G. Reinforcement
learning i: Introduction, 1998.
Szepesvári, Csaba. Algorithms for Reinforcement Learning. Morgan and Claypool, 2010.
Tsitsiklis, John N. and Roy, Benjamin Van. An analysis
of temporal-difference learning with function approximation. IEEE Transactions on Automatic Control, 42:
674–690, 1997.

Yu, Bin. Rates of convergence for empirical processes stationnary mixing sequences. The Annals of Probability,
22(1):94–116, January 1994.
Yu, Huizhen. Convergence of least-squares temporal difference methods under general conditions. In ICML, pp.
1207–1214, 2010.

