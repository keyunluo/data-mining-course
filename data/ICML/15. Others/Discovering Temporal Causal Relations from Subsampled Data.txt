Discovering Temporal Causal Relations from Subsampled Data

Mingming Gong∗1
MINGMING . GONG @ STUDENT. UTS . EDU . AU
Kun Zhang∗2,3
KZHANG @ TUEBINGEN . MPG . DE
Bernhard Schölkopf2
BS @ TUEBINGEN . MPG . DE
Dacheng Tao1
DACHENG . TAO @ UTS . EDU . AU
Philipp Geiger2
PGEIGER @ TUEBINGEN . MPG . DE
1
Centre for Quantum Computation and Intelligent Systems, FEIT, University of Technology, Sydney, NSW, Australia
2
Max Plank Institute for Intelligent Systems, Tübingen 72076, Germany
3
Information Sciences Institute, University of Southern California

Abstract
Granger causal analysis has been an important
tool for causal analysis for time series in various
fields, including neuroscience and economics,
and recently it has been extended to include instantaneous effects between the time series to
explain the contemporaneous dependence in the
residuals. In this paper, we assume that the time
series at the true causal frequency follow the vector autoregressive model. We show that when the
data resolution becomes lower due to subsampling, neither the original Granger causal analysis nor the extended one is able to discover the
underlying causal relations. We then aim to answer the following question: can we estimate
the temporal causal relations at the right causal
frequency from the subsampled data? Traditionally this suffers from the identifiability problems: under the Gaussianity assumption of the
data, the solutions are generally not unique. We
prove that, however, if the noise terms are nonGaussian, the underlying model for the highfrequency data is identifiable from subsampled
data under mild conditions. We then propose an
Expectation-Maximization (EM) approach and a
variational inference approach to recover temporal causal relations from such subsampled data.
Experimental results on both simulated and real
data are reported to illustrate the performance of
the proposed approaches.

Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s). * Equal contribution.

1. Introduction
Granger causal analysis (Granger, 1980) has been widely
used to find the temporal causal relations from time series. Time series x1 is said to cause times series x2 in the
Granger’s sense, if and only if the past and current values of
x1 contain useful information to predict the future values of
x2 that are not contained elsewhere.1 In practice, although
its nonlinear or nonparametric extensions exist, Granger
causal analysis usually assumes a linear model, and consequently, the Granger causal relations can be seen by fitting
the vector autoregressive (VAR) regression model (Sims,
1980). When using VAR to estimate temporal causal relations, one assumes that the data are obtained at the right
causal frequency, i.e., the VAR model serves as an approximator to the true data-generating process. However, in
practice the causal frequency is usually unknown, and the
data are available at some fixed frequency such as daily,
weekly, or monthly. As a consequence, the sampling frequency of the data is usually different from the true causal
frequency.
There are two typical aggregation schemes to generate lowresolution or low-frequency data from high frequency ones.
One is by subsampling or systematic sampling: for every k consecutive observations, one is kept, the rest being
skipped. We call k the subsampling factor. The other is to
take the local averages of k consecutive, non-overlapping
observations as the new observations. See Silvestrini &
Veredas (2008) for a survey on aggregation of univariate
and multivariate time series models. Subsampling is a common phenomenon in time series, and is our main focus in
1
In physics, it might be more mathematically tractable to construct theoretical models in continuous time, and often an exact
description requires the use of continuous time. However, we
would like to note that some time series are inherently discrete;
an example is the dividend paid by a company to shareholders
in successive years. Furthermore, even for continuous processes,
their causal interactions may take place at discrete points.

Discovering Temporal Causal Relations from Subsampled Data

this paper. As observations are temporally aggregated, the
observed “causal structure” may be different from the original true one. As claimed in (Weiss, 1984), “some care
needs to be taken in causality testing, as causality is defined for the true processes and not for the equation on
the (temporally) aggregated or sampled data.” Various contributions have been made on how temporal aggregation
changes the Granger causal relations in the data (Rajaguru
& Abeysinghe, 2008; Breitung & Swanson, 2002); for instance, temporal aggregation could cause spurious instantaneous correlations in the time series. However, little work
has been done to recover the temporal causal relations at the
proper causal frequency from the aggregated (or subsampled) data. In this paper, we are concerned with whether
it is possible to recover the original causal relations at the
causal frequency from the subsampled data, and if it is, how
to do so.
Even if the original time series are generated by a VAR,
as the time resolution becomes lower, one can see that
the residuals are no longer contemporaneously independent (Wei, 2006, Chapter 20). To account for that, in
addition to the time delayed causal relations, it was proposed to incorporate instantaneous effects between the
variables (Hyvärinen et al., 2010). This extension has
received considerable interest in neuroscience and economics. However, it is not clear how the discovered causal
relations are related to those at the original causal frequency. In particular, as stated in (Granger, 1988), it was
advocated that there is no true instantaneous causality;2
spurious instantaneous causality may be found whenever
the interval at which data are collected is lower than the
causal frequency. In this paper, our results indicate that the
instantaneous causal relations estimated by those methods
are usually different from the true ones at the causal frequency.
We aim to recover the linear temporal causal relations
from the subsampled data. We assume that the original
time series at the causal frequency are stationary. The
difficulty comes from the information loss in the missing
observations caused by subsampling. It has been shown
in (Palm & Nijman, 1984; Harvey, 1989) that with only
the second-order information of the low-resolution data,
usually the temporal causal relations are not identifiable.
We assume that the error or noise terms are non-Gaussian,
and under some additional mild conditions on the temporal causal relations, we show that interestingly, they can
be uniquely recovered from subsampled data. To this end,
we adopt the mixture of Gaussians for the distributions of
the noise terms, and propose two estimation approaches.
One is based on the Expectation-Maximization (EM) al2

Instantaneous causality might happen, say, in quantum
physics. Here we focus on temporal causality.

gorithm; however, its computational complexity increases
very rapidly along with the dimension of the time series
and the subsampling factor k. The other resorts to the variational inference framework, making the estimation procedure computationally efficient.
There has been plenty of work in economics for temporal disaggregation of the low-resolution time series, with
or without the side information from related indicators observed at the desired high frequency (Harvey & Chung,
2000; Moauro & Savio, 2005; Proietti, 2006). However,
temporal disaggregation does not imply that the temporal causal relations in the high frequency data can be correctly recovered. The autocovariance structure of the lowresolution time series usually does not contain enough information to identify all parameters in the high-frequency
model (Palm & Nijman, 1984; Harvey, 1989), and little attention has been paid to find further conditions to ensure
that such parameters are identifiable. The work by Danks &
Plis (2014) aims to infer the causal structure at the correct
causal frequency directly from the causal structure learned
from the subsampled data; they do not assume any specific
form for the causal relations and their method is completely
nonparametric, but on the other hand, an MCMC search is
needed, which involves high computational load, and their
method cannot estimate the causal strength.
This paper is organized as follows. In Section 2 we review
Granger causal analysis with instantaneous effects, which
was recently proposed for finding causal relations in time
series when the VAR residuals are contemporaneously dependent. In Section 3 we study the effect of decreasing
the temporal resolution of the time series by subsampling;
in particular, it is found that unfortunately, both the VAR
model and Granger causal analysis with instantaneous effects fail to recover the temporal causal relations underlying the data at the causal frequency. We then investigate whether it is possible to recover the original temporal
causal relations from subsampled data. Interestingly, under the non-Gaussianity assumption of the data as well as
other mild assumptions, we prove that the temporal causal
relations at the causal frequency can be recovered from
subsampled data. Next, in Section 4 we propose practical methods, including the EM algorithm and variational
inference procedure, to achieve so. In Section 5 we report
experimental results on both simulated and real data. Finally, Section 6 concludes the paper.

2. Granger Causality and Its Extension with
Instantaneous Effects
For Granger causal analysis in the linear case (Granger,
1980), one fits the following VAR model (Sims, 1980) on
the data:
xt = Axt−1 + et ,
(1)

Discovering Temporal Causal Relations from Subsampled Data

where xt = (x1t , x2t , ..., xnt )| is the vector of the observed data, et = (e1t , ..., ent )| is the temporally and contemporaneously independent noise process, and A contains
the temporal causal relations. We call A the causal transition matrix.
Now let us assume that xt also contains instantaneous effects. Let B contains the instantaneous causal relations between xt . Equation (1) changes to
xt = Bxt + Axt−1 + et ,
⇒(I − B)xt = Axt−1 + et ,
⇒xt = (I − B)−1 Axt−1 + (I − B)−1 et .

(2)

To estimate all involved parameters in Granger causality
with instantaneous effects, wo estimation procedures have
been proposed. The two-step method first estimates the errors in the above VAR model and then apply independent
component analysis (ICA) (Hyvärinen et al., 2001) on the
estimated errors Hyvärinen et al. (2008). The other is based
on multichannel blind deconvolution, which is statistically
more efficient (Zhang & Hyvärinen, 2009).

3. Identifiability of the Causal Relations from
Subsampled Data
Suppose the original high-resolution data were generated
by (1). We consider low-resolution data generated by subsampling (or systematic sampling) with the subsampling
factor k. Here we are interested in finding the causal transition matrix A which generated the original data from
the subsampled data. Traditionally, if one uses only the
second-order information, this suffers from parameter identification issues (Palm & Nijman, 1984), i.e., the same
subsampled (low-frequency) model may disaggregate to
several high frequency models, which are observationally
equivalent at the low frequency.
3.1. Effect of Subsampling (Systematic Sampling)
Suppose that due to the low resolution of the data,
there is an observation every k time steps. That is, the
low-resolution observations X̃ = (x̃1 , x̃2 , ..., x̃T ) are
(x1 , x1+k , ..., x1+(T −1)k ); here we have assumed that the
first sampled point is x1 . We then have
x̃t+1 = x1+tk = Ax1+tk−1 + e1+tk
= A(Ax1+tk−2 + e1+tk−1 ) + e1+tk
k−1
X

Al e1+tk−l .

Equation (3) follows the vector autoregression (VAR)
model, and then the following result directly follows.
Theorem 1. If one fits a VAR model on the subsampled
data x̃t generated according to (3), as done by the traditional Granger causal analysis (Granger, 1980), the discovery temporal causal relations are given by Ak as the
sample size T → ∞.
It has been pointed out (Marcellino, 1999) that the estimated time-delayed causal relation is not a time series
property invariant to temporal aggregation.3 Let us give
an illustration on this.
Misleading Granger causal relations
 in subsampled

0.8 0.5
data: An illustration Suppose A =
. Con0 −0.8
sider the case where k = 2. The corresponding VAR model
would be


0.64
0
x̃
+ ~et .
x̃t = A2 x̃t−1 + ~et =
0
0.64 t−1
That is, the causal influence from x2,t−1 to x1t is missing
in the corresponding subsampled data (with k = 2).


0.6 0.6
Suppose A =
. Then the VAR model on the
0.6 −0.6
subsampled data is
x̃t = A2 x̃t−1 + ~et ,
 0 


e
0.72
0
0
2
0
where A =
, ~et = et + Aet−1 = 1t
+
0
0.72
e02t

  0

e
0.6 0.6
· 01,t−1 , and e0t−l = e1+(t−1)k−l . Clearly
0.6 −0.6
e2,t−1
the delayed causal relations between x1t and x2t are missing. Furthermore, one can see that Cov(~e1t , ~e2t ) = 0. If e0it
are Gaussian, ~e1t and ~e2t are independent from each other,
and thus there are no instantaneous causal effects. If they
are non-Gaussian, ~et is a linear mixture of four independent
components, which are e01t , e02t , e01,t−1 , and e02,t−1 , and it is
not possible to decompose it into two independent components; that is, the Granger causal model with instantaneous
effects does not hold for the subsampled data.
3.2. Identifiability of the Causal Relations at the Causal
Frequency
Suppose the system (1) is stable. Then all eigenvalues of
A have modulus smaller than one (Lütkepohl, 2005). As

= ...
= Ak x̃t +

the kth order subsampled time series x̃t .

(3)

l=0

We denote by ~et+1 the noise term, i.e., ~et+1 =
Pk−1 l
l=0 A e1+tk−l . We call (A, e, k) the representation of

3
More precisely, it gives a comprehensive study on the effects of temporal aggregation on exogeneity, causality, cointegration, unit roots, seasonal unit roots, impulse response functions,
and trend-cycles decompositions; it finds that cointegration and
unit roots are invariant to temporal aggregation, whereas the other
properties are not (Marcellino, 1999).

Discovering Temporal Causal Relations from Subsampled Data

a consequence, the eigenvalues of Ak become smaller and
smaller as k increases, and the estimate of Ak by fitting the
VAR model on X̃ involves large estimation errors on finite
samples. Moreover, even if we can estimate Ak perfectly,
given the value of Ak , there are usually a large number of
possible solutions to A (Mitchell, 2003), which is different
from the case where A is a scalar.4
An important issue is the identifiability of A, i.e., whether
it is possible to identify the original temporal causal relations, as implied by A, from the low-resolution subsampled data x̃t . In other words, suppose x̃t also admits another representation (A0 , e0 , k), and we aim to see the relationship between A0 and A; in particular, if we always
have A0 = A, then as n → ∞, the causal relationship at
the correct resolution, A, can be uniquely recovered from
the low-resolution data. In fact, it has been demonstrated
in (Palm & Nijman, 1984) that with only the second-order
information, usually A is not identifiable. That is, the same
low-frequency model may disaggregate to several high frequency models, which are observationally equivalent at the
low frequency (according to the second-order statistics).
However, we shall see when non-Gaussianity of the data
is considered, the identifiability of A is achievable.
Let
2

L , [I A A · · · A

k−1

].

(4)

The error terms in (3) correspond to the following mixing
procedure of random vectors:
~e = Lẽ, where
(0)

(5)
(1)

(k−1)

(1)
ẽ = (e1 , ..., e(0)
n , e1 , ..., en , ..., e1

, ..., e(k−1)
)| .
n
(l)

The components of ẽ are independent, and for each i, ei ,
l = 0, ..., k − 1, have the same distribution pei .
First, we note that under the condition that pei are nonGaussian, L can be estimated up to the permutation and
scaling indeterminacies (including the sign indeterminacy)
of the columns, as given in the following lemma.
Proposition 1. Suppose that all pei are non-Gaussian.
Given k and X̃ which is generated according to (3), L can
be determined up to permutation and scaling of columns.
Proof. For the proof, let us introduce the following lemma.
It was proven in Kagan et al. (1973, Theorem 10.3.1).

0
For instance, the 2 × 2 identity matrix
has in1


b
c
finite symmetric rational square roots given by a1
,
c −b






b
−c 1 −b c
−b −c
1
,
, and a1
, where b is a ara −c
−b a c
b
−c
b
bitrary nonnegative integer and c and a are arbitrary positive integers such that b2 + c2 = a2 (Mitchell, 2003).
4



1
0

Lemma 1. Let ~e = Jr and ~e = Ms be two representations
of the n-dimensioal random vector ~e, where J and M are
constant matrices of orders n × l and n × m, respectively,
and r = (r1 , ..., rl )| and s = (s1 , ..., sm )| are random
vectors with independent components. Then the following
assertions hold.
(i) If the ith column of J is not proportional to any column of M, then ri is Gaussian.
(ii) If the ith column of J is proportional to the jth column
of M, then the logarithms of the characteristic functions of ri and sj differ by a polynomial in a neighborhood of the origin.
Equation (3) is a VAR model, and by making use of the
second-order statistical information (i.e., autocovariances),
we can estimate Ak and get rid of the contribution of the
first term in (3). Then we focus on the noise part, which
is given in (5). Since all pei are non-Gaussian, according
to (i) of Lemma 1 or Theorem 1 in (Eriksson & Koivunen,
2004), we know that L can be determined up to the permutation and scaling of columns.
We make the following assumptions on the underlying dynamic process (1) and the distributions pei , and then we
have the identifiability result for the causal transition matrix A.
A1. The system is stable, in that all eigenvalues of A have
modulus smaller than one.
A2. The distributions pei are different for different i after
re-scaling by any non-zero scale factor, their characteristic functions are all analytic (or they are all nonvanishing), and none of them has an exponent factor
with a polynomial of degree at least 2.
The following identifiability result on A states that in various situations, A for the original high-resolution data is
fully identifiable.
Theorem 2. Suppose all of eit are non-Gaussian, and that
the data x̃t are generated by (3) and that it also admits
another kth order subsampling representation (A0 , e0 , k).
Let assumptions A1 and A2 hold. When the number of observed data points T → ∞, the following statements are
true.
(i) A0 can be represented as A0 = AD1 , where D1 is a
diagonal matrix with 1 or −1 on its diagonal. If we
constrain the self influences, represented by diagonal
entries of A and A0 , to be positive,5 then A0 = A.
5
We note that this is usually the case in neuroscience and economics.

Discovering Temporal Causal Relations from Subsampled Data

(ii) If each pei is asymmetric, we have A0 = A.
(iii) If A is of full rank, all its diagonal entries are nonzero, and the graph implied by A is weakly connected,6 then we have that A0 = A for odd k and
that A0 must be A or −A for even k.
A complete proof of Theorem 2 can be found in Section 1
of the Supplementary Material.
3.3. Relation to Granger Causality with Instantaneous
Effects
In general, the estimated error terms in the subsampled
times series are not spatially independent any more. The
contemporaneous dependence in the noise terms inspired
the model of Granger causality with instantaneous effects (Reale & Tunnicliffe Wilson, 2001; Hyvärinen et al.,
2010); see (2). This model might provide an approximation
to the underlying causal relations; however, in principle it
does not hold for the low-resolution data obtained by subsampling, as one can see from the following theorem.7
Theorem 3. Suppose the subsampled data x̃t were generated by (3) and that all of eit are non-Gaussian. Further
assume that A is not diagonal, such that there exist causal
relations between different time series. As T → ∞, for the
subsampled data x̃t , the model of Granger causality with
instantaneous effects, represented by (2), does not hold, in
that the error terms estimated with the VAR model are not
linear mixtures of only n independent components.
A complete proof of Theorem 3 can be found in Section 2
of the Supplementary Material.

4. Estimating the Temporal Causal Relations
from Subsampled data
As stated in the previous section, to recover the temporal causal relations from systematically subsampled data,
we have to make use of the non-Gaussianity of the data.
Therefore, we use a Gaussian mixture
Pm model to represent
2
each noise term pei , i.e., pei = c=1 wi,c N (ei |µi,c , σi,c
),
Pm
Pm
where wi,c ≥ 0, c=1 wi,c = 1, and c=1 wi,c µi,c =
0, i = 1, ..., n. The VAR model on the low resolution data
6

In an undirected graph, two vertices xi and xj are called connected if it contains a path from xi to xj . A undirected graph is
said to be connected if every pair of vertices in the graph is connected, and furthermore, a directed graph is called weakly connected if replacing all of its directed edges with undirected edges
produces a connected undirected graph (Diestel, 1997).
7
In this paper we assume causal sufficiency, that is, there is
no hidden time series which causes more than one observed time
series. However, we note that in the confounded case, it is still
the case that in principle, the model of Granger causality with
instantaneous effects does not hold.

(3) can be simplified as
x̃t = Ak x̃t−1 + Lẽt ,
(e|1+(t−1)k , e|1+(t−1)k−1 , ...,

(6)
e|1+(t−1)k−(k−1) )| .

where ẽt =
It can be seen that each component of ẽ can also
be represented
using a Gaussian mixture model
Pm
2
pẽi =
w̃
zi =1 i,zi N (ẽi |µ̃i,zi , σ̃i,zi ), i = 1, 2, ..., nk.
According to the structure of ẽ, some components of
ẽ share the same Gaussian mixture parameters, i.e.,
w̃j+nl,c = wj,c , µ̃j+nl,c = µj,c , σ̃j+nl,c = σj,c , j =
1, ..., n, l = 0, ..., k − 1, c = 1, ..., m.
Consequently, we can write down the conditional distribution p(x̃t |x̃t−1 ) as
Z
X
p(x̃t |x̃t−1 ) =
p(zt ) p(ẽt |zt )p(x̃t |ẽt , x̃t−1 )dẽt ,
zt

Qnk
where zt = (zt,1 , ..., zt,nk )| , p(zt ) =
p(z ) =
i=1
Qnk
Qnk
Qnk t,i
w̃
,
p(ẽ
|z
)
=
p(ẽ
|z
)
=
t t
t,i t,i
i=1 i,zt,i
i=1
i=1 N (ẽt,i
2
k
|µ̃i,zt,i , σ̃i,z
x̃t−1 +
),
and
p(x̃
|ẽ
,
x̃
)
=
N
(x̃
|A
t t
t−1
t
t,i
Lẽt , Λ). Here we assume a fixed and small Λ for regularization, because there is no additional additive noise term in
(6). The model can be seen as an extension of the Independent Factor Analysis (IFA) (Attias, 1999) with additional
constraints on the model parameters.
4.1. Parameter Estimation via EM algorithm
Given the subsampling factor k, we use the ExpectationMaximization (EM) algorithm to obtain the maximum
likelihood estimation of the model parameters Θ =
(A, wi,c , µi,c , σi,c ) . Considering zt and ẽt as latent variables, we maximizePthe EM lower bound L(q, Θ) of the
data log-likelihood t ln p(x̃t |x̃t−1 , Θ) with respect to parameters Θ (M step) and find the distribution q(zt , ẽt ) over
the latent variables (E step) alternately until convergence.
In the E step, given the parameters Θ0 from the previous iteration, the lower bound L(q, Θ0 ) is maximized with respect to q, resulting in q(zt , ẽt |Θ0 ) =
p(zt |x̃t , x̃t−1 , Θ0 )p(ẽt |zt , x̃t , x̃t−1 , Θ0 ), which is the posterior distribution of the latent variables.
In the M step, given the posterior distribution q(zt , ẽt |Θ0 ),
the lower bound is maximized with respect to the parameters Θ. Because the EM lower bound can be decomposed into several terms which only depend on subsets of
the parameters, the parameters can be updated independently. However, w
updated jointly due
Pi,cmand µi,c must
Pbe
m
to the constraints c=1 wi,c = 1, c=1 wi,c µi,c = 0, i =
1, ..., n. This is a constrained nonlinear programming problem and we solve it by interior point methods (Byrd et al.,
1999). After updating wi,c and µi,c , we update σi,c which
has a closed form solution. Because the lower bound involves Al , l = 1, ...k, A has no analytic solutions. Thus

Discovering Temporal Causal Relations from Subsampled Data

we update A via the conjugate gradient descent algorithm.
In practice, the convergence of EM algorithm is very slow
when the the noise variance Λ approches zero. We adopt
the adaptive overrelaxed EM (Salakhutdinov & Roweis,
2003) algorithm to obtain a faster rate of convergence. Details of the EM algorithm can be found in Section 3 of the
Supplementary Material.
4.2. Mean Field Approximation
One problem with the EM algorithm is that the number
of Gaussian mixture components will increase exponentially in nk. Thus, in the E step, the posterior marginals
p(ẽt,i , zt,i |x̃t , x̃t−1 ) would involve mnk sums at each iteration. To make the algorithm computationally more efficient, we make the mean field assumption and approximate
the true posterior p(zt , ẽt |x̃t , x̃t−1 ) with the factorized distribution q(zt , ẽt ) = q(zt )q(ẽt ). Using the factorized posterior distribution, we can obtain the posterior of ẽt and zt,i
independently. Therefore, the computational load is linear
in nk. The variational EM lower bound is
Z
XX
L=
q(zt ) q(ẽt ) ln p(x̃t , ẽt , zt |x̃t−1 , Θ) dẽt
t

−

zt

XX
t

q(zt ) ln q(zt ) −

zt

XZ

q(ẽt ) ln q(ẽt ) dẽt .

t

The variational M step is similar to the M step in the original EM algorithm. In the E step, given Θ0 from the previous M step, q(zt |Θ0 ) and q(ẽt |Θ0 ) are updated alternately
by maximizing the lower bound:
q(zt |Θ0 ) ∝ exp hln p(x̃t , ẽt , zt |x̃t−1 , Θ0 )iq(ẽt |Θ0 ) ,

(7)

q(ẽt |Θ0 ) ∝ exp hln p(x̃t , ẽt , zt |x̃t−1 , Θ0 )iq(zt |Θ0 ) .

(8)

In (7), the expectation of the log-likelihood with respect to
q(ẽt |Θ0 ) is calculated as
hln p(x̃t , ẽt , zt |x̃t−1 , Θ0 )iq(ẽt |Θ0 )
=

nk
X

ln p(zt,i ) +

i=1

nk
X

ln p(Lt,i |zt,i ) + const,

i=1

where
D
E
(ẽt,i − µ̃0i,zt,i )2

q(ẽt,i |Θ0 )

ln p(Lt,i |zt,i ) = −

02
2σ̃i,z
t,i

0
− ln σ̃i,z
.
t,i

Thus, the posterior q(zt |Θ0 ) can be obtained as
p(Lt,i |zt,i )p(zt,i )
q(zt,i |Θ0 ) = Pm
.
0
0
z 0 =1 p(Lt,i |zt,i )p(zt,i )

(9)

the log-likelihood with respect to q(zt |Θ0 ) is in the form of
a log-likelihood of joint Gaussian distribution and q(ẽt |Θ0 )
thus can be efficiently obtained from the Gaussian posterior
distribution.
4.3. Determination of the subsampling factor k
One practical issue is that the subsampling factor k is usually unknown. Therefore we need a principled way to
choose the best k for our algorithms. In this paper, we
used cross-validation on the log-likelihood of the models to
choose the optimal k; specifically, we consider the value of
k which gives the highest cross-validated log-likelihood as
the optimal one. In our experiments, we used 5-fold cross
validation.

5. Experimental Results
In this section we present experimental results on both
simulated and read data to show the effectiveness of the
proposed method to estimate the temporal causal relations
from subsampled data. The objective function to be maximized by the proposed estimation methods is not convex.
To avoid possible local optima, we used the transition matrix estimated by fitting VAR on the subsampled data to
initialize the causal transition matrix A, and use random
initializations for the remaining parameters. With such an
initialization scheme, we did not find any case where the
proposed methods converge to unwanted solutions.
5.1. Simulated Data
To investigate the effectiveness of the proposed estimation
methods, we conducted a series of simulations. We first
generated the data at casual frequency by the VAR model
(1) with randomly generated matrix A and independent
Gaussian mixture noises et . The elements in A are uniformly distributed between −0.5 and 0.5. The Gaussian
mixture model contains two components for each dimension. We used both super-Gaussian and sub-Gaussian distributions for the noise terms. The parameters were wi,1 =
0.8, wi,2 = 0.2, µi,1 = 0, µi,2 = 0, σi,1 = 0.05, σi,2 = 1
for super-Gaussian noise and wi,1 = 0.5, wi,2 = 0.5,
µi,1 = −2, σi,2 = 2, σi,1 = 0.5, σi,2 = 0.5 for
sub-Gaussian noise. Low-resolution observations were obtained by subsampling the high-resolution data by subsampling factor k. We tested data with dimension n = 2, subsampling factor k = 2 and 3, and sample size T = 100 and
300, respectively. We denote the proposed EM algorithm
by Non-Gaussian EM (NG-EM) and the mean-field approximated algorithm by Non-Gaussian Mean-Field (NGMF).

t,i

It can be seen that the computational complexity of the posteriors q(zt,i |Θ0 ) is linear in nk. In (8), the expectation of

To our best knowledge, the problem considered in this
paper has not been well studied, and we have not found

Discovering Temporal Causal Relations from Subsampled Data

To further illustrate the limitations of Gaussian noise models, we plot the contour of the log-likelihood function with
respect to the two off-diagonal elements of Â. Given a pair
of off-diagonal elements, we optimized the log-likelihood
over the diagonal elements. The off-diagonal elements
were sampled from −0.8 to 0.8 at an interval of 0.01. The

true causal matrix A is 0.65, −0.16; 0.15, 0.65 .
Figure 2 shows the negative maximum log-likelihood function of non-Gaussian and Gaussian models computed from
the subsampled data, with both super-Gaussian and subGaussian noise terms. We used the same noise parameters as in the first simulation. It can be seen that, in both
super-Gaussian (a & b) and sub-Gaussian case (c & d),
the log-likelihood functions of Gaussian models have multiple solutions with the same likelihood value, while the
log-likelihood functions of non-Gaussian models have only
one global solution, which is around the true values. This
is consistent with the theoretical results that the causal relations might not be uniquely determined using Gaussian

super-Gaussian noise
k=2
k=3
T=100
T=300
T=100
T=300
7.27e-4 3.24e-4 1.70e-3 6.57e-4
5.09e-3 2.62e-3 6.98e-3 5.22e-3
1.33e-2 7.23e-3 1.63e-2 8.66e-3
3.89e-1 3.93e-1 4.87e-1 4.82e-1
8.76e-2 8.51e-2 8.67e-2 8.47e-2

sub-Gaussian noise
k=2
k=3
T=100
T=300
T=100
T=300
5.76e-3 2.36e-3 1.31e-2 5.33e-3
6.72e-3 3.31e-3 1.80e-2 6.17e-3
3.56e-2 7.71e-3 2.64e-2 8.06e-3
3.61e-1 3.73e-1 4.80e-1 4.76e-1
8.81e-2 8.73e-2 9.01e-2 8.57e-2

Table 1. Comparison of different methods on simulated superGaussian and sub-Gaussian data using Mean Square Error (MSE)
between the true A and the estimated A. The results are shown
for different subsampling factors (k = 2, 3) and different length
of data (T = 100, 300).

noise models.
Finally, to test the effectiveness of the subsampling factor determination scheme in Section 4.3, we applied crossvalidation on 50 randomly generated subsampled time series of length T = 100 and found that this scheme always
produces the correct value of k, no matter k = 2 or 3.
4
2

4
PSNR = 1.34e+01

estimated signal

Table 1 shows the mean square error (MSE) of the estimated parameters A. One can see that as the sample sizes
T increases, our methods obtain better results. Furthermore, the estimation error increases with the subsampling
factor k. Compared to other methods, our method achieves
the lowest estimation error in the estimated A. The method
assuming Gaussian noise produces higher error because the
solution is not unique and the algorithm may converge to an
local optimal solution which is far away from the true A.
BFL and SW do not perform well because they are based
on interpolation and thus lose some high frequency information. Our methods can also recover the causal-frequency
data based on the estimated noise terms êt . We used the
posterior mean of noise terms as the estimate. Given the
estimated noise, we can reconstruct the causal-frequency
data based on the VAR model. Figure 1 gives the scatter
plot of the estimated causal-frequency data against the true
ones; one can see that NG-EM has a much better recovery performance than BFL, as indicated by a higher Peak
Signal-to-Noise Ratio (PSNR). Moreover, as noted above,
the causal-frequency data recovered by BFL cannot give a
reliable estimation of A.

NG-EM
NG-MF
G-EM
BFL
SW

estimated signal

any existing method aiming at recovering the causal transition matrix from subsampled data. We compared our methods to two classical time series disaggregation methods:
the Boot-Feibes-Lisma (BFL) method (Boot et al., 1967)
and Stram-Wei (SW) method (Stram & Wei, 1986). These
two methods try to recover the high resolution data using
interpolation-based methods. To show the advantages of
using non-Gaussianity of the data, we also compared our
NG-EM and NG-MF with the method assuming Gaussian
noise, denoted as G-EM, obtained by setting the noise distribution in NG-EM to a single Gaussian one. We repeated
the experiments for 20 replications.

0
−2
−4
−4

−2

0
true signal

2

4

(a) Recovered by NG-EM

2

PSNR = 7.52e+00

0
−2
−4
−4

−2

0
true signal

2

4

(b) Recovered by BFL

Figure 1. Recovery of the causal-frequency data using the proposed EM method and the traditional methods: (a) The recovery
results of the proposed NG-EM method (P SN R = 13.4); (b)
The recovery results of the BFL method (P SN R = 7.52).

5.2. Real Data
We conducted experiments on the Temperature Ozone data
and the Temperature in House data (Peters et al., 2013).
We used the subsampling factor determination scheme in
Section 4.3 to determine the optimal value of k as well
as whether the frequency of the given data is lower than
the causal frequency. For the data whose resolution is not
lower than the “causal” one (which corresponds to the optimal sampling factor k determined by cross validation), we
manually subsampled them to generate low-resolution data
and then repeated the subsampling factor determination
procedure to find the optimal causal frequency and the corresponding causal relations. Since the BFL and SW methods do not aim to estimate the causal relations at causal
frequency, they are not suitable for comparison.
Temperature Ozone. The Temperature Ozone data is
the 50th causal-effect pair from the website https://
webdav.tuebingen.mpg.de/cause-effect/.

Discovering Temporal Causal Relations from Subsampled Data
0.8

0.8
15

5
8

15

0.4

153
15

156

8
15

8

0

155
158

156

158
156
155

−0.2
−0.4
8
15

−0.6

−0.4

−0.2

0

0.2

0.4

2
15 53
1
5
11556
8
15

0.6

94.5
.4

−0.6

86

−0.8
−0.8

0.8

−0.6

−0.4

−0.2

0.8

50
7

48
6
48
6

7 7
49 49
7
4590

7

49

5

47

1

47

466

0

507

471
5
497 47 486 507

7

6

49

48

A(2,1)

50
50 7
7

497

7

0.2

523.65
530.82

507

7
50

0.4

−0.2

−0.2

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

A(1,2)

(c) Sub-Gaussian, G-EM

0.8

507
497
486

−0.4

−0.4

−0.2

0

0.2

0.4

47

7

−0.6

1
475

507

50

−0.8
−0.8

5

497

−0.6

47

53
52 0.8
3. 2
65

−0.6

507

530.82
.5
516 4
.3
509 7
.1
5028.94
49 96.7
4

−0.4

−0.8
−0.8

0.6

50

509.34
51
53 523.6 6.5
0.8
5
2

0.6

7

A(2,1)

0.8

49

0

0.4

6
48

502.

0.2

(b) Super-Gaussian, NG-EM

0.8

4
0.2 509.3.5
516

0

A(1,2)

(a) Super-Gaussian, G-EM
0.4 498.94
17

.5

−0.2

A(1,2)

7
2.1 4
50 98.9
4
0.6
496.7

94

86.4

0

−0.4

3
15

15
155 6

−0.6
−0.8
−0.8

.2
.5
94 86.478 70.1

0.2

21
5

A(2,1)

A(2,1)

0.2

0.6

155
156

0.4

8

8 5565
15 11 153
15
2
15

0.6

0.6

0.8

A(1,2)

(d) Sub-Gaussian, NG-EM

Figure 2. The contour plot of the negative log-likelihood function
with repect to the two off-diagonal elmemnts of Â: (a) negative log-likelihood function of the Gaussian model computed on
super-Gaussian data, (b) negative log-likelihood function of the
non-Gaussian model computed on super-Gaussian data, (c) negative log-likelihood function of the Gaussian model computed
on sub-Gaussian data, (d) negative log-likelihood function of the
non-Gaussian model computed on sub-Gaussian data.



0.9894 −0.0004
, respectively. It is interesting to
0.0136 0.9873
note that the cross-validated likelihood always increases
as k varies from 1 (corresponding to a 1-hour sampling
interval) to 5 (12-minute sampling interval) . This indicates
that the causal frequency is very high; in fact, note that
2 and 3 are adjacent, and it seems reasonable to consider
the two processes as continuous ones. If we allow k to go
to infinity, the VAR model provides an approximator to
continuous processes.
For 2 → 4, the cross-validated log-likelihood is
273.533, 273.716, 322.347, 370.555, and 370.547, respectively, as k rangesfrom 1 to 5. The estimated
causal transi

0.9416 0.0077
0.9707 0.0037
tion matrix is
,
,
0.0638 0.9557
0.0338 0.9764




0.9804 0.0024
0.9853 0.0018
,
,
and
0.0228 0.9842
0.0172 0.9880


0.9883 0.0014
. Here it seems that k = 4 (corre0.0138 0.9905
sponding to a 15-minute sampling interval) should be
preferred. Note that 2 and 4 are not adjacent. Causal
influences between them take some time; in this case, a
VAR model with a 15-minute sampling interval might
provide a good approximation to the true processes.

6. Conclusion
The data have records of daily temperature X and
ozone density Y . The ground truth is Y → X. The
cross-validated log-likelihood is −89.638, −89.197,
and −90.246, respectively, as k ranges from 1 to 3.
Therefore, we consider k = 2 as the best subsampling factor. The estimated transition
  matrix A for

0.7285 0.1769
0.8312 0.1370
k = 1, 2, 3 is
,
,
−0.0378 0.9526
0.0093 0.9537


0.8816 0.0989
and
, respectively. We can see from
0.0292 0.9462
the results that the transition matrix A at k = 2 gives the
weakest response from effect X to cause Y , which seems
plausible.
Temperature in House. The Temperature in House
dataset contains temperature recorded hourly in six rooms
(1 - Shed, 2 - Outside, 3 - Kitchen Boiler, 4 - Living room,
5 - WC, 6 - Bathroom) of a house. We analyzed the causal
relations 2 → 3 and 2 → 4 because they are relatively
strong. For 2 → 3, the cross-validated log-likelihood is
183.596, 184.076, 184.139, 184.168, and 184.183, respectively, as k ranges
from 1 to 5. The estimated transition


0.9476 −0.0024
0.9735 −0.0011
matrix A is
,
,
0.0621
0.9394
0.0329  0.9688



0.9823 −0.0007
0.9867 −0.0005
,
,
and
0.0223 0.9790
0.0169 0.9841

Sometimes the observed time series were actually obtained
by subsampling the true processes. We have considered the
issue of recovering linear temporal causal relations at the
true causal frequency from such time series. We were concerned with the situation, under certain mild conditions on
the structure of the causal relations where the noise terms
in the causal time series are non-Gaussian. We have shown
that in this situation, the causal relations are identifiable.
Two practical methods, one based on the EM algorithm
and the other the variational inference framework, have
been proposed to estimate the causal relations from lowresolution data. The method based on variational inference
is computationally more efficient, and is recommended if
the data have high dimensions or many points. As a line
of our future research, we are trying to further improve the
computational efficiency of the proposed methods, especially the one based on variational inference, to solve largescale problems.

Acknowledgments
The authors thank Biwei Huang, Peter Spirtes, and Michel
Besserve for helpful discussions. ZK was supported in part
by DARPA grant No. W911NF-12-1-0034. GM and TD
were supported by Australian Research Council Projects
FT-130101457 and DP-140102164.

Discovering Temporal Causal Relations from Subsampled Data

References
Attias, H. Independent factor analysis. Neural Computation, 11
(4):803–851, 1999.
Boot, J.C.G., Feibes, W., and Lisman, J.H.C. Further methods
of derivation of quarterly figures from annual data. Applied
Statistics, pp. 65–75, 1967.
Breitung, J. and Swanson, N. R. Temporal aggregation and spurious instantaneous causality in multiple time series models.
Journal of Time Series Analysis, 23:651–665, 2002.
Byrd, R.H., Hribar, M.E., and Nocedal, J. An interior point algorithm for large-scale nonlinear programming. SIAM Journal
on Optimization, 9(4):877–900, 1999.
Danks, D. and Plis, S. Learning causal structure from undersampled time series. In JMLR: Workshop and Conference Proceedings, 2014. To appear.
Diestel, R. Graph Theory. Springer-Verlag, 1997.
Eriksson, J. and Koivunen, V. Identifiability, separability, and
uniqueness of linear ICA models. IEEE Signal Processing Letters, 11(7):601–604, 2004.

Palm, F. C. and Nijman, T. E. Missing observations in the dynamic regression model. Econometrica, 52:1415–1435, 1984.
Peters, J., Janzing, D., and Schölkopf, B. Causal inference on time
series using restricted structural equation models. In Advances
in Neural Information Processing Systems, pp. 154–162, 2013.
Proietti, T. Temporal disaggregation by state space methods: Dynamic regression methods revisited. The Econometrics Journal, 9:357–372, 2006.
Rajaguru, G. and Abeysinghe, T. Temporal aggregation, cointegration and causality inference. Economics Letters, 101:223–
226, 2008.
Reale, M. and Tunnicliffe Wilson, G. Identification of vector AR
models with recursive structural errors using conditional independence graphs. Statistical Methods and Applications, 10(13):49–65, 2001.
Salakhutdinov, R. and Roweis, S. Adaptive overrelaxed bound
optimization methods. In Proceedings of the 20th International
Conference on Machine Learning (ICML2003), pp. 664–671,
2003.

Granger, C. Testing for causality: A personal viewpoint. Journal
of Economic Dynamics and Control, 2, 1980.

Silvestrini, A. and Veredas, D. Temporal aggregation of univariate and multivariate time series models: A survey. Journal of
Economic Surveys, 22:458–497, 2008.

Granger, C. Some recent developments in a concept of causality.
Journal of Economietrics, 39:199–211, 1988.

Sims, C. A. Macroeconomics and reality. Econometrica, 48:1–48,
1980.

Harvey, A. C. Forecasting, Structural Time Series Models and the
Kalman Filter. Cambridge University Press, 1989.

Stram, D.O. and Wei, W.S. A methodological note on the disaggregation of time series totals. Journal of Time Series Analysis,
7(4):293–302, 1986.

Harvey, A. C. and Chung, C. H. Estimating the underlying change
in unemployment in the uk. Journal of the Royal Statistics
Society, Series A, 163:303–309, 2000.

Wei, W. S. Time Series Analysis: Univariate and Multivariate
Methods. Pearson, 2006. 2nd Edition.

Hyvärinen, A., Karhunen, J., and Oja, E. Independent Component
Analysis. John Wiley & Sons, Inc, 2001.

Weiss, A. Systematic sampling and temporal aggregation in time
series models. Journal of Econometrics, 26:271–281, 1984.

Hyvärinen, A., Shimizu, S., and Hoyer, P. O. Causal modelling
combining instantaneous and lagged effects: an identifiable
model based on non-Gaussianity. In Proceedings of the 25th
International Conference on Machine Learning (ICML2008),
pp. 424–431, Helsinki, Finland, 2008.

Zhang, K. and Hyvärinen, A. Acyclic causality discovery with additive noise: An information-theoretical perspective. In Proc.
European Conference on Machine Learning and Principles
and Practice of Knowledge Discovery in Databases (ECML
PKDD) 2009, Bled, Slovenia, 2009.

Hyvärinen, A., Zhang, K., Shimizu, S., and Hoyer, P. Estimation of a structural vector autoregression model using nongaussianity. Journal of Machine Learning Research, pp. 1709–
1731, 2010.
Kagan, A. M., Linnik, Y. V., and Rao, C. R. Characterization
Problems in Mathematical Statistics. Wiley, New York, 1973.
Lütkepohl, H. New Introduction to Multiple Time Series Analysis.
Berlin: Springer, 2005.
Marcellino, M. Some consequences of temporal aggregation in
empirical analysis. Journal of Business and Economic Statistics, 17:129–136, 1999.
Mitchell, D. W. Using pythagorean triples to generate square roots
of I2 . The Mathematical Gazette, 87:499–500, 2003.
Moauro, F. and Savio, G. Temporal disaggregation using multivariate structural time series models. Journal of Econometrics,
8:210–234, 2005.

