A Theoretical Analysis of Metric Hypothesis Transfer Learning

Michaël Perrot
MICHAEL . PERROT @ UNIV- ST- ETIENNE . FR
Amaury Habrard
AMAURY. HABRARD @ UNIV- ST- ETIENNE . FR
Université de Lyon, Université Jean Monnet de Saint-Etienne,
Laboratoire Hubert Curien, CNRS, UMR5516, F-42000, Saint-Etienne, France.

Abstract
We consider the problem of transferring some
a priori knowledge in the context of supervised
metric learning approaches. While this setting
has been successfully applied in some empirical
contexts, no theoretical evidence exists to justify
this approach. In this paper, we provide a theoretical justification based on the notion of algorithmic stability adapted to the regularized metric learning setting. We propose an on-averagereplace-two-stability model allowing us to prove
fast generalization rates when an auxiliary source
metric is used to bias the regularizer. Moreover,
we prove a consistency result from which we
show the interest of considering biased weighted
regularized formulations and we provide a solution to estimate the associated weight. We also
present some experiments illustrating the interest
of the approach in standard metric learning tasks
and in a transfer learning problem where few labelled data are available.

1. Introduction
A lot of machine learning problems, such as clustering,
classification or ranking, require to accurately compare examples by means of distances or similarities. Designing
a good metric for a task at hand is thus of crucial importance. Manually tuning a metric is in general difficult and
tedious, a recent trend consists to learn the metrics directly
from data. This has led to the emergence of supervised
metric learning, see (Bellet et al., 2013; Kulis, 2013) for
up-to-date surveys. The underlying idea is to infer automatically the parameters of a metric in order to capture the
idiosyncrasies of the data. In a supervised classification
perspective, this is generally done by trying to satisfy pairbased constraints aiming at assigning a small (resp. large)
Proceedings of the 32 nd International Conference on Machine
Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).

score to pairs of examples of the same class (resp. different class). Most of the existing work has notably focused on learning
p Mahalanobis-like distances of the form
dM (x, x0 ) = (x − x0 )T M(x − x0 ) where M is a positive semi-definite (PSD) matrix1 , the learned matrix being
typically plugged in a k-Nearest Neighbor classifier allowing one to achieve a better accuracy than the standard Euclidean distance.
Recently, there is a growing interest for methods
able to take into account some background knowledge
(Parameswaran & Weinberger, 2010; Cao et al., 2013;
Bohné et al., 2014) for learning M. This is in particular the
case for supervised regularized metric learning approaches
where the regularizer is biased with respect to an auxiliary
metric given under the form of a matrix. The main objective here is to make use of this a priori knowledge in a
setting where only few labelled data are available to help
learning. For example, in the context of learning a PSD
matrix M plugged into a Mahalanobis-like distance as discussed above, let I be the identity matrix used as an auxiliary knowledge, kM − Ik is a biased regularizer often
considered. This regularization can be interpreted as follows: learn M while trying to stay close to the Euclidean
distance, or from another standpoint try to learn a matrix M
which performs better than I. Other standard matrices can
be used such as Σ−1 the inverse of the variance-covariance
matrix, note that if we take the 0 matrix, we retrieve the
classical unbiased regularization term.
Another useful setting comes when I is replaced by any
auxiliary matrix MS learned from another task. This corresponds to a transfer learning approach where the biased
regularization can be interpreted as transferring the knowledge brought by MS for learning M. This setting is appropriate when the distributions over training and testing domains are different but related. Domain adaptation strate1
Note that this distance is a generalization of some wellknown distances: when M = I, I being the identity matrix, we
retrieve the Euclidean distance, when M = Σ−1 where Σ is the
variance-covariance matrix of the data at hand, it actually corresponds to the original definition of a Mahalanobis distance.

A Theoretical Analysis of Metric Hypothesis Transfer Learning

gies (Ben-David et al., 2010) propose to make use of the relationship between the training examples, called the source
domain, and the testing instances, called the target domain
to infer a model. However, it is sometimes not possible to
have access to all the training examples, for example when
some new domains are acquired incrementally. In this context, transferring the information directly from the model
learned from the source domain without any other access to
the source domain is of crucial importance. In the context
of this paper, we call this setting Metric Hypothesis Transfer Learning in reference to the Hypothesis Transfer Learning model introduced in (Kuzborskij & Orabona, 2013) in
the context of classical supervised learning.
Metric learning generally suffers from a lack of theoretical justifications, in particular metric hypothesis transfer
learning has never been investigated from a theoretical
standpoint. In this paper, we propose to bridge this gap
by providing a theoretical analysis showing that supervised
regularized metric learning approaches using a biased regularization are well-founded. Our theoretical analysis is
based on algorithmic stability arguments allowing one to
derive generalization guarantees when a learning algorithm
does not suffer too much from a little change in the training sample. As a first contribution, we introduce a new
notion of stability called on-average-replace-two-stability
that is well-suited to regularized metric learning formulations. This notion allows us to prove a high probability
generalization bound for metric hypothesis transfer learning achieving a fast converge rate in O(1/n) in the context of admissible, lipschitz and convex losses. In a second
step, we provide a consistency result from which we justify
the interest of weighted biased regularization of the form
kM − βMS k where β is a parameter to set. From this
result, we derive an approach for assessing this parameter
without resorting to a costly parameter tuning procedure.
We also provide an experimental study showing the effectiveness of transfer metric learning with weighted biased
regularization in the presence of few labeled data both on
standard metric learning and transfer learning tasks.
This paper is organized as follows. Section 2 introduces
some notations and definitions while Section 3 discusses
some related work. Our theoretical analysis is presented in
Section 4. We detail our experiments in Section 5 before
concluding in Section 6.

2. Notations and Definitions
We start by introducing several notations and definitions
that will be used throughout the paper. Let T be a domain
equipped with a probability distribution DT defined over
X × Y, where X ⊆ Rd and Y is the label set. We consider
metrics corresponding to distance functions X × X → R+
parameterized by a d × d positive semi-definite (PSD) ma-

trix M denoted M  0. In the following, a metric will
be represented by its matrix M. We also consider that we
have access to some additional information under the form
of an auxiliary d × d matrix MS , throughout this paper we
call this additional information source metric or source hypothesis. We denote the Frobenius norm by k · kF , Mkl
represents the value of the entry at index (k, l) in matrix
M, [a]+ = max(a, 0) denotes the hinge loss and [n] the
set {1, . . . , n} for any n ∈ N.
Let T = {zi = (xi , yi )}ni=1 be a labeled training set drawn
from DT . We consider the following learning framework
for biased regularized metric learning:
M∗ = arg min LT (M) + λkM − MS kF

(1)

M0

P
where LT (M) = n12 z,z0 ∈T l(M, z, z0 ) stands for the
empirical risk of a metric hypothesis M. Similarly we denote the true risk by LDT (M) = Ez,z0 ∼DT l(M, z, z0 ). In
this work we only consider convex, k-lipschitz and (σ, m)admissible losses for which we recall the definitions below.
Definition 1 (k-lipschitz continuity). A loss function
l(M, z, z0 ) is k-lipschitz w.r.t. its first argument if, for any
matrices M, M0 and any pair of examples z, z0 , there exists
k ≥ 0 such that:
|l(M, z, z0 ) − l(M0 , z, z0 )| ≤ kkM − M0 kF .
This property ensures that the loss deviation does not exceed the deviation between matrices M and M0 with respect to a positive constant k.
Definition 2 ((σ, m)-admissibility). A loss function
l(M, z, z0 ) is (σ, m)-admissible, w.r.t. M, if it is convex
w.r.t. its first argument and if for any two pairs of examples
z1 , z2 and z3 , z4 , we have:
|l(M, z1 , z2 ) − l(M, z3 , z4 )| ≤ σ |y1 y2 − y3 y4 | + m
where yi yj = 1 if yi = yj and −1 otherwise. Thus
|y1 y2 − y3 y4 | ∈ {0, 2}.
This property bounds the difference between the losses of
two pairs of examples by a value only related to the labels
plus a constant independent from M.
To derive our theoretical results, we make use of the notion
of algorithmic stability which allows one to provide generalization guarantees. A learning algorithm is stable if a
slight modification in its input does not change its output
much. In our analysis we use two definitions of stability.
On the one hand, we introduce in Section 4.1 the notion
of on-average-replace-two-stability which is an adaptation
to metric learning of the notion of on-average-replace-onestability proposed in (Shalev-Shwartz & Ben-David, 2014)
and recalled in Def. 3 below.

A Theoretical Analysis of Metric Hypothesis Transfer Learning

Definition 3 (On-average-replace-one-stability). Let  :
N → R be monotonically decreasing and U (n) be the uniform distribution over [n]. An algorithm A is on-averagereplace-one-stable with rate (n) if for any distribution DT


ET ∼DT n l(A(T i ), zi ) − l(A(T ), zi ) ≤ (n)
i∼U (n)
z0 ∼DT

where A(T ), respectively A(T i ) is the optimal solution of
algorithm A when learning with training set T , respectively
T i . T i is obtained by replacing the ith example of T by z0 .
This property ensures that, given an example, learning with
or without it will not imply a big change in the hypothesis
prediction. Note that the property is required to be true on
average over all the possible training sets of size n.
On the other hand, we consider an adaptation of the framework of uniform stability for metric learning proposed in
(Jin et al., 2009) and recalled in Def. 4.
Definition 4 (Uniform stability). A learning algorithm has
a uniform stability in K
n , with K ≥ 0 a constant, if ∀i,

 K
∗


sup l(M∗ , z, z0 ) − l(Mi , z, z0 ) ≤
n
z,z0 ∼DT
∗

where M∗ is the matrix learned on the training set T , Mi
is the matrix learned on the training set T i obtained by
replacing the ith example of T by a new independent one.
Uniform stability requires that a small change in the training set does not imply a significant variation
in the learned

models output. The constraint in O n1 over the supremum
makes this property rather strong since it considers a worst
case over the possible pairs of examples to compare, whatever the training set. It is actually one of the most general
algorithmic stability setting (Bousquet & Elisseeff, 2002).

3. Related Work
3.1. Metric Learning
Based on the pioneering approach of (Xing et al., 2002),
metric learning aims at finding the parameters of a distance function by maximizing the distance between dissimilar examples (i.e. examples of different class) while
maintaining a small distance between similar ones (i.e. of
similar class). Following this idea, one of the most famous approach, called LMNN (Weinberger et al., 2005),
proposes to learn a PSD matrix dedicated to improve the
k-nearest neighbours algorithm. To do so, the authors force
the metric to respect triplet-based local constraints of the
form (zi , zj , zk ) where zj and zk belong to the neighbourhood of zi , zi and zj being of the same class, and zk being
of opposite class. The constraints impose that zi should
be closer to zj than to zk with respect to a margin ε. In

ITML, (Davis et al., 2007) propose to use a LogDet divergence as a regularizer allowing one to ensure an automatic
enforcement of the PSD constraint. The idea is to force the
learned matrix M to stay as close as possible to a good matrix MS defined a-priori (in general MS is chosen as the
identity matrix). Indeed, if this divergence is finite, the authors show that M is guaranteed to be PSD. This constraint
over M can be interpreted as a biased regularization w.r.t.
MS .
The idea behind biased regularization has been successfully
used in many metric learning approaches. For example,
(Zha et al., 2009) have proposed to replace the identity matrix (MS = I) originally used in ITML by matrices previously learned on so called auxiliary data sets. Similarly, in
(Parameswaran & Weinberger, 2010) the authors are interested in Multi-Task metric learning. They propose to learn
one metric for each task and a global metric common to
all the tasks. For this global metric, they consider a biased
regularization of the form kM − Ik2F where I is the identity matrix but they do not study any other kind of source
information. In (Cao et al., 2013), the authors use a similar
biased regularization to learn a metric learning model for
face recognition. As a last example, (Bohné et al., 2014)
introduce a regularization of the form kM − βIkF where
they learn M and β. In our work, instead of optimizing
these two parameters, we derive a theoretically founded algorithm to choose beforehand the optimal value of β.
3.2. Theoretical Frameworks in Metric Learning
Theoretically speaking, there is not a lot of frameworks for
metric learning. The goal of generalization guarantees is to
show that the empirical estimation of the error of an algorithm does not deviate much from the true error. One of the
main difficulty in deriving bounds for metric learning is the
fact that instead of considering examples drawn i.i.d. from
a distribution, we consider pairs of examples which might
not be independent. Building upon the framework of stability proposed in (Bousquet & Elisseeff, 2002), (Jin et al.,
2009) propose one of the first study of the generalization
ability of a metric learning algorithm. Building upon this
work, (Perrot et al., 2014) give theoretical guarantees for
a local metric learning algorithm and (Bellet et al., 2012)
derive generalization guarantees for a similarity learning
algorithm. Other ways to derive generalization guarantees
are to use the Rademacher complexity as in (Cao et al.,
2012; Guo & Ying, 2014) or to use the notion of algorithmic robustness (Bellet & Habrard, 2015).
3.3. Biased Regularization in Supervised Learning
Biased regularization has already been studied in non metric learning settings. For example in (Kienzle & Chellapilla, 2006), the authors propose to use biased regular-

A Theoretical Analysis of Metric Hypothesis Transfer Learning

ization to learn SVM classifiers. A first theoretical study
of biased regularization in the context of regularized least
squares has been proposed in (Kuzborskij & Orabona,
2013). Their study is based on a notion of hypothesis stability less general than the uniform stability used in our approach. In (Kuzborskij & Orabona, 2014), the authors derive generalization bounds based on the Rademacher complexity for regularized empirical risk minimization methods in a supervised learning setting. Their results show that
if the true risk of the source hypothesis on the target domain is low, then the generalization rate can be improved.
However computing the true risk of the source hypothesis
is not possible in practice. In our analysis, we derive a generalization bound which depends on the empirical risk and
the complexity (w.r.t. the regularization term) of the source
metric. It allows us to derive an algorithm to minimize the
generalization bound taking into account the performance
and the complexity of the source metric.

4. Contribution
We divide our contribution consisting of a theoretical
analysis of Alg. 1 given convex, k-lipschitz and (σ, m)admissible losses into three parts. First, we provide an on
average analysis for ET [LDT (M∗ )] where M∗ represents
the metric learned with Alg. 1 using training set T . This
analysis allows us to bound the expected loss over distribution DT with respect to the loss of the auxiliary metric
MS over DT . It shows that on average the learned metric
tends to be better than the given source MS , with a fast
convergence rate in O(1/n). Second, we provide a consistency analysis of our framework
leading to a standard

1
convergence rate of O √n w.r.t the empirical loss over
T optimized in Alg. 1. In a third part, we specialize the
previous consistency result to a specific loss and show that
it is possible to refine our generalization bound in order to
depend both on the complexity of our source metric MS
and its empirical performance on the training set T . We
then deduce an approach to weight the importance of the
source hypothesis for optimizing the generalization bound.

distribution DT :
h
T ∼DT n
i,j∼U (n)
z1 ,z2 ∼DT

E

i
j∗
l(Mi , zi , zj ) − l(M∗ , zi , zj ) ≤ (n)
j∗

where M∗ , respectively Mi , is the optimal solution
j
when learning with the training set T , respectively T i .
j
T i is obtained by replacing zi , the ith example of T , by
z1 to get a training set T i and then by replacing zj , the j th
example of T i , by z2 .
Note that when this definition holds, it implies
ET [LDT (M∗ ) − LT (M∗ )] ≤ (n). The next theorem
shows that our algorithm is on-average-replace-two-stable.
Theorem 1 (On-average-replace-two-stability). Given a
training sample T of size n drawn i.i.d. from DT , our algo2
rithm is on-average-replace-two-stable with (n) = 8k
λn .
Proof. The proof of Th. 1 can be found in the supplementary material.
We can now bound the expected true risk of our algorithm.
Theorem 2 (On average bound). For any convex, klipschitz loss, we have:
ET ∼DT n [LDT (M∗ )] ≤ LDT (MS ) +

8k2
λn

where the expected value is taken over size-n training sets.
Proof. We have:
ET [LDT (M∗ )]
= ET [LDT (M∗ )] + ET [LT (M∗ )] − ET [LT (M∗ )]
= ET [LT (M∗ )] + ET [LDT (M∗ ) − LT (M∗ )]
≤ ET [LT (MS )] +

8k2
.
λn

(2)

Inequality 2 is obtained by noting that from Th. 1 we have
2
ET [LDT (M∗ ) − LT (M∗ )] ≤ 8k
λn , then the convexity of
our algorithm and the optimality of M∗ give LT (M∗ ) ≤
LT (M∗ )+λkM∗ −MS k2F ≤ LT (MS )+λkMS −MS k2F .
Noting that ET [LT (MS )] = LDT (MS ) gives Th. 2.

4.1. On average analysis
Def. 3 allows one to perform an average analysis over the
expected loss, however its formulation is not tailored to
metric learning approaches that work with pair of examples. Thus we propose an adaptation of it that we call onaverage-replace-two-stability allowing one to derive sharp
bounds for metric learning.
Definition 5 (On-average-replace-two-stability). Let  :
N → R be monotonically decreasing and let U (n) be the
uniform distribution over [n]. A metric learning algorithm
is on-average-replace-two-stable with rate (n) if for every

This bound shows that with a sufficient number of examples w.r.t. a fast convergence rate in O(1/n), we will on
average obtain a metric which is at least as good as the
source hypothesis. Thus choosing a good source metric is
key to learn well.
4.2. Consistency analysis
We now provide a consistency analysis taking into account
the empirical risk optimized in Alg. 1. We begin by showing that our algorithm is uniformly stable w.r.t. Def. 4 in
the next theorem.

A Theoretical Analysis of Metric Hypothesis Transfer Learning

Theorem 3 (Uniform stability). Given a training sample
T of n examples drawn i.i.d. from DT , our algorithm has
4k2
a uniform stability in K
n with K = λ .
Proof. The beginning of the proof follows closely the one
proposed in (Bousquet & Elisseeff, 2002) and is postponed
to the supplementary material for the sake of readability.
We consider the end of the proof here. We have
B≤

4kt
k∆MkF
n

where B = λkM−MS k2F −λkM−t∆M−MS k2F +λkMi −
MS k2F − λkMi + t∆M − MS k2F .
Setting t = 12 we have:

Proof. The proof is available in the supplementary.
 
This bound shows that with a convergence rate in O √1n
the true risk of our algorithm is bounded above by the empirical risk justifying the consistency of the approach. In
the next section, we propose an extension of this analysis
to include the performance of the source metric. This extension allows us to introduce a natural weighting of the
source metric in order to improve the proposed bound.
4.3. Refinement with weighted source hypothesis

part we study a specific loss, namely l(M, z, z0 ) =
In this
0
yy ((x − x0 )T M(x − x0 ) − γyy0 ) + where yy 0 = 1 if
1
B = λkM − MS k2F − λkM − ∆M − MS k2F
y = y 0 and −1 otherwise. The convexity follows from the
2
1
2
i
2
i
use of the hinge loss. In the next two lemmas, we show that
+ λkM − MS kF − λkM + ∆M − MS kF
2
this loss is k-lipschitz continuous and (σ, m)-admissible.

XX
1
(Mkl − MS kl )2 − (Mkl − (Mkl −Mikl ) − MS kl )2 The (σ, m)-admissibility result is of high importance be=λ
2
cause it allows us to introduce some information coming
k
l

from the source matrix MS .
1
i
2
i
i
2
+(Mkl − MS kl ) − (Mkl + (Mkl − Mkl ) − MS kl )
2
Lemma 1 (k-lipschitz continuity). Let M and M0 be two
XX
1
1
matrices and z, z0 be two examples. Our loss l(M, z, z0 ) is
=λ
(Mkl −MS kl )2 −( (Mkl −MS kl )+ (Mikl −MS kl ))2
2
2
k-lipschitz continuous with k = maxx,x0 kx − x0 k2 .
i
j

1
1
+(Mikl − MS kl )2 − ( (Mkl − MS kl ) + (Mikl − MS kl ))2 Proof. The proof is available in the supplementary.
2
2
XX1
Lemma 2 ((σ, m)-admissibility). Let z1 , z2 , z3 , z4 be four
=λ
((Mkl − MS kl )2
2
examples and M∗ be the optimal solution of Problem 1.
i
j
i
The convex and k-lipschitz loss function l(M, z, z0 ) is
+(Mikl − MS kl )2 − 2(Mkl − MS kl )(Mikl − MS kl ))
(σ, m)-admissible with σ = q
max(γy3 y4 , γy1 y2 ) and

XX1
λ
LT (MS )
2
i
2
0
2
=λ
(Mkl − MS kl − Mkl − MS kl ) = k∆MkF . m = 2 maxx,x0 kx − x k (
+ kMS kF ).
λ
2
2
i
j

Then we obtain
4k
4k
λ
k∆Mk2F ≤
k∆MkF ⇔ k∆MkF ≤
.
2
2n
λn

Using the k-lipschitz continuity of the loss, we have:
sup |l(M, z, z0 ) − l(Mi , z, z0 )| ≤ kk∆MkF ≤
z,z0

Setting K =

4k2
λ

4k2
.
λn

LT (M∗ )+λkM∗ −MS k2F ≤ LT (MS ) + λkMS − MS k2F
r
LT (MS )
∗ 2
∗
⇒
λkε kF ≤ LT (MS ) ⇔ kε kF ≤
λ

Now we can prove the (σ, m)-admissibility of our loss.

concludes the proof.

Using the fact that our algorithm is uniformly stable, we
can derive generalization guarantees as stated in Th. 4.
Theorem 4 (Generalization bound). With probability 1−δ,
for any matrix M learned with our K uniformly stable
algorithm and for any convex, k-lipschitz and (σ, m)admissible loss, we have:
s
LDT (M) ≤ LT (M) + (4σ + 2m + c)

Proof. Let ε∗ = M∗ − MS be the difference between the
learned and the source metric. We first bound the frobenius
norm of ε∗ w.r.t. the performance of the source metric.

 
ln 2δ
1
+O
2n
n

where c is a constant linked to the k-lipschitz property of
the loss.

|l(M∗ , z1 , z2 ) − l(M∗ , z3 , z4 )|
h
i
=| y1 y2 ((x1 − x2 )T M∗ (x1 − x2 ) − γy1 y2 )
+
h
i
T
∗
− y3 y4 ((x3 − x4 ) M (x3 − x4 ) − γy3 y4 ) |
+

T

∗

≤|y1 y2 ((x1 − x2 ) M (x1 − x2 ) − γy1 y2 )
− y3 y4 ((x3 − x4 )T M∗ (x3 − x4 ) − γy3 y4 )|
≤|y1 y2 (x1 − x2 )T M∗ (x1 − x2 )
− y3 y4 (x3 − x4 )T M∗ (x3 − x4 )|
+ |y3 y4 γy3 y4 − y1 y2 γy1 y2 |

(3)

A Theoretical Analysis of Metric Hypothesis Transfer Learning
≤2 max0 ((x − x0 )T M∗ (x − x0 ))

and more specifically C(MS ) by adding a weighting parameter β ≥ 0 on the source metric MS . This parameter is
a way to control the trade-off between complexity and performance of the source metric. It can be assessed by means
of the following optimization problem:

x,x

+ |y3 y4 − y1 y2 | max(γy3 y4 , γy1 y2 )
≤2 max0 ((x − x0 )T (ε∗ + MS )(x − x0 ))
x,x

+ |y3 y4 − y1 y2 | max(γy3 y4 , γy1 y2 )

β ∗ = arg min C(βMS )

≤2 max0 kx − x0 k2 (kε∗ kF + kMS kF )
x,x

+ |y3 y4 − y1 y2 | max(γy3 y4 , γy1 y2 )
r
LT (MS )
≤2 max0 kx − x0 k2 (
+ kMS kF )
x,x
λ
+ |y3 y4 − y1 y2 | max(γy3 y4 , γy1 y2 ).

(4)

Inequality 3 comes from the 1-lipschitz property of the
hinge loss. We obtain inequality 4 by applying the CauchySchwarz inequality and some classical
norm properties.
q
S)
Setting m = 2 maxx,x0 kx − x0 k2 ( LT (M
+ kMS kF )
λ
and σ = max(γy3 y4 , γy1 y2 ) gives the lemma.

Using Lemmas 1 and 2 we can now derive, in Th. 5, a generalization bound associated with our specific loss.
Theorem 5 (Generalization bound). With probability 1 − δ
for any matrix M learned with Alg. 1, we have:
LDT (M) ≤LT (M) + O
r
+

 
1
n

LT (MS )
+ kMS kF + cγ
λ

!s

(5)

β

ln 2δ
2n

where cγ is a constant linked to the k-lipschitz property of
the loss and the chosen margins.
Proof. The proof is the same as for Th. 4 replacing k, σ
and m by their values.
 
As for Th. 4, the convergence rate is in O √1n . The term
q

def
LT (MS )
C(MS ) =
+
kM
k
mainly depends on
S F
λ
the quality of the
 source hypothesis MS . The product
C(MS )O √1n means that as the number of examples
available for learning increases, the quality of the source
metric is of decreasing importance. A similar result has already been stated in domain adaptation or transfer learning
in (Ben-David et al., 2010; Kuzborskij & Orabona, 2013)
where they show that as the number of target examples increases, the necessity of having source examples decreases.
Given a source hypothesis MS , it is possible to optimize it
w.r.t. the bound derived in Th. 5. Indeed, note that C(MS )
corresponds to a trade-off between the complexity of the
source metric and its performance on the training set. The
lower the value of this term, the tighter the bound. Hence,
we propose a way to minimize the generalization bound

Note that the bound derived in Th. 5 holds whatever the
value of MS . Thus replacing it with β ∗ MS does not impact the theoretical study proposed in this section.
Interpretation of the value of β ∗ We can distinguish
three main cases. First if the source hypothesis performs
poorly on the training set at hand we expect β ∗ to be as
small as possible to reduce the importance of MS . In
a sense, we tend to go back to the classical case were
MS = 0. Second if the source hypothesis is complex and
performs well, we expect β ∗ to be rather small to reduce
the complexity of the hypothesis while keeping a good performance on the training set. Third if the source hypothesis
is simple and performs well, we expect β ∗ to be closer to
one since MS is already a good choice.
Learning β ∗ Problem 5 is highly non differentiable2 and
non convex. However, it remains simple in the sense that
we have only one parameter to assess and we used a classical subgradient descent to solve it. Even if it is not convex, our empirical study shows no need to perform many
restarts to output a good solution: we always found almost
the same solution. As a consequence, we applied only one
optimization procedure in our experiments.
In this section we presented a new framework for metric
learning where one can use a source hypothesis to add
some side information during the learning process. We
have shown thatour 
approach is consistent with a conver1
√
. Furthermore, given a specific loss,
gence rate in O
n
we have shown that the use of a weighting parameter to
control the importance of the source metric is theoretically
founded. In the next part we empirically demonstrate that
we can obtain competitive results both in a classical metric
learning setting and in a domain adaptation setting.

5. Experiments
We propose an empirical study according to two directions
depending on the choice of the source metric. First, using
some well-known distances as a source metric, we show
that our framework performs well on classical supervised
metric learning tasks of the UCI database and we empirically demonstrate the interest of learning the β parameter.
2
To avoid this problem, we can use the classical relaxation
with slack variables.

A Theoretical Analysis of Metric Hypothesis Transfer Learning

Dataset
Breast
Pima
Scale
Wine

1-NN
95.31 ± 1.11
67.92 ± 1.95
78.73 ± 1.69
93.40 ± 2.70

Baselines
ITML
95.40 ± 1.37
68.13 ± 1.86
87.31 ± 2.35
93.82 ± 2.63

LMNN
95.60 ± 0.92
67.90 ± 2.05
86.20 ± 2.83
93.47 ± 1.80

IDENTITY
96.06 ± 0.77
67.87 ± 1.57
80.98 ± 1.51
95.42 ± 1.71

IDENTITY-B1
95.75 ± 0.87
67.54 ± 1.99
80.82 ± 1.27
95.07 ± 1.68

Our approach
MAHALANOBIS
95.71 ± 0.84
68.37 ± 2.00
81.35 ± 1.17
94.31 ± 2.01

MAHALANOBIS-B1
94.76 ± 1.38
66.31 ± 2.37
80.88 ± 1.43
80.56 ± 5.75

Table 1. Results of the experiments conducted on the UCI datasets. Each value corresponds to the mean and standard deviation over 10
runs. For each dataset we highlight the best result using a bold font. Approaches with the suffix -B1 do not learn β, it is fixed to 1.

Second, we apply our framework in a semi-supervised Domain Adaptation task. We show that, using only source
information through a learned metric, our method is able to
compete with state of the art algorithms.
Setup In all our experiments we use limited training
dataset, making it difficult to apply any kind of crossvalidation to set the parameters. Thus we propose to fix
them as follows. First the positive and negative margin are
respectively set to the 5th and 95th percentile of the training
set possible distances computed with the source metric as
proposed in (Davis et al., 2007). Next we set λ such that the
two terms of Eq. 5 are equals, i.e. we balance the complexity and performance importance with respect to the source
metric. The β parameter is then learned using Algorithm 5.
In all the experiments we plug our metric in a 1-nearest
neighbour classifier to classify the examples of the test set.
Furthermore, the significance of the results is assessed with
a paired samples t-test considering that an approach is significantly better when the p-value is lower than 0.05.
5.1. Classical Supervised Metric Learning
First we start by conducting experiments on several UCI
datasets (Lichman, 2013), namely breast, pima, scale and
wine. We propose to consider three source metrics: (i)
Zero: No source hypothesis, (ii) Identity: Euclidean
distance, (iii) Mahalanobis: Inverse of the variancecovariance matrix computed on the training set.
For the last two hypothesis we propose two experiments,
one where we set β = 1 and one where we learn β using
Algorithm 5. The goal of this experiment is to show the
interest of automatically setting β. We consider a 1-nearest
neighbour (1-NN) classifier using the Euclidean Distance
as the baseline and also report the results of two well known
metric learning algorithms, namely ITML, (Davis et al.,
2007) and LMNN (Weinberger et al., 2005). The results
averaged over 10 runs are reported in Table 1. For each
run we randomly draw a training set containing 20% of the
data available for each class and we test the metric on the
remaining 80% of data.
These experiments highlight the interest of learning the β
parameter. When we consider the performance of our approach with and without learning β, we mainly notice the

following facts. First, learning β always leads to an improvement on all the datasets and the final result is better
than the 1N N classifier. Second, learning β when considering the identity matrix as the source metric seems to be
of limited interest as the differences in accuracy are only
significant for the wine dataset. This can be justified by
the fact that, in this case, it only consists of a rescaling of
the diagonal of the matrix and it does not change much the
behaviour of the distance. Finally, learning β when considering the variance-covariance matrix as the source metric
leads to a significant improvement of the performance of
the metric except on the breast dataset. This is particularly
true for the wine dataset with a gain of nearly 14% in accuracy. It can be explained by the fact that, for this dataset, we
are learning with less than 40 examples. Thus the original
Mahalanobis distance does not carry as much information
as in the other datasets and is thus of a lower quality. Learning β allows us to compensate this drawback and to obtain
results which are even better than ITML or LMNN.
5.2. Metric learning for Semi-supervised Domain
Adaptation
In this section we consider a Semi-supervised Domain
Adaptation (DA) task with the Office-Caltech dataset. This
dataset consists of four domains: Amazon (A), Caltech (C),
DSLR (D) and Webcam (W) for which we consider 10
classes. This leads to consider 12 different adaptation problems when we alternatively take each domain as the source
or the target dataset. In these experiments we use the same
splits as the ones considered in (Hoffman et al., 2013) since
they are freely available from the authors website and follow their experimental setup. The results averaged over 20
runs and for each run 8 labelled source examples (20 if the
source is Amazon) and 3 labelled target examples are selected. The data is normalized thanks to the zscore and the
dimensionality is reduced to 20 thanks to a simple PCA.
The results are presented in Table 2 where we compare the
performance of our algorithm to 6 baselines: (i) 1-NNS : a
1-NN using the source examples, (ii) 1-NNT : a 1-NN using the target examples, (iii) LMNNT : a 1-NN on the target
examples using the metric learned by LMNN on the source
examples, (iv) ITMLT : a 1-NN on the target examples using the metric learned by ITML on the source examples, (v)
MMDT: a DA method (Hoffman et al., 2013), (vi) GFK:

A Theoretical Analysis of Metric Hypothesis Transfer Learning
Task
A→C
A→D
A→W
C→A
C→D
C→W
D→A
D→C
D→W
W→A
W→C
W→D
Mean

1-NNS
35.95 ± 1.30
33.58 ± 4.37
33.68 ± 3.60
37.37 ± 2.95
31.89 ± 5.77
28.60 ± 6.13
33.59 ± 1.77
31.16 ± 1.19
76.92 ± 2.18
32.19 ± 3.04
27.67 ± 2.58
64.61 ± 4.30
38.93 ± 3.26

1-NNT
31.92 ± 3.24
53.31 ± 4.31
66.25 ± 3.87
47.28 ± 4.15
54.17 ± 4.76
65.06 ± 6.27
47.81 ± 3.56
32.22 ± 2.98
66.19 ± 4.60
48.25 ± 3.52
30.74 ± 3.92
54.84 ± 5.17
49.84 ± 4.20

Baselines
LMNNT
ITMLT
32.42 ± 3.03 32.56 ± 4.17
49.96 ± 3.53 44.33 ± 8.18
62.62 ± 4.49 58.17 ± 10.63
42.97 ± 3.76 45.16 ± 7.60
46.02 ± 6.54 48.07 ± 8.98
55.79 ± 5.09 59.21 ± 9.71
40.57 ± 3.79 45.06 ± 6.78
27.96 ± 3.03 29.93 ± 4.84
65.36 ± 3.82 66.74 ± 7.16
41.69 ± 3.71 45.11 ± 5.72
28.60 ± 3.41 28.99 ± 4.31
56.89 ± 5.06 57.76 ± 7.03
45.90 ± 4.11 46.76 ± 7.09

MMDT
39.76 ± 2.25
54.25 ± 4.32
64.91 ± 5.71
51.05 ± 3.38
52.80 ± 4.84
62.75 ± 5.19
50.39 ± 3.40
35.70 ± 3.25
74.43 ± 3.10
50.56 ± 3.66
34.86 ± 3.62
62.52 ± 4.40
52.83 ± 3.93

GFK
37.81 ± 1.85
51.54 ± 3.55
59.36 ± 4.30
46.36 ± 2.94
58.07 ± 3.90
63.26 ± 5.89
40.77 ± 2.55
30.64 ± 1.98
74.98 ± 2.89
43.26 ± 2.34
29.95 ± 3.05
71.93 ± 4.07
50.66 ± 3.28

MAHALANOBIS
32.65 ± 3.76
54.69 ± 3.96
67.11 ± 5.11
50.15 ± 4.87
56.77 ± 4.63
64.64 ± 6.44
49.48 ± 4.41
32.90 ± 3.14
65.57 ± 4.52
50.80 ± 3.63
31.54 ± 3.60
57.17 ± 6.50
51.12 ± 4.55

Our approach
ITML
32.93 ± 4.60
51.54 ± 4.03
64.09 ± 5.20
49.89 ± 5.25
53.78 ± 7.23
64.00 ± 6.08
49.11 ± 4.09
32.99 ± 3.58
66.38 ± 6.04
50.16 ± 4.32
31.40 ± 4.29
56.85 ± 5.51
50.26 ± 5.02

LMNN
34.66 ± 3.66
54.72 ± 5.00
67.62 ± 5.18
50.36 ± 4.67
57.44 ± 4.48
65.11 ± 5.25
49.67 ± 4.00
33.84 ± 2.99
69.72 ± 3.78
50.92 ± 4.00
32.64 ± 3.52
61.14 ± 5.78
52.32 ± 4.36

Table 2. Metric Learning for Semi-Supervised Domain Adaptation. For the sake of readability we design the considered domains by
their initials. S → T stands for adaptation from the source domain to the target domain. Each time we consider the mean and standard
deviation over 20 runs. For each task, the best result is highlighted with a bold font.

another DA approach (Gong et al., 2012).
The last two methods need the source sample while in our
case we only use a source metric learned from the source
instances. For our biased regularization framework we consider 3 possible metrics learned on the sources examples,
namely (i) Mahalanobis, (ii) ITML and (iii) LMNN.
These results show that metric hypothesis transfer learning
can perform well in a Semi-supervised Domain Adaptation
setting. Indeed, we perform better than directly plugging
the metrics learned by LMNN and ITML in a 1-nearest
neighbour classifier. Moreover, we obtain accuracies which
are competitive with state of the art approaches like MMDT
or GFK while using less information. If we compare our
approach using LMNN as the source metric with MMDT,
we note that MMDT is significantly better than our approach on 4 out of 12 tasks while we are significantly better on 3 and 5 ends as a draw. Hence we can conclude
that our method presents a similar level of performance
than MMDT. Similarly, if we compare our approach using
LMNN as the source metric with GFK, we obtain that GFK
is significantly better than our approach on 3 tasks, we are
significantly better on 7 and 2 lead to a draw. Hence, we
can conclude that our approach performs better than GFK.
If we compare the performances of both ITML and LMNN
as metrics used directly in a nearest neighbour classifier
one can intuitively expect ITML to be a better source hypothesis than LMNN. However, in practice using the metric
learned by LMNN as the source hypothesis yields better results. This suggests that using a learned source model that
tends to overfit reasonably the learning source sample can
be of potential interest in a transfer learning context. Indeed LMNN does not use a regularization term in its formulation and it is well know that LMNN is prone to overfitting. Since, the parameter β penalizes the source metric
w.r.t. its complexity it may limit the impact of the source
metric to what is needed for the transfer. Nevertheless, this

point deserves further investigation.

6. Conclusion
In this paper we presented a new theoretical analysis for
metric hypothesis transfer learning. This framework takes
into account a source hypothesis information to help learning by means of a biased regularization. This biased regularization can be interpreted into two ways: (i) when the
source metric is an a priori known metric such as the identity matrix, the objective is to infer a new metric that performs better than the source metric, (ii) when the source
metric has been learned from another domain, the formulation allows one to transfer the knowledge from the source
metric to the new domain. This last interpretation refers to
a transfer learning setting where the learner does not have
access to source examples and can only make use of the
source model in the presence of few labelled data.
Our analysis has shown that this framework is theoretically
well founded and that a good source hypothesis can facilitate fast generalization in O(1/n). Moreover, we have
provided a consistency analysis from which we have developed a generalization bound able to consider both the
performance and the complexity of the source hypothesis.
This has led to the use of weighted source hypothesis to
optimize the bound in a theoretically sound way.
As stated in (Kuzborskij & Orabona, 2014) in another context, our results stress the importance of choosing good
source hypothesis. However, choosing the best source metric from few labelled data is a difficult problem of crucial importance. One perspective could be to consider
notions of reverse validations as used in some transfer
learning/domain adaptation tasks (Bruzzone & Marconcini,
2010; Zhong et al., 2010). Another perspective would be to
extend our framework to other settings and other kind of
regularizers.

A Theoretical Analysis of Metric Hypothesis Transfer Learning

References
Bellet, Aurélien and Habrard, Amaury. Robustness and
Generalization for Metric Learning. Neurocomputing,
151(1):259–267, 2015.
Bellet, Aurélien, Habrard, Amaury, and Sebban, Marc.
Similarity learning for provably accurate sparse linear
classification. In Proc. of the 29th International Conference on Machine Learning, ICML 2012, Edinburgh,
Scotland, UK, June 26 - July 1, 2012, 2012.
Bellet, Aurélien, Habrard, Amaury, and Sebban, Marc. A
survey on metric learning for feature vectors and structured data. CoRR, abs/1306.6709, 2013.
Ben-David, Shai, Blitzer, John, Crammer, Koby, Kulesza,
Alex, Pereira, Fernando, and Vaughan, Jennifer Wortman. A theory of learning from different domains. Machine Learning, 79(1-2):151–175, 2010.
Bohné, Julien, Ying, Yiming, Gentric, Stéphane, and Pontil, Massimiliano. Large margin local metric learning. In
Computer Vision - ECCV 2014 - 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proc.,
Part II, pp. 679–694, 2014.
Bousquet, Olivier and Elisseeff, André. Stability and generalization. Journal of Machine Learning Research, 2:
499–526, 2002.
Bruzzone, Lorenzo and Marconcini, Mattia. Domain adaptation problems: A DASVM classification technique and
a circular validation strategy. Transaction Pattern Analysis and Machine Intelligence, 32(5):770–787, 2010.
Cao, Qiong, Guo, Zheng-Chu, and Ying, Yiming. Generalization bounds for metric and similarity learning. CoRR,
abs/1207.5437, 2012.
Cao, Qiong, Ying, Yiming, and Li, Peng. Similarity metric
learning for face recognition. In Proc. of the IEEE International Conference on Computer Vision (ICCV), pp.
2408–2415, 2013.
Davis, Jason V., Kulis, Brian, Jain, Prateek, Sra, Suvrit, and
Dhillon, Inderjit S. Information-theoretic metric learning. In Machine Learning, Proc. of the Twenty-Fourth
International Conference (ICML 2007), Corvallis, Oregon, USA, June 20-24, 2007, pp. 209–216, 2007.
Gong, Boqing, Shi, Yuan, Sha, Fei, and Grauman, Kristen.
Geodesic flow kernel for unsupervised domain adaptation. In 2012 IEEE Conference on Computer Vision and
Pattern Recognition, Providence, RI, USA, June 16-21,
2012, pp. 2066–2073, 2012.

Guo, Zheng-Chu and Ying, Yiming. Guaranteed classification via regularized similarity learning. Neural Computation, 26(3):497–522, 2014. doi: 10.1162/NECO
a 00556. URL http://dx.doi.org/10.1162/
NECO_a_00556.
Hoffman, Judy, Rodner, Erik, Donahue, Jeff, Saenko,
Kate, and Darrell, Trevor. Efficient learning of domaininvariant image representations. CoRR, abs/1301.3224,
2013.
Jin, Rong, Wang, Shijun, and Zhou, Yang. Regularized
distance metric learning: Theory and algorithm. In Advances in Neural Information Processing Systems 22:
23rd Annual Conference on Neural Information Processing Systems 2009. Proc. of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada., pp.
862–870, 2009.
Kienzle, Wolf and Chellapilla, Kumar. Personalized
handwriting recognition via biased regularization. In
Machine Learning, Proc. of the Twenty-Third International Conference (ICML 2006), Pittsburgh, Pennsylvania, USA, June 25-29, 2006, pp. 457–464, 2006.
Kulis, Brian. Metric learning: A survey. Foundations and
Trends in Machine Learning, 5(4):287–364, 2013.
Kuzborskij, Ilja and Orabona, Francesco. Stability and hypothesis transfer learning. In Proc. of the 30th International Conference on Machine Learning, ICML 2013,
Atlanta, GA, USA, 16-21 June 2013, pp. 942–950, 2013.
Kuzborskij, Ilja and Orabona, Francesco.
Learning
by transferring from auxiliary hypotheses.
CoRR,
abs/1412.1619, 2014.
Lichman, M. UCI machine learning repository, 2013. URL
http://archive.ics.uci.edu/ml.
Parameswaran, Shibin and Weinberger, Kilian Q. Large
margin multi-task metric learning. In Advances in Neural Information Processing Systems 23: 24th Annual
Conference on Neural Information Processing Systems
2010. Proc. of a meeting held 6-9 December 2010,
Vancouver, British Columbia, Canada., pp. 1867–1875,
2010.
Perrot, Michaël, Habrard, Amaury, Muselet, Damien, and
Sebban, Marc. Modeling perceptual color differences
by local metric learning. In Computer Vision - ECCV
2014 - 13th European Conference, Zurich, Switzerland,
September 6-12, 2014, Proc., Part V, pp. 96–111, 2014.
Shalev-Shwartz, Shai and Ben-David, Shai. Understanding
Machine Learning - From Theory to Algorithms, chapter
Regularization and Stability, pp. 137–149. Cambridge
University Press, 2014.

A Theoretical Analysis of Metric Hypothesis Transfer Learning

Weinberger, Kilian Q., Blitzer, John, and Saul,
Lawrence K.
Distance metric learning for large
margin nearest neighbor classification. In Advances
in Neural Information Processing Systems 18 [Neural
Information Processing Systems, NIPS 2005, December
5-8, 2005, Vancouver, British Columbia, Canada], pp.
1473–1480, 2005.
Xing, Eric P., Ng, Andrew Y., Jordan, Michael I., and Russell, Stuart J. Distance metric learning with application
to clustering with side-information. In Advances in Neural Information Processing Systems 15 [Neural Information Processing Systems, NIPS 2002, December 9-14,
2002, Vancouver, British Columbia, Canada], pp. 505–
512, 2002.
Zha, Zheng-Jun, Mei, Tao, Wang, Meng, Wang, Zengfu,
and Hua, Xian-Sheng. Robust distance metric learning
with auxiliary knowledge. In IJCAI 2009, Proc. of the
21st International Joint Conference on Artificial Intelligence, Pasadena, California, USA, July 11-17, 2009, pp.
1327–1332, 2009.
Zhong, ErHeng, Fan, Wei, Yang, Qiang, Verscheure,
Olivier, and Ren, Jiangtao. Cross validation framework to choose amongst models and datasets for transfer learning. In Proc. of European Conference on Machine Learning and Knowledge Discovery in Databases
(ECML/PKDD), volume 6323 of LNCS, pp. 547–562.
Springer, 2010.

